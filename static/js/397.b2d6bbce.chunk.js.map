{"version":3,"file":"static/js/397.b2d6bbce.chunk.js","mappings":"4gCAAO,MAAMA,EAAa,yBACbC,EAAgB,gCAChBC,EAA0B,GAAHC,OAAMF,EAAa,OCK1CG,EAAoC,CAO7CC,QAAS,CAAC,EACV,oBAAqB,CAAC,EACtBC,SAAU,CAAC,EACXC,SAAU,CAAC,EACXC,OAAQ,CAAC,EACT,SAAU,CAAC,EACX,iBAAkB,CAAC,EACnB,eAAgB,CAAC,EACjBC,KAAM,CAAC,EACP,eAAgB,CAAC,EACjBC,WAAY,CAAC,EACbC,OAAQ,CAAC,EACTC,OAAQ,CAAC,EACTC,OAAQ,CAAC,EACTC,OAAQ,CAAC,EACTC,SAAU,CAAC,EACXC,SAAU,CAAC,EACXC,UAAW,CAAC,EACZC,UAAW,CAAC,EACZC,SAAU,CAAC,EACXC,SAAU,CAAC,EACXC,UAAW,CAAC,EACZ,UAAW,CAAC,GCjCT,MAAMC,UAA6BC,MACtCC,WAAAA,CAAYC,GACRC,MAAMD,GACNE,KAAKC,KAAO,sBAChB,EAEG,MAAMC,UAAkCP,EAC3CE,WAAAA,CAAYC,GACRC,MAAMD,GACNE,KAAKC,KAAO,YAChB,EAEG,MAAME,UAAoCR,EAC7CE,WAAAA,CAAYC,GACRC,MAAMD,GACNE,KAAKC,KAAO,cAChB,EAEJ,MAAMG,UAAwCT,EAG1CE,WAAAA,CAAYC,EAASO,EAAaC,GAC9BP,MAAMD,IAASS,EAAAA,EAAAA,GAAA,4BAAAA,EAAAA,EAAAA,GAAA,4BACfP,KAAKK,aAAWG,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACTH,GACCA,EAAYI,QACV,CACEA,SAAOD,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACAH,EAAYI,SACX,kBAAmBJ,EAAYI,QAAU,CAAEC,cAAe,0BAAwBC,SAI5FA,GAEVX,KAAKM,aAAeA,CACxB,EAKG,MAAMM,UAAwCR,EACjDP,WAAAA,CAAYC,EAASO,EAAaC,GAC9BP,MAAMD,EAASO,EAAaC,GAC5BN,KAAKC,KAAO,kBAChB,EAKG,MAAMY,UAAmCT,EAC5CP,WAAAA,CAAYC,EAASO,EAAaC,GAC9BP,MAAMD,EAASO,EAAaC,GAC5BN,KAAKC,KAAO,aAChB,EAKG,MAAMa,UAA2CnB,EACpDE,WAAAA,CAAYC,GACRC,MAAMD,GACNE,KAAKC,KAAO,qBAChB,EClEG,SAASc,EAAQC,GACpB,OAAIC,MAAMC,QAAQF,GACPA,EAEJ,CAACA,EACZ,CCCO,MAAMG,EAITtB,WAAAA,CAAYuB,EAAUC,GAAwC,IAA/BC,EAAqBC,UAAAC,OAAA,QAAAb,IAAAY,UAAA,IAAAA,UAAA,IAAQhB,EAAAA,EAAAA,GAAA,yBAAAA,EAAAA,EAAAA,GAAA,wBAAAA,EAAAA,EAAAA,GAAA,qCACxDP,KAAKoB,SAAWA,EAChBpB,KAAKqB,QAAUA,EACfrB,KAAKsB,sBAAwBA,CACjC,CAIAG,WAAAA,CAAYC,GACR,MAA6B,iBAAtBA,EAAOC,WAAgC,GAAHnD,OAAMF,EAAa,KAAAE,OAAIwB,KAAKoB,UAAapB,KAAKqB,OAC7F,CAIAO,QAAAA,CAASF,GACL,MAAI,SAAUA,EAAOG,MAAUH,EAAOG,KAAKC,KAChCJ,EAAOG,KAAKC,KAEhBC,KAAKC,UAAUhC,KAAKiC,eAAeP,GAC9C,CAIAQ,OAAAA,CAAQR,GACJ,MAAML,EAAUrB,KAAKyB,YAAYC,GAC3BS,EAAQnC,KAAKoC,UAAUV,GAAQW,QAAQ,OAAQ,IACrD,MAAO,GAAP7D,OAAU6C,EAAO,KAAA7C,OAAI2D,EACzB,CAIAG,cAAAA,CAAeZ,EAAQa,GACnB,MAAM9B,EAAU,CAAC,EAOjB,MAN0B,SAAtBiB,EAAOC,aACPlB,EAAuB,cAAI,UAAHjC,OAAakD,EAAOc,cAE3CD,IACD9B,EAAQ,gBAAkB,oBAEvBA,CACX,EAGG,MAAMgC,UAA+BtB,EACxCtB,WAAAA,CAAYuB,EAAUC,GAClBtB,MAAMqB,EAAUC,EADgCE,UAAAC,OAAA,QAAAb,IAAAY,UAAA,IAAAA,UAAA,GAEpD,CACAa,SAAAA,GACI,MAAO,qBACX,CACAH,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOkB,EAAOG,MAAI,IACda,MAAOhB,EAAOgB,OAEtB,CACA,iBAAMC,CAAYC,GACd,GAAwB,kBAAbA,GACP3B,MAAMC,QAAgB,OAAR0B,QAAQ,IAARA,OAAQ,EAARA,EAAUC,UACK,kBAAd,OAARD,QAAQ,IAARA,OAAQ,EAARA,EAAUE,UACO,kBAAT,OAARF,QAAQ,IAARA,OAAQ,EAARA,EAAUG,KACU,kBAAZ,OAARH,QAAQ,IAARA,OAAQ,EAARA,EAAUF,cAEgB/B,IAAhCiC,EAASI,oBAC0B,OAAhCJ,EAASI,oBAC8B,kBAAhCJ,EAASI,qBACO,kBAAZ,OAARJ,QAAQ,IAARA,OAAQ,EAARA,EAAUK,OACjB,OAAOL,EAEX,MAAM,IAAI9B,EAAmC,gCACjD,EAEG,MAAMoC,UAA+B/B,EACxCtB,WAAAA,CAAYuB,EAAUC,GAClBtB,MAAMqB,EAAUC,EADgCE,UAAAC,OAAA,QAAAb,IAAAY,UAAA,IAAAA,UAAA,GAEpD,CACAU,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOkB,EAAOG,MAAI,IACda,MAAOhB,EAAOgB,OAEtB,CACAN,SAAAA,GACI,MAAO,gBACX,CACA,iBAAMO,CAAYC,GACd,MAAMO,EAAMpC,EAAQ6B,GACpB,GAAI3B,MAAMC,QAAQiC,IACdA,EAAI3B,OAAS,GACb2B,EAAIC,MAAOC,GAAmB,kBAANA,KAAoBA,GAAK,mBAAoBA,GAAiC,kBAArBA,EAAEC,gBACnF,OAAOH,EAAI,GAEf,MAAM,IAAIrC,EAAmC,2CACjD,EAEG,MAAMyC,UAAqCd,EAC9C5C,WAAAA,GACIE,MAAM,OAAQ,gCAClB,CACA0B,WAAAA,CAAYC,GACR,GAA0B,aAAtBA,EAAOC,WACP,MAAM,IAAIxB,EAA4B,kEAE1C,OAAOH,KAAKqB,OAChB,EClHG,SAASmC,EAAgBC,GAC5B,GAAIC,WAAWC,OACX,OAAOD,WAAWC,OAAOC,KAAKH,GAAKI,SAAS,UAE3C,CACD,MAAMC,EAAM,GAIZ,OAHAL,EAAIM,QAASC,IACTF,EAAIG,KAAKC,OAAOC,aAAaH,MAE1BN,WAAWU,KAAKN,EAAIO,KAAK,IACpC,CACJ,CCXO,SAASC,EAAab,EAAKc,GAC9B,OAAOd,EAAIe,SAASD,EACxB,CCGO,SAASE,EAAKC,EAAGC,GACpB,MAAMC,EAAW3D,MAAMC,QAAQyD,GAASA,EAAQ,CAACA,GAEjD,OCLG,SAAcD,EAAGC,GACpB,OAAOE,OAAOC,OAAO,CAAC,KAAMH,EAAMI,IAAKC,IACnC,QAAgBrE,IAAZ+D,EAAEM,GACF,MAAO,CAAE,CAACA,GAAON,EAAEM,MAG/B,CDDWC,CAAKP,EADKG,OAAOK,KAAKR,GAAGS,OAAQH,IAAUV,EAAaM,EAAUI,IAE7E,CEHO,MAAMI,EAAyC,CAAC,qBAAsB,uBACtE,MAAMC,UAAwBlE,EACjCtB,WAAAA,GACIE,MAAM,eAAgB,GAAFvB,OAAKF,EAAa,iBAC1C,CACA2D,cAAAA,CAAeP,GACX,OAAOA,EAAOG,IAClB,CACAK,OAAAA,CAAQR,GACJ,OAAIA,EAAOgB,MAAM4C,WAAW,YAAc5D,EAAOgB,MAAM4C,WAAW,YACvD5D,EAAOgB,MAEX3C,MAAMmC,QAAQR,EACzB,CACAU,SAAAA,CAAUV,GACN,OAAIA,EAAO6D,MAAQ,CAAC,qBAAsB,uBAAuBf,SAAS9C,EAAO6D,MAEtE,UAAP/G,OAAiBkD,EAAOgB,MAAK,cAAAlE,OAAakD,EAAO6D,MAE9C,UAAP/G,OAAiBkD,EAAOgB,MAC5B,CACA,iBAAMC,CAAYC,GACd,OAAOA,CACX,EA4QG,MAAM4C,UAA8CH,EACvD,iBAAM1C,CAAYC,GAEd,GAAwB,kBAAbA,GACM,OAAbA,GACA,WAAYA,GACZ,WAAYA,GACZ3B,MAAMC,QAAQ0B,EAAS6C,SACvBxE,MAAMC,QAAQ0B,EAAS8C,SACvB9C,EAAS6C,OAAOjE,SAAWoB,EAAS8C,OAAOlE,QAC3CoB,EAAS6C,OAAOrC,MAAOuC,GAA2B,kBAAVA,IACxC/C,EAAS8C,OAAOtC,MAAOwC,GAA2B,kBAAVA,GAAqB,CAC7D,MAAMF,EAAS9C,EAAS8C,OACxB,OAAO9C,EAAS6C,OAAOV,IAAI,CAACY,EAAOE,KAAU,CACzCF,QACAC,MAAOF,EAAOG,KAEtB,CACA,GAAI5E,MAAMC,QAAQ0B,IAAaA,EAASQ,MAAMoC,EAAsCM,uBAChF,OAAOlD,EAEX,MAAM,IAAI9B,EAAmC,6HACjD,CACA,4BAAOgF,CAAsBC,GACzB,MAAwB,kBAATA,KACTA,GACF,UAAWA,GACX,UAAWA,GACW,kBAAfA,EAAKJ,OACU,kBAAfI,EAAKH,KACpB,EAUG,MAAMI,UAA8CX,EACvD,eAAOY,CAASF,GACZ,MAAwB,kBAATA,KACTA,GACF,eAAgBA,GACW,kBAApBA,EAAKG,YACZ,WAAYH,GACW,kBAAhBA,EAAKI,QACZ,UAAWJ,GACX9E,MAAMC,QAAQ6E,EAAKK,QACnBL,EAAKK,MAAMhD,MAAOC,GAAmB,kBAANA,IAC/B,gBAAiB0C,GACjB9E,MAAMC,QAAQ6E,EAAKM,cACnBN,EAAKM,YAAYjD,MAAOkD,GAAUrF,MAAMC,QAAQoF,IAAUA,EAAMlD,MAAOC,GAAmB,kBAANA,GAC5F,CACA,iBAAMV,CAAYC,GACd,GAAI3B,MAAMC,QAAQ0B,IAAa3B,MAAMC,QAAQ0B,GACvCA,EAASQ,MAAO2C,GAASC,EAAsCC,SAASF,IACxEC,EAAsCC,SAASrD,GACjD,OAAO3B,MAAMC,QAAQ0B,GAAYA,EAAS,GAAKA,EAEnD,MAAM,IAAI9B,EAAmC,sKACjD,ECvWJ,IAAIyF,EAAeC,QAIZ,SAASC,IACZ,OAAOF,CACX,CCAO,MAAMG,EAAgC,IAAIC,IA0B1CC,eAAeC,EAAsCC,EAAStE,EAAauE,GAC9E,IAAIC,EACJ,GAAIN,EAA8BO,IAAIH,GAElCE,EAA2BN,EAA8BQ,IAAIJ,OAE5D,KAAAK,EAAAC,EACD,MAAMC,EAAM,GAAH7I,OAAMH,EAAU,gBAAAG,OAAesI,EAAO,sCACzCQ,QAA4B,QAAfH,EAAQ,OAAPJ,QAAO,IAAPA,OAAO,EAAPA,EAASQ,aAAK,IAAAJ,EAAAA,EAAII,OAAOF,EAAK,CAC9C5G,QAAoB,OAAX+B,QAAW,IAAXA,GAAAA,EAAa8C,WAAW,OAAS,CAAE5E,cAAe,UAAFlC,OAAYgE,IAAkB,CAAC,IAE5F,IAAK8E,EAAKE,GAAI,KAAAC,EAOLC,EANL,GAAoC,QAApCD,EAAIH,EAAK7G,QAAQyG,IAAI,uBAAe,IAAAO,IAAhCA,EAAkCnC,WAAW,oBAO7C,MAAM,IAAIzE,EAA2B,wDAADrC,OAAyDsI,GAAW,CAAEO,MAAKM,OAAQ,OAAS,CAAEC,UAA2C,QAAlCF,EAAEJ,EAAK7G,QAAQyG,IAAI,uBAAe,IAAAQ,EAAAA,EAAI,GAAIG,OAAQP,EAAKO,OAAQC,WAAYR,EAAKS,SAPzJ,CAClE,MAAMC,QAAcV,EAAKW,OACgC,IAAAC,EAAzD,GAAI,UAAWF,GAAgC,kBAAhBA,EAAMA,MACjC,MAAM,IAAInH,EAA2B,wDAADrC,OAAyDsI,EAAO,MAAAtI,OAAKwJ,EAAMA,OAAS,CAAEX,MAAKM,OAAQ,OAAS,CAAEC,UAA2C,QAAlCM,EAAEZ,EAAK7G,QAAQyG,IAAI,uBAAe,IAAAgB,EAAAA,EAAI,GAAIL,OAAQP,EAAKO,OAAQC,KAAME,GAExO,CAIJ,CACA,IAAIG,EAAU,KACd,IACIA,QAAgBb,EAAKW,MACzB,CACA,MAAAG,GAAM,IAAAC,EACF,MAAM,IAAIxH,EAA2B,wDAADrC,OAAyDsI,EAAO,0CAA0C,CAAEO,MAAKM,OAAQ,OAAS,CAAEC,UAA2C,QAAlCS,EAAEf,EAAK7G,QAAQyG,IAAI,uBAAe,IAAAmB,EAAAA,EAAI,GAAIR,OAAQP,EAAKO,OAAQC,WAAYR,EAAKS,QACrQ,CACwC,IAAAO,EAAxC,GAAY,QAARlB,EAACe,SAAO,IAAAf,IAAPA,EAASJ,yBACV,MAAM,IAAInG,EAA2B,0EAADrC,OAA2EsI,EAAO,KAAK,CAAEO,MAAKM,OAAQ,OAAS,CAAEC,UAA2C,QAAlCU,EAAEhB,EAAK7G,QAAQyG,IAAI,uBAAe,IAAAoB,EAAAA,EAAI,GAAIT,OAAQP,EAAKO,OAAQC,WAAYR,EAAKS,SAElPf,EAnDR,SAA2CF,EAASE,GAChD,OAAKA,EAID/F,MAAMC,QAAQ8F,GACPA,EAGJnC,OAAO0D,QAAQvB,GAA0BjC,IAAIyD,IAAA,IAAEpH,EAAUqH,GAAQD,EAAA,MAAM,CAC1EpH,WACAsH,UAAW5B,EACX6B,WAAYF,EAAQE,WACpBd,OAAQY,EAAQZ,OAChBtC,KAAMkD,EAAQlD,KACdqD,QAASH,EAAQG,QACjBC,mBAAoBJ,EAAQI,sBAdrB,EAgBf,CAiCmCC,CAAkChC,EAASqB,EAAQnB,0BAC9EN,EAA8BqC,IAAIjC,EAASE,EAC/C,CACA,OAAOA,CACX,CAiCOJ,eAAeoC,EAAgB5H,EAAU0F,EAASmC,GACrD,MAAMC,EAASzC,IACf,GAAIwC,EAAa,CACb,GAAI7H,EACA,MAAM,IAAIlB,EAA0B,8DAGxC,MAAO,cACX,CAKA,GAJKkB,IACD8H,EAAOC,IAAI,gKACX/H,EAAW,QAEE,SAAbA,EAAqB,KAAAgI,EACrB,IAAKtC,EACD,MAAM,IAAI5G,EAA0B,0DAGxCkB,EAAsB,QAAdgI,SADevC,EAAsCC,IACzC,UAAE,IAAAsC,OAAA,EAAXA,EAAahI,SACxB8H,EAAOC,IAAI,0BAA2B/H,EAC1C,CACA,IAAKA,EACD,MAAM,IAAIlB,EAA0B,6CAAD1B,OAA8CsI,EAAO,MAE5F,OAAO1F,CACX,CC9HO,SAASiI,EAAMC,GAClB,OAAO,IAAIC,QAASC,IAChBC,WAAW,IAAMD,IAAWF,IAEpC,CCJO,SAASI,EAAMC,GAClB,MAAO,aAAaC,KAAKD,IAAeA,EAAWrE,WAAW,IAClE,CCqBO,MAAMuE,EAA8B,CAAC,aAAc,YAAa,YAAa,eACpF,MAAMC,UAAkB3I,EACpBtB,WAAAA,CAAYwH,GACRtH,MAAM,SAAUsH,GAAO,kBAC3B,CACApF,cAAAA,CAAeP,GACX,OAAOA,EAAOG,IAClB,CACAO,SAAAA,CAAUV,GACN,MAAO,IAAPlD,OAAWkD,EAAOgB,MACtB,CACAJ,cAAAA,CAAeZ,EAAQqI,GACnB,MAAMtJ,EAAU,CACZC,cAAqC,iBAAtBgB,EAAOC,WAAgC,UAAHnD,OAAakD,EAAOc,aAAW,OAAAhE,OAAYkD,EAAOc,cAKzG,OAHKuH,IACDtJ,EAAQ,gBAAkB,oBAEvBA,CACX,EAEJ,MAAMuJ,UAAuBF,EACzB,6BAAMG,CAAwBrH,EAAUyE,EAAK5G,GACzC,IAAK4G,IAAQ5G,EACT,MAAM,IAAIP,EAA0B,oCAAD1B,OAAqCwB,KAAKuF,KAAI,UAGrF,IADkB3C,EAASsH,WAEvB,MAAM,IAAIpJ,EAAmC,2CAADtC,OAA4CwB,KAAKuF,KAAI,8CAErG,IAAIsC,EAASjF,EAASiF,OACtB,MAAMsC,EAAY,IAAIC,IAAI/C,GACpBhG,EAAU,GAAH7C,OAAM2L,EAAUE,SAAQ,MAAA7L,OAAK2L,EAAUG,MAAI9L,OAAsB,0BAAnB2L,EAAUG,KAAmC,UAAY,IAG9GxD,EAAU,IAAIsD,IAAIxH,EAAS2H,cAAcC,SACzCC,EAAcN,EAAUO,OACxBC,EAAY,GAAHnM,OAAM6C,GAAO7C,OAAGsI,EAAO,WAAAtI,OAAUiM,GAC1CG,EAAY,GAAHpM,OAAM6C,GAAO7C,OAAGsI,GAAOtI,OAAGiM,GACzC,KAAkB,cAAX5C,GAAwB,OACrBwB,EAAM,KACZ,MAAMwB,QAAuBtD,MAAMoD,EAAW,CAAElK,YACxB,IAAAqK,EAAxB,IAAKD,EAAerD,GAChB,MAAM,IAAI5G,EAAgC,kDAAmD,CAAEyG,IAAKsD,EAAWhD,OAAQ,OAAS,CAC5HC,UAAqD,QAA5CkD,EAAED,EAAepK,QAAQyG,IAAI,uBAAe,IAAA4D,EAAAA,EAAI,GACzDjD,OAAQgD,EAAehD,OACvBC,WAAY+C,EAAe9C,SAGnC,IACIF,SAAgBgD,EAAe5C,QAAQJ,MAC3C,CACA,MAAOG,GACH,MAAM,IAAIlH,EAAmC,+EACjD,CACJ,CACA,MAAMiK,QAAuBxD,MAAMqD,EAAW,CAAEnK,YAChD,IAAIuK,EACJ,IACIA,QAAeD,EAAe9C,MAClC,CACA,MAAOD,GACH,MAAM,IAAIlH,EAAmC,+EACjD,CACA,OAAOkK,CACX,EAEJ,SAASC,EAAcnE,EAAS+B,GAC5B,MAAO,GAAPrK,OAAUH,EAAU,KAAAG,OAAIsI,EAAO,kBAAAtI,OAAiBqK,EACpD,CCzFA,MAAMqC,EAA2B,6BCcjC,MAAMC,EAAoB,uBCd1B,MAAMC,EAA0B,6BCAhC,MAAMC,EAAsB,+B,6CCkBtBC,EAAsB,wBClB5B,MAAMC,EAAsB,mCCgB5B,MAAMC,EAAwB,gD,mBCE9B,MAAMC,UAAsBtK,EACxBtB,WAAAA,CAAYwH,GACRtH,MAAM,YAAasH,GAAO,4BAC9B,CACAjF,SAAAA,CAAUV,GACN,OAAIA,EAAOgB,MAAM8B,SAAS,KACf,iBAEJ,aAAPhG,OAAoBkD,EAAOgB,MAAK,eACpC,CACAT,cAAAA,CAAeP,GACX,MAAO,CACHgK,OAAKlL,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACEiE,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC7BH,EAAOG,KAAK8J,YAAU,IACzBC,OAAQlK,EAAOG,KAAKgK,SAExBC,QAASpK,EAAOgB,MAAM8B,SAAS,KAAO9C,EAAOgB,MAAMqJ,MAAM,KAAK,QAAKpL,EAE3E,CACA2B,cAAAA,CAAeZ,EAAQqI,GACnB,MAAMtJ,EAAU,CAAEC,cAAe,UAAFlC,OAAYkD,EAAOc,aAAewJ,OAAQ,QAIzE,OAHKjC,IACDtJ,EAAQ,gBAAkB,oBAEvBA,CACX,CACAyB,OAAAA,CAAQR,GACJ,MAAML,EAAUrB,KAAKyB,YAAYC,GACjC,OAAIA,EAAOgB,MAAM8B,SAAS,KACf,GAAPhG,OAAU6C,EAAO,mBAEd,GAAP7C,OAAU6C,EAAO,eAAA7C,OAAckD,EAAOgB,MAAK,eAC/C,ECpDJ,MAAMuJ,EAAwB,0BCC9B,MAAMC,EAAwB,2BCE9B,MAAMC,EAA2B,2BACjCvF,eAAewF,GAAiBP,EAAQQ,GACpC,MAAMC,EAAO9I,EAAgB,IAAI+I,WAAWV,aAAkBW,YAAcX,QAAeA,EAAOY,gBAIlG,MAAO,CAAEH,OAAMI,OAHAzL,MAAMC,QAAQmL,IAAcA,EAAUjJ,MAAOuJ,GAA2B,kBAAVA,GACvEN,EACA,CAACC,GAEX,CACA,MAAMM,WAAwBzL,EAC1BtB,WAAAA,CAAYwH,GACRtH,MAAM,YAAasH,GAAO8E,EAC9B,CACA/J,SAAAA,CAAUV,GACN,MAAO,WAAPlD,OAAkBkD,EAAOgB,MAC7B,CACAT,cAAAA,CAAeP,GAAQ,IAAAmL,EACnB,MAAM1E,GAAO3H,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACNiE,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC5BH,EAAOG,KAAK8J,WAAalH,EAAK/C,EAAOG,KAAK8J,WAAY,CAAC,gBAAahL,GAAS,IACjFiL,OAAQlK,EAAOG,KAAKgK,SAWxB,MARgC,UAAd,QAAdgB,EAAAnL,EAAO+G,eAAO,IAAAoE,OAAA,EAAdA,EAAgBjE,WAChBT,EAAQ2E,MAAQ,CACZ,CACIC,KAAMrL,EAAO+G,QAAQC,UACrBsE,MAAO,KAIZ7E,CACX,CACA,iBAAMxF,CAAYC,EAAUyE,EAAK5G,GAC7B,IAAK4G,IAAQ5G,EACT,MAAM,IAAIP,EAA0B,mDAExC,MAAMiK,EAAY,IAAIC,IAAI/C,GACpB4F,EAAa,IAAI7C,IAAIxH,EAASd,KAAKoL,KAAKhG,KAAKsD,SAE7CnJ,EAAU,GAAH7C,OAAM2L,EAAUE,SAAQ,MAAA7L,OAAK2L,EAAUG,MAAI9L,OAAsB,0BAAnB2L,EAAUG,KAAmC,aAAe,IACjHM,EAAY,GAAHpM,OAAM6C,GAAO7C,OAAGyO,GAE/B,OAAa,CACT,MAAMlC,QAAuBxD,MAAMqD,EAAW,CAAEnK,YACxB,IAAA0M,EAAxB,IAAKpC,EAAevD,GAChB,MAAM,IAAI5G,EAAgC,wDAAyD,CAAEyG,IAAKuD,EAAWjD,OAAQ,OAAS,CAClIC,UAAqD,QAA5CuF,EAAEpC,EAAetK,QAAQyG,IAAI,uBAAe,IAAAiG,EAAAA,EAAI,GACzDtF,OAAQkD,EAAelD,OACvBC,WAAYiD,EAAehD,SAGnC,MACMqF,SADerC,EAAe9C,QACVnG,KAC1B,OAAQsL,EAAWvF,QACf,IAAK,YAAa,KAAAwF,EAEd,GAAuB,QAAnBA,EAACD,EAAWE,eAAO,IAAAD,IAAlBA,EAAqB,GACtB,MAAM,IAAIvM,EAAmC,0FAEjD,MAAMyM,QAAsBhG,MAAM6F,EAAWE,QAAQ,IAC9B,IAAAE,EAAvB,IAAKD,EAAc/F,GACf,MAAM,IAAI5G,EAAgC,0DAA2D,CAAEyG,IAAK+F,EAAWE,QAAQ,GAAI3F,OAAQ,OAAS,CAChJC,UAAoD,QAA3C4F,EAAED,EAAc9M,QAAQyG,IAAI,uBAAe,IAAAsG,EAAAA,EAAI,GACxD3F,OAAQ0F,EAAc1F,OACtBC,WAAYyF,EAAcxF,SAGlC,aAAawF,EAAcE,MAC/B,CACA,IAAK,SACD,MAAM,IAAI3M,EAAmCsM,EAAWpF,OAAS,eAErE,cAEUqB,EAAM,KACZ,SAGZ,CACJ,EC5DG,MAAMqE,GAAY,CACrBhP,QAAS,CACLiP,eAAgB,ICRjB,cAAwClL,EAC3C5C,WAAAA,GACIE,MAAM,UAHe,+BAIzB,IDOA,oBAAqB,CACjB,gBAAiB,IEPlB,cAA6CoB,EAChDtB,WAAAA,GACIE,MAAM,oBAH4B,yBAItC,CACAkC,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOiE,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC7BH,EAAOG,KAAK8J,YAAU,IACzBC,OAAQlK,EAAOG,KAAKgK,QAE5B,CACAvJ,cAAAA,CAAeZ,EAAQqI,GACnB,MAAMtJ,EAAU,CACZC,cAAqC,iBAAtBgB,EAAOC,WAAgC,UAAHnD,OAAakD,EAAOc,aAAW,SAAAhE,OAAckD,EAAOc,cAK3G,OAHKuH,IACDtJ,EAAQ,gBAAkB,oBAEvBA,CACX,CACA2B,SAAAA,CAAUV,GACN,IAAKA,EACD,MAAM,IAAIxB,EAA0B,uBAExC,MAAO,OAAP1B,OAAckD,EAAOgB,MACzB,CACA,iBAAMC,CAAYC,EAAUyE,EAAK5G,EAASmN,GACtC,MAAM1E,EAASzC,IACToH,EAAS,IAAIzD,IAAIxH,EAASkL,aAChC,IAAK,IAAIC,EAAO,EAAGA,EAAO,EAAGA,IAAQ,OAC3B1E,EAAM,KACZH,EAAO8E,MAAM,mDAADxP,OAAoDuP,EAAO,EAAC,OACxEF,EAAOI,aAAalF,IAAI,UAAWgF,EAAKlK,SAAS,KACjD,MAAMyD,QAAaC,MAAMsG,EAAQ,CAAEpN,QAAS,CAAE,eAAgB,sBAChD,IAAAgH,EAAd,IAAKH,EAAKE,GACN,MAAM,IAAI5G,EAAgC,oDAAqD,CAAEyG,IAAKwG,EAAOhK,WAAY8D,OAAQ,MAAOlH,QAAS,CAAE,eAAgB,qBAAwB,CAAEmH,UAA2C,QAAlCH,EAAEH,EAAK7G,QAAQyG,IAAI,uBAAe,IAAAO,EAAAA,EAAI,GAAII,OAAQP,EAAKO,OAAQC,WAAYR,EAAKS,SAE1R,MAAMI,QAAgBb,EAAKW,OAC3B,GAAuB,kBAAZE,GACPA,GACA,WAAYA,GACc,kBAAnBA,EAAQN,QACI,UAAnBM,EAAQN,QACR,WAAYM,GACc,kBAAnBA,EAAQ6C,QACf7C,EAAQ6C,QACR,WAAY7C,EAAQ6C,QACa,kBAA1B7C,EAAQ6C,OAAOkD,OAAqB,CAC3C,GAAmB,SAAfN,EACA,OAAOzF,EAAQ6C,OAEnB,GAAmB,QAAf4C,EACA,OAAOzF,EAAQ6C,OAAOkD,OAE1B,MAAMC,QAAc5G,MAAMY,EAAQ6C,OAAOkD,QACzC,aAAaC,EAAMV,MACvB,CACJ,CACA,MAAM,IAAI3M,EAAmC,gGACjD,IFlDAnC,SAAU,CACNgP,eAAgB,IGfjB,cAAyClL,EAC5C5C,WAAAA,GACIE,MAAM,WAAY,0BACtB,IHcAnB,SAAU,CACN+O,eAAgB,IIjBjB,cAAyClL,EAC5C5C,WAAAA,GACIE,MAAM,WAHgB,2BAI1B,CACAqC,SAAAA,GACI,MAAO,oCACX,CACAE,cAAAA,CAAeZ,EAAQa,GACnB,MAAM9B,EAAU,CACZC,cAAqC,iBAAtBgB,EAAOC,WAAgC,UAAHnD,OAAakD,EAAOc,aAAW,OAAAhE,OAAYkD,EAAOc,cAKzG,OAHKD,IACD9B,EAAQ,gBAAkB,oBAEvBA,CACX,IJIA5B,OAAQ,CACJ8O,eAAgB,IKrBjB,cAAuClL,EAC1C5C,WAAAA,GACIE,MAAM,SAAU,yBACpB,CACAqC,SAAAA,GACI,MAAO,oCACX,ILiBA,SAAU,CACN,gBAAiB,IZoDlB,cAAmC0H,EACtC7H,cAAAA,CAAeP,GAAQ,IAAAmL,EACnB,MAAM1E,GAAO3H,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACNiE,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC7BH,EAAOG,KAAK8J,YAAU,IACzByC,WAAW,EACXxC,OAAQlK,EAAOG,KAAKgK,SAaxB,MAXgC,UAAd,QAAdgB,EAAAnL,EAAO+G,eAAO,IAAAoE,OAAA,EAAdA,EAAgBjE,UAAsBlH,EAAO+G,QAAQI,qBACrDV,EAAQ2E,MAAQ,CACZ,CACIC,KAAM9B,EAAcvJ,EAAO+G,QAAQC,UAAWhH,EAAO+G,QAAQI,oBAC7DmE,MAAO,IAGmB,gBAA9BtL,EAAO+G,QAAQE,aACfR,EAAQkG,WAAa,6CAGtBlG,CACX,CACA,iBAAMxF,CAAYC,EAAUyE,EAAK5G,EAASmN,GACtC,GAAwB,kBAAbhL,GACP,WAAYA,GACZ3B,MAAMC,QAAQ0B,EAAS8J,SACvB9J,EAAS8J,OAAOlL,OAAS,GACzB,QAASoB,EAAS8J,OAAO,IACS,kBAA3B9J,EAAS8J,OAAO,GAAGrF,IAAkB,CAC5C,GAAmB,SAAfuG,EACA,OAAApN,EAAAA,EAAAA,GAAA,GAAYoC,GAEhB,GAAmB,QAAfgL,EACA,OAAOhL,EAAS8J,OAAO,GAAGrF,IAE9B,MAAMiH,QAAoB/G,MAAM3E,EAAS8J,OAAO,GAAGrF,KACnD,aAAaiH,EAAYb,MAC7B,CACA,MAAM,IAAI3M,EAAmC,4DACjD,GYzFI,iBAAkB,IZoQnB,cAAoCgJ,EACvC7H,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOiE,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC7BH,EAAOG,KAAK8J,YAAU,IACzB5D,KAAMrG,EAAOG,KAAKgK,QAE1B,CACA,iBAAMlJ,CAAYC,GAAU,IAAA2L,EACxB,MAAMpL,EAAMP,EACZ,GAA+B,kBAAjB,OAAHO,QAAG,IAAHA,GAAU,QAAPoL,EAAHpL,EAAKqL,aAAK,IAAAD,OAAA,EAAVA,EAAYlH,KACnB,MAAM,IAAIvG,EAAmC,wHAADtC,OAAyHuD,KAAKC,UAAUY,KAExL,MAAM0L,QAAoB/G,MAAMpE,EAAIqL,MAAMnH,KACrB,IAAAoH,EAArB,IAAKH,EAAY9G,GACb,MAAM,IAAI5G,EAAgC,8BAADpC,OAA+B2E,EAAIqL,MAAMnH,IAAG,MAAA7I,OAAK8P,EAAYI,YAAc,CAAErH,IAAKlE,EAAIqL,MAAMnH,IAAKM,OAAQ,MAAOlH,QAAS,CAAE,eAAgB,qBAAwB,CACxMmH,UAAkD,QAAzC6G,EAAEH,EAAY7N,QAAQyG,IAAI,uBAAe,IAAAuH,EAAAA,EAAI,GACtD5G,OAAQyG,EAAYzG,OACpBC,WAAYwG,EAAYvG,SAGhC,IACI,aAAauG,EAAYb,MAC7B,CACA,MAAOzF,GAAO,IAAA2G,EACV,MAAM,IAAI/N,EAAgC,8BAADpC,OAA+B2E,EAAIqL,MAAMnH,IAAG,MAAA7I,OAAKwJ,aAAiBpI,MAAQoI,EAAMlI,QAAUoE,OAAO8D,IAAU,CAAEX,IAAKlE,EAAIqL,MAAMnH,IAAKM,OAAQ,MAAOlH,QAAS,CAAE,eAAgB,qBAAwB,CACxOmH,UAAkD,QAAzC+G,EAAEL,EAAY7N,QAAQyG,IAAI,uBAAe,IAAAyH,EAAAA,EAAI,GACtD9G,OAAQyG,EAAYzG,OACpBC,WAAYwG,EAAYvG,QAEhC,CACJ,GYlSI,gBAAiB,IZkJlB,cAAmCiC,EAEtCnK,WAAAA,GACIE,MAAM,0BAAyBQ,EAAAA,EAAAA,GAAA,oBAC/BP,KAAKuF,KAAO,eAChB,CACAnD,SAAAA,CAAUV,GACN,MAA0B,iBAAtBA,EAAOC,WACA,IAAPnD,OAAWkD,EAAOgB,MAAK,qBAEpB,IAAPlE,OAAWkD,EAAOgB,MACtB,CACAT,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOiE,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC7BH,EAAOG,KAAK8J,YAAU,IACzBC,OAAQlK,EAAOG,KAAKgK,QAE5B,CACA,iBAAMlJ,CAAYC,EAAUyE,EAAK5G,GAC7B,MAAMuK,QAAehL,KAAKiK,wBAAwBrH,EAAUyE,EAAK5G,GACjE,GAAsB,kBAAXuK,GACLA,GACF,UAAWA,GACa,kBAAjBA,EAAO4D,OACZ5D,EAAO4D,OACT,QAAS5D,EAAO4D,OACY,kBAArB5D,EAAO4D,MAAMvH,KACpBqC,EAAMsB,EAAO4D,MAAMvH,KAAM,CACzB,MAAMiH,QAAoB/G,MAAMyD,EAAO4D,MAAMvH,KAC7C,aAAaiH,EAAYb,MAC7B,CAEI,MAAM,IAAI3M,EAAmC,8HAADtC,OAA+HuD,KAAKC,UAAUgJ,IAElM,GYpLI,iBAAkB,IZyFnB,cAAoChB,EAEvCnK,WAAAA,GACIE,MAAM,0BAAyBQ,EAAAA,EAAAA,GAAA,oBAC/BP,KAAKuF,KAAO,gBAChB,CACAnD,SAAAA,CAAUV,GACN,MAA0B,iBAAtBA,EAAOC,WACA,IAAPnD,OAAWkD,EAAOgB,MAAK,qBAEpB,IAAPlE,OAAWkD,EAAOgB,MACtB,CACAT,cAAAA,CAAeP,GAAQ,IAAAmN,EACnB,MAAM1G,EAAUzG,EAAOG,KASvB,MARgC,UAAd,QAAdgN,EAAAnN,EAAO+G,eAAO,IAAAoG,OAAA,EAAdA,EAAgBjG,UAAsBlH,EAAO+G,QAAQI,qBACrDV,EAAQ2E,MAAQ,CACZ,CACIC,KAAM9B,EAAcvJ,EAAO+G,QAAQC,UAAWhH,EAAO+G,QAAQI,oBAC7DmE,MAAO,KAIZ7E,CACX,CACA,yBAAM2G,CAAoBjN,GACtB,MAAMkN,EAAWlN,EAAKgK,kBAAkBmD,KAAOnN,EAAKgK,OAAOoD,KAAO,YAC5DC,EAAe,QAAH1Q,OAAWuQ,EAAQ,YAAAvQ,OAAWgF,EAAgB,IAAI+I,WAAW1K,EAAKgK,kBAAkBW,YAAc3K,EAAKgK,aAAehK,EAAKgK,OAAOY,iBACpJ,OAAAjM,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOiE,EAAK5C,EAAM,CAAC,SAAU,gBAAc,IACvCsN,UAAWD,GACRrN,EAAK8J,YACL9J,GAAI,IAEPuN,WAAY,CAACF,IAErB,CACA,iBAAMvM,CAAYC,EAAUyE,EAAK5G,GAC7B,MAAMuK,QAAehL,KAAKiK,wBAAwBrH,EAAUyE,EAAK5G,GACjE,GAAsB,kBAAXuK,GACLA,GACF,WAAYA,GACZ/J,MAAMC,QAAQ8J,EAAO0B,SACrB1B,EAAO0B,OAAOlL,OAAS,GACK,kBAArBwJ,EAAO0B,OAAO,IACnB1B,EAAO0B,OAAO,IAChB,QAAS1B,EAAO0B,OAAO,IACS,kBAAzB1B,EAAO0B,OAAO,GAAGrF,KACxBqC,EAAMsB,EAAO0B,OAAO,GAAGrF,KAAM,CAC7B,MAAMiH,QAAoB/G,MAAMyD,EAAO0B,OAAO,GAAGrF,KACjD,aAAaiH,EAAYb,MAC7B,CAEI,MAAM,IAAI3M,EAAmC,uIAADtC,OAAwIuD,KAAKC,UAAUgJ,IAE3M,GY9II,+BAAgC,IZoOjC,cAAkDlB,EACrDxH,cAAAA,CAAeZ,EAAQqI,GACnB,MAAMtJ,EAAUV,MAAMuC,eAAeZ,EAAQqI,GAE7C,OADAtJ,EAAQ,gBAAkB,mBACnBA,CACX,CACA,iBAAMkC,CAAYC,GACd,MAAMO,EAAMP,EACZ,GAAyB,kBAAX,OAAHO,QAAG,IAAHA,OAAG,EAAHA,EAAK4E,MACZ,MAAM,IAAIjH,EAAmC,4HAADtC,OAA6HuD,KAAKC,UAAUY,KAE5L,MAAO,CAAEmF,KAAM5E,EAAI4E,KACvB,CACA,yBAAM+G,CAAoBjN,GACtB,MAAM4L,EAAO,SAAU5L,GAAQA,EAAKC,gBAAgBkN,KAAOnN,EAAKC,KAAO,WAAYD,EAAOA,EAAKgK,YAASlL,EAClG0O,EAAkB,OAAJ5B,QAAI,IAAJA,OAAI,EAAJA,EAAMwB,KAC1B,IAAKI,EACD,MAAM,IAAInP,EAA0B,+GAExC,IAAK2J,EAA4BrF,SAAS6K,GACtC,MAAM,IAAInP,EAA0B,8CAAD1B,OAA+C6Q,EAAW,oCAAA7Q,OAAmCqL,EAA4BxF,KAAK,QAErK,MAAMiL,EAAc9L,EAAgB,IAAI+I,iBAAiBkB,EAAKhB,gBAC9D,OAAAjM,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACyBiE,EAAK5C,EAAtB,SAAUA,EAAkB,OAAqB,WAAS,IAC9D0N,UAAW,QAAF/Q,OAAU6Q,EAAW,YAAA7Q,OAAW8Q,IAEjD,GY9PI,qBAAsB,IZiSvB,cAAyCtF,EAE5CnK,WAAAA,GACIE,MAAM,0BAAyBQ,EAAAA,EAAAA,GAAA,oBAC/BP,KAAKuF,KAAO,oBAChB,CACAnD,SAAAA,CAAUV,GACN,MAA0B,iBAAtBA,EAAOC,WACA,IAAPnD,OAAWkD,EAAOgB,MAAK,qBAEpB,IAAPlE,OAAWkD,EAAOgB,MACtB,CACAT,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOiE,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC7BH,EAAOG,KAAK8J,YAAU,IACzByC,WAAW,GAEnB,CACA,yBAAMU,CAAoBjN,GACtB,MAAM4L,EAAO,SAAU5L,GAAQA,EAAKC,gBAAgBkN,KAAOnN,EAAKC,KAAO,WAAYD,EAAOA,EAAKgK,YAASlL,EAClGoO,EAAWtB,aAAgBuB,KAAOvB,EAAKwB,KAAO,YAC9CO,EAAchM,EAAgB,IAAI+I,WAAWkB,aAAgBjB,YAAciB,QAAaA,EAAKhB,gBACnG,OAAAjM,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOiE,EAAK5C,EAAM,CAAC,SAAU,aAAc,UACpCA,EAAK8J,YACL9J,GAAI,IACPsN,UAAW,QAAF3Q,OAAUuQ,EAAQ,YAAAvQ,OAAWgR,GACtCpB,WAAW,GAEnB,CACA,iBAAMzL,CAAYC,EAAUyE,EAAK5G,GAC7B,MAAMuK,QAAehL,KAAKiK,wBAAwBrH,EAAUyE,EAAK5G,GACjE,GAAsB,kBAAXuK,GACI,OAAXA,GACA,UAAWA,GACa,kBAAjBA,EAAOmD,OACG,OAAjBnD,EAAOmD,OACP,QAASnD,EAAOmD,OACY,kBAArBnD,EAAOmD,MAAM9G,IAAkB,CACtC,MAAMoI,QAAqBlI,MAAMyD,EAAOmD,MAAM9G,KACxB,IAAAqI,EAAtB,IAAKD,EAAajI,GACd,MAAM,IAAI5G,EAAgC,0CAADpC,OAA2CwM,EAAOmD,MAAM9G,KAAO,CAAEA,IAAK2D,EAAOmD,MAAM9G,IAAKM,OAAQ,OAAS,CAC9IC,UAAmD,QAA1C8H,EAAED,EAAahP,QAAQyG,IAAI,uBAAe,IAAAwI,EAAAA,EAAI,GACvD7H,OAAQ4H,EAAa5H,OACrBC,WAAY2H,EAAa1H,SAGjC,MAAM4H,QAAiBF,EAAahC,OAC9BmC,QAAwBD,EAASlD,cAEvC,MAAO,CACH,CACI9G,MAAO,OACPC,MAAO,EACPiK,KALWrM,EAAgB,IAAI+I,WAAWqD,KAQtD,CACA,MAAM,IAAI9O,EAAmC,4HAADtC,OAA6HuD,KAAKC,UAAUY,IAC5L,GY5VI,iBAAkB,IZmLnB,cAAoCoH,EAEvCnK,WAAAA,GACIE,MAAM,0BAAyBQ,EAAAA,EAAAA,GAAA,oBAC/BP,KAAKuF,KAAO,gBAChB,CAEAnD,SAAAA,CAAUV,GACN,MAA6B,iBAAtBA,EAAOC,WAAgC,IAAHnD,OAAOkD,EAAOgB,MAAK,yBAAAlE,OAA0BkD,EAAOgB,MACnG,CAEAT,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOiE,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC7BH,EAAOG,KAAK8J,YAAU,IAEzBwD,UAAWzN,EAAOG,KAAKsN,WAE/B,CAEA,yBAAML,CAAoBjN,GACtB,MAAMkN,EAAWlN,EAAKgK,kBAAkBmD,KAAOnN,EAAKgK,OAAOoD,KAAO,YAClE,OAAAzO,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOiE,EAAK5C,EAAM,CAAC,SAAU,gBAAc,IACvCsN,UAAW,QAAF3Q,OAAUuQ,EAAQ,YAAAvQ,OAAWgF,EAAgB,IAAI+I,WAAW1K,EAAKgK,kBAAkBW,YAAc3K,EAAKgK,aAAehK,EAAKgK,OAAOY,kBACvI5K,EAAK8J,YACL9J,EAEX,CAEA,iBAAMc,CAAYC,EAAUyE,EAAK5G,GAC7B,MAAMuK,QAAehL,KAAKiK,wBAAwBrH,EAAUyE,EAAK5G,GACjE,GAAsB,kBAAXuK,GACI,OAAXA,GACA,UAAWA,GACa,kBAAjBA,EAAO4D,OACG,OAAjB5D,EAAO4D,OACP,QAAS5D,EAAO4D,OACY,kBAArB5D,EAAO4D,MAAMvH,KACpB,QAAS2D,EAAO4D,OAChBlF,EAAMsB,EAAO4D,MAAMvH,KAAM,CACzB,MAAMiH,QAAoB/G,MAAMyD,EAAO4D,MAAMvH,KAC7C,aAAaiH,EAAYb,MAC7B,CACA,MAAM,IAAI3M,EAAmC,mHAADtC,OAA0GuD,KAAKC,UAAUgJ,IACzK,IY9NA,iBAAkB,CACd2C,eAAgB,IX9CjB,cAA8ClL,EACjD5C,WAAAA,GACIE,MAAM,iBAAkBmL,EAC5B,GW4CI,kBAAmB,IX1CpB,cAA8ChI,EACjDrD,WAAAA,GACIE,MAAM,iBAAkBmL,EAC5B,CACAjJ,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,CACIkC,MAAOhB,EAAOgB,OACX+B,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC5BH,EAAOG,KAAK8J,YAAUnL,EAAAA,EAAAA,GAAA,CAElBsP,WAAYpO,EAAOG,KAAK8J,WAAWoE,gBAChCtL,EAAK/C,EAAOG,KAAK8J,WAAY,wBAElChL,GAAS,IACfiL,OAAQlK,EAAOG,KAAKgK,QAE5B,CACA,iBAAMlJ,CAAYC,GACd,GAAwB,kBAAbA,GACP,YAAaA,GACb3B,MAAMC,QAAgB,OAAR0B,QAAQ,IAARA,OAAQ,EAARA,EAAUC,UACG,kBAAZ,OAARD,QAAQ,IAARA,OAAQ,EAARA,EAAUF,OAAoB,CAErC,MAAO,CACHY,eAFeV,EAASC,QAAQ,GAELkF,KAEnC,CACA,MAAM,IAAIjH,EAAmC,sEACjD,IWgBA,eAAgB,CACZ,gBAAiB,IjBvBlB,cAAyCuE,EAC5C,iBAAM1C,CAAYC,EAAUyE,EAAK5G,EAASmN,GACtC,IAAKhL,EACD,MAAM,IAAI9B,EAAmC,0FAEjD,GAAuB,iBAAZ8B,EAAsB,CAC7B,GAAmB,SAAfgL,EACA,OAAApN,EAAAA,EAAAA,GAAA,GAAYoC,GAEhB,GAAI,SAAUA,GAAY3B,MAAMC,QAAQ0B,EAASd,OAASc,EAASd,KAAK,GAAGkO,SAAU,CACjF,MAAMC,EAAarN,EAASd,KAAK,GAAGkO,SACpC,GAAmB,QAAfpC,EACA,MAAO,0BAAPpP,OAAiCyR,GAErC,MAAMC,QAAuB3I,MAAM,0BAAD/I,OAA2ByR,IAC7D,aAAaC,EAAezC,MAChC,CACA,GAAI,WAAY7K,GAAY3B,MAAMC,QAAQ0B,EAASuN,QAAS,CACxD,GAAmB,QAAfvC,EACA,OAAOhL,EAASuN,OAAO,GAE3B,MAAM7B,QAAoB/G,MAAM3E,EAASuN,OAAO,IAEhD,aADmB7B,EAAYb,MAEnC,CACJ,CACA,GAAI7K,aAAoBoM,KAAM,CAC1B,GAAmB,QAAfpB,GAAuC,SAAfA,EAAuB,CAC/C,MAAMwC,QAAYxN,EAAS6J,cAAc4D,KAAMC,GAAQ3M,OAAOC,KAAK0M,GAAKzM,SAAS,WACjF,MAAsB,QAAf+J,EAAuB,0BAAHpP,OAA6B4R,GAAQ,CAAED,OAAQ,0BAAF3R,OAA4B4R,GACxG,CACA,OAAOxN,CACX,CACA,MAAM,IAAI9B,EAAmC,mFACjD,GiBVI6M,eAAgB,IjBYjB,cAA4CtI,EAC/CnD,OAAAA,CAAQR,GACJ,IAAI2F,EAcJ,OAZIA,EADA3F,EAAOgB,MAAM4C,WAAW,YAAc5D,EAAOgB,MAAM4C,WAAW,YACxD5D,EAAOgB,MAAM6N,OAGb,GAAH/R,OAAMwB,KAAKyB,YAAYC,GAAO,YAAAlD,OAAWkD,EAAOgB,OAEvD2E,EAAMA,EAAIhF,QAAQ,OAAQ,IACtBgF,EAAImJ,SAAS,OACbnJ,GAAO,oBAEDA,EAAImJ,SAAS,uBACnBnJ,GAAO,wBAEJA,CACX,CACApF,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOkB,EAAOG,MAAI,IACda,MAAOhB,EAAOgB,OAEtB,CACA,iBAAMC,CAAYC,GACd,OAAOA,CACX,GiBrCI,kBAAmB,IjBuCpB,cAA4CyC,EAC/C,iBAAM1C,CAAYC,GACd,MAAMO,EAAMpC,EAAQ6B,GACpB,GAAI3B,MAAMC,QAAQiC,IAAQA,EAAIC,MAAOC,GAAM,mBAAoBA,GAAkC,kBAArB,OAADA,QAAC,IAADA,OAAC,EAADA,EAAGC,iBAC1E,OAAU,OAAHH,QAAG,IAAHA,OAAG,EAAHA,EAAM,GAEjB,MAAM,IAAIrC,EAAmC,8GACjD,GiB7CI,sBAAuB,IjBuMxB,cAAgDuE,EACnD,iBAAM1C,CAAYC,GACd,MAAMuN,EAAiB,OAARvN,QAAQ,IAARA,OAAQ,EAARA,EAAW,GAC1B,GAAI3B,MAAMC,QAAQiP,IAAWA,EAAO/M,MAAOC,GAA0B,kBAAZ,OAADA,QAAC,IAADA,OAAC,EAADA,EAAGsC,QAAyC,kBAAZtC,EAAEuC,OACtF,OAAOuK,EAEX,MAAM,IAAIrP,EAAmC,wHACjD,GiB7MI,qBAAsB,IjB+MvB,cAA+CuE,EAClD,iBAAM1C,CAAYC,GACd,GAAI3B,MAAMC,QAAQ0B,GACZA,EAASQ,MAAO2C,GAAyB,kBAATA,KAC5BA,GACqB,kBAAhBA,EAAKI,QACQ,kBAAbJ,EAAK0K,KACU,kBAAf1K,EAAKH,OACU,kBAAfG,EAAK2K,OACM,kBAAb9N,GACHA,GACyB,kBAApBA,EAASuD,QACQ,kBAAjBvD,EAAS6N,KACU,kBAAnB7N,EAASgD,OACU,kBAAnBhD,EAAS8N,MACpB,OAAOzP,MAAMC,QAAQ0B,GAAYA,EAAS,GAAKA,EAEnD,MAAM,IAAI9B,EAAmC,oJACjD,GiBhOI,uBAAwB,IjB6CzB,cAAiDuE,EACpD,iBAAM1C,CAAYC,GACd,GAAI3B,MAAMC,QAAQ0B,IACdA,EAASQ,MAAOC,GAAmB,kBAANA,GAAwB,OAANA,GAAiC,kBAAZA,EAAEsC,OAAyC,kBAAZtC,EAAEuC,OACrG,OAAOhD,EAEX,MAAM,IAAI9B,EAAmC,uJACjD,GiBnDI,+BAAgC,IjBqDjC,cAAwDuE,EAC3D,iBAAM1C,CAAYC,GACd,OAAOA,CACX,CACA,yBAAMkM,CAAoBjN,GACtB,MAAO,SAAUA,EACXA,GAAIrB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAECiE,EAAK5C,EAAM,WAAS,IACvBC,KAAMD,EAAKgK,QAEvB,GiB/DI,YAAa,IjBgOd,cAAsCxG,EACzC,iBAAM1C,CAAYC,GACd,GAAI3B,MAAMC,QAAQ0B,IACdA,EAASQ,MAAOC,GAAyB,kBAAZA,EAAEuC,OACL,kBAAfvC,EAAEsN,UACU,kBAAZtN,EAAEuN,OACc,kBAAhBvN,EAAEwN,WACb,OAAOjO,EAEX,MAAM,IAAI9B,EAAmC,mJACjD,GiBzOI,qBAAsB,IjBkGvB,cAA+CuE,EAClD,iBAAM1C,CAAYC,GACd,MAAMkO,EAAgB,SAACrN,EAAKsN,GAA2B,IAAjBC,EAAQzP,UAAAC,OAAA,QAAAb,IAAAY,UAAA,GAAAA,UAAA,GAAG,EAC7C,QAAIyP,EAAWD,KAEXtN,EAAIL,MAAOC,GAAMpC,MAAMC,QAAQmC,IACxBI,EAAIL,MAAOC,GAAMyN,EAAczN,EAAG0N,EAAUC,EAAW,IAGvDvN,EAAIL,MAAOC,GAAmB,kBAANA,GAEvC,EACA,GAAIpC,MAAMC,QAAQ0B,IAAakO,EAAclO,EAAU,EAAG,GACtD,OAAOA,EAEX,MAAM,IAAI9B,EAAmC,sIACjD,GiBjHI,uBAAwB,IjBmHzB,cAAiDuE,EACpD,iBAAM1C,CAAYC,GACd,GAAI3B,MAAMC,QAAQ0B,IAAaA,EAASQ,MAAOC,GAAyB,kBAAZA,EAAEsC,OAAyC,kBAAZtC,EAAEuC,OACzF,OAAOhD,EAEX,MAAM,IAAI9B,EAAmC,yHACjD,GiBxHI,qBAAsB,IjB0HvB,cAA+CuE,EAClD,iBAAM1C,CAAYC,GACd,GAAI3B,MAAMC,QAAQ0B,IACdA,EAASQ,MAAOC,GAAyB,kBAAZA,EAAEsC,OACT,kBAAXtC,EAAEwM,YACIlP,IAAZ0C,EAAEuC,OAA0C,kBAAZvC,EAAEuC,QACvC,OAAOhD,EAEX,MAAM,IAAI9B,EAAmC,qIACjD,CACA,yBAAMgO,CAAoBjN,GACtB,OAAArB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOqB,GAAI,IACPgK,OAAQrI,EAAgB,IAAI+I,WAAW1K,EAAKgK,kBAAkBW,YAAc3K,EAAKgK,aAAehK,EAAKgK,OAAOY,iBAEpH,GiBxII,8BAA+B,IjBiFhC,cAAuDpH,EAC1D,iBAAM1C,CAAYC,GACd,GAAI3B,MAAMC,QAAQ0B,IACdA,EAASQ,MAAO2C,GAAyB,kBAATA,KAC1BA,GACsB,kBAAb,OAAJA,QAAI,IAAJA,OAAI,EAAJA,EAAMI,UACQ,kBAAbJ,EAAK0K,KAAwC,qBAAb1K,EAAK0K,OACtB,kBAAf1K,EAAKH,OAA4C,qBAAfG,EAAKH,SACxB,kBAAfG,EAAK2K,OAA4C,qBAAf3K,EAAK2K,QACnD,OAAO9N,EAAS,GAEpB,MAAM,IAAI9B,EAAmC,6JACjD,GiB5FI,gBAAiB,IjByIlB,cAAyCuE,EAC5C,iBAAM1C,CAAYC,GACd,GAAwC,kBAArB,OAARA,QAAQ,IAARA,OAAQ,EAARA,EAAUU,gBACjB,MAAM,IAAIxC,EAAmC,sGAEjD,OAAO8B,CACX,GiB9II,mBAAoB,IjBuKrB,cAA6CyC,EAChD,iBAAM1C,CAAYC,GACd,GAAI3B,MAAMC,QAAQ0B,IACdA,EAASQ,MAAOC,GAAyB,kBAAZA,EAAEsC,OACR,kBAAZtC,EAAEuC,OACa,kBAAfvC,EAAE4N,IAAIC,MACS,kBAAf7N,EAAE4N,IAAIE,MACS,kBAAf9N,EAAE4N,IAAIG,MACS,kBAAf/N,EAAE4N,IAAII,MACjB,OAAOzO,EAEX,MAAM,IAAI9B,EAAmC,oLACjD,GiBlLI,iBAAkB,IjB0DnB,cAA0CuE,EAC7C,iBAAM1C,CAAYC,GACd,IAAK3B,MAAMC,QAAQ0B,GACf,MAAM,IAAI9B,EAAmC,oFAEjD,IAAK8B,EAASQ,MAAO2C,GACO,kBAATA,GACXA,GACA,UAAWA,GACW,kBAAfA,EAAKJ,OACZ,iBAAkBI,GACc,kBAAzBA,EAAK,iBACZ,SAAUA,GACW,kBAAdA,EAAK0H,MAEhB,MAAM,IAAI3M,EAAmC,kHAEjD,OAAO8B,CACX,GiB3EI,iCAAkC,IjBmLnC,cAAyDyC,EAC5D,iBAAM1C,CAAYC,GACd,GAAI3B,MAAMC,QAAQ0B,IAAaA,EAASQ,MAAOC,GAAyB,kBAAZA,EAAEsC,OAAyC,kBAAZtC,EAAEuC,OACzF,OAAOhD,EAEX,MAAM,IAAI9B,EAAmC,mIACjD,GiBxLI,2BAA4B,IAAIwQ,EAChC,iBAAkB,IjB4InB,cAA0CjM,EAC7C,yBAAMyJ,CAAoBjN,GACtB,OAAKA,EAAK8J,YAQNnL,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOqB,GAAI,IACPgK,OAAQrI,EAAgB,IAAI+I,WAAW1K,EAAKgK,kBAAkBW,YAAc3K,EAAKgK,aAAehK,EAAKgK,OAAOY,mBAThHjM,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOqB,GAAI,IACPa,MAAOb,EAAKa,MACZZ,KAAMD,EAAKgK,QASvB,CACA,iBAAMlJ,CAAYC,GACd,GAAIA,aAAoBoM,KACpB,OAAOpM,EAEX,MAAM,IAAI9B,EAAmC,kFACjD,GiBhKI,sBAAuB,IjBiQxB,cAAgDuE,EACnD,iBAAM1C,CAAYC,GACd,GAAI3B,MAAMC,QAAQ0B,IAAaA,EAASQ,MAAOC,GAAmB,kBAANA,GACxD,OAAOT,EAEX,MAAM,IAAI9B,EAAmC,gGACjD,GiBtQI,2BAA4B,IAAIwQ,EAChC,yBAA0B,IjBiU3B,cAAmDjM,EACtD,iBAAM1C,CAAYC,GACd,GAAI3B,MAAMC,QAAQ0B,IAAaA,EAASQ,MAAOC,GAAmB,kBAANA,GACxD,OAAOT,EAEX,MAAM,IAAI9B,EAAmC,mGACjD,GiBtUI,iBAAkB,IjB2TnB,cAA0CuE,EAC7C,iBAAM1C,CAAYC,GACd,OAAOA,CACX,GiB7TI,uBAAwB,IjB6RzB,cAAiDyC,EACpD,iBAAM1C,CAAYC,GACd,GAAI3B,MAAMC,QAAQ0B,IACdA,EAASQ,MAAOC,GAAuB,kBAAVA,EAAEoN,KACD,kBAAnBpN,EAAEkO,cACU,kBAAZlO,EAAEuC,OACU,kBAAZvC,EAAEqN,OACS,kBAAXrN,EAAEmO,MACb,OAAO5O,EAEX,MAAM,IAAI9B,EAAmC,0KACjD,GiBvSI2Q,YAAa,IjBySd,cAAyCpM,EAC5C,iBAAM1C,CAAYC,GACd,GAAI3B,MAAMC,QAAQ0B,IAAaA,EAASQ,MAAOC,GAAqC,kBAAvB,OAADA,QAAC,IAADA,OAAC,EAADA,EAAGqO,mBAC3D,OAA4B,KAAb,OAAR9O,QAAQ,IAARA,OAAQ,EAARA,EAAUpB,QAAuB,OAARoB,QAAQ,IAARA,OAAQ,EAARA,EAAW,GAAKA,EAEpD,MAAM,IAAI9B,EAAmC,4GACjD,GiB9SI6Q,cAAe,IjBgThB,cAA2CtM,EAC9C,iBAAM1C,CAAYC,GACd,GAAI3B,MAAMC,QAAQ0B,IAAaA,EAASQ,MAAOC,GAAiC,kBAAnB,OAADA,QAAC,IAADA,OAAC,EAADA,EAAGuO,eAC3D,OAAe,OAARhP,QAAQ,IAARA,OAAQ,EAARA,EAAW,GAEtB,MAAM,IAAI9B,EAAmC,0GACjD,GiBrTI,4BAA6B,IjBoU9B,cAAqDuE,EACxD,iBAAM1C,CAAYC,GACd,GAAI3B,MAAMC,QAAQ0B,IACdA,EAASQ,MAAO2C,GAAyB,kBAATA,KAAuBA,GAAgC,kBAAb,OAAJA,QAAI,IAAJA,OAAI,EAAJA,EAAMI,SAA6C,kBAAfJ,EAAKH,OAC/G,OAAOhD,EAAS,GAEpB,MAAM,IAAI9B,EAAmC,+HACjD,GiB1UI,qBAAsB,IjB4UvB,cAA+CuE,EAClD,iBAAM1C,CAAYC,GACd,GAAI3B,MAAMC,QAAQ0B,IAAaA,EAASQ,MAAOC,GAAmB,kBAANA,GACxD,OAAOT,EAEX,MAAM,IAAI9B,EAAmC,+FACjD,GiBjVI,gBAAiB,IjBmVlB,cAAyCuE,EAC5C,iBAAM1C,CAAYC,GACd,OAAOA,CACX,IiBpVA,eAAgB,CACZ+K,eAAgB,IMnEjB,cAA0ClL,EAC7C5C,WAAAA,GACIE,MAAM,eAAgB,2BAC1B,CACAqC,SAAAA,GACI,MAAO,gCACX,IN+DAtD,KAAM,CACF6O,eAAgB,IV7DjB,cAAqClL,EACxC5C,WAAAA,GACIE,MAAM,OAAQoL,EAClB,CACA/I,SAAAA,GACI,MAAO,6BACX,GUwDI,kBAAmB,IVtEpB,cAAqCc,EACxCrD,WAAAA,GACIE,MAAM,OAAQoL,EAClB,CACA/I,SAAAA,GACI,MAAO,6BACX,IUkEArD,WAAY,CACR,gBAAiB,ITjDlB,cAAwCoC,EAC3CtB,WAAAA,GACIE,MAAM,aAAcqL,EACxB,CACAhJ,SAAAA,CAAUV,GAEN,MAAO,wBACX,CACAO,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOiE,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC7BH,EAAOG,KAAK8J,YAAU,IACzBC,OAAQlK,EAAOG,KAAKgK,OACpBwC,WAAY3M,EAAOgB,OAE3B,CACA,iBAAMC,CAAYC,EAAUyE,EAAK5G,EAASmN,GACtC,GAAwB,kBAAbhL,GACP,WAAYA,GACZ3B,MAAMC,QAAQ0B,EAAS8J,SACvB9J,EAAS8J,OAAO,IACoB,kBAA7B9J,EAAS8J,OAAO,GAAGyB,MAC1B,MAAmB,SAAfP,GACApN,EAAAA,EAAAA,GAAA,GAAYoC,GAEG,QAAfgL,EACO,0BAAPpP,OAAiCoE,EAAS8J,OAAO,GAAGyB,OAEjD5G,MAAM,0BAAD/I,OAA2BoE,EAAS8J,OAAO,GAAGyB,QAASkC,KAAMlN,GAAQA,EAAIsK,QAEzF,MAAM,IAAI3M,EAAmC,gEACjD,GSmBI6M,eAAgB,ITxFjB,cAA2ClL,EAC9C5C,WAAAA,GACIE,MAAM,aAAcqL,EACxB,GSsFI,kBAAmB,ITpFpB,cAA2ClI,EAC9CrD,WAAAA,GACIE,MAAM,aAAcqL,EACxB,CACAhJ,SAAAA,GACI,MAAO,qBACX,CACAH,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,CACIqR,SAAU,CAAC,CAAEC,QAASpQ,EAAOG,KAAKgK,OAAQkG,KAAM,UAC5CrQ,EAAOG,KAAK8J,YAAUnL,EAAAA,EAAAA,GAAA,CAElBsP,WAAYpO,EAAOG,KAAK8J,WAAWoE,gBAChCtL,EAAK/C,EAAOG,KAAK8J,WAAY,wBAElChL,GACH8D,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAAc,IAC9Ca,MAAOhB,EAAOgB,OAEtB,CACA,iBAAMC,CAAYC,GACd,GAAwB,kBAAbA,GACP,YAAaA,GACb3B,MAAMC,QAAgB,OAAR0B,QAAQ,IAARA,OAAQ,EAARA,EAAUC,UACG,kBAAZ,OAARD,QAAQ,IAARA,OAAQ,EAARA,EAAUF,OAAoB,CAErC,MAAO,CACHY,eAFeV,EAASC,QAAQ,GAEL/C,QAAQgS,QAE3C,CACA,MAAM,IAAIhR,EAAmC,kEACjD,ISuDA9B,OAAQ,CACJ,gBAAiB,IRvDlB,cAAoCmC,EACvCtB,WAAAA,GACIE,MAAM,SAAUsL,EACpB,CACApJ,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOiE,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC7BH,EAAOG,KAAK8J,YAAU,IACzBqG,gBAAiB,WACjBpG,OAAQlK,EAAOG,KAAKgK,OACpBnJ,MAAOhB,EAAOgB,OAEtB,CACAN,SAAAA,GACI,MAAO,uBACX,CACA,iBAAMO,CAAYC,EAAUyE,EAAK5G,EAASmN,GACtC,GAAwB,kBAAbhL,GACP,SAAUA,GACV3B,MAAMC,QAAQ0B,EAASd,OACvBc,EAASd,KAAKN,OAAS,GACvB,aAAcoB,EAASd,KAAK,IACS,kBAA9Bc,EAASd,KAAK,GAAGkO,SAAuB,CAC/C,GAAmB,SAAfpC,EACA,OAAApN,EAAAA,EAAAA,GAAA,GAAYoC,GAEhB,MAAMqN,EAAarN,EAASd,KAAK,GAAGkO,SACpC,MAAmB,QAAfpC,EACO,0BAAPpP,OAAiCyR,GAE9B1I,MAAM,0BAAD/I,OAA2ByR,IAAcI,KAAMlN,GAAQA,EAAIsK,OAC3E,CACA,MAAM,IAAI3M,EAAmC,4DACjD,GQuBI6M,eAAgB,IR7FjB,cAAuClL,EAC1C5C,WAAAA,GACIE,MAAM,SAAUsL,EACpB,CACApJ,cAAAA,CAAeP,GAAQ,IAAAuQ,EACnB,MAAM9J,EAAUpI,MAAMkC,eAAeP,GAC/BwQ,EAAiBxQ,EAAOG,KAAKmQ,gBAInC,MAH6B,iBAAX,OAAdE,QAAc,IAAdA,OAAc,EAAdA,EAAgBjD,OAAoD,QAA9BgD,EAAIC,EAAeC,mBAAW,IAAAF,GAA1BA,EAA4BG,SACtEjK,EAAqB,YAAI+J,EAAeC,YAAYC,QAEjDjK,CACX,GQmFI,kBAAmB,IRjFpB,cAAuCjF,EAC1CrD,WAAAA,GACIE,MAAM,SAAUsL,EACpB,CACApJ,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOkB,EAAOG,MAAI,IACda,MAAOhB,EAAOgB,MACdkJ,OAAQlK,EAAOG,KAAKgK,QAE5B,CACA,iBAAMlJ,CAAYC,GAAU,IAAAyP,EACxB,GAAwB,kBAAbzP,GACP,YAAaA,GACb3B,MAAMC,QAAgB,OAAR0B,QAAQ,IAARA,OAAQ,EAARA,EAAUC,UACxBD,EAASC,QAAQrB,OAAS,GACW,kBAAX,QAA1B6Q,EAAOzP,EAASC,QAAQ,UAAE,IAAAwP,OAAA,EAAnBA,EAAqBtK,MAC5B,MAAO,CACHzE,eAAgBV,EAASC,QAAQ,GAAGkF,MAG5C,MAAM,IAAIjH,EAAmC,8DACjD,GQ4DI,qBAAsB,IRvBvB,cAA0CK,EAC7CtB,WAAAA,GACIE,MAAM,SAAUsL,EACpB,CACApJ,cAAAA,CAAeP,GACX,MAAO,CACHgK,MAAOhK,EAAOG,KAAKgK,OACnBnJ,MAAOhB,EAAOgB,MAEtB,CACAN,SAAAA,GACI,MAAO,eACX,CACA,iBAAMO,CAAYC,GACd,OAAOA,EAASd,KAAKiD,IAAKuN,GAASA,EAAKC,UAC5C,IQUAtT,OAAQ,CACJ0O,eAAgB,IPxEjB,cAAuClL,EAC1C5C,WAAAA,GACIE,MAAM,SAAUuL,EACpB,CACAlJ,SAAAA,GACI,MAAO,6BACX,GOmEI,kBAAmB,IPjFpB,cAAuCc,EAC1CrD,WAAAA,GACIE,MAAM,SAAUuL,EACpB,CACAlJ,SAAAA,GACI,MAAO,6BACX,GO4EI,gBAAiB,IPlElB,cAAoCjB,EACvCtB,WAAAA,GACIE,MAAM,SAAUuL,EACpB,CACAlJ,SAAAA,CAAUV,GACN,MAAO,aAAPlD,OAAoBkD,EAAOgB,MAC/B,CACAT,cAAAA,CAAeP,GAAQ,IAAA8Q,EACnB,MAAAhK,EAAyE,QAAzEgK,EAAmD9Q,EAAOG,KAAK8J,kBAAU,IAAA6G,EAAAA,EAAI,CAAC,GAAxE,oBAAEC,GAAwCjK,EAAhBkK,GAAcC,EAAAA,EAAAA,GAAAnK,EAAAoK,GAC9C,OAAApS,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOiE,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC7B6Q,GAAc,IACjBG,MAAOJ,EACP7G,OAAQlK,EAAOG,KAAKgK,QAE5B,CACA,iBAAMlJ,CAAYC,EAAUyE,EAAK5G,GAC7B,IAAK4G,IAAQ5G,EACT,MAAM,IAAIP,EAA0B,uDAExC,MAAM4S,EAASlQ,EAASmQ,QACxB,IAAKD,EACD,MAAM,IAAIhS,EAAmC,+FAEjD,MAAMqJ,EAAY,IAAIC,IAAI/C,GACpBhG,EAAU,GAAH7C,OAAM2L,EAAUE,SAAQ,MAAA7L,OAAK2L,EAAUG,MAAI9L,OAAsB,0BAAnB2L,EAAUG,KAAmC,UAAY,IAC9GM,EAAY,GAAHpM,OAAM6C,EAAO,kCAAA7C,OAAiCsU,GAC7D,IACI1F,EADAvF,EAAS,GAEb,KAAkB,wBAAXA,GAA+C,uBAAXA,GAAiC,OAClEwB,EAAM,KACZ,MAAM0B,QAAuBxD,MAAMqD,EAAW,CAAEnK,YACxB,IAAA0M,EAAxB,IAAKpC,EAAevD,GAChB,MAAM,IAAI5G,EAAgC,8BAA+B,CAAEyG,IAAKuD,EAAWjD,OAAQ,MAAOlH,WAAW,CACjHmH,UAAqD,QAA5CuF,EAAEpC,EAAetK,QAAQyG,IAAI,uBAAe,IAAAiG,EAAAA,EAAI,GACzDtF,OAAQkD,EAAelD,OACvBC,WAAYiD,EAAehD,SAGnC,IAEI,GADAqF,QAAmBrC,EAAe9C,SAC9BmF,GACsB,kBAAfA,GACP,SAAUA,GACVA,EAAW7H,MACgB,kBAApB6H,EAAW7H,MAClB,WAAY6H,EAAW7H,MACW,kBAA3B6H,EAAW7H,KAAKsC,QAIvB,MAAM,IAAI/G,EAAmC,wFAH7C+G,EAASuF,EAAW7H,KAAKsC,MAKjC,CACA,MAAOG,GACH,MAAM,IAAIlH,EAAmC,yFACjD,CACJ,CACA,GAAe,uBAAX+G,EACA,MAAM,IAAI/G,EAAmC,oCAEjD,GAA0B,kBAAfsM,GACLA,GACF,WAAYA,GACiB,kBAAtBA,EAAW4F,QAChB5F,EAAW4F,QACb/R,MAAMC,QAAQkM,EAAW4F,SACzB5F,EAAW4F,OAAOxR,OAAS,GAC3B,cAAe4L,EAAW4F,OAAO,IACS,kBAAnC5F,EAAW4F,OAAO,GAAGC,WAC5BvJ,EAAM0D,EAAW4F,OAAO,GAAGC,WAAY,CACvC,MAAM3E,QAAoB/G,MAAM6F,EAAW4F,OAAO,GAAGC,WACrD,aAAa3E,EAAYb,MAC7B,CAEI,MAAM,IAAI3M,EAAmC,gIAADtC,OAAiIuD,KAAKC,UAAUoL,IAEpM,IOTAlO,OAAQ,CACJ,gBAAiB,INlGlB,cAAoCiC,EACvCtB,WAAAA,GACIE,MAAM,SAAUwL,EACpB,CACAtJ,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOiE,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC7BH,EAAOG,KAAK8J,YAAU,IACzBqG,gBAAiB,WACjBpG,OAAQlK,EAAOG,KAAKgK,OACpBnJ,MAAOhB,EAAOgB,OAEtB,CACAN,SAAAA,GACI,MAAO,uBACX,CACA,iBAAMO,CAAYC,EAAUyE,EAAK5G,EAASmN,GACtC,GAAwB,kBAAbhL,GACP,SAAUA,GACV3B,MAAMC,QAAQ0B,EAASd,OACvBc,EAASd,KAAKN,OAAS,GACvB,aAAcoB,EAASd,KAAK,IACS,kBAA9Bc,EAASd,KAAK,GAAGkO,SAAuB,CAC/C,GAAmB,SAAfpC,EACA,OAAApN,EAAAA,EAAAA,GAAA,GAAYoC,GAEhB,MAAMqN,EAAarN,EAASd,KAAK,GAAGkO,SACpC,MAAmB,QAAfpC,EACO,0BAAPpP,OAAiCyR,GAE9B1I,MAAM,0BAAD/I,OAA2ByR,IAAcI,KAAMlN,GAAQA,EAAIsK,OAC3E,CACA,MAAM,IAAI3M,EAAmC,4DACjD,GMkEI6M,eAAgB,INxGjB,cAAuClL,EAC1C5C,WAAAA,GACIE,MAAM,SAAUwL,EACpB,IMuGApM,OAAQ,CACJwO,eAAgB,IO1GjB,cAAuClL,EAC1C5C,WAAAA,GAEIE,MAAM,SAJc,0BAIiB,EACzC,IPwGAV,SAAU,CACNsO,eAAgB,IL9FjB,cAAyClL,EAC5C5C,WAAAA,GACIE,MAAM,WAAYyL,EACtB,GK4FI,kBAAmB,IL1FpB,cAAyCtI,EAC5CrD,WAAAA,GACIE,MAAM,WAAYyL,EACtB,CACAvJ,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,CACIkC,MAAOhB,EAAOgB,OACX+B,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC5BH,EAAOG,KAAK8J,YAAUnL,EAAAA,EAAAA,GAAA,CAElBsP,WAAYpO,EAAOG,KAAK8J,WAAWoE,gBAChCtL,EAAK/C,EAAOG,KAAK8J,WAAY,wBAElChL,GAAS,IACfiL,OAAQlK,EAAOG,KAAKgK,QAE5B,CACA,iBAAMlJ,CAAYC,GACd,GAAwB,kBAAbA,GACP,YAAaA,GACb3B,MAAMC,QAAgB,OAAR0B,QAAQ,IAARA,OAAQ,EAARA,EAAUC,UACG,kBAAZ,OAARD,QAAQ,IAARA,OAAQ,EAARA,EAAUF,OAAoB,CAErC,MAAO,CACHY,eAFeV,EAASC,QAAQ,GAELkF,KAEnC,CACA,MAAM,IAAIjH,EAAmC,gEACjD,IKgEA1B,SAAU,CACNuO,eAAgB,IQrHjB,cAAyClL,EAC5C5C,WAAAA,GACIE,MAAM,WAAY,0BACtB,IRoHAT,UAAW,CACP,gBAAiB,IJjElB,cAAuCmM,EAC1CxJ,cAAAA,CAAeP,GAAQ,IAAAmL,EACnB,MAAO,CACHnB,OAAKlL,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACEiE,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC7BH,EAAOG,KAAK8J,YAAU,IACzBC,OAAQlK,EAAOG,KAAKgK,OACpBqH,aAA0C,UAAd,QAAdrG,EAAAnL,EAAO+G,eAAO,IAAAoE,OAAA,EAAdA,EAAgBjE,UAAsBlH,EAAO+G,QAAQI,mBAAkB,0BAAArK,OACrDkD,EAAO+G,QAAQC,gBACzC/H,IAEVmL,QAASpK,EAAOgB,MAAM8B,SAAS,KAAO9C,EAAOgB,MAAMqJ,MAAM,KAAK,QAAKpL,EAE3E,CACA,iBAAMgC,CAAYQ,EAAKkE,EAAK5G,EAASmN,GAIjC,GAAmB,kBAARzK,GAAoB,WAAYA,GAA6B,kBAAfA,EAAIgN,QAAuBzG,EAAMvG,EAAIgN,QAAS,CACnG,GAAmB,SAAfvC,EACA,OAAApN,EAAAA,EAAAA,GAAA,GAAY2C,GAEhB,GAAmB,QAAfyK,EACA,OAAOzK,EAAIgN,OAEf,MAAM7B,QAAoB/G,MAAMpE,EAAIgN,QACpC,aAAa7B,EAAYb,MAC7B,CAEA,GAAmB,kBAARtK,GACP,WAAYA,GACZlC,MAAMC,QAAQiC,EAAIgN,SAClBhN,EAAIgN,OAAO3O,OAAS,GACK,kBAAlB2B,EAAIgN,OAAO,GAAiB,CACnC,GAAmB,SAAfvC,EACA,OAAApN,EAAAA,EAAAA,GAAA,GAAY2C,GAEhB,GAAmB,QAAfyK,EACA,OAAOzK,EAAIgN,OAAO,GAEtB,MAAM7B,QAAoB/G,MAAMpE,EAAIgN,OAAO,IAC3C,aAAa7B,EAAYb,MAC7B,CACA,MAAM,IAAI3M,EAAmC,+DACjD,GIsBI,iBAAkB,IJpBnB,cAAwC2K,EAC3CxJ,cAAAA,CAAeP,GACX,MAAMyG,EAAUpI,MAAMkC,eAAeP,GAC/BgK,EAAQvD,EAAe,MAC7B,GAAqB,kBAAVuD,GAAgC,OAAVA,GAAkB,WAAYA,EAAO,CAClE,MAAMyH,EAAWzH,EACjByH,EAAe,KAAIA,EAAiB,cAC7BA,EAAiB,MAC5B,CACA,OAAOhL,CACX,CACA,iBAAMxF,CAAYC,GACd,GAAIA,aAAoBoM,KACpB,OAAOpM,EAEX,GAAIA,GAAgC,kBAAbA,GACf,WAAYA,EAAU,CACtB,GAA+B,kBAApBA,EAASuN,OAAqB,CACrC,MAAM7B,QAAoB/G,MAAM3E,EAASuN,QACzC,aAAa7B,EAAYb,MAC7B,CACK,GAAIxM,MAAMC,QAAQ0B,EAASuN,QAAS,CACrC,MAAM7B,QAAoB/G,MAAM3E,EAASuN,OAAO,IAChD,aAAa7B,EAAYb,MAC7B,CACJ,CAEJ,MAAM,IAAI3M,EAAmC,gEACjD,GIPI,gBAAiB,IJSlB,cAAuC2K,EAC1C,iBAAM9I,CAAYC,GACd,GAAwB,kBAAbA,GACLA,GACF,WAAYA,GACe,kBAApBA,EAASuN,QAChBzG,EAAM9G,EAASuN,QAAS,CACxB,MAAM7B,QAAoB/G,MAAM3E,EAASuN,QACzC,aAAa7B,EAAYb,MAC7B,CACA,MAAM,IAAI3M,EAAmC,+DACjD,GInBI,iBAAkB,IJiEnB,cAAwC2K,EAC3CxJ,cAAAA,CAAeP,GAAQ,IAAAmN,EACnB,MAAO,CACHnD,OAAKlL,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACEiE,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC7BH,EAAOG,KAAK8J,YAAU,IACzByH,YAAa1R,EAAOG,KAAKgK,OACzBqH,aAA0C,UAAd,QAAdrE,EAAAnN,EAAO+G,eAAO,IAAAoG,OAAA,EAAdA,EAAgBjG,UAAsBlH,EAAO+G,QAAQI,mBAAkB,0BAAArK,OACrDkD,EAAO+G,QAAQC,gBACzC/H,IAEVmL,QAASpK,EAAOgB,MAAM8B,SAAS,KAAO9C,EAAOgB,MAAMqJ,MAAM,KAAK,QAAKpL,EAE3E,CACA,yBAAMmO,CAAoBjN,GACtB,MAAM,OAAEgK,GAAwBhK,EAAbwR,GAAQV,EAAAA,EAAAA,GAAK9Q,EAAI+Q,GAG9BU,EAAS9P,EADD,IAAI+I,iBAAiBV,EAAOY,gBAEpC8G,EAAa,QAAH/U,OAAWqN,EAAOoD,MAAQ,aAAY,YAAAzQ,OAAW8U,GACjE,OAAA9S,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACO6S,GAAQ,IACXxH,OAAQ0H,GAEhB,CACA,iBAAM5Q,CAAYC,GACd,GAAwB,kBAAbA,GACLA,GACF,WAAYA,GACZ3B,MAAMC,QAAQ0B,EAASuN,SACvBvN,EAASuN,OAAO3O,OAAS,GACK,kBAAvBoB,EAASuN,OAAO,GAAiB,CACxC,MAAM7B,QAAoB/G,MAAM3E,EAASuN,OAAO,IAChD,aAAa7B,EAAYb,MAC7B,CACA,GAAwB,kBAAb7K,GACLA,GACF,WAAYA,GACe,kBAApBA,EAASuN,QAChBzG,EAAM9G,EAASuN,QAAS,CACxB,MAAM7B,QAAoB/G,MAAM3E,EAASuN,QACzC,aAAa7B,EAAYb,MAC7B,CACA,MAAM,IAAI3M,EAAmC,gEACjD,GI5GI,+BAAgC,IJoBjC,cAAsD2K,EACzDxJ,cAAAA,CAAeP,GACX,MAAO,CACHgK,OAAKlL,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACEiE,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC7BH,EAAOG,KAAK8J,YAAU,IACzB6C,MAAO9M,EAAOG,KAAKgK,SAEvBC,QAASpK,EAAOgB,MAAM8B,SAAS,KAAO9C,EAAOgB,MAAMqJ,MAAM,KAAK,QAAKpL,EAE3E,CACA,yBAAMmO,CAAoBjN,GACtB,MAAM4L,EAAO,SAAU5L,GAAQA,EAAKC,gBAAgBkN,KAAOnN,EAAKC,KAAO,WAAYD,EAAOA,EAAKgK,YAASlL,EACxG,IAAK8M,KAAUA,aAAgBuB,MAC3B,MAAM,IAAIpP,MAAM,8BAGpB,MACM0T,EAAS9P,EADD,IAAI+I,iBAAiBkB,EAAKhB,gBAElC+G,EAAa,QAAHhV,OAAWiP,EAAKwB,MAAQ,YAAW,YAAAzQ,OAAW8U,GAC9D,OAAA9S,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACyBiE,EAAK5C,EAAtB,SAAUA,EAAkB,OAAqB,WAAS,IAC9DgK,OAAQ2H,GAEhB,CACA,iBAAM7Q,CAAYC,GACd,GAAgC,kBAAb,OAARA,QAAQ,IAARA,OAAQ,EAARA,EAAUuN,QACjB,MAAO,CAAEpI,KAAMnF,EAASuN,QAC5B,GAAIlP,MAAMC,QAAgB,OAAR0B,QAAQ,IAARA,OAAQ,EAARA,EAAUuN,SAAyC,kBAAvBvN,EAASuN,OAAO,GAC1D,MAAO,CAAEpI,KAAMnF,EAASuN,OAAO,IACnC,MAAMsD,EAAc,OAAR7Q,QAAQ,IAARA,OAAQ,EAARA,EAAUuN,OACtB,GAAIsD,GAAsB,kBAARA,EAAkB,CAChC,GAAiC,kBAAtBA,EAAIC,cACX,MAAO,CAAE3L,KAAM0L,EAAIC,eACvB,GAA+B,kBAApBD,EAAIhC,YACX,MAAO,CAAE1J,KAAM0L,EAAIhC,aACvB,GAA4B,kBAAjBgC,EAAIE,SAAuB,CAClC,MAAMC,QAAUrM,MAAMkM,EAAIE,UAC1B,MAAO,CAAE5L,WAAY6L,EAAE7L,OAC3B,CACJ,CACA,MAAM,IAAIjH,EAAmC,8EACjD,II5DAvB,UAAW,CACPoO,eAAgB,IS9HjB,cAA0ClL,EAC7C5C,WAAAA,GACIE,MAAM,YAAa,2BACvB,CACAkC,cAAAA,CAAeP,GACX,MAAMwQ,EAAiBxQ,EAAOG,KAAKmQ,gBACuC,IAAAC,EAA7C,iBAAX,OAAdC,QAAc,IAAdA,OAAc,EAAdA,EAAgBjD,OAA0BiD,EAAeC,eACpB,QAArCF,EAAIC,EAAeC,YAAY0B,cAAM,IAAA5B,GAAAA,KACjCC,EAAeC,YAAY0B,QAAS,IAI5C,OADgB9T,MAAMkC,eAAeP,EAEzC,GTkHI,qBAAsB,IShHvB,cAA6CP,EAChDtB,WAAAA,GACIE,MAAM,YAAa,2BACvB,CACAqC,SAAAA,GACI,MAAO,gBACX,CACA,iBAAMO,CAAYC,GACd,GAAwB,kBAAbA,GAAyB,SAAUA,GAAY3B,MAAMC,QAAQ0B,EAASd,MAC7E,OAAOc,EAASd,KAAKiD,IAAKuN,GAASA,EAAKC,WAE5C,MAAM,IAAIzR,EAAmC,iFACjD,CACAmB,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,GAAA,CACIkC,MAAOhB,EAAOgB,MACdgJ,MAAOhK,EAAOG,KAAKgK,QAChBnK,EAAOG,KAElB,IT+FArC,SAAU,CACNmO,eAAgB,IHjIjB,cAAyClL,EAC5C5C,WAAAA,GACIE,MAAM,WAAYkM,EACtB,GG+HI,kBAAmB,IH7HpB,cAAyC/I,EAC5CrD,WAAAA,GACIE,MAAM,WAAYkM,EACtB,CACAhK,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,CACIkC,MAAOhB,EAAOgB,OACXhB,EAAOG,MAAI,IACd+J,OAAQlK,EAAOG,KAAKgK,QAE5B,CACA,iBAAMlJ,CAAYC,GACd,GAAwB,kBAAbA,GACM,OAAbA,GACA,YAAaA,GACb3B,MAAMC,QAAQ0B,EAASC,UACvBD,EAASC,QAAQrB,OAAS,EAAG,CAC7B,MAAMsS,EAAalR,EAASC,QAAQ,GACpC,GAA0B,kBAAfiR,GACLA,GACF,SAAUA,GACVA,EAAW/L,MACgB,kBAApB+L,EAAW/L,KAClB,MAAO,CACHzE,eAAgBwQ,EAAW/L,KAGvC,CACA,MAAM,IAAIjH,EAAmC,gEACjD,GGiGI,qBAAsB,IH/FvB,cAA4CK,EAC/CtB,WAAAA,GACIE,MAAM,WAAYkM,EACtB,CACAhK,cAAAA,CAAeP,GACX,MAAO,CACHgK,MAAOhK,EAAOG,KAAKgK,OACnBnJ,MAAOhB,EAAOgB,MAEtB,CACAN,SAAAA,GACI,MAAO,eACX,CACA,iBAAMO,CAAYC,GACd,OAAOA,EAASd,KAAKiD,IAAKuN,GAASA,EAAKC,UAC5C,IGkFA9S,SAAU,CACN,gBAAiB,IF7FlB,cAAsC0B,EACzCtB,WAAAA,GACIE,MAAM,WAAYmM,EACtB,CACA9J,SAAAA,GACI,MAAO,uBACX,CACAH,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOiE,EAAK/C,EAAOG,KAAM,CAAC,SAAU,gBAC7BH,EAAOG,KAAK8J,YAAU,IACzBC,OAAQlK,EAAOG,KAAKgK,OACpBmG,gBAAiB,SACjBtP,MAAOhB,EAAOgB,OAEtB,CACA,iBAAMC,CAAYC,EAAUyE,EAAK5G,EAASmN,GACtC,GAAwB,kBAAbhL,GACP,SAAUA,GACV3B,MAAMC,QAAQ0B,EAASd,OACvBc,EAASd,KAAKN,OAAS,GACvB,aAAcoB,EAASd,KAAK,IACS,kBAA9Bc,EAASd,KAAK,GAAGkO,SAAuB,CAC/C,GAAmB,SAAfpC,EACA,OAAApN,EAAAA,EAAAA,GAAA,GAAYoC,GAEhB,MAAMqN,EAAarN,EAASd,KAAK,GAAGkO,SACpC,MAAmB,QAAfpC,EACO,0BAAPpP,OAAiCyR,GAE9B1I,MAAM,0BAAD/I,OAA2ByR,IAAcI,KAAMlN,GAAQA,EAAIsK,OAC3E,CACA,MAAM,IAAI3M,EAAmC,8DACjD,GE6DI6M,eAAgB,IFtIjB,cAAyClL,EAC5C5C,WAAAA,GACIE,MAAM,WAAYmM,EACtB,CACAjK,cAAAA,CAAeP,GAAQ,IAAAqS,EACnB,MAAM5L,EAAUpI,MAAMkC,eAAeP,GAC/BsQ,EAAkB7J,EAAQ6J,gBAOhC,MAN8B,iBAAX,OAAfA,QAAe,IAAfA,OAAe,EAAfA,EAAiB/C,OAAyC,OAAf+C,QAAe,IAAfA,GAA4B,QAAb+B,EAAf/B,EAAiBG,mBAAW,IAAA4B,GAA5BA,EAA8B3B,SACzEjK,EAAQ6J,gBAAkB,CACtB/C,KAAM,cACNmD,OAAQJ,EAAgBG,YAAYC,SAGrCjK,CACX,GEyHI,kBAAmB,IFvHpB,cAAyCjF,EAC5CrD,WAAAA,GACIE,MAAM,WAAYmM,EACtB,CACAjK,cAAAA,CAAeP,GACX,OAAAlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,CACIkC,MAAOhB,EAAOgB,OACXhB,EAAOG,MAAI,IACd+J,OAAQlK,EAAOG,KAAKgK,QAE5B,CACA,iBAAMlJ,CAAYC,GACd,GAAwB,kBAAbA,GACP,YAAaA,GACb3B,MAAMC,QAAgB,OAAR0B,QAAQ,IAARA,OAAQ,EAARA,EAAUC,UACG,kBAAZ,OAARD,QAAQ,IAARA,OAAQ,EAARA,EAAUF,OAAoB,CAErC,MAAO,CACHY,eAFeV,EAASC,QAAQ,GAELkF,KAEnC,CACA,MAAM,IAAIjH,EAAmC,gEACjD,IEmGApB,UAAW,CACP,gBAAiB,IDxDlB,cAAyCkN,GAC5C/M,WAAAA,GACIE,MAAMoM,EACV,GCsDI,gBAAiB,IDpDlB,cAAyCS,GAC5C/M,WAAAA,GACIE,MAAMoM,EACV,GCkDI,iBAAkB,IDhDnB,cAA0CS,GAC7C/M,WAAAA,GACIE,MAAMoM,EACV,CACA,yBAAM2C,CAAoBjN,GAAM,IAAAmS,EAAAC,EAAAC,EAC5B,MAAM7H,EAAuB,QAAd2H,EAAGnS,EAAK6K,cAAM,IAAAsH,EAAAA,EAAmB,QAAnBC,EAAIpS,EAAK8J,kBAAU,IAAAsI,OAAA,EAAfA,EAAiBvH,QAC5C,KAAEJ,EAAI,OAAEI,SAAiBN,GAAiBvK,EAAKgK,OAAQQ,GAC7D,OAAA7L,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAYqB,GAAI,IAAEgK,OAAuB,QAAjBqI,EAAErS,EAAK8J,kBAAU,IAAAuI,OAAA,EAAfA,EAAiBtI,OAAQuC,MAAO7B,EAAMI,UACpE,GCyCI,iBAAkB,IDvCnB,cAA0CE,GAC7C/M,WAAAA,GACIE,MAAMoM,EACV,CACA,yBAAM2C,CAAoBjN,GAAM,IAAAsS,EAAAC,EAAAC,EAC5B,MAAMhI,EAAuB,QAAd8H,EAAGtS,EAAK6K,cAAM,IAAAyH,EAAAA,EAAmB,QAAnBC,EAAIvS,EAAK8J,kBAAU,IAAAyI,OAAA,EAAfA,EAAiB1H,QAC5C,KAAEJ,EAAI,OAAEI,SAAiBN,GAAiBvK,EAAKgK,OAAQQ,GAC7D,OAAA7L,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAYqB,GAAI,IAAEgK,OAAuB,QAAjBwI,EAAExS,EAAK8J,kBAAU,IAAA0I,OAAA,EAAfA,EAAiBzI,OAAQuC,MAAO7B,EAAMI,UACpE,ICiCA,UAAW,CACPiB,eAAgB,IUlIjB,cAAoClL,EACvC5C,WAAAA,GACIE,MAAM,UAHW,mBAIrB,CACAuC,cAAAA,CAAeZ,EAAQqI,GACnB,MAAMtJ,EAAUV,MAAMuC,eAAeZ,EAAQqI,GAG7C,OAFAtJ,EAAQ,oBAAsB,eAC9BA,EAAQ,mBAAqB,WACtBA,CACX,CACA2B,SAAAA,GACI,MAAO,+BACX,KVyHG,SAASkS,GAAkBlT,EAAUmE,GACxC,GAAkB,iBAAbnE,IAAgCmE,GAAsB,SAAbnE,EAC1C,OAAO,IAAIkQ,EAEf,IAAK/L,EACD,MAAM,IAAIrF,EAA0B,yFAExC,KAAMkB,KAAYsM,IACd,MAAM,IAAIxN,EAA0B,aAAD1B,OAAc4C,EAAQ,0CAAA5C,OAAyCqG,OAAOK,KAAKwI,MAElH,MAAM6G,EAAgB7G,GAAUtM,GAChC,IAAKmT,KAAmBhP,KAAQgP,GAC5B,MAAM,IAAIrU,EAA0B,SAAD1B,OAAU+G,EAAI,kCAAA/G,OAAiC4C,EAAQ,wBAAA5C,OAAuBqG,OAAOK,KAAkB,OAAbqP,QAAa,IAAbA,EAAAA,EAAiB,CAAC,KAEnJ,OAAOA,EAAchP,EACzB,CWtKA,SAASiP,GAAeC,EAAGC,GACzB1U,KAAKuE,EAAIkQ,EAAGzU,KAAK2U,EAAID,CACvB,CCDA,SAASE,GAAoBH,GAC3B,OAAO,WACL,OAAO,IAAII,GAAeJ,EAAEK,MAAM9U,KAAMuB,WAC1C,CACF,CACA,SAASsT,GAAeJ,GACtB,IAAIb,EAAGmB,EACP,SAASC,EAAOpB,EAAGmB,GACjB,IACE,IAAIE,EAAIR,EAAEb,GAAGmB,GACXrQ,EAAIuQ,EAAEtI,MACNuI,EAAIxQ,aAAa,GACnB6E,QAAQC,QAAQ0L,EAAIxQ,EAAEH,EAAIG,GAAG2L,KAAK,SAAU0E,GAC1C,GAAIG,EAAG,CACL,IAAIC,EAAI,WAAavB,EAAI,SAAW,OACpC,IAAKlP,EAAEiQ,GAAKI,EAAEK,KAAM,OAAOJ,EAAOG,EAAGJ,GACrCA,EAAIN,EAAEU,GAAGJ,GAAGpI,KACd,CACA0I,EAAOJ,EAAEG,KAAO,SAAW,SAAUL,EACvC,EAAG,SAAUN,GACXO,EAAO,QAASP,EAClB,EACF,CAAE,MAAOA,GACPY,EAAO,QAASZ,EAClB,CACF,CACA,SAASY,EAAOZ,EAAGQ,GACjB,OAAQR,GACN,IAAK,SACHb,EAAEpK,QAAQ,CACRmD,MAAOsI,EACPG,MAAM,IAER,MACF,IAAK,QACHxB,EAAE0B,OAAOL,GACT,MACF,QACErB,EAAEpK,QAAQ,CACRmD,MAAOsI,EACPG,MAAM,KAGXxB,EAAIA,EAAE2B,MAAQP,EAAOpB,EAAE4B,IAAK5B,EAAE6B,KAAOV,EAAI,IAC5C,CACA/U,KAAK0V,QAAU,SAAUjB,EAAGQ,GAC1B,OAAO,IAAI1L,QAAQ,SAAU7E,EAAGwQ,GAC9B,IAAIC,EAAI,CACNK,IAAKf,EACLgB,IAAKR,EACLzL,QAAS9E,EACT4Q,OAAQJ,EACRK,KAAM,MAERR,EAAIA,EAAIA,EAAEQ,KAAOJ,GAAKvB,EAAImB,EAAII,EAAGH,EAAOP,EAAGQ,GAC7C,EACF,EAAG,mBAAqBR,EAAU,SAAMzU,KAAa,YAAI,EAC3D,CCzDA,SAAS2V,GAAqBlB,GAC5B,OAAO,IAAI,GAAcA,EAAG,EAC9B,CCFA,SAASmB,GAAwBb,GAC/B,IAAIN,EAAI,CAAC,EACPQ,GAAI,EACN,SAASY,EAAKpB,EAAGb,GACf,OAAOqB,GAAI,EAAIrB,EAAI,IAAIrK,QAAQ,SAAU0L,GACvCA,EAAEF,EAAEN,GAAGb,GACT,GAAI,CACFwB,MAAM,EACNzI,MAAO,IAAI,GAAciH,EAAG,GAEhC,CACA,OAAOa,EAAE,oBAAsBqB,QAAUA,OAAOC,UAAY,cAAgB,WAC1E,OAAO/V,IACT,EAAGyU,EAAEc,KAAO,SAAUR,GACpB,OAAOE,GAAKA,GAAI,EAAIF,GAAKc,EAAK,OAAQd,EACxC,EAAG,mBAAqBA,EAAS,QAAMN,EAAS,MAAI,SAAUM,GAC5D,GAAIE,EAAG,MAAMA,GAAI,EAAIF,EACrB,OAAOc,EAAK,QAASd,EACvB,GAAI,mBAAqBA,EAAU,SAAMN,EAAU,OAAI,SAAUM,GAC/D,OAAOE,GAAKA,GAAI,EAAIF,GAAKc,EAAK,SAAUd,EAC1C,GAAIN,CACN,CCtBA,SAASuB,GAAepC,GACtB,IAAIqB,EACFF,EACArQ,EACA+P,EAAI,EACN,IAAK,oBAAsBqB,SAAWf,EAAIe,OAAOG,cAAevR,EAAIoR,OAAOC,UAAWtB,KAAM,CAC1F,GAAIM,GAAK,OAASE,EAAIrB,EAAEmB,IAAK,OAAOE,EAAEiB,KAAKtC,GAC3C,GAAIlP,GAAK,OAASuQ,EAAIrB,EAAElP,IAAK,OAAO,IAAIyR,GAAsBlB,EAAEiB,KAAKtC,IACrEmB,EAAI,kBAAmBrQ,EAAI,YAC7B,CACA,MAAM,IAAI0R,UAAU,+BACtB,CACA,SAASD,GAAsBvC,GAC7B,SAASyC,EAAkCzC,GACzC,GAAI/O,OAAO+O,KAAOA,EAAG,OAAOrK,QAAQ+L,OAAO,IAAIc,UAAUxC,EAAI,uBAC7D,IAAIqB,EAAIrB,EAAEwB,KACV,OAAO7L,QAAQC,QAAQoK,EAAEjH,OAAO0D,KAAK,SAAUuD,GAC7C,MAAO,CACLjH,MAAOiH,EACPwB,KAAMH,EAEV,EACF,CACA,OAAOkB,GAAwB,SAA+BvC,GAC5D5T,KAAKsW,EAAI1C,EAAG5T,KAAKiV,EAAIrB,EAAE2B,IACzB,EAAGY,GAAsBI,UAAY,CACnCD,EAAG,KACHrB,EAAG,KACHM,KAAM,WACJ,OAAOc,EAAkCrW,KAAKiV,EAAEH,MAAM9U,KAAKsW,EAAG/U,WAChE,EACA,OAAU,SAAiBqS,GACzB,IAAIqB,EAAIjV,KAAKsW,EAAU,OACvB,YAAO,IAAWrB,EAAI1L,QAAQC,QAAQ,CACpCmD,MAAOiH,EACPwB,MAAM,IACHiB,EAAkCpB,EAAEH,MAAM9U,KAAKsW,EAAG/U,WACzD,EACA,MAAS,SAAgBqS,GACvB,IAAIqB,EAAIjV,KAAKsW,EAAU,OACvB,YAAO,IAAWrB,EAAI1L,QAAQ+L,OAAO1B,GAAKyC,EAAkCpB,EAAEH,MAAM9U,KAAKsW,EAAG/U,WAC9F,GACC,IAAI4U,GAAsBvC,EAC/B,CHgBAiB,GAAe0B,UAAU,mBAAqBT,QAAUA,OAAOG,eAAiB,mBAAqB,WACnG,OAAOjW,IACT,EAAG6U,GAAe0B,UAAUhB,KAAO,SAAUd,GAC3C,OAAOzU,KAAK0V,QAAQ,OAAQjB,EAC9B,EAAGI,GAAe0B,UAAiB,MAAI,SAAU9B,GAC/C,OAAOzU,KAAK0V,QAAQ,QAASjB,EAC/B,EAAGI,GAAe0B,UAAkB,OAAI,SAAU9B,GAChD,OAAOzU,KAAK0V,QAAQ,SAAUjB,EAChC,EIlEO,M,oDCQP,IAAI+B,GAAQ,KAKL5P,eAAe6P,GAAmB5U,EAAM6U,EAAgB3P,GAC3D,MAAQrE,MAAOiU,GAAe9U,EACxBT,EAAWsV,EAAetV,UAC1B,KAAEmE,GAAgB,OAAPwB,QAAO,IAAPA,EAAAA,EAAW,CAAC,EAE7B,GAAIlF,EAAKoH,aAA4B,iBAAb7H,EACpB,MAAM,IAAIlB,EAA0B,uDAExC,GAAIyW,GAAcjN,EAAMiN,GACpB,MAAM,IAAIzW,EAA0B,gEAExC,GAAI2B,EAAKoH,YAEL,OAAO2N,GAA8C,OAAVD,QAAU,IAAVA,EAAAA,EAAc9U,EAAKoH,YAAayN,EAAgB7U,OAAMlB,EAAWoG,GAEhH,IAAK4P,IAAepR,EAChB,MAAM,IAAIrF,EAA0B,sDAGxC,MAAM2W,EAAoB,OAAVF,QAAU,IAAVA,EAAAA,QAsGpB/P,eAAgCrB,GAAM,IAAAuR,EAC7BN,KACDA,SAQR5P,iBACI,MAAMS,EAAM,GAAH7I,OAAMH,EAAU,cACnB8E,QAAYoE,MAAMF,GACX,IAAA0P,EAAb,IAAK5T,EAAIqE,GACL,MAAM,IAAI3G,EAA2B,0DAA2D,CAAEwG,MAAKM,OAAQ,OAAS,CAAEC,UAA0C,QAAjCmP,EAAE5T,EAAI1C,QAAQyG,IAAI,uBAAe,IAAA6P,EAAAA,EAAI,GAAIlP,OAAQ1E,EAAI0E,OAAQC,WAAY3E,EAAI4E,SAEpN,aAAa5E,EAAI8E,MACrB,CAfsB+O,IAElB,MAAMC,EAAWT,GAAMjR,GACvB,IAA4B,QAAxBuR,EAAS,OAARG,QAAQ,IAARA,OAAQ,EAARA,EAAUC,OAAO1V,cAAM,IAAAsV,EAAAA,EAAI,IAAM,EAClC,MAAM,IAAI5W,EAA0B,qCAAD1B,OAAsC+G,EAAI,0CAEjF,OAAO0R,EAASC,OAAO,GAAGnU,EAC9B,CA/GyCoU,CAAiB5R,GACtD,GAAImR,EAAepV,wBAA0BqV,EACzC,MAAM,IAAIzW,EAA0B,YAAD1B,OAAa4C,EAAQ,gDAE5D,MAAM4F,EAA2B0P,EAAepV,sBAC1C,CACEF,SAAUA,EAEVuH,WAAYyO,GAAqBT,EAAYvV,GAE7CsH,UAAWiO,EACX9O,OAAQ,OAERtC,KAAMA,ShCuBXqB,eAA2ClF,EAAQqF,GACtD,MAAMmC,EAASzC,IACf,GAAwB,SAApB/E,EAAON,UAAuC,mBAAhBM,EAAO6D,KAGrC,MAAO,CACHmD,UAAWhH,EAAOoF,QAClB1F,SAAU,OACVuH,WAAYjH,EAAOoF,QACnBe,OAAQ,OACRtC,KAAM,kBAGd,GAAI9G,EAAkCiD,EAAON,UAAUM,EAAOoF,SAC1D,OAAOrI,EAAkCiD,EAAON,UAAUM,EAAOoF,SAErE,MACMuQ,SADiBxQ,EAAsCnF,EAAOoF,QAASpF,EAAOc,YAAauE,IAChEuQ,KAAM7O,GAAYA,EAAQrH,WAAaM,EAAON,UAC/E,GAAIiW,EAAiB,CACjB,MAAME,EAAsC,iBAApB7V,EAAON,UAA+BkD,EAAac,EAAwC1D,EAAO6D,MACpHH,EACA,CAAC1D,EAAO6D,MACd,IAAKjB,EAAaiT,EAAiBF,EAAgB9R,MAC/C,MAAM,IAAIrF,EAA0B,SAAD1B,OAAUkD,EAAOoF,QAAO,+BAAAtI,OAA8BkD,EAAO6D,KAAI,kBAAA/G,OAAiBkD,EAAON,SAAQ,sBAAA5C,OAAqB6Y,EAAgB9R,KAAI,MAKjL,MAH+B,YAA3B8R,EAAgBxP,QAChBqB,EAAOsO,KAAK,SAADhZ,OAAUkD,EAAOoF,QAAO,qCAAAtI,OAAoCkD,EAAON,SAAQ,oCAEnFiW,CACX,CACA,OAAO,IACX,CgCpDgBI,CAA4B,CAChC3Q,QAAS+P,EAETtR,KAAMA,EACNnE,WACAoB,YAAaX,EAAKW,aACnB,CAAE+E,MAAc,OAAPR,QAAO,IAAPA,OAAO,EAAPA,EAASQ,QACzB,IAAKP,EACD,MAAM,IAAI9G,EAA0B,0EAAD1B,OAA2EqY,EAAO,MAGzH,OAAOD,GAAoC5P,EAAyB2B,WAAY+N,EAAgB7U,EAAMmF,EAA0BD,EACpI,CAKO,SAAS6P,GAAoCc,EAAehB,EAAgB7U,EAAM4G,EAAS1B,GAC9F,MAAM,YAAEvE,EAAW,YAAEyG,EAAa7H,SAAUuW,EAAa,MAAEjV,GAA4Bb,EAAlB+V,GAAajF,EAAAA,EAAAA,GAAK9Q,EAAI+Q,IAGrFxR,EAAWsV,EAAetV,UAC1B,mBAAEyW,EAAkB,KAAEtS,EAAI,OAAEuS,EAAM,OAAEC,GAAkB,OAAPhR,QAAO,IAAPA,EAAAA,EAAW,CAAC,EAC3DpF,EAAa,MACf,GAAI+U,EAAepV,uBAEXkB,GAAeA,EAAY8C,WAAW,OACtC,MAAM,IAAIpF,EAA0B,YAAD1B,OAAa4C,EAAQ,sDAGhE,OAAIoB,EACOA,EAAY8C,WAAW,OAAS,WAAa,eAE7B,YAAvBuS,EAEO,sBAEJ,MACV,EAfkB,GAiBb/Q,EAAqB,OAAXmC,QAAW,IAAXA,EAAAA,EAAeyO,EACzBrQ,EAAMqP,EAAexU,QAAQ,CAC/BP,aACAe,MAAOoE,EACPvB,SAGE9E,EAAUiW,EAAepU,eAAe,CAC1CE,cACAb,cACD,SAAUE,KAAUA,EAAKC,MACxBiW,IACAtX,E3CjG2B,gB2CiGIsX,GAInC,MACMC,EAAY,CADG,GAAHxZ,ODtGM,yBCsGY,KAAAA,ODvGT,UCwG2B,qBAAdyZ,UAA4BA,UAAUD,eAAYrX,GACrFwE,OAAQ9B,QAAY1C,IAAN0C,GACdgB,KAAK,KACV5D,EAAQ,cAAgBuX,EAExB,MAAMlQ,EAAO4O,EAAe9U,SAAS,CACjCC,KAAM+V,EACNlV,MAAOgV,EACPnS,OACAkD,YAKJ,IAAIyP,EAC8B,kBAAvBL,EACPK,EAAcL,GAEc,IAAvBA,IACLK,EAAc,WASlB,MAAO,CAAE7Q,MAAK8Q,MAPJ3X,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,CACNC,UACAkH,OAAQ,OACRG,KAAMA,GACFoQ,EAAc,CAAEA,oBAAgBvX,GAAS,IAC7CmX,WAGR,CAmBA,SAASV,GAAqB1U,EAAOtB,GACjC,IAAKsB,EAAM4C,WAAW,GAAD9G,OAAI4C,EAAQ,MAC7B,MAAM,IAAIlB,EAA0B,eAAD1B,OAAgB4C,EAAQ,0BAAA5C,OAAyB4C,EAAQ,aAAA5C,OAAYkE,EAAK,OAEjH,OAAOA,EAAM0V,MAAMhX,EAASI,OAAS,EACzC,CC3GO,SAAS6W,GAASC,GACrB,IAAIC,EACAC,EACAC,EACAC,GAAyB,EAE7B,OAAO,SAAiBjV,QACL9C,IAAX4X,GACAA,EAAS9U,EACT+U,EAAW,EACXC,GAAe,GAIfF,EAiGZ,SAAgBI,EAAGC,GACf,MAAMzV,EAAM,IAAIoJ,WAAWoM,EAAEnX,OAASoX,EAAEpX,QAGxC,OAFA2B,EAAI4F,IAAI4P,GACRxV,EAAI4F,IAAI6P,EAAGD,EAAEnX,QACN2B,CACX,CAtGqB3E,CAAO+Z,EAAQ9U,GAE5B,MAAMoV,EAAYN,EAAO/W,OACzB,IAAIsX,EAAY,EAChB,KAAON,EAAWK,GAAW,CACrBH,IACyB,KAArBH,EAAOC,KACPM,IAAcN,GAElBE,GAAyB,GAG7B,IAAIK,GAAW,EACf,KAAOP,EAAWK,IAA0B,IAAbE,IAAkBP,EAC7C,OAAQD,EAAOC,IACX,KAAK,IACoB,IAAjBC,IACAA,EAAcD,EAAWM,GAE7B,MACJ,KAAK,GACDJ,GAAyB,EAE7B,KAAK,GACDK,EAAUP,EAItB,IAAiB,IAAbO,EAGA,MAGJT,EAAOC,EAAOS,SAASF,EAAWC,GAAUN,GAC5CK,EAAYN,EACZC,GAAe,CACnB,CACIK,IAAcD,EACdN,OAAS5X,EAEU,IAAdmY,IAGLP,EAASA,EAAOS,SAASF,GACzBN,GAAYM,EAEpB,CACJ,CC9GA,SAASG,GAAWnR,GAChB,IAAIhG,EAAO,KACX,GAAIgG,aAAgBkH,MAAQlH,aAAgB0E,YACxC1K,EAAO,6BAEN,GAAoB,kBAATgG,EACZ,IACIhG,EAAOC,KAAKmX,MAAMpR,EACtB,CACA,MAAAM,GACItG,EAAOgG,CACX,CAKJ,OAHIhG,EAAKU,cACLV,EAAKU,YAAc,cAEhBV,CACX,CAIO8E,eAAeuS,GAAatX,EAAM6U,EAAgB3P,GAAS,IAAAI,EAAAiS,EAC9D,MAAM,IAAE/R,EAAG,KAAE8Q,SAAe1B,GAAmB5U,EAAM6U,EAAgB3P,GAC/DnE,QAAgC,QAAfuE,EAAQ,OAAPJ,QAAO,IAAPA,OAAO,EAAPA,EAASQ,aAAK,IAAAJ,EAAAA,EAAII,OAAOF,EAAK8Q,GAChDkB,EAAiB,CAAEhS,MAAK8Q,QAC9B,IAAgC,KAArB,OAAPpR,QAAO,IAAPA,OAAO,EAAPA,EAASuS,iBAAgD,MAApB1W,EAASiF,OAC9C,OAAOsR,GAAatX,EAAM6U,EAAgB3P,GAE9C,IAAKnE,EAAS4E,GAAI,KAAA+R,EAAAC,EACd,MAAMnK,EAAczM,EAASnC,QAAQyG,IAAI,gBACzC,GAAI,CAAC,mBAAoB,4BAA4BuS,KAAMC,GAAkB,OAAXrK,QAAW,IAAXA,OAAW,EAAXA,EAAa/J,WAAWoU,IAAM,CAC5F,MAAMvJ,QAAevN,EAASqF,OACiD,IAAA0R,EAAAC,EAQkCpR,EAAAqR,EAAAC,EAAAC,EAQ5GC,EAAAC,EAhBL,GAAI,CAAC,IAAK,IAAK,IAAK,KAAKzV,SAAS5B,EAASiF,SAAkB,OAAPd,QAAO,IAAPA,GAAAA,EAASmT,eAC3D,MAAM,IAAItZ,EAAgC,YAADpC,OAAaqD,EAAKT,SAAQ,wDAAA5C,OAAuDqD,EAAKa,MAAK,cAAAlE,OAAauD,KAAKC,UAAUmO,EAAOnI,QAAU,CAC7KX,MACAM,OAAmB,QAAbgS,EAAExB,EAAKxQ,cAAM,IAAAgS,EAAAA,EAAI,MACvBlZ,QAAS0X,EAAK1X,QACdqH,KAAMmR,GAAWd,EAAKrQ,OACvB,CAAEF,UAA+C,QAAtCgS,EAAEhX,EAASnC,QAAQyG,IAAI,uBAAe,IAAA0S,EAAAA,EAAI,GAAI/R,OAAQjF,EAASiF,OAAQC,KAAMqI,IAE/F,GAA4B,kBAAjBA,EAAOnI,OAA+C,kBAAlBmI,EAAOgK,QAAiD,kBAAnBhK,EAAOrQ,QACvF,MAAM,IAAIc,EAAgC,gCAADpC,OAA8D,QAA9DgK,EAA6C,QAA7CqR,EAAiC1J,EAAOnI,aAAK,IAAA6R,EAAAA,EAAI1J,EAAOgK,cAAM,IAAA3R,EAAAA,EAAI2H,EAAOrQ,SAAW,CACzHuH,MACAM,OAAmB,QAAbmS,EAAE3B,EAAKxQ,cAAM,IAAAmS,EAAAA,EAAI,MACvBrZ,QAAS0X,EAAK1X,QACdqH,KAAMmR,GAAWd,EAAKrQ,OACvB,CAAEF,UAA+C,QAAtCmS,EAAEnX,EAASnC,QAAQyG,IAAI,uBAAe,IAAA6S,EAAAA,EAAI,GAAIlS,OAAQjF,EAASiF,OAAQC,KAAMqI,IAG3F,MAAM,IAAIvP,EAAgC,oFAAqF,CAC3HyG,MACAM,OAAmB,QAAbqS,EAAE7B,EAAKxQ,cAAM,IAAAqS,EAAAA,EAAI,MACvBvZ,QAAS0X,EAAK1X,QACdqH,KAAMmR,GAAWd,EAAKrQ,OACvB,CAAEF,UAA+C,QAAtCqS,EAAErX,EAASnC,QAAQyG,IAAI,uBAAe,IAAA+S,EAAAA,EAAI,GAAIpS,OAAQjF,EAASiF,OAAQC,KAAMqI,GAEnG,CACA,MAAMrQ,EAAqB,OAAXuP,QAAW,IAAXA,GAAAA,EAAa/J,WAAW,qBAAuB1C,EAASmF,YAASpH,EACjF,MAAM,IAAIC,EAAgC,gCAADpC,OAAwC,OAAPsB,QAAO,IAAPA,EAAAA,EAAW,uDAAyD,CAC1IuH,MACAM,OAAmB,QAAb4R,EAAEpB,EAAKxQ,cAAM,IAAA4R,EAAAA,EAAI,MACvB9Y,QAAS0X,EAAK1X,QACdqH,KAAMmR,GAAWd,EAAKrQ,OACvB,CAAEF,UAA+C,QAAtC4R,EAAE5W,EAASnC,QAAQyG,IAAI,uBAAe,IAAAsS,EAAAA,EAAI,GAAI3R,OAAQjF,EAASiF,OAAQC,KAAa,OAAPhI,QAAO,IAAPA,EAAAA,EAAW,IAC1G,CACA,GAAwC,QAAxCsZ,EAAIxW,EAASnC,QAAQyG,IAAI,uBAAe,IAAAkS,GAApCA,EAAsC9T,WAAW,oBAAqB,CAEtE,MAAO,CAAExD,WADWc,EAASqF,OACdoR,iBACnB,CAEA,MAAO,CAAEvX,WADWc,EAAS6K,OACR4L,iBACzB,CAIO,SAAgBe,GAAqBC,EAAAC,EAAAC,GAAA,OAAAC,GAAA1F,MAAC,KAADvT,UAAA,CA4G3C,SAAAiZ,KAAA,OAAAA,GAAA5F,GA5GM,UAAsC/S,EAAM6U,EAAgB3P,GAAS,IAAA0T,EAAAC,EACxE,MAAM,IAAErT,EAAG,KAAE8Q,SAAMxC,GAASc,IAAkBjW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAC,CAAC,EAAIqB,GAAI,IAAE8Y,QAAQ,IAAQjE,EAAgB3P,IACpFnE,QAAQ+S,IAAwB,QAAf8E,EAAQ,OAAP1T,QAAO,IAAPA,OAAO,EAAPA,EAASQ,aAAK,IAAAkT,EAAAA,EAAIlT,OAAOF,EAAK8Q,IACtD,IAAgC,KAArB,OAAPpR,QAAO,IAAPA,OAAO,EAAPA,EAASuS,iBAAgD,MAApB1W,EAASiF,OAC9C,aAAO+N,GAAAI,GAAOoE,GAAsBvY,EAAM6U,EAAgB3P,KAE9D,IAAKnE,EAAS4E,GAAI,KAAAoT,EAAAC,EAAAC,EACd,GAAwC,QAAxCF,EAAIhY,EAASnC,QAAQyG,IAAI,uBAAe,IAAA0T,GAApCA,EAAsCtV,WAAW,oBAAqB,CACtE,MAAM6K,QAAMwF,GAAS/S,EAASqF,QACiD,IAAA8S,EAAAC,EAQzCC,EAAAC,EAQqDC,EAAAC,EAUnDC,EAAAC,EA1BxC,GAAI,CAAC,IAAK,IAAK,IAAK,KAAK9W,SAAS5B,EAASiF,SAAkB,OAAPd,QAAO,IAAPA,GAAAA,EAASmT,eAC3D,MAAM,IAAItZ,EAAgC,YAADpC,OAAaqD,EAAKT,SAAQ,wDAAA5C,OAAuDqD,EAAKa,MAAK,cAAAlE,OAAauD,KAAKC,UAAUmO,EAAOnI,QAAU,CAC7KX,MACAM,OAAmB,QAAboT,EAAE5C,EAAKxQ,cAAM,IAAAoT,EAAAA,EAAI,MACvBta,QAAS0X,EAAK1X,QACdqH,KAAMmR,GAAWd,EAAKrQ,OACvB,CAAEF,UAA+C,QAAtCoT,EAAEpY,EAASnC,QAAQyG,IAAI,uBAAe,IAAA8T,EAAAA,EAAI,GAAInT,OAAQjF,EAASiF,OAAQC,KAAMqI,IAE/F,GAA4B,kBAAjBA,EAAOnI,MACd,MAAM,IAAIpH,EAAgC,gCAADpC,OAAiC2R,EAAOnI,OAAS,CACtFX,MACAM,OAAmB,QAAbsT,EAAE9C,EAAKxQ,cAAM,IAAAsT,EAAAA,EAAI,MACvBxa,QAAS0X,EAAK1X,QACdqH,KAAMmR,GAAWd,EAAKrQ,OACvB,CAAEF,UAA+C,QAAtCsT,EAAEtY,EAASnC,QAAQyG,IAAI,uBAAe,IAAAgU,EAAAA,EAAI,GAAIrT,OAAQjF,EAASiF,OAAQC,KAAMqI,IAE/F,GAAIA,EAAOnI,OAAS,YAAamI,EAAOnI,OAAyC,kBAAzBmI,EAAOnI,MAAMlI,QAEjE,MAAM,IAAIc,EAAgC,gCAADpC,OAAiC2R,EAAOnI,MAAMlI,SAAW,CAC9FuH,MACAM,OAAmB,QAAbwT,EAAEhD,EAAKxQ,cAAM,IAAAwT,EAAAA,EAAI,MACvB1a,QAAS0X,EAAK1X,QACdqH,KAAMmR,GAAWd,EAAKrQ,OACvB,CAAEF,UAA+C,QAAtCwT,EAAExY,EAASnC,QAAQyG,IAAI,uBAAe,IAAAkU,EAAAA,EAAI,GAAIvT,OAAQjF,EAASiF,OAAQC,KAAMqI,IAG/F,GAA8B,kBAAnBA,EAAOrQ,QACd,MAAM,IAAIc,EAAgC,gCAADpC,OAAiC2R,EAAOrQ,SAAW,CACxFuH,MACAM,OAAmB,QAAb0T,EAAElD,EAAKxQ,cAAM,IAAA0T,EAAAA,EAAI,MACvB5a,QAAS0X,EAAK1X,QACdqH,KAAMmR,GAAWd,EAAKrQ,OACvB,CAAEF,UAA+C,QAAtC0T,EAAE1Y,EAASnC,QAAQyG,IAAI,uBAAe,IAAAoU,EAAAA,EAAI,GAAIzT,OAAQjF,EAASiF,OAAQC,KAAMqI,GAEnG,CACA,MAAM,IAAIvP,EAAgC,oFAAqF,CAC3HyG,MACAM,OAAmB,QAAbkT,EAAE1C,EAAKxQ,cAAM,IAAAkT,EAAAA,EAAI,MACvBpa,QAAS0X,EAAK1X,QACdqH,KAAMmR,GAAWd,EAAKrQ,OACvB,CAAEF,UAA+C,QAAtCkT,EAAElY,EAASnC,QAAQyG,IAAI,uBAAe,IAAA4T,EAAAA,EAAI,GAAIjT,OAAQjF,EAASiF,OAAQC,KAAM,IAC/F,CAC4E,IAAAyT,EAAAC,EAA5E,GAAyC,QAArCd,EAAC9X,EAASnC,QAAQyG,IAAI,uBAAe,IAAAwT,IAApCA,EAAsCpV,WAAW,qBAClD,MAAM,IAAI1E,EAAgC,+FACtCgC,EAASnC,QAAQyG,IAAI,gBAAiB,CACtCG,MACAM,OAAmB,QAAb4T,EAAEpD,EAAKxQ,cAAM,IAAA4T,EAAAA,EAAI,MACvB9a,QAAS0X,EAAK1X,QACdqH,KAAMmR,GAAWd,EAAKrQ,OACvB,CAAEF,UAA+C,QAAtC4T,EAAE5Y,EAASnC,QAAQyG,IAAI,uBAAe,IAAAsU,EAAAA,EAAI,GAAI3T,OAAQjF,EAASiF,OAAQC,KAAM,KAE/F,IAAKlF,EAASkF,KACV,OAEJ,MAAM2T,EAAS7Y,EAASkF,KAAK4T,YAC7B,IAAIC,EAAS,GACb,MAIMC,EAAUvD,GD1Bb,SAAqBwD,EAAMC,EAASC,GACvC,IAAIjc,EAmDG,CACHgC,KAAM,GACNka,MAAO,GACPjZ,GAAI,GACJkZ,WAAOtb,GAtDX,MAAMub,EAAU,IAAIC,YAEpB,OAAO,SAAgBC,EAAM3D,GACzB,GAAoB,IAAhB2D,EAAK5a,OAEI,OAATua,QAAS,IAATA,GAAAA,EAAYjc,GACZA,EA4CD,CACHgC,KAAM,GACNka,MAAO,GACPjZ,GAAI,GACJkZ,WAAOtb,QA9CF,GAAI8X,EAAc,EAAG,CAGtB,MAAM4D,EAAQH,EAAQI,OAAOF,EAAKpD,SAAS,EAAGP,IACxC8D,EAAc9D,GAAyC,KAA1B2D,EAAK3D,EAAc,GAAqC,EAAI,GACzF9L,EAAQuP,EAAQI,OAAOF,EAAKpD,SAASuD,IAC3C,OAAQF,GACJ,IAAK,OAGDvc,EAAQgC,KAAOhC,EAAQgC,KACjBhC,EAAQgC,KAAO,KAAO6K,EACtBA,EACN,MACJ,IAAK,QACD7M,EAAQkc,MAAQrP,EAChB,MACJ,IAAK,KACDkP,EAAK/b,EAAQiD,GAAK4J,GAClB,MACJ,IAAK,QAAS,CACV,MAAMsP,EAAQO,SAAS7P,EAAO,IACzB8P,MAAMR,IACPH,EAAQhc,EAAQmc,MAAQA,GAE5B,KACJ,EAER,CACJ,CACJ,CCd6BS,CAAY,OAAW,OAJ/BV,IAEbL,EAAO1X,KAAK+X,MAGhB,IACI,OAAa,CACT,MAAM,KAAE5G,EAAI,MAAEzI,SAAOgJ,GAAS8F,EAAOkB,QACrC,GAAIvH,EACA,OAEJwG,EAAQjP,GACR,IAAK,MAAMqP,KAASL,EAChB,GAAIK,EAAMla,KAAKN,OAAS,EAAG,CACvB,GAAmB,WAAfwa,EAAMla,KACN,OAEJ,MAAMA,EAAOC,KAAKmX,MAAM8C,EAAMla,MAC9B,GAAoB,kBAATA,GAA8B,OAATA,GAAiB,UAAWA,EAAM,KAAA8a,EAAAC,EAC9D,MAAMC,EAAiC,kBAAfhb,EAAKkG,MACvBlG,EAAKkG,MACiB,kBAAflG,EAAKkG,OACVlG,EAAKkG,OACL,YAAalG,EAAKkG,OACY,kBAAvBlG,EAAKkG,MAAMlI,QAChBgC,EAAKkG,MAAMlI,QACXiC,KAAKC,UAAUF,EAAKkG,OAC9B,MAAM,IAAIpH,EAAgC,0EAADpC,OAA2Ese,GAAY,CAC5HzV,MACAM,OAAmB,QAAbiV,EAAEzE,EAAKxQ,cAAM,IAAAiV,EAAAA,EAAI,MACvBnc,QAAS0X,EAAK1X,QACdqH,KAAMmR,GAAWd,EAAKrQ,OACvB,CAAEF,UAA+C,QAAtCiV,EAAEja,EAASnC,QAAQyG,IAAI,uBAAe,IAAA2V,EAAAA,EAAI,GAAIhV,OAAQjF,EAASiF,OAAQC,KAAMhG,GAC/F,OACMA,CACV,CAEJ6Z,EAAS,EACb,CACJ,CAAC,QAEGF,EAAOsB,aACX,CACJ,GAACvC,GAAA1F,MAAA,KAAAvT,UAAA,CClLMqF,eAAeoW,GAAQnb,EAAMkF,GACjBN,IACR+Q,KAAK,oIACZ,MACMd,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACb,OAAPlC,QAAO,IAAPA,OAAO,EAAPA,EAASxB,MAE5D,aADqB4T,GAAatX,EAAM6U,EAAgB3P,IAC1CjF,IAClB,CCPO,SAAgBmb,GAAgB5C,EAAAC,GAAA,OAAA4C,GAAApI,MAAC,KAADvT,UAAA,CAMtC,SAAA2b,KAAA,OAAAA,GAAAtI,GANM,UAAiC/S,EAAMkF,GAC3BN,IACR+Q,KAAK,6IACZ,MACMd,EAAiBpC,SADTqB,GAAS3M,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,cACb,OAAPlC,QAAO,IAAPA,OAAO,EAAPA,EAASxB,YAC5DqQ,GAAAI,GAAOoE,GAAsBvY,EAAM6U,EAAgB3P,IACvD,IAAC+N,MAAA,KAAAvT,UAAA,CCbM,SAASU,GAAeJ,GAC3B,MAAO,SAAUA,EACXA,GAAIrB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAECiE,EAAK5C,EAAM,WAAS,IACvBC,KAAMD,EAAKgK,QAEvB,CCAOjF,eAAeuW,GAAoBtb,EAAMkF,GAC5C,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,wBAC7Cd,EAAUlG,GAAeJ,IACvBC,KAAMqB,SAAcgW,GAAahR,EAASuO,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACzDuG,GAAO,IACVxB,KAAM,0BAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCTOyD,eAAewW,GAAavb,EAAMkF,GACrC,MAAMrE,EAAQ,WAAYb,EAAOA,EAAKa,WAAQ/B,EAExC+V,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUsB,GACH,kBAC7CyF,EAAUlG,GAAeJ,IACvBC,KAAMqB,SAAcgW,GAAahR,EAASuO,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACzDuG,GAAO,IACVxB,KAAM,oBAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCXOyD,eAAeyW,GAA2Bxb,EAAMkF,GACnD,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,gCAC7Cd,QAAgBuO,EAAe5H,oBAAoBjN,IACjDC,KAAMqB,SAAcgW,GAAahR,EAASuO,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACzDuG,GAAO,IACVxB,KAAM,kCAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCTOyD,eAAe0W,GAAazb,EAAMkF,GACrC,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,mBAC3CnH,KAAMqB,SAAcgW,GAAatX,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACtDuG,GAAO,IACVxB,KAAM,oBAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCdO,SAASlB,GAAeJ,GAC3B,MAAO,SAAUA,EAAOA,GAAIrB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAQiE,EAAK5C,EAAM,WAAS,IAAEC,KAAMD,EAAKgK,QACzE,CCKOjF,eAAe2W,GAAoB1b,EAAMkF,GAC5C,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,wBAC7Cd,EAAUlG,GAAeJ,IACvBC,KAAMqB,SAAcgW,GAAahR,EAASuO,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACzDuG,GAAO,IACVxB,KAAM,0BAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCTOyD,eAAe4W,GAAkB3b,EAAMkF,GAC1C,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,sBAC7Cd,QAAgBuO,EAAe5H,oBAAoBjN,IACjDC,KAAMqB,SAAcgW,GAAahR,EAASuO,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACzDuG,GAAO,IACVxB,KAAM,yBAEJ,IAAE8B,EAAG,KAAE8Q,SAAe1B,GAAmB5U,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAOuG,GAAO,IAAExB,KAAM,wBACzF,OAAOmR,EAAe/T,YAAYQ,EAAKkE,EAAK8Q,EAAK1X,QACrD,CCVOmG,eAAe6W,GAAa5b,EAAMkF,GACrC,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,kBAC7Cd,QAAgBuO,EAAe5H,oBAAoBjN,IACjDC,KAAMqB,SAAcgW,GAAahR,EAASuO,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACzDuG,GAAO,IACVxB,KAAM,qBAEJ,IAAE8B,EAAG,KAAE8Q,SAAe1B,GAAmB5U,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAOuG,GAAO,IAAExB,KAAM,oBACzF,OAAOmR,EAAe/T,YAAYQ,EAAKkE,EAAK8Q,EAAK1X,QACrD,CCXOmG,eAAe8W,GAAY7b,EAAMkF,GACpC,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,iBAC7Cd,EAAUlG,GAAeJ,IACvBC,KAAMqB,SAAcgW,GAAahR,EAASuO,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACzDuG,GAAO,IACVxB,KAAM,mBAEV,OAAOmR,EAAe/T,YAAYQ,EAAI,GAC1C,CCROyD,eAAe+W,GAAa9b,EAAMkF,GACrC,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,kBAC7Cd,QAAgBuO,EAAe5H,oBAAoBjN,IACjDC,KAAMqB,SAAcgW,GAAahR,EAASuO,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACzDuG,GAAO,IACVxB,KAAM,qBAEJ,IAAE8B,EAAG,KAAE8Q,SAAe1B,GAAmB5U,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAOuG,GAAO,IAAExB,KAAM,oBACzF,OAAOmR,EAAe/T,YAAYQ,EAAKkE,EAAK8Q,EAAK1X,QACrD,CCXOmG,eAAegX,GAAiB/b,EAAMkF,GACzC,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,uBAC7Cd,QAAgBuO,EAAe5H,oBAAoBjN,IACjDC,KAAMqB,EAAG,eAAEkW,SAAyBF,GAAahR,EAASuO,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACzEuG,GAAO,IACVxB,KAAM,yBAEV,OAAOmR,EAAe/T,YAAYQ,EAAKkW,EAAehS,IAAKgS,EAAelB,KAAK1X,QACnF,CCTOmG,eAAeiX,GAAiBhc,EAAMkF,GACzC,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,uBAC7Cd,QAAgBuO,EAAe5H,oBAAoBjN,IACjDC,KAAMqB,EAAG,eAAEkW,SAAyBF,GAAahR,EAASuO,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACzEuG,GAAO,IACVxB,KAAM,yBAEV,OAAOmR,EAAe/T,YAAYQ,EAAKkW,EAAehS,IAAKgS,EAAelB,KAAK1X,QACnF,CCROmG,eAAekX,GAAgBjc,EAAMkF,GACxC,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,oBAC7Cd,EAAUlG,GAAeJ,IACvBC,KAAMqB,SAAcgW,GAAahR,EAASuO,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACzDuG,GAAO,IACVxB,KAAM,sBAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCbOyD,eAAemX,GAAYlc,EAAMkF,GACpC,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,kBAC3CnH,KAAMqB,SAAcgW,GAAatX,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACtDuG,GAAO,IACVxB,KAAM,oBAEJ,IAAE8B,EAAG,KAAE8Q,SAAe1B,GAAmB5U,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAOuG,GAAO,IAAExB,KAAM,mBACzF,OAAOmR,EAAe/T,YAAYQ,EAAKkE,EAAK8Q,EAAK1X,QAAgB,OAAPsG,QAAO,IAAPA,OAAO,EAAPA,EAAS6G,WACvE,CCTOhH,eAAeoX,GAAYnc,EAAMkF,GACpC,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,kBAC3CnH,KAAMc,SAAmBuW,GAAatX,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAC3DuG,GAAO,IACVxB,KAAM,oBAEJ,IAAE8B,EAAG,KAAE8Q,SAAe1B,GAAmB5U,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAOuG,GAAO,IAAExB,KAAM,mBACzF,OAAOmR,EAAe/T,YAAYC,EAAUyE,EAAK8Q,EAAK1X,QAC1D,CCaOmG,eAAeqX,GAA4Bpc,EAAMkF,GACpD,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,kCAC7Cd,QAzBVvB,eAA8B/E,GAC1B,OAAIA,EAAKgK,kBAAkBmD,MACvBxO,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOqB,GAAI,IACPgK,OAAQ,CACJsC,MAAO3K,EAAgB,IAAI+I,iBAAiB1K,EAAKgK,OAAOY,oBAKhEjM,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOqB,GAAI,IACPgK,OAAQ,CACJsC,MAAO3K,EAAgB,IAAI+I,WAAW1K,EAAKgK,OAAOsC,iBAAiB3B,YAAc3K,EAAKgK,OAAOsC,YAActM,EAAKgK,OAAOsC,MAAM1B,kBAI7I,CAQ0BxK,CAAeJ,IAC7BC,KAAMqB,SAAcgW,GAAahR,EAASuO,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACzDuG,GAAO,IACVxB,KAAM,oCAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CC5BOyD,eAAesT,GAAerY,EAAMkF,GACvC,IAAI2P,EACJ,GAAK7U,EAAKT,UAA8B,SAAlBS,EAAKT,SAItB,CAEDsV,EAAiBpC,SADMtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aAC1B,iBACjD,MALIyN,EAAiB,IAAInT,EAMzB,MAAQzB,KAAMc,SAAmBuW,GAAatX,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAC3DuG,GAAO,IACVxB,KAAM,oBAEV,OAAOmR,EAAe/T,YAAYC,EACtC,CCfO,SAAgBsb,GAAoB7D,EAAAC,GAAA,OAAA6D,GAAArJ,MAAC,KAADvT,UAAA,CAc1C,SAAA4c,KAAA,OAAAA,GAAAvJ,GAdM,UAAqC/S,EAAMkF,GAC9C,IAAI2P,EACJ,GAAK7U,EAAKT,UAA8B,SAAlBS,EAAKT,SAItB,CAEDsV,EAAiBpC,SADHqB,GAAS3M,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,cAC1B,iBACjD,MALIyN,EAAiB,IAAInT,QAMzBqS,GAAAI,GAAOoE,GAAsBvY,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAC1CuG,GAAO,IACVxB,KAAM,qBAEd,IAACuP,MAAA,KAAAvT,UAAA,CCfMqF,eAAewX,GAAkBvc,EAAMkF,GAC1C,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,uBAC3CnH,KAAMqB,SAAcgW,GAAatX,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACtDuG,GAAO,IACVxB,KAAM,wBAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCROyD,eAAeyX,GAASxc,EAAMkF,GACjC,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,cAC3CnH,KAAMqB,SAAcgW,GAAatX,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACtDuG,GAAO,IACVxB,KAAM,eAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCROyD,eAAe0X,GAAkBzc,EAAMkF,GAC1C,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,uBAC3CnH,KAAMqB,SAAcgW,GAAatX,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACtDuG,GAAO,IACVxB,KAAM,wBAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCROyD,eAAe2X,GAAmB1c,EAAMkF,GAC3C,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,wBAC3CnH,KAAMqB,SAAcgW,GAAatX,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACtDuG,GAAO,IACVxB,KAAM,yBAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCROyD,eAAe+K,GAAc9P,EAAMkF,GACtC,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,kBAC3CnH,KAAMqB,SAAcgW,GAAatX,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACtDuG,GAAO,IACVxB,KAAM,mBAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCROyD,eAAe4X,GAAuB3c,EAAMkF,GAC/C,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,6BAC3CnH,KAAMqB,SAAcgW,GAAatX,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACtDuG,GAAO,IACVxB,KAAM,8BAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCROyD,eAAe6X,GAAmB5c,EAAMkF,GAC3C,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,wBAC3CnH,KAAMqB,SAAcgW,GAAatX,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACtDuG,GAAO,IACVxB,KAAM,yBAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCROyD,eAAe8X,GAAe7c,EAAMkF,GACvC,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,oBAC3CnH,KAAMc,SAAmBuW,GAAatX,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAC3DuG,GAAO,IACVxB,KAAM,qBAEV,OAAOmR,EAAe/T,YAAYC,EACtC,CCRO,SAAgB+b,GAAoBtE,EAAAC,GAAA,OAAAsE,GAAA9J,MAAC,KAADvT,UAAA,CAO1C,SAAAqd,KAAA,OAAAA,GAAAhK,GAPM,UAAqC/S,EAAMkF,GAC9C,MACM2P,EAAiBpC,SADTqB,GAAS3M,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,cACpB,yBACnD2M,GAAAI,GAAOoE,GAAsBvY,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAC1CuG,GAAO,IACVxB,KAAM,sBAEd,IAACuP,MAAA,KAAAvT,UAAA,CCPMqF,eAAeiY,GAAoBhd,EAAMkF,GAC5C,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,yBAC3CnH,KAAMqB,SAAcgW,GAAatX,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACtDuG,GAAO,IACVxB,KAAM,0BAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCROyD,eAAe6K,GAAY5P,EAAMkF,GACpC,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,gBAC3CnH,KAAMqB,SAAcgW,GAAatX,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACtDuG,GAAO,IACVxB,KAAM,iBAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCROyD,eAAekY,GAAuBjd,EAAMkF,GAC/C,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,6BAC3CnH,KAAMqB,SAAcgW,GAAatX,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACtDuG,GAAO,IACVxB,KAAM,8BAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCPOyD,eAAemY,GAA0Bld,EAAMkF,GAClD,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,+BAC7C+V,GAAOxe,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACNqB,GAAI,IACPgK,OAAQ,CACJoT,SAAUpd,EAAKgK,OAAOoT,SAEtB9Q,MAAO3K,EAAgB,IAAI+I,iBAAiB1K,EAAKgK,OAAOsC,MAAM1B,oBAG9D3K,KAAMqB,SAAcgW,GAAa6F,EAAStI,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACzDuG,GAAO,IACVxB,KAAM,iCAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CChBOyD,eAAesY,GAAwBrd,EAAMkF,GAChD,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,6BAC7C+V,GAAOxe,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACNqB,GAAI,IACPgK,OAAQ,CACJoT,SAAUpd,EAAKgK,OAAOoT,SAEtB9Q,MAAO3K,EAAgB,IAAI+I,iBAAiB1K,EAAKgK,OAAOsC,MAAM1B,oBAG9D3K,KAAMqB,SAAcgW,GAAa6F,EAAStI,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACzDuG,GAAO,IACVxB,KAAM,+BAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCfOyD,eAAeuY,GAAsBtd,EAAMkF,GAC9C,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,2BAC3CnH,KAAMqB,SAAcgW,GAAatX,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACtDuG,GAAO,IACVxB,KAAM,4BAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCROyD,eAAewY,GAAkBvd,EAAMkF,GAC1C,MACM2P,EAAiBpC,SADAtL,EAAgBnH,EAAKT,SAAUS,EAAKa,MAAOb,EAAKoH,aACpB,uBAC3CnH,KAAMqB,SAAcgW,GAAatX,EAAM6U,GAAclW,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACtDuG,GAAO,IACVxB,KAAM,wBAEV,OAAOmR,EAAe/T,YAAYQ,EACtC,CCbO,MAAMkc,GAGTxf,WAAAA,GAAmD,IAAvC2C,EAAWjB,UAAAC,OAAA,QAAAb,IAAAY,UAAA,GAAAA,UAAA,GAAG,GAAI+d,EAAc/d,UAAAC,OAAA,QAAAb,IAAAY,UAAA,GAAAA,UAAA,GAAG,CAAC,GAAChB,EAAAA,EAAAA,GAAA,4BAAAA,EAAAA,EAAAA,GAAA,8BAC7CP,KAAKwC,YAAcA,EACnBxC,KAAKsf,eAAiBA,EACtB,IAAK,MAAOrf,EAAMsf,KCTGve,EDSiBwV,ECRnC3R,OAAO0D,QAAQvH,IDSd6D,OAAO2a,eAAexf,KAAMC,EAAM,CAC9Bwf,YAAY,EACZ9S,MAAOA,CAACjL,EAAQqF,IAEhBwY,GACA/e,EAAAA,EAAAA,GAAA,CACEyI,YAAaqW,EAAerW,YAAazG,eAAgBd,IAAMlB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAC1DiE,EAAK6a,EAAgB,CAAC,iBACtBvY,MClBhB,IAAsB/F,CDsBzB,CAMA0e,QAAAA,CAASzW,GACL,OAAO,IAAIoW,GAAgBrf,KAAKwC,aAAWhC,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAOR,KAAKsf,gBAAc,IAAErW,gBAC3E,EAMG,MAAM0W,WAAoBN,IEnCjC,IAAIO,GAAc/a,OAAOgb,OAAO,CAC9BC,KAAM,OAENC,eAAgB,iBAEhBC,cAAe,gBAEfC,WAAY,aAEZC,OAAQ,SAERC,UAAW,YAEXC,WAAY,aAEZC,cAAe,gBAEfC,eAAgB,iBAEhBC,eAAgB,iBAEhBC,gBAAiB,kBAEjBC,kBAAmB,oBAEnBC,mBAAoB,qBAEpBC,iBAAkB,mBAElBC,kBAAmB,oBAEnBC,MAAO,QAEPC,IAAK,MAELC,MAAO,QAEPC,KAAM,OAENC,aAAc,eAEdC,uBAAwB,yBAExBC,6BAA8B,+BAE9BC,yBAA0B,2BAE1BC,cAAe,gBAEfC,QAAS,YAGPC,GAAQ,MAMV1hB,WAAAA,CAAY8M,EAAOsC,GACjBjP,KAAK2M,MAAQA,EACb3M,KAAKiP,KAAOA,CACd,GAEF,SAASuS,GAAOC,GACd,MAAO,KAAK7X,KAAK6X,EACnB,CACA,SAASC,GAAUD,GACjB,MAAO,QAAQ7X,KAAK6X,EACtB,CACA,SAASE,GAAaF,GACpB,MAAO,KAAK7X,KAAK6X,EACnB,CACA,IAAIG,GAAwB,CAE1B,CAAC,KAAMhC,GAAYS,eACnB,CAAC,KAAMT,GAAYU,gBACnB,CAAC,KAAMV,GAAYW,gBACnB,CAAC,KAAMX,GAAYY,iBAEnB,CAAC,IAAKZ,GAAYO,WAClB,CAAC,IAAKP,GAAYQ,YAClB,CAAC,IAAKR,GAAYe,kBAClB,CAAC,IAAKf,GAAYgB,mBAClB,CAAC,IAAKhB,GAAYa,mBAClB,CAAC,IAAKb,GAAYc,oBAClB,CAAC,IAAKd,GAAYiB,OAClB,CAAC,IAAKjB,GAAYkB,KAClB,CAAC,IAAKlB,GAAYmB,OAClB,CAAC,IAAKnB,GAAYoB,MAElB,CAAC,KAAMpB,GAAYwB,0BACnB,CAAC,KAAMxB,GAAYwB,0BACnB,CAAC,KAAMxB,GAAYwB,0BACnB,CAAC,KAAMxB,GAAYwB,0BACnB,CAAC,IAAKxB,GAAYwB,0BAClB,CAAC,IAAKxB,GAAYwB,0BAElB,CAAC,IAAKxB,GAAYsB,wBAClB,CAAC,IAAKtB,GAAYsB,wBAClB,CAAC,IAAKtB,GAAYsB,wBAClB,CAAC,IAAKtB,GAAYuB,8BAClB,CAAC,IAAKvB,GAAYuB,8BAClB,CAAC,IAAKvB,GAAYuB,8BAElB,CAAC,IAAKvB,GAAYM,SAEhB2B,GAAoC,IAAIlb,IAAI,CAC9C,CAAC,IAAK,MAEN,CAAC,IAAK,MAEN,CAAC,IAAK,MAEN,CAAC,IAAK,MAEN,CAAC,IAAK,MAEN,CAAC,IAAK,MAEN,CAAC,IAAK,KAEN,CAAC,IAAK,KAEN,CAAC,KAAM,QA+LT,IAAImb,GAAY,MAAMjiB,WAAAA,IAAAU,EAAAA,EAAAA,GAAA,YACb,YAAW,GAEhBwhB,GAAU,cAAcD,GAC1BjiB,WAAAA,CAAYiI,GACV/H,SAAQQ,EAAAA,EAAAA,GAAA,YAGH,WAFLP,KAAK8H,KAAOA,CACd,GAGEka,GAAK,cAAcF,GACrBjiB,WAAAA,CAAY+J,EAAM9B,EAAMma,GACtBliB,SAAQQ,EAAAA,EAAAA,GAAA,YAKH,MAJLP,KAAK4J,KAAOA,EACZ5J,KAAK8H,KAAOA,EACZ9H,KAAKiiB,UAAYA,CACnB,GAGEC,GAAM,cAAcJ,GACtBjiB,WAAAA,CAAYsiB,EAASC,EAAUta,EAAMua,GACnCtiB,SAAQQ,EAAAA,EAAAA,GAAA,YAMH,OALLP,KAAKmiB,QAAUA,EACfniB,KAAKoiB,SAAWA,EAChBpiB,KAAK8H,KAAOA,EACZ9H,KAAKqiB,aAAeA,CACtB,GAGEC,GAAQ,cAAcR,GAAUjiB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YAC3B,QAAO,GAEZgiB,GAAW,cAAcT,GAAUjiB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YAC9B,WAAU,GAEfiiB,GAAe,cAAcV,GAC/BjiB,WAAAA,CAAY4iB,EAAU9V,EAAO7E,GAC3B/H,SAAQQ,EAAAA,EAAAA,GAAA,YAKH,OAJLP,KAAKyiB,SAAWA,EAChBziB,KAAK2M,MAAQA,EACb3M,KAAK8H,KAAOA,CACd,GAGE4a,GAAQ,cAAcZ,GACxBjiB,WAAAA,CAAYI,EAAM4B,EAAMiG,GACtB/H,SAAQQ,EAAAA,EAAAA,GAAA,YAKH,SAJLP,KAAKC,KAAOA,EACZD,KAAK6B,KAAOA,EACZ7B,KAAK8H,KAAOA,CACd,GAGEwZ,GAAU,cAAcQ,GAC1BjiB,WAAAA,CAAY8M,GACV5M,SAAQQ,EAAAA,EAAAA,GAAA,YAGH,WAFLP,KAAK2M,MAAQA,CACf,GAGEgW,GAAa,cAAcb,GAAUjiB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YAChC,aAAY,GAEjBqiB,GAAmB,cAAcD,GACnC9iB,WAAAA,CAAYgjB,EAAQC,EAAUC,GAC5BhjB,SAAQQ,EAAAA,EAAAA,GAAA,YAKH,oBAJLP,KAAK6iB,OAASA,EACd7iB,KAAK8iB,SAAWA,EAChB9iB,KAAK+iB,SAAWA,CAClB,GAGEC,GAAiB,cAAcL,GACjC9iB,WAAAA,CAAYojB,EAAQphB,GAClB9B,SAAQQ,EAAAA,EAAAA,GAAA,YAIH,kBAHLP,KAAKijB,OAASA,EACdjjB,KAAK6B,KAAOA,CACd,GAGEoe,GAAa,cAAc0C,GAI7B9iB,WAAAA,CAAY8M,GACV5M,SAAQQ,EAAAA,EAAAA,GAAA,YAGH,cAFLP,KAAK2M,MAAQA,CACf,GAGEuW,GAAU,cAAcP,GAC1B9iB,WAAAA,CAAY8M,GACV5M,SAAQQ,EAAAA,EAAAA,GAAA,YAGH,WAFLP,KAAK2M,MAAQA,CACf,GAGEwW,GAAiB,cAAcD,GAAQrjB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YAClC,iBAAgB,GAErB6iB,GAAe,cAAcF,GAAQrjB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YAChC,eAAc,GAEnByf,GAAgB,cAAckD,GAAQrjB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YACjC,gBAAe,GAEpB8iB,GAAe,cAAcH,GAAQrjB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YAChC,eAAc,GAEnB+iB,GAAe,cAAcJ,GAAQrjB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YAChC,eAAc,GAEnBgjB,GAAgB,cAAcL,GAAQrjB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YACjC,gBAAe,GAEpBijB,GAAmB,cAAcb,GACnC9iB,WAAAA,CAAY4jB,EAAUC,EAAMC,GAC1B5jB,SAAQQ,EAAAA,EAAAA,GAAA,YAKH,oBAJLP,KAAKyjB,SAAWA,EAChBzjB,KAAK0jB,KAAOA,EACZ1jB,KAAK2jB,MAAQA,CACf,GAGEC,GAAmB,cAAcjB,GACnC9iB,WAAAA,CAAYgkB,EAAS1e,GACnBpF,SAAQQ,EAAAA,EAAAA,GAAA,YAIH,oBAHLP,KAAK6jB,QAAUA,EACf7jB,KAAKmF,OAASA,CAChB,GAGE2e,GAAkB,cAAchC,GAClCjiB,WAAAA,CAAYsF,EAAQ2C,GAClB/H,SAAQQ,EAAAA,EAAAA,GAAA,YAIH,mBAHLP,KAAKmF,OAASA,EACdnF,KAAK8H,KAAOA,CACd,GAGEic,GAAmB,cAAcpB,GACnC9iB,WAAAA,CAAYmkB,EAAKpa,GACf7J,SAAQQ,EAAAA,EAAAA,GAAA,YAIH,oBAHLP,KAAKgkB,IAAMA,EACXhkB,KAAK4J,KAAOA,CACd,GAGEqa,GAAiB,cAActB,GACjC9iB,WAAAA,CAAYgkB,EAASK,EAAQta,GAC3B7J,SAAQQ,EAAAA,EAAAA,GAAA,YAKH,kBAJLP,KAAK6jB,QAAUA,EACf7jB,KAAKkkB,OAASA,EACdlkB,KAAK4J,KAAOA,CACd,GAGEua,GAAkB,cAAcxB,GAClC9iB,WAAAA,CAAY4jB,EAAUW,GACpBrkB,SAAQQ,EAAAA,EAAAA,GAAA,YAIH,mBAHLP,KAAKyjB,SAAWA,EAChBzjB,KAAKokB,SAAWA,CAClB,GAGEC,GAAkB,cAAc1B,GAClC9iB,WAAAA,GAA0D,IAA9C6Q,EAAKnP,UAAAC,OAAA,QAAAb,IAAAY,UAAA,GAAAA,UAAA,QAAG,EAAQ+iB,EAAI/iB,UAAAC,OAAA,QAAAb,IAAAY,UAAA,GAAAA,UAAA,QAAG,EAAQwM,EAAIxM,UAAAC,OAAA,QAAAb,IAAAY,UAAA,GAAAA,UAAA,QAAG,EAChDxB,SAAQQ,EAAAA,EAAAA,GAAA,YAKH,mBAJLP,KAAK0Q,MAAQA,EACb1Q,KAAKskB,KAAOA,EACZtkB,KAAK+N,KAAOA,CACd,GAGEwW,GAA4B,cAAc5B,GAC5C9iB,WAAAA,CAAY2V,EAAK7I,GACf5M,SAAQQ,EAAAA,EAAAA,GAAA,YAIH,6BAHLP,KAAKwV,IAAMA,EACXxV,KAAK2M,MAAQA,CACf,GAGE6X,GAAmB,cAAc7B,GACnC9iB,WAAAA,CAAYukB,GACVrkB,SAAQQ,EAAAA,EAAAA,GAAA,YAGH,oBAFLP,KAAKokB,SAAWA,CAClB,GAGEK,GAAgB,cAAc3C,GAChCjiB,WAAAA,CAAYqW,EAAMwO,EAAY5c,GAC5B/H,SAAQQ,EAAAA,EAAAA,GAAA,YAKH,iBAJLP,KAAKkW,KAAOA,EACZlW,KAAK0kB,WAAaA,EAClB1kB,KAAK8H,KAAOA,CACd,GAGE6c,GAAU,cAAchC,GAC1B9iB,WAAAA,CAAY+kB,EAAWC,EAAUC,GAC/B/kB,SAAQQ,EAAAA,EAAAA,GAAA,YAKH,WAJLP,KAAK4kB,UAAYA,EACjB5kB,KAAK6kB,SAAWA,EAChB7kB,KAAK8kB,UAAYA,CACnB,GAKF,SAAS5L,GAAM6L,GACb,MAAMC,EAAU,IAAIjD,GAAQ,IAC5B,IAAIkD,EAAU,EACd,SAASC,EAAOjW,EAAMjH,GACpB,MAAMmd,EAAOJ,EAAOE,KACpB,IAAKE,GAAQA,EAAKlW,OAASA,EACzB,MAAM,IAAIrP,MAAM,iBAADpB,OAAkBwJ,EAAK,MAAAxJ,OAAK2mB,EAAKlW,KAAI,SAAAzQ,OAAQyQ,EAAI,MAElE,OAAOkW,CACT,CACA,SAASC,EAAiBnlB,GACxB,IAAKolB,EAAaplB,GAChB,MAAM,IAAIqlB,YAAY,YAAD9mB,OAAayB,MAElCglB,CACJ,CACA,SAASM,IACP,OAAQR,EAAOE,GAAShW,MACtB,KAAK2Q,GAAY0B,QACf,OAAO,IAAIA,GAAQyD,EAAOE,KAAWtY,OACvC,KAAKiT,GAAYE,KACf,OAmBG,IAAIE,GAAckF,EAAOtF,GAAYE,KAAM,uBAAuBnT,OAlBvE,KAAKiT,GAAYS,cACf,OAmBN,WAEE,GADA6E,EAAOtF,GAAYS,cAAe,oCAC9B0E,EAAOE,GAAShW,OAAS2Q,GAAYK,WACvC,MAAM,IAAIqF,YAAY,0BAAD9mB,OAA2BumB,EAAOE,GAAShW,OAElE,MAAMhP,EAAO8kB,EAAOE,GAAStY,MAC7B,IAAI3B,EACJ,OAAQ/K,GACN,IAAK,QACDglB,EACFja,EAoFN,WACE,MAAM0Y,EAAO8B,IACb,IAAI7Y,EAAQ,KACZ,MAAM7E,EAAO,GACb,GAAI2d,EAAG7F,GAAYM,UACf+E,EACFtY,EAAQ6Y,QACH,CAEL,IADAN,EAAOtF,GAAYU,eAAgB,sBAC3BoF,EAAY,WAClB5d,EAAK7D,KAAKshB,KAEZL,EAAOtF,GAAYS,cAAe,qBAClC+E,EAAiB,SACnB,CAEA,OADAF,EAAOtF,GAAYU,eAAgB,oCAC5B,IAAIkC,GAAakB,EAAM/W,EAAO7E,EACvC,CArGe6d,GACT,MACF,IAAK,OACDV,EACFja,EAAS4a,IACTV,EAAOtF,GAAYS,cAAe,qBAClC+E,EAAiB,SACjBF,EAAOtF,GAAYU,eAAgB,qBACnC,MACF,IAAK,UACD2E,EACFja,EAkHN,WACE,MAAM/K,EAAO4lB,IACb,GAAkB,eAAd5lB,EAAKgP,KACP,MAAM,IAAIqW,YAAY,iDAExB,MAAMzjB,EAAOikB,IACbZ,EAAOtF,GAAYU,eAAgB,oCACnC,MAAMxY,EAAO,GACb,MAAQ4d,EAAY,aAClB5d,EAAK7D,KAAKshB,KAEZ,OAAO,IAAI7C,GAAMziB,EAAM4B,EAAMiG,EAC/B,CA9Heie,GACTb,EAAOtF,GAAYS,cAAe,qBAClC+E,EAAiB,YACjBF,EAAOtF,GAAYU,eAAgB,qBACnC,MACF,IAAK,QACD2E,EACFja,EAqIN,WACE,MAAMgb,EAAeR,GAAwB,GAC7C,KAAMQ,aAAwB/F,IAAc+F,aAAwB1C,IAClE,MAAM,IAAIgC,YAAY,wDAAD9mB,OAAyDwnB,EAAa/W,KAAI,aAEjG,IAAKoW,EAAa,MAChB,MAAM,IAAIC,YAAY,mDAEtBL,EACF,MAAM7C,EAAW6D,IACjBf,EAAOtF,GAAYU,eAAgB,oCACnC,MAAMxY,EAAO,GACb,MAAQ4d,EAAY,SAAU,SAC5B5d,EAAK7D,KAAKshB,KAEZ,MAAMW,EAAc,GACpB,GAAIR,EAAY,QAId,MAHET,IACAA,EACFC,EAAOtF,GAAYU,eAAgB,qCAC3BoF,EAAY,WAClBQ,EAAYjiB,KAAKshB,KAGrB,OAAO,IAAIrD,GAAI8D,EAAc5D,EAAUta,EAAMoe,EAC/C,CA9JeC,GACTjB,EAAOtF,GAAYS,cAAe,qBAClC+E,EAAiB,UACjBF,EAAOtF,GAAYU,eAAgB,qBACnC,MACF,IAAK,OAAQ,GACT2E,EACF,IAAIP,EAAa,KACbe,EAAG7F,GAAYO,aACjBuE,EAAaoB,KAEf,MAAM7C,EAAS4C,IACf,GAAoB,eAAhB5C,EAAOhU,KACT,MAAM,IAAIqW,YAAY,gDAExB,MAAMc,EAAWN,IACjBZ,EAAOtF,GAAYU,eAAgB,oCACnC,MAAMxY,EAAO,GACb,MAAQ4d,EAAY,YAClB5d,EAAK7D,KAAKshB,KAEZL,EAAOtF,GAAYS,cAAe,iBAClC+E,EAAiB,WACjBF,EAAOtF,GAAYU,eAAgB,oCACnC,MAAM+F,EAAW,IAAIrD,GAAeC,EAAQmD,GAC5Cpb,EAAS,IAAIyZ,GAAc4B,EAAU3B,EAAY5c,GACjD,KACF,CACA,IAAK,UACDmd,EACFC,EAAOtF,GAAYU,eAAgB,oCACnCtV,EAAS,IAAIsX,GACb,MACF,IAAK,aACD2C,EACFC,EAAOtF,GAAYU,eAAgB,oCACnCtV,EAAS,IAAIuX,GACb,MACF,IAAK,SAAU,GACX0C,EACF,IAAIqB,EAAaT,IACbS,aAAsBrG,IAAcwF,EAAG7F,GAAYO,aACrDmG,EAAaC,EAAoBD,IAEnCpB,EAAOtF,GAAYU,eAAgB,oCACnC,MAAMkG,EAAa,GACnB,MAAQd,EAAY,cAClBc,EAAWviB,KAAKshB,KAElBL,EAAOtF,GAAYS,cAAe,iBAClC+E,EAAiB,aACjBF,EAAOtF,GAAYU,eAAgB,iBACnCtV,EAAS,IAAI8Y,GAAgBwC,EAAYE,GACzC,KACF,CACA,QACE,MAAM,IAAIlB,YAAY,2BAAD9mB,OAA4ByB,IAErD,OAAO+K,CACT,CA1Gayb,GACT,KAAK7G,GAAYW,eACf,OAyGN,WACE2E,EAAOtF,GAAYW,eAAgB,qCACnC,MAAMvV,EAASib,IAEf,OADAf,EAAOtF,GAAYY,gBAAiB,qCAC7BxV,CACT,CA9Ga0b,GACT,QACE,MAAM,IAAIpB,YAAY,0BAAD9mB,OAA2BumB,EAAOE,GAAShW,OAEtE,CACA,SAASwW,IAAa,QAAAkB,EAAAplB,UAAAC,OAAPolB,EAAK,IAAA3lB,MAAA0lB,GAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAALD,EAAKC,GAAAtlB,UAAAslB,GAClB,OAAO5B,EAAU2B,EAAMplB,QAAUujB,EAAOvjB,QAAUolB,EAAMxjB,MAAM,CAAC6L,EAAMkG,IAAMlG,IAAS8V,EAAOE,EAAU9P,GAAGlG,KAC1G,CACA,SAASyW,IAAsB,QAAAoB,EAAAC,EAAAC,EAAAC,EAAA1lB,UAAAC,OAAP0lB,EAAK,IAAAjmB,MAAAgmB,GAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAALD,EAAKC,GAAA5lB,UAAA4lB,GAC3B,OAAsB,QAAfL,EAAA/B,EAAOE,UAAQ,IAAA6B,OAAA,EAAfA,EAAiB7X,QAAS2Q,GAAYS,gBAAoC,QAAnB0G,EAAAhC,EAAOE,EAAU,UAAE,IAAA8B,OAAA,EAAnBA,EAAqB9X,QAAS2Q,GAAYK,YAAciH,EAAM1iB,SAA4B,QAApBwiB,EAACjC,EAAOE,EAAU,UAAE,IAAA+B,OAAA,EAAnBA,EAAqBra,MAC5J,CACA,SAAS0Y,IAAuB,QAAA+B,EAAA7lB,UAAAC,OAAP0lB,EAAK,IAAAjmB,MAAAmmB,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAALH,EAAKG,GAAA9lB,UAAA8lB,GAC5B,OAAOpC,EAAUiC,EAAM1lB,QAAUujB,EAAOvjB,QAAU0lB,EAAM9jB,MAAM,CAACnD,EAAMkV,IAAmC,eAA7B4P,EAAOE,EAAU9P,GAAGlG,MAAyBhP,IAAS8kB,EAAOE,EAAU9P,GAAGxI,MACvJ,CAoHA,SAASiZ,IACP,MAAMhc,EAAOqc,IACbf,EAAOtF,GAAYU,eAAgB,oCACnC,MAAMxY,EAAO,GACPma,EAAY,GAClB,MAAQyD,EAAY,OAAQ,OAAQ,UAClC5d,EAAK7D,KAAKshB,KAEZ,GAAIG,EAAY,QAAS,GACrBT,IACAA,EACF,MAAMja,EAAS4a,IACf3D,EAAUhe,KAAK+G,EACjB,MAAO,GAAI0a,EAAY,QAIrB,MAHET,IACAA,EACFC,EAAOtF,GAAYU,eAAgB,qCAC3BoF,EAAY,UAClBzD,EAAUhe,KAAKshB,KAGnB,OAAO,IAAIvD,GAAGpY,EAAM9B,EAAMma,EAC5B,CAcA,SAASuD,IACP,MAAMjG,EADgChe,UAAAC,OAAA,QAAAb,IAAAY,UAAA,IAAAA,UAAA,GACjBskB,EAAyBI,EACxCqB,EAAc,CAAC/H,KACfgI,EAAU9B,EAAG7F,GAAYiB,OAC/B,KAAO0G,MACHtC,EACFqC,EAAYrjB,KAAKsb,KACZkG,EAAG7F,GAAYiB,UAItB,OAAO0G,EAAU,IAAIjE,GAAagE,GAAeA,EAAY,EAC/D,CA2BA,SAASrB,IACP,OAAOuB,GACT,CACA,SAASA,IACP,MAAM7O,EAAI8O,IACV,GAAIpC,EAAa,MAAO,GACpBJ,EACF,MAAMrb,EAAO6d,IACb,GAAIpC,EAAa,QAAS,GACtBJ,EACF,MAAMH,EAAY0C,IAClB,OAAO,IAAI7C,GAAQ/a,EAAM+O,EAAGmM,EAC9B,CACE,OAAO,IAAIf,GAAiBpL,EAAG/O,EAEnC,CACA,OAAO+O,CACT,CACA,SAAS8O,IACP,IAAI/D,EAAOgE,IACX,KAAOrC,EAAa,OAAO,CACzB,MAAM5B,EAAWsB,EAAOE,KACtBA,EACF,MAAMtB,EAAQ+D,IACdhE,EAAO,IAAIF,GAAiBC,EAAUC,EAAMC,EAC9C,CACA,OAAOD,CACT,CACA,SAASgE,IACP,IAAIhE,EAAOiE,IACX,KAAOtC,EAAa,QAAQ,CAC1B,MAAM5B,EAAWsB,EAAOE,KACtBA,EACF,MAAMtB,EAAQgE,IACdjE,EAAO,IAAIF,GAAiBC,EAAUC,EAAMC,EAC9C,CACA,OAAOD,CACT,CACA,SAASiE,IACP,IAAIhE,EACJ,KAAO0B,EAAa,QAAQ,CAC1B,MAAM5B,EAAWsB,EAAOE,KACtBA,EACF,MAAMxP,EAAMkS,IACZhE,EAAQ,IAAIQ,GAAgBV,EAAUhO,EACxC,CACA,OAAY,OAALkO,QAAK,IAALA,EAAAA,EAET,WACE,IAAID,EAAOkE,IACX,OAAa,CACX,IAAInE,EACJ,GAAI4B,EAAa,MAAO,MACtB5B,EAAW,IAAIlC,GAAM,SAAU3B,GAAYK,YAC3CgF,GAAW,OACN,GAAII,EAAa,MACtB5B,EAAWsB,EAAOE,SACb,KAAIQ,EAAG7F,GAAYwB,0BAGxB,MAFAqC,EAAWsB,EAAOE,IAGpB,CACA,MAAMtB,EAAQiE,IACdlE,EAAO,IAAIF,GAAiBC,EAAUC,EAAMC,EAC9C,CACA,OAAOD,CACT,CApBkBmE,EAClB,CAoBA,SAASD,IACP,IAAIlE,EAAOoE,IACX,KAAOrC,EAAG7F,GAAYsB,yBAAyB,CAC7C,MAAMuC,EAAWsB,EAAOE,KACtBA,EACF,MAAMtB,EAAQmE,IACdpE,EAAO,IAAIF,GAAiBC,EAAUC,EAAMC,EAC9C,CACA,OAAOD,CACT,CAQA,SAAS6C,EAAoBtD,GAC3B,IAAI8E,EAAa,IAAI/E,GAAeC,EAAQ6C,KAK5C,OAJAiC,EAAaC,EAAsBD,GAC/BtC,EAAG7F,GAAYO,aACjB4H,EAAaxB,EAAoBwB,IAE5BA,CACT,CACA,SAASjC,IACPZ,EAAOtF,GAAYO,UAAW,mDAC9B,MAAMte,EAIR,WACE,MAAMA,EAAO,GACb,MAAQ4jB,EAAG7F,GAAYQ,aAAa,CAClC,IAAIgE,EACJ,GAAIW,EAAOE,GAAShW,OAAS2Q,GAAYuB,8BAA0D,MAA1B4D,EAAOE,GAAStY,MAAe,GACpGsY,EACF,MAAMgD,EAAOhC,IACb7B,EAAW,IAAII,GAAiByD,EAClC,MAEE,GADA7D,EAAW6B,IACPR,EAAG7F,GAAYM,QAAS,CAE1B,KADE+E,IACIb,aAAoBnE,IACxB,MAAM,IAAIqF,YAAY,4CAExB,MAAM3Y,EAAQsZ,IACd7B,EAAW,IAAIG,GAA0BH,EAAUzX,EACrD,CAEF9K,EAAKoC,KAAKmgB,GACNqB,EAAG7F,GAAYiB,UACfoE,CAEN,CACA,OAAOpjB,CACT,CA7BeqmB,GAEb,OADAhD,EAAOtF,GAAYQ,WAAY,mDACxBve,CACT,CA2BA,SAASsmB,IACP,MAAMC,EAAS,GACf,IAAIC,GAAU,EACd,MAAQ5C,EAAG7F,GAAYc,qBACjB+E,EAAG7F,GAAYmB,QACjBqH,EAAOnkB,UAAK,KACVghB,EACFoD,GAAU,IAEVD,EAAOnkB,KAAKgiB,KACRR,EAAG7F,GAAYmB,WACfkE,EACFoD,GAAU,IAIhB,GAAsB,IAAlBD,EAAO5mB,OACT,MAAM,IAAI8jB,YAAY,8DAExB,GAAI+C,EAAS,CACX,GAAID,EAAO5mB,OAAS,EAClB,MAAM,IAAI8jB,YAAY,+CAExB,OAAO,IAAIjB,MAAmB+D,EAChC,CACA,OAAOA,EAAO,EAChB,CACA,SAASJ,EAAsBnF,GAC7B,KAAO4C,EAAG7F,GAAYkB,MAAQ2E,EAAG7F,GAAYa,oBAAoB,CAC/D,MAAMgD,EAAWsB,EAAOE,GAExB,IAAInC,IADFmC,EAEF,MAAMlC,EAAWU,EAASxU,OAAS2Q,GAAYa,kBAC/C,GAAIsC,EACFD,EAAWqF,IACXjD,EAAOtF,GAAYc,mBAAoB,wCAGvC,GADAoC,EAAW+C,IACW,eAAlB/C,EAAS7T,KACX,MAAM,IAAIqW,YAAY,8CAG1BzC,EAAS,IAAID,GAAiBC,EAAQC,EAAUC,EAClD,CACA,OAAOF,CACT,CACA,SAASiF,IACP,IAAIpE,EAAO4E,IACX,KAAO7C,EAAG7F,GAAYuB,+BAA+B,CACnD,MAAMsC,EAAWsB,EAAOE,KAClBtB,EAAQ2E,IACd5E,EAAO,IAAIF,GAAiBC,EAAUC,EAAMC,EAC9C,CACA,OAAOD,CACT,CACA,SAAS4E,IACP,IAAIzE,EAeN,WACE,IAAIA,EAvHN,WACE,MAAM0E,EAASP,EAAsBnC,KACrC,OAAIJ,EAAG7F,GAAYO,WACVoG,EAAoBgC,GAEtBA,CACT,CAiHgBC,GACd,KAAO/C,EAAG7F,GAAYoB,OAAO,GACzBiE,EACF,IAAI9f,EAAS0gB,IACb,KAAM1gB,aAAkB8a,IACtB,MAAM,IAAIqF,YAAY,sCAEpBG,EAAG7F,GAAYO,aACjBhb,EAASohB,EAAoBphB,IAE/B0e,EAAU,IAAID,GAAiBC,EAAS1e,EAC1C,CACA,OAAO0e,CACT,CA7BgB4E,GACd,KAAOpD,EAAa,OAAO,GACvBJ,EACF,MAAMf,EAASmB,EAAa,OACxBnB,KACAe,EAEJ,MAAM9f,EAAS0gB,IACf,KAAM1gB,aAAkB8a,IACtB,MAAM,IAAIqF,YAAY,oCAExBzB,EAAU,IAAII,GAAeJ,EAASK,EAAQ/e,EAChD,CACA,OAAO0e,CACT,CAgBA,SAASgC,IACP,MAAMjV,EAAQmU,EAAOE,KACrB,OAAQrU,EAAM3B,MACZ,KAAK2Q,GAAYG,eAAgB,CAC/B,MAAM2I,EAAM9X,EAAMjE,MAClB,OAAO+b,EAAIlkB,SAAS,KAAO,IAAI4e,GAAauF,OAAOD,IAAQ,IAAIvF,GAAewF,OAAOD,GACvF,CACA,KAAK9I,GAAYI,cAAe,CAC9B,IAAIrT,EAAQiE,EAAMjE,MAClB,KAAO8Y,EAAG7F,GAAYI,gBACpBrT,GAASoY,EAAOE,KAAWtY,MAE7B,OAAO,IAAIqT,GAAcrT,EAC3B,CACA,KAAKiT,GAAYK,WACf,OAAO,IAAIA,GAAWrP,EAAMjE,OAC9B,KAAKiT,GAAYO,UAAW,CAC1B,MAAM4H,EAAavC,IAEnB,OADAN,EAAOtF,GAAYQ,WAAY,sEACxB2H,CACT,CACA,KAAKnI,GAAYa,kBAAmB,CAClC,MAAMmI,EAAS,GACf,MAAQnD,EAAG7F,GAAYc,qBACrBkI,EAAO3kB,KAAKgiB,KACRR,EAAG7F,GAAYiB,UACfoE,EAIN,QADEA,EACK,IAAI5B,GAAauF,EAC1B,CACA,KAAKhJ,GAAYe,iBAAkB,CACjC,MAAMiI,EAAyB,IAAIjiB,IACnC,MAAQ8e,EAAG7F,GAAYgB,oBAAoB,CACzC,MAAMpL,EAAMyQ,IACZf,EAAOtF,GAAYmB,MAAO,0DAC1B,MAAMpU,EAAQsZ,IACd2C,EAAO7f,IAAIyM,EAAK7I,GACZ8Y,EAAG7F,GAAYiB,UACfoE,CAEN,CAEA,QADEA,EACK,IAAI1B,GAAcqF,EAC3B,CACA,QACE,MAAM,IAAItD,YAAY,qBAAD9mB,OAAsBoS,EAAM3B,OAEvD,CACA,KAAOgW,EAAUF,EAAOvjB,QACtBwjB,EAAQld,KAAK7D,KAAKshB,KAEpB,OAAOP,CACT,CAGA,SAAS6D,GAAMnY,EAAO4T,GAAgB,IAAVvW,EAAIxM,UAAAC,OAAA,QAAAb,IAAAY,UAAA,GAAAA,UAAA,GAAG,OACpB,IAAT+iB,IACFA,EAAO5T,EACPA,EAAQ,GAEV,MAAM1F,EAAS,GACf,IAAK,IAAImK,EAAIzE,EAAOyE,EAAImP,EAAMnP,GAAKpH,EACjC/C,EAAO/G,KAAKkR,GAEd,OAAOnK,CACT,CACA,SAASoN,GAAM0Q,EAAOpY,EAAO4T,GAAgB,IAAVvW,EAAIxM,UAAAC,OAAA,QAAAb,IAAAY,UAAA,GAAAA,UAAA,GAAG,EACxC,MAAMwnB,EAAYC,KAAKC,KAAKlb,GACxBgb,GAAa,GACfrY,GAAc,OAALA,QAAK,IAALA,EAAAA,EAAAA,EAAU,GAAK,EAAIsY,KAAKE,IAAIJ,EAAMtnB,OAASkP,EAAO,GAAKsY,KAAKG,IAAIzY,EAAOoY,EAAMtnB,QACtF8iB,GAAY,OAAJA,QAAI,IAAJA,EAAAA,EAAAA,EAASwE,EAAMtnB,QAAU,EAAIwnB,KAAKE,IAAIJ,EAAMtnB,OAAS8iB,EAAM,GAAK0E,KAAKG,IAAI7E,EAAMwE,EAAMtnB,UAE7FkP,GAAc,OAALA,QAAK,IAALA,EAAAA,EAAAA,EAAUoY,EAAMtnB,OAAS,GAAK,EAAIwnB,KAAKE,IAAIJ,EAAMtnB,OAASkP,GAAQ,GAAKsY,KAAKG,IAAIzY,EAAOoY,EAAMtnB,OAAS,GAC/G8iB,GAAY,OAAJA,QAAI,IAAJA,EAAAA,EAAAA,GAAU,IAAM,EAAI0E,KAAKE,IAAIJ,EAAMtnB,OAAS8iB,GAAO,GAAK0E,KAAKG,IAAI7E,EAAMwE,EAAMtnB,OAAS,IAEhG,MAAMwJ,EAAS,GACf,IAAK,IAAImK,EAAIzE,EAAOqY,EAAY5T,EAAI4T,EAAYzE,EAAMnP,GAAKpH,EACzD/C,EAAO/G,KAAK6kB,EAAM3T,IAEpB,OAAOnK,CACT,CAIA,SAASoe,GAAaC,GACpB,OAEF,SAAkBC,EAAMD,GACtB,MAAME,EAAqB,IAAIC,KAAKC,oBAAe,EAAQ,CAAEC,MAAO,SAC9DC,EAAsB,IAAIH,KAAKC,oBAAe,EAAQ,CAAEC,MAAO,UAC/DE,EAAQ3U,GAAMA,EAAI,GAAK,IAAMA,EAAIA,EAAEpR,WACzC,OAAOwlB,EAAQhnB,QAAQ,eAAiBuO,IACtC,OAAQA,GACN,IAAK,KACH,OAAO0Y,EAAKO,cAAchmB,WAC5B,IAAK,KACH,OAAO+lB,EAAKN,EAAKQ,WAAa,GAChC,IAAK,KACH,OAAOF,EAAKN,EAAKS,WACnB,IAAK,KACH,OAAOJ,EAAoBK,OAAOV,GACpC,IAAK,KACH,OAAOC,EAAmBS,OAAOV,GACnC,IAAK,KACH,OAAOM,EAAKN,EAAKW,YACnB,IAAK,KACH,OAAOL,EAAKN,EAAKY,cACnB,IAAK,KACH,MAAO,IACT,QACE,OAAOtZ,IAGf,CA5BSuZ,CAAyB,IAAIC,KAAQf,EAC9C,CA8CA,IAAIgB,GAAe,cAAczqB,QAE7B0qB,GAAkB,cAAc1qB,QAEhC2qB,GAAe,MAUjB1qB,WAAAA,GAA4B,IAAhB8M,EAAKpL,UAAAC,OAAA,QAAAb,IAAAY,UAAA,GAAAA,UAAA,QAAG,GAAMhB,EAAAA,EAAAA,GAAA,YATnB,iBAAcA,EAAAA,EAAAA,GAAA,sBAErBA,EAAAA,EAAAA,GAAA,gBAG2B,IAAIoG,KAK7B3G,KAAK2M,MAAQA,CACf,CAMA6d,QAAAA,GACE,OAAO,IAAIC,KAAezqB,KAAK2M,MACjC,CACA9I,QAAAA,GACE,OAAOK,OAAOlE,KAAK2M,MACrB,GAEE+d,GAAe,cAAcH,GAAa1qB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YACrC,eAAc,GAEnBoqB,GAAa,cAAcJ,GAAa1qB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YACnC,aAAY,CACnBsD,QAAAA,GACE,OAAO7D,KAAK2M,MAAQ,IAAM,EAAI3M,KAAK2M,MAAMie,QAAQ,GAAK5qB,KAAK2M,MAAM9I,UACnE,GAEEgnB,GAAc,cAAcN,GAAa1qB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YACpC,gBAAaA,EAAAA,EAAAA,GAAA,gBACO,IAAIoG,IAAI,CACjC,CACE,QACA,IAAImkB,GAAc,IACT,IAAID,GAAY7qB,KAAK2M,MAAMoe,iBAGtC,CACE,QACA,IAAID,GAAc,IACT,IAAID,GAAY7qB,KAAK2M,MAAMqe,iBAGtC,CACE,QACA,IAAIF,GAAc,IACT,IAAID,GAAY7qB,KAAK2M,MAAM4D,UAGtC,CACE,QACA,IAAIua,GAAc,IACT,IAAID,GAAsB7qB,KAAK2M,MAhH/BtK,QAAQ,QAAU4oB,GAAMA,EAAEF,kBAmHrC,CACE,aACA,IAAID,GAAc,IACT,IAAID,GAAY7qB,KAAK2M,MAAMue,OAAO,GAAGH,cAAgB/qB,KAAK2M,MAAMyL,MAAM,MAGjF,CAAC,SAAU,IAAIsS,GAAa1qB,KAAK2M,MAAMnL,SACvC,CACE,SACA,IAAIspB,GAAc,IACT,IAAID,GAAY7qB,KAAK2M,MAAMwe,aAGtC,CACE,SACA,IAAIL,GAAc,IACT,IAAID,GAAY7qB,KAAK2M,MAAMye,eAGtC,CACE,aACA,IAAIN,GAAejpB,IACjB,GAAoB,IAAhBA,EAAKL,OACP,MAAM,IAAI5B,MAAM,+CAElB,MAAMyrB,EAAUxpB,EAAK,GACrB,GAAIwpB,aAAmBR,GACrB,OAAO,IAAIJ,GAAazqB,KAAK2M,MAAMrH,WAAW+lB,EAAQ1e,QACjD,GAAI0e,aAAmBC,GAAY,CACxC,IAAK,MAAMhZ,KAAQ+Y,EAAQ1e,MAAO,CAChC,KAAM2F,aAAgBuY,IACpB,MAAM,IAAIjrB,MAAM,+CAElB,GAAII,KAAK2M,MAAMrH,WAAWgN,EAAK3F,OAC7B,OAAO,IAAI8d,IAAa,EAE5B,CACA,OAAO,IAAIA,IAAa,EAC1B,CACA,MAAM,IAAI7qB,MAAM,iEAGpB,CACE,WACA,IAAIkrB,GAAejpB,IACjB,GAAoB,IAAhBA,EAAKL,OACP,MAAM,IAAI5B,MAAM,6CAElB,MAAMyrB,EAAUxpB,EAAK,GACrB,GAAIwpB,aAAmBR,GACrB,OAAO,IAAIJ,GAAazqB,KAAK2M,MAAM6D,SAAS6a,EAAQ1e,QAC/C,GAAI0e,aAAmBC,GAAY,CACxC,IAAK,MAAMhZ,KAAQ+Y,EAAQ1e,MAAO,CAChC,KAAM2F,aAAgBuY,IACpB,MAAM,IAAIjrB,MAAM,6CAElB,GAAII,KAAK2M,MAAM6D,SAAS8B,EAAK3F,OAC3B,OAAO,IAAI8d,IAAa,EAE5B,CACA,OAAO,IAAIA,IAAa,EAC1B,CACA,MAAM,IAAI7qB,MAAM,+DAGpB,CACE,QAGA,IAAIkrB,GAAejpB,IAAS,IAAA0pB,EAAAC,EAC1B,MAAMC,EAAa,QAAVF,EAAG1pB,EAAK,UAAE,IAAA0pB,EAAAA,EAAI,IAAIG,GAC3B,KAAMD,aAAeZ,IAAeY,aAAeC,IACjD,MAAM,IAAI9rB,MAAM,yCAElB,MAAM+rB,EAAkB,QAAVH,EAAG3pB,EAAK,UAAE,IAAA2pB,EAAAA,EAAI,IAAId,IAAc,GAC9C,KAAMiB,aAAoBjB,IACxB,MAAM,IAAI9qB,MAAM,sCAElB,IAAIoL,EAAS,GACb,GAAIygB,aAAeC,GAAW,CAC5B,MAAM3jB,EAAO/H,KAAK2M,MAAMye,YACxB,IAAK,MAAQ,EAAGQ,EAAK,MAAE/lB,KAAWkC,EAAK8jB,SAAS,QAAS,CACvD,IAAwB,IAApBF,EAAShf,OAAgB3B,EAAOxJ,QAAUmqB,EAAShf,YAAmB,IAAV9G,EAAkB,CAChFmF,EAAO/G,KAAK2nB,EAAQ7jB,EAAKqQ,MAAMvS,EAAQ+lB,EAAMpqB,SAC7C,KACF,CACAwJ,EAAO/G,KAAK2nB,EACd,CACF,KAAO,CACL,GAAkB,KAAdH,EAAI9e,MACN,MAAM,IAAI/M,MAAM,mBAElBoL,EAAShL,KAAK2M,MAAMZ,MAAM0f,EAAI9e,QACN,IAApBgf,EAAShf,OAAgB3B,EAAOxJ,OAASmqB,EAAShf,OACpD3B,EAAO/G,KAAK+G,EAAO8gB,OAAOH,EAAShf,OAAOtI,KAAKonB,EAAI9e,OAEvD,CACA,OAAO,IAAI2e,GAAWtgB,EAAOjG,IAAKgnB,GAAS,IAAIlB,GAAYkB,QAG/D,CACE,UACA,IAAIjB,GAAejpB,IACjB,GAAIA,EAAKL,OAAS,EAChB,MAAM,IAAI5B,MAAM,6CAElB,MAAMosB,EAAWnqB,EAAK,GAChBoqB,EAAWpqB,EAAK,GACtB,KAAMmqB,aAAoBnB,IAAeoB,aAAoBpB,IAC3D,MAAM,IAAIjrB,MAAM,uCAElB,IAAIssB,EAE4C,IAAAC,EAD5CtqB,EAAKL,OAAS,EAEd0qB,EADmB,0BAAjBrqB,EAAK,GAAGoN,KACwB,QAA7Bkd,EAAGtqB,EAAK,GAAG8K,MAAMzF,IAAI,gBAAQ,IAAAilB,EAAAA,EAAI,IAAIT,GAElC7pB,EAAK,GAGfqqB,EAAQ,IAAIR,GAEd,KAAMQ,aAAiBxB,IAAgBwB,aAAiBR,IACtD,MAAM,IAAI9rB,MAAM,qDAElB,OAAO,IAAIirB,GA5MnB,SAAiBuB,EAAKC,EAAUC,EAAUJ,GACxC,GAAc,IAAVA,EACF,OAAOE,EACT,IAAIG,EAAqB,MAATL,GAAiBA,EAAQ,EAAIM,IAAWN,EACxD,MAAMb,EAA8B,IAApBgB,EAAS7qB,OAAe,IAAIirB,OAAO,OAAQ,MAAQ,IAAIA,OAAoBJ,EANlFhqB,QAAQ,sBAAuB,QAM8D,MACtG,OAAO+pB,EAAIM,WAAWrB,EAAUO,GAC1BW,EAAY,KACZA,EACKD,GAEFV,EAEX,CAgM+BvpB,CAAQrC,KAAK2M,MAAOqf,EAASrf,MAAOsf,EAAStf,MAAOuf,EAAMvf,aAGrF,GAEA8d,GAAe,cAAcF,GAAa1qB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YACrC,eAAc,GAEvB,SAASosB,GAAOjhB,EAAOkhB,EAAQC,GAAsC,IAA/BC,IAAsBvrB,UAAAC,OAAA,QAAAb,IAAAY,UAAA,KAAAA,UAAA,GAC1D,MAAMwrB,EAAoB,OAALF,QAAK,IAALA,EAAAA,EAAS,EAC9B,OAAQnhB,EAAMuD,MACZ,IAAK,YACH,MAAO,OACT,IAAK,iBACH,OAAO6d,EAAyB,OAAS,YAC3C,IAAK,eACL,IAAK,aACL,IAAK,cACL,IAAK,eACH,OAAO/qB,KAAKC,UAAU0J,EAAMiB,OAC9B,IAAK,aACL,IAAK,cAAe,CAClB,MAAMqgB,EAAcJ,EAAS,IAAIK,OAAOL,GAAU,GAC5CM,EAAc,KAAOF,EAAYC,OAAOF,GACxCI,EAAkBD,EAAcF,EACtC,GAAmB,eAAfthB,EAAMuD,KAAuB,CAC/B,MAAMme,EAAO1hB,EAAMiB,MAAM5H,IACtB1B,GAAMspB,GAAOtpB,EAAGupB,EAAQG,EAAe,EAAGD,IAE7C,OAAOF,EAAS,IAAHpuB,OAAO2uB,GAAe3uB,OAAG4uB,EAAK/oB,KAAK,IAAD7F,OAAK2uB,KAAkB3uB,OAAG0uB,EAAW,SAAA1uB,OAAU4uB,EAAK/oB,KAAK,MAAK,IAC/G,CAAO,CACL,MAAM+oB,EAAOnsB,MAAM2C,KAAK8H,EAAMiB,MAAMpE,WAAWxD,IAAIyD,IAAkB,IAAhBgN,EAAK7I,GAAMnE,EAC9D,MAAMjE,EAAI,IAAH/F,OAAOgX,EAAG,OAAAhX,OAAMmuB,GAAOhgB,EAAOigB,EAAQG,EAAe,EAAGD,IAC/D,OAAOF,EAAS,GAAHpuB,OAAM2uB,GAAe3uB,OAAG+F,GAAMA,IAE7C,OAAOqoB,EAAS,IAAHpuB,OAAO4uB,EAAK/oB,KAAK,MAAI7F,OAAG0uB,EAAW,SAAA1uB,OAAU4uB,EAAK/oB,KAAK,MAAK,IAC3E,CACF,CACA,QACE,MAAM,IAAIzE,MAAM,2BAADpB,OAA4BkN,EAAMuD,OAEvD,CACA,IAAIoe,GAAc,cAAc9C,GAAa1qB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YACpC,gBAAaA,EAAAA,EAAAA,GAAA,gBAYO,IAAIoG,IAAI,CACjC,CACE,MACA,IAAImkB,GAAcwC,IAAyB,IAAAC,EAAAC,EAAA,IAAvBhY,EAAKiY,GAAaH,EACpC,KAAM9X,aAAeqV,IACnB,MAAM,IAAIjrB,MAAM,oCAADpB,OAAqCgX,EAAIvG,OAE1D,OAAgD,QAAhDse,EAAgC,QAAhCC,EAAOxtB,KAAK2M,MAAMzF,IAAIsO,EAAI7I,cAAM,IAAA6gB,EAAAA,EAAIC,SAAY,IAAAF,EAAAA,EAAI,IAAI7B,MAG5D,CAAC,QAAS,IAAIZ,GAAc,IAAM9qB,KAAK0tB,UACvC,CAAC,OAAQ,IAAI5C,GAAc,IAAM9qB,KAAKkF,SACtC,CAAC,SAAU,IAAI4lB,GAAc,IAAM9qB,KAAK4oB,WACxC,CACE,WACA,IAAIkC,GAAejpB,IAAS,IAAA8rB,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAC1B,IAAIC,EAAyB,IAAItnB,IACjC,MAAMunB,EAAiBrsB,EAAKsD,OAAQsQ,KAC9BA,aAAe0Y,MACjBF,EAASxY,EAAI9I,OACN,IAILyhB,EAAoE,QAAvDT,EAAuB,QAAvBC,EAAGM,EAAeG,GAAG,UAAE,IAAAT,EAAAA,EAAIK,EAAO/mB,IAAI,yBAAiB,IAAAymB,EAAAA,EAAI,IAAIlD,IAAa,GAC/F,KAAM2D,aAAyB3D,IAC7B,MAAM,IAAI7qB,MAAM,oCAElB,MAAM0uB,EAA6C,QAA3CT,EAAuB,QAAvBC,EAAGI,EAAeG,GAAG,UAAE,IAAAP,EAAAA,EAAIG,EAAO/mB,IAAI,aAAK,IAAA2mB,EAAAA,EAAI,IAAIhD,GAAY,OACvE,KAAMyD,aAAczD,IAClB,MAAM,IAAIjrB,MAAM,uBAElB,IAAK,CAAC,MAAO,SAAS4E,SAAS8pB,EAAG3hB,OAChC,MAAM,IAAI/M,MAAM,sCAElB,MAAM2uB,EAAuD,QAAhDR,EAAuB,QAAvBC,EAAGE,EAAeG,GAAG,UAAE,IAAAL,EAAAA,EAAIC,EAAO/mB,IAAI,kBAAU,IAAA6mB,EAAAA,EAAI,IAAItD,IAAa,GAClF,KAAM8D,aAAmB9D,IACvB,MAAM,IAAI7qB,MAAM,6BAElB,MAAM8tB,EAAQzsB,MAAM2C,KAAK5D,KAAK2M,MAAMpE,WAAWxD,IAAIypB,IAAA,IAAEhZ,EAAK7I,GAAM6hB,EAAA,OAAK,IAAIlD,GAAW,CAAC,IAAIT,GAAYrV,GAAM7I,MAAS8hB,KAAK,CAAC9V,EAAGC,KAC3H,MAAM/S,EAAqB,QAAbyoB,EAAG3hB,MAAkB,EAAI,EAGjC3B,EAAS0jB,GAFF/V,EAAEhM,MAAM9G,GACR+S,EAAEjM,MAAM9G,GAC2BuoB,EAAczhB,OAC9D,OAAO4hB,EAAQ5hB,OAAS3B,EAASA,IAEnC,OAAO,IAAIsgB,GAAWoC,QAG1B,CApDFlD,QAAAA,GACE,OAAO,IAAIC,GAAazqB,KAAK2M,MAAMgiB,KAAO,EAC5C,CAmDAjB,KAAAA,GACE,OAAO,IAAIpC,GACTrqB,MAAM2C,KAAK5D,KAAK2M,MAAMpE,WAAWxD,IAAI6pB,IAAA,IAAEpZ,EAAK7I,GAAMiiB,EAAA,OAAK,IAAItD,GAAW,CAAC,IAAIT,GAAYrV,GAAM7I,MAEjG,CACAzH,IAAAA,GACE,OAAO,IAAIomB,GAAWrqB,MAAM2C,KAAK5D,KAAK2M,MAAMzH,QAAQH,IAAKyQ,GAAQ,IAAIqV,GAAYrV,IACnF,CACAoT,MAAAA,GACE,OAAO,IAAI0C,GAAWrqB,MAAM2C,KAAK5D,KAAK2M,MAAMic,UAC9C,CACA/kB,QAAAA,GACE,OAAO8oB,GAAO3sB,KAAM,KAAM,GAAG,EAC/B,GAEEmuB,GAAwB,cAAcd,GAAYxtB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YAC7C,wBAAuB,GAE5B+qB,GAAa,cAAcf,GAAa1qB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YACnC,eAAYA,EAAAA,EAAAA,GAAA,gBACQ,IAAIoG,IAAI,CAAC,CAAC,SAAU,IAAI+jB,GAAa1qB,KAAK2M,MAAMnL,WAAU,CASrFgpB,QAAAA,GACE,OAAO,IAAIC,GAAazqB,KAAK2M,MAAMnL,OAAS,EAC9C,CACAqC,QAAAA,GACE,OAAO8oB,GAAO3sB,KAAM,KAAM,GAAG,EAC/B,GAEE6uB,GAAa,cAAcvD,GAAWzrB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YACjC,aAAY,GAEjBuqB,GAAgB,cAAcP,GAAa1qB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YACtC,gBAAe,GAEpBmrB,GAAY,cAAcnB,GAAa1qB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YAClC,YAAW,GAEhBuuB,GAAiB,cAAcvE,GAAa1qB,WAAAA,GAAA,SAAA0B,YAAAhB,EAAAA,EAAAA,GAAA,YACvC,iBAAgB,GAErBwuB,GAAc,MAChBlvB,WAAAA,CAAYmvB,IAGZzuB,EAAAA,EAAAA,GAAA,iBAG4B,IAAIoG,IAAI,CAClC,CACE,YACA,IAAImkB,GAAejpB,IACjB,GAAoB,IAAhBA,EAAKL,OACP,OAAO,IAAI6rB,GAA4B,IAAI1mB,KAE7C,GAAoB,IAAhB9E,EAAKL,UAAkBK,EAAK,aAAcwrB,IAC5C,MAAM,IAAIztB,MAAM,yEAElB,OAAOiC,EAAK,UAIlBtB,EAAAA,EAAAA,GAAA,aAGwB,IAAIoG,IAAI,CAC9B,CAAC,UAAYkd,GAA6B,iBAAjBA,EAAQ5U,MACjC,CAAC,WAAa4U,GAAYA,aAAmBiH,IAC7C,CACE,MACCjH,IACC,KAAMA,aAAmB6G,IACvB,MAAM,IAAI9qB,MAAM,iBAADpB,OAAkBqlB,EAAQ5U,OAE3C,OAAO4U,EAAQlX,MAAQ,IAAM,IAGjC,CACE,OACCkX,IACC,KAAMA,aAAmB6G,IACvB,MAAM,IAAI9qB,MAAM,kBAADpB,OAAmBqlB,EAAQ5U,OAE5C,OAAO4U,EAAQlX,MAAQ,IAAM,IAGjC,CAAC,QAAUkX,GAA6B,iBAAjBA,EAAQ5U,OAA4B4U,EAAQlX,OACnE,CAAC,OAASkX,GAA6B,iBAAjBA,EAAQ5U,MAA2B4U,EAAQlX,OACjE,CAAC,OAASkX,GAA6B,cAAjBA,EAAQ5U,MAC9B,CAAC,SAAW4U,GAA6B,gBAAjBA,EAAQ5U,MAChC,CAAC,SAAW4U,GAAYA,aAAmB6G,IAAgB7G,aAAmB8G,IAC9E,CAAC,UAAY9G,GAAYA,aAAmB6G,IAC5C,CAAC,WAAa7G,GAA6B,eAAjBA,EAAQ5U,MAA0C,gBAAjB4U,EAAQ5U,MACnE,CAAC,UAAY4U,GAA6B,gBAAjBA,EAAQ5U,MACjC,CACE,QACC4U,IACC,MAAMuI,EAAMvI,EAAQlX,MACpB,MAAwB,gBAAjBkX,EAAQ5U,MAA0Bmd,IAAQA,EAAIpB,gBAGzD,CACE,QACCnH,IACC,MAAMuI,EAAMvI,EAAQlX,MACpB,MAAwB,gBAAjBkX,EAAQ5U,MAA0Bmd,IAAQA,EAAIrB,gBAGzD,CAAC,OAASlH,GAA6B,cAAjBA,EAAQ5U,MAC9B,CAAC,UAAY4U,GAA6B,mBAAjBA,EAAQ5U,MACjC,CAAC,YAAc4U,GAA6B,mBAAjBA,EAAQ5U,MACnC,CAAC,UAAW,CAAC0J,EAAGC,IAAMD,EAAEhM,QAAUiM,EAAEjM,OACpC,CAAC,KAAM,CAACgM,EAAGC,IAAMD,EAAEhM,QAAUiM,EAAEjM,UArE/B3M,KAAKgvB,OAASA,CAChB,CAyEAjmB,GAAAA,CAAI9I,EAAM0M,GACR,OAAO3M,KAAKivB,gBAAgBhvB,EAAMivB,GAAuBviB,GAC3D,CACAsiB,eAAAA,CAAgBhvB,EAAM0M,GACpB,GAAI3M,KAAKmvB,UAAUloB,IAAIhH,GACrB,MAAM,IAAIqlB,YAAY,8BAAD9mB,OAA+ByB,IAGtD,OADAD,KAAKmvB,UAAUpmB,IAAI9I,EAAM0M,GAClBA,CACT,CAUAyiB,WAAAA,CAAYnvB,EAAM0M,GAEhB,OADA3M,KAAKmvB,UAAUpmB,IAAI9I,EAAM0M,GAClBA,CACT,CAMAnD,OAAAA,CAAQvJ,GACN,GAAID,KAAKmvB,UAAUloB,IAAIhH,GACrB,OAAOD,KAET,GAAIA,KAAKgvB,OACP,OAAOhvB,KAAKgvB,OAAOxlB,QAAQvJ,GAE7B,MAAM,IAAIL,MAAM,qBAADpB,OAAsByB,GACvC,CACAovB,cAAAA,CAAepvB,GACb,IAAI,IAAAqvB,EACF,OAA6C,QAA7CA,EAAOtvB,KAAKwJ,QAAQvJ,GAAMkvB,UAAUjoB,IAAIjH,UAAK,IAAAqvB,EAAAA,EAAI,IAAIR,EACvD,CAAE,MAAA1mB,GACA,OAAO,IAAI0mB,EACb,CACF,GAeF,SAASS,GAAkBjd,EAAMkd,GAC/B,MAAMC,EAAQD,EAAczjB,MAAM,KAClC,IAAIY,EAAQ2F,EACZ,IAAK,MAAMyZ,KAAQ0D,EACjB,GAAI9iB,aAAiB0gB,GAAa,KAAAqC,EAChC/iB,EAA6B,QAAxB+iB,EAAG/iB,EAAMA,MAAMzF,IAAI6kB,UAAK,IAAA2D,EAAAA,EAAI,IAAIZ,EACvC,KAAO,MAAIniB,aAAiB2e,IAQ1B,OAAO,IAAIwD,GAR2B,CACtC,MAAMjpB,EAAQ2W,SAASuP,EAAM,IAC7B,MAAKtP,MAAM5W,IAAUA,GAAS,GAAKA,EAAQ8G,EAAMA,MAAMnL,QAGrD,OAAO,IAAIstB,GAFXniB,EAAQA,EAAMA,MAAM9G,EAIxB,CAEA,CAEF,OAAO8G,CACT,CACA,SAAS+hB,GAAqB/V,EAAGC,GAA0B,IAAvBwV,EAAa7sB,UAAAC,OAAA,QAAAb,IAAAY,UAAA,IAAAA,UAAA,GAC/C,GAAIoX,aAAa+S,IAAa9S,aAAa8S,GACzC,OAAO,EAET,GAAI/S,aAAa+S,IAAa9S,aAAa8S,GACzC,MAAM,IAAI9rB,MAAM,kBAADpB,OAAmBma,EAAE1J,KAAI,UAAAzQ,OAASoa,EAAE3J,OAErD,GAAI0J,aAAamW,IAAkBlW,aAAakW,GAC9C,OAAO,EAET,GAAInW,aAAamW,IAAkBlW,aAAakW,GAC9C,MAAM,IAAIlvB,MAAM,kBAADpB,OAAmBma,EAAE1J,KAAI,UAAAzQ,OAASoa,EAAE3J,OAErD,MAAM0gB,EAAiBprB,GAAMA,aAAammB,IAAgBnmB,aAAaomB,IAAcpmB,aAAakmB,GAC5FmF,EAAmBrrB,GACnBA,aAAakmB,GACRlmB,EAAEoI,MAAQ,EAAI,EAEhBpI,EAAEoI,MAEX,GAAIgjB,EAAchX,IAAMgX,EAAc/W,GAAI,CACxC,MAAMiX,EAAOD,EAAgBjX,GACvBmX,EAAOF,EAAgBhX,GAC7B,OAAOiX,EAAOC,GAAQ,EAAID,EAAOC,EAAO,EAAI,CAC9C,CACA,GAAInX,EAAE1J,OAAS2J,EAAE3J,KACf,MAAM,IAAIrP,MAAM,mCAADpB,OAAoCma,EAAE1J,KAAI,SAAAzQ,OAAQoa,EAAE3J,OAErE,GACO,gBADC0J,EAAE1J,KACY,CAClB,IAAI8gB,EAAOpX,EAAEhM,MACTqjB,EAAOpX,EAAEjM,MAKb,OAJKyhB,IACH2B,EAAOA,EAAK/E,cACZgF,EAAOA,EAAKhF,eAEP+E,EAAOC,GAAQ,EAAID,EAAOC,EAAO,EAAI,CAC9C,CAEE,MAAM,IAAIpwB,MAAM,wBAADpB,OAAyBma,EAAE1J,MAEhD,CACA,IAAIghB,GAAc,MAEhBpwB,WAAAA,CAAYqwB,IAAK3vB,EAAAA,EAAAA,GAAA,sBACfP,KAAKmwB,OAAY,OAAHD,QAAG,IAAHA,EAAAA,EAAO,IAAInB,EAC3B,CAIAqB,GAAAA,CAAIpL,GACF,OAAOhlB,KAAKqwB,SAASrL,EAAShlB,KAAKmwB,OACrC,CAIAG,wBAAAA,CAAyBC,EAAMC,GAC7B,MAAM9M,EAAO1jB,KAAKqwB,SAASE,EAAK7M,KAAM8M,GACtC,OAAQD,EAAK9M,SAAS9W,OACpB,IAAK,MACH,OAAO+W,EAAK8G,WAAW7d,MAAQ3M,KAAKqwB,SAASE,EAAK5M,MAAO6M,GAAe9M,EAC1E,IAAK,KACH,OAAOA,EAAK8G,WAAW7d,MAAQ+W,EAAO1jB,KAAKqwB,SAASE,EAAK5M,MAAO6M,GAEpE,MAAM7M,EAAQ3jB,KAAKqwB,SAASE,EAAK5M,MAAO6M,GACxC,OAAQD,EAAK9M,SAAS9W,OACpB,IAAK,KACH,OAAO,IAAI8d,GAAa/G,EAAK/W,OAASgX,EAAMhX,OAC9C,IAAK,KACH,OAAO,IAAI8d,GAAa/G,EAAK/W,OAASgX,EAAMhX,OAEhD,GAAI+W,aAAgBoL,IAAkBnL,aAAiBmL,GAAgB,CACrE,GAAInL,aAAiBmL,IAAkB,CAAC,KAAM,UAAUtqB,SAAS+rB,EAAK9M,SAAS9W,OAC7E,OAAO,IAAI8d,GAAqC,WAAxB8F,EAAK9M,SAAS9W,OAExC,MAAM,IAAI/M,MAAM,4BAADpB,OAA6B+xB,EAAK9M,SAAS9W,MAAK,wBACjE,CAAO,GAAI+W,aAAgBgI,IAAa/H,aAAiB+H,GACvD,MAAM,IAAI9rB,MAAM,2CACX,GAA4B,MAAxB2wB,EAAK9M,SAAS9W,MACvB,OAAO,IAAIke,GAAYnH,EAAK/W,MAAM9I,WAAa8f,EAAMhX,MAAM9I,YACtD,IAAK6f,aAAgBgH,IAAgBhH,aAAgBiH,MAAgBhH,aAAiB+G,IAAgB/G,aAAiBgH,IAAa,CACzI,MAAMhS,EAAI+K,EAAK/W,MAAOiM,EAAI+K,EAAMhX,MAChC,OAAQ4jB,EAAK9M,SAAS9W,OACpB,IAAK,IACL,IAAK,IACL,IAAK,IAAK,CACR,MAAMxJ,EAA8B,MAAxBotB,EAAK9M,SAAS9W,MAAgBgM,EAAIC,EAA4B,MAAxB2X,EAAK9M,SAAS9W,MAAgBgM,EAAIC,EAAID,EAAIC,EAE5F,OADgB8K,aAAgBiH,IAAchH,aAAiBgH,GAC9C,IAAIA,GAAWxnB,GAAO,IAAIunB,GAAavnB,EAC1D,CACA,IAAK,IACH,OAAO,IAAIwnB,GAAWhS,EAAIC,GAC5B,IAAK,IAAK,CACR,MAAM6X,EAAM9X,EAAIC,EAEhB,OADgB8K,aAAgBiH,IAAchH,aAAiBgH,GAC9C,IAAIA,GAAW8F,GAAO,IAAI/F,GAAa+F,EAC1D,CACA,IAAK,IACH,OAAO,IAAIhG,GAAa9R,EAAIC,GAC9B,IAAK,IACH,OAAO,IAAI6R,GAAa9R,EAAIC,GAC9B,IAAK,KACH,OAAO,IAAI6R,GAAa9R,GAAKC,GAC/B,IAAK,KACH,OAAO,IAAI6R,GAAa9R,GAAKC,GAEnC,MAAO,GAAI8K,aAAgB4H,IAAc3H,aAAiB2H,IACxD,GACO,MADCiF,EAAK9M,SAAS9W,MAElB,OAAO,IAAI2e,GAAW5H,EAAK/W,MAAMnO,OAAOmlB,EAAMhX,aAE7C,GAAIgX,aAAiB2H,GAAY,CACtC,MAAM/C,OAA6D,IAApD5E,EAAMhX,MAAM2K,KAAMjU,GAAMA,EAAEsJ,QAAU+W,EAAK/W,OACxD,OAAQ4jB,EAAK9M,SAAS9W,OACpB,IAAK,KACH,OAAO,IAAI8d,GAAalC,GAC1B,IAAK,SACH,OAAO,IAAIkC,IAAclC,GAE/B,CACA,IAAI7E,aAAgBmH,IAAelH,aAAiBkH,KAE3C,MADC0F,EAAK9M,SAAS9W,MAElB,OAAO,IAAIke,GAAYnH,EAAK/W,MAAM9I,WAAa8f,EAAMhX,MAAM9I,YAGjE,GAAI6f,aAAgBmH,IAAelH,aAAiBkH,GAClD,OAAQ0F,EAAK9M,SAAS9W,OACpB,IAAK,KACH,OAAO,IAAI8d,GAAa9G,EAAMhX,MAAMnI,SAASkf,EAAK/W,QACpD,IAAK,SACH,OAAO,IAAI8d,IAAc9G,EAAMhX,MAAMnI,SAASkf,EAAK/W,QAGzD,GAAI+W,aAAgBmH,IAAelH,aAAiB0J,GAClD,OAAQkD,EAAK9M,SAAS9W,OACpB,IAAK,KACH,OAAO,IAAI8d,GAAa9G,EAAMhX,MAAM1F,IAAIyc,EAAK/W,QAC/C,IAAK,SACH,OAAO,IAAI8d,IAAc9G,EAAMhX,MAAM1F,IAAIyc,EAAK/W,QAGpD,MAAM,IAAI2Y,YAAY,qBAAD9mB,OAAsB+xB,EAAK9M,SAAS9W,MAAK,cAAAnO,OAAaklB,EAAKzU,KAAI,SAAAzQ,OAAQmlB,EAAM1U,MACpG,CACAyhB,iBAAAA,CAAkB7uB,EAAM2uB,GACtB,MAAMG,EAAsB,GACtBC,EAAmC,IAAIjqB,IAC7C,IAAK,MAAMyd,KAAYviB,EACrB,GAAsB,qBAAlBuiB,EAASnV,KAA6B,CACxC,MAAM4hB,EAAazM,EACb0M,EAAM9wB,KAAKqwB,SAASQ,EAAWzM,SAAUoM,GAC/C,KAAMM,aAAexF,IACnB,MAAM,IAAI1rB,MAAM,oCAADpB,OAAqCsyB,EAAI7hB,OAE1D,IAAK,MAAMqD,KAAQwe,EAAInkB,MACrBgkB,EAAoB1sB,KAAKqO,EAE7B,MAAO,GAAsB,8BAAlB8R,EAASnV,KAAsC,CACxD,MAAM8hB,EAAQ3M,EACdwM,EAAiB7nB,IAAIgoB,EAAMvb,IAAI7I,MAAO3M,KAAKqwB,SAASU,EAAMpkB,MAAO6jB,GACnE,KAAO,CACL,GAAII,EAAiBjC,KAAO,EAC1B,MAAM,IAAI/uB,MAAM,2DAElB+wB,EAAoB1sB,KAAKjE,KAAKqwB,SAASjM,EAAUoM,GACnD,CAEF,MAAO,CAACG,EAAqBC,EAC/B,CACAI,WAAAA,CAAYnN,EAASyC,EAAYkK,GAC/B,GAAwB,eAApBlK,EAAWrX,KAAuB,CACpC,MAAM9J,EAASmhB,EACf,GAAqB,WAAjBnhB,EAAOwH,MACT,OAAO,IAAIke,GAAY8B,GAAO9I,IAEhC,GAAIA,aAAmByH,GACrB,OAAQnmB,EAAOwH,OACb,IAAK,OACH,OAAOkX,EACT,IAAK,QACH,OAAOA,EAAQlX,MAAM,GACvB,IAAK,OACH,OAAOkX,EAAQlX,MAAMkX,EAAQlX,MAAMnL,OAAS,GAC9C,IAAK,SACH,OAAO,IAAIkpB,GAAa7G,EAAQlX,MAAMnL,QACxC,IAAK,UACH,OAAO,IAAI8pB,GAAWzH,EAAQlX,MAAMyL,QAAQmW,WAC9C,IAAK,OACH,OAAO,IAAIjD,GAAWzH,EAAQlX,MAAMyL,QAAQqW,KAAK,CAAC9V,EAAGC,IAAM8V,GAAqB/V,EAAGC,GAAG,KAExF,IAAK,OACH,OAAO,IAAIiS,GAAYhH,EAAQlX,MAAM5H,IAAK1B,GAAMA,EAAEsJ,OAAOtI,KAAK,KAChE,IAAK,SACH,OAAO,IAAIwmB,GAAY8B,GAAO9I,EAAS,KAAM,GAAG,IAClD,IAAK,SAAU,CACb,MAAMoN,EAAuB,IAAIC,IAC3B/gB,EAAS,GACf,IAAK,MAAMmC,KAAQuR,EAAQlX,MACpBskB,EAAKhqB,IAAIqL,EAAK3F,SACjBskB,EAAKE,IAAI7e,EAAK3F,OACdwD,EAAOlM,KAAKqO,IAGhB,OAAO,IAAIgZ,GAAWnb,EACxB,CACA,QACE,MAAM,IAAIvQ,MAAM,8BAADpB,OAA+B2G,EAAOwH,aAEpD,GAAIkX,aAAmBgH,GAC5B,OAAQ1lB,EAAOwH,OACb,IAAK,SACL,IAAK,QACL,IAAK,QACL,IAAK,QACL,IAAK,aAAc,CACjB,MAAMykB,EAAUvN,EAAQwN,SAASnqB,IAAI/B,EAAOwH,OAC5C,GAAIykB,aAAmBtG,GACrB,OAAOsG,EAAQzkB,MAEb,GACA6jB,GAEG,GAAIY,aAAmB1G,GAC5B,OAAO0G,EAEP,MAAM,IAAIxxB,MAAM,+BAADpB,OAAgC2G,EAAOwH,OAE1D,CACA,IAAK,OACH,OAAO,IAAIke,GAAYhH,EAAQlX,MAAM4D,QACvC,IAAK,SACH,OAAO,IAAIsa,GACThH,EAAQlX,MAAMZ,MAAM,MAAMhH,IACxB,CAAC1B,EAAG8R,IAEI,IAANA,GAAwB,IAAb9R,EAAE7B,OAAe6B,EAAI,OAASA,GAE3CgB,KAAK,OAEX,IAAK,OACL,IAAK,SACH,OAAOwf,EACT,IAAK,MAAO,CACV,MAAMiN,EAAMtU,SAASqH,EAAQlX,MAAO,IACpC,OAAO,IAAI+d,GAAajO,MAAMqU,GAAO,EAAIA,EAC3C,CACA,IAAK,QAAS,CACZ,MAAMA,EAAMQ,WAAWzN,EAAQlX,OAC/B,OAAO,IAAIge,GAAWlO,MAAMqU,GAAO,EAAIA,EACzC,CACA,QACE,MAAM,IAAIlxB,MAAM,+BAADpB,OAAgC2G,EAAOwH,aAErD,GAAIkX,aAAmB6G,IAAgB7G,aAAmB8G,GAC/D,OAAQxlB,EAAOwH,OACb,IAAK,MACH,OAAOkX,aAAmB6G,GAAe,IAAIA,GAAa1B,KAAKuI,IAAI1N,EAAQlX,QAAU,IAAIge,GAAW3B,KAAKuI,IAAI1N,EAAQlX,QACvH,IAAK,MACH,OAAO,IAAI+d,GAAa1B,KAAKwI,MAAM3N,EAAQlX,QAC7C,IAAK,QACH,OAAO,IAAIge,GAAW9G,EAAQlX,OAChC,QACE,MAAM,IAAI/M,MAAM,gCAADpB,OAAiC2G,EAAOwH,aAEtD,GAAIkX,aAAmBwJ,GAC5B,OAAQloB,EAAOwH,OACb,IAAK,QACH,OAAO,IAAI2e,GACTrqB,MAAM2C,KAAKigB,EAAQlX,MAAMpE,WAAWxD,IAAI0sB,IAAA,IAAEjc,EAAK7I,GAAM8kB,EAAA,OAAK,IAAInG,GAAW,CAAC,IAAIT,GAAYrV,GAAM7I,OAEpG,IAAK,SACH,OAAO,IAAI+d,GAAa7G,EAAQlX,MAAMgiB,MACxC,QAAS,CACP,MAAMyC,EAAUvN,EAAQwN,SAASnqB,IAAI/B,EAAOwH,OAC5C,GAAIykB,EACF,OAAIA,aAAmBtG,GACdsG,EAAQzkB,MAAM,GAAI6jB,GAEpBY,EAET,MAAM,IAAIxxB,MAAM,+BAADpB,OAAgC2G,EAAOwH,OACxD,OAEG,GAAIkX,aAAmB4G,GAC5B,OAAQtlB,EAAOwH,OACb,IAAK,OACH,OAAO,IAAI8d,GAAa5G,EAAQlX,OAClC,IAAK,MACH,OAAO,IAAI+d,GAAa7G,EAAQlX,MAAQ,EAAI,GAC9C,IAAK,QACH,OAAO,IAAIge,GAAW9G,EAAQlX,MAAQ,EAAI,GAC5C,IAAK,SACH,OAAO,IAAIke,GAAYhH,EAAQlX,MAAQ,OAAS,SAClD,QACE,MAAM,IAAI/M,MAAM,gCAADpB,OAAiC2G,EAAOwH,QAG7D,MAAM,IAAI/M,MAAM,wBAADpB,OAAyB2G,EAAOwH,MAAK,eAAAnO,OAAcqlB,EAAQ5U,MAC5E,CAAO,GAAwB,mBAApBqX,EAAWrX,KAA2B,CAC/C,MAAM9J,EAASmhB,EACf,GAA2B,eAAvBnhB,EAAO8d,OAAOhU,KAChB,MAAM,IAAIrP,MAAM,mBAADpB,OAAoB2G,EAAO8d,OAAOhU,OAEnD,MAAMyiB,EAAavsB,EAAO8d,OAAOtW,MACjC,GAAmB,WAAf+kB,EAAyB,KAAAC,EAC3B,MAAO,CAAE1D,GAAUjuB,KAAK0wB,kBAAkBvrB,EAAOtD,KAAM2uB,GACjD5D,EAA6B,QAAvB+E,EAAG1D,EAAO/mB,IAAI,iBAAS,IAAAyqB,EAAAA,EAAI,IAAIjG,GAC3C,KAAMkB,aAAkBlC,IAAgBkC,aAAkBlB,IACxD,MAAM,IAAI9rB,MAAM,mCAElB,OAAO,IAAIirB,GAAY8B,GAAO9I,EAAS+I,EAAOjgB,OAChD,CAAO,GAAmB,SAAf+kB,EAAuB,KAAAE,EAAAC,EAChC,IAAIllB,EACJ,GAAIkX,aAAmBgH,GACrBle,EAAQ1L,MAAM2C,KAAKigB,EAAQlX,WACtB,MAAIkX,aAAmByH,IAG5B,MAAM,IAAI1rB,MAAM,wBAADpB,OAAyBkzB,EAAU,eAAAlzB,OAAcqlB,EAAQ5U,OAFxEtC,EAAQkX,EAAQlX,MAAM5H,IAAK1B,GAAMA,EAAEsJ,MAGrC,CACA,MAAO9K,EAAMosB,GAAUjuB,KAAK0wB,kBAAkBvrB,EAAOtD,KAAM2uB,GACrDsB,EAAiD,QAAxCF,EAAa,QAAbC,EAAGhwB,EAAKwsB,GAAG,UAAE,IAAAwD,EAAAA,EAAI5D,EAAO/mB,IAAI,oBAAY,IAAA0qB,EAAAA,EAAI,IAAI/G,GAAY,IAC3E,KAAMiH,aAAqBjH,IACzB,MAAM,IAAIjrB,MAAM,8BAElB,OAAO,IAAIirB,GAAYle,EAAMtI,KAAKytB,EAAUnlB,OAC9C,CAAO,GAAmB,QAAf+kB,GAAuC,UAAfA,EAAwB,KAAAK,EAAAC,EACzD,MAAOnwB,EAAMosB,GAAUjuB,KAAK0wB,kBAAkBvrB,EAAOtD,KAAM2uB,GACrD/C,EAAkD,QAAtCsE,EAAa,QAAbC,EAAGnwB,EAAKwsB,GAAG,UAAE,IAAA2D,EAAAA,EAAI/D,EAAO/mB,IAAI,kBAAU,IAAA6qB,EAAAA,EAAoB,QAAfL,EAAuB,IAAIhH,GAAa,GAAK,IAAIC,GAAW,GACzH,GAAI9G,aAAmBgH,GAAa,CAClC,MAAMiG,EAAqB,QAAfY,EAAuBlV,SAASqH,EAAQlX,MAAO,IAAM2kB,WAAWzN,EAAQlX,OACpF,OAAO8P,MAAMqU,GAAOrD,EAA8B,QAAfiE,EAAuB,IAAIhH,GAAaoG,GAAO,IAAInG,GAAWmG,EACnG,CAAO,GAAIjN,aAAmB6G,IAAgB7G,aAAmB8G,GAC/D,OAAO9G,EACF,GAAIA,aAAmB4G,GAC5B,MAAsB,QAAfiH,EAAuB,IAAIhH,GAAa7G,EAAQlX,MAAQ,EAAI,GAAK,IAAIge,GAAW9G,EAAQlX,MAAQ,EAAI,GAE3G,MAAM,IAAI/M,MAAM,wBAADpB,OAAyBkzB,EAAU,eAAAlzB,OAAcqlB,EAAQ5U,MAE5E,CAAO,GAAmB,YAAfyiB,EAA0B,KAAAO,EAAAC,EAAAC,EACnC,MAAOtwB,EAAMosB,GAAUjuB,KAAK0wB,kBAAkBvrB,EAAOtD,KAAM2uB,GACrD/C,EAAsB,QAAVwE,EAAGpwB,EAAK,UAAE,IAAAowB,EAAAA,EAAI,IAAIpH,GAAY,IAC1CuH,EAA+C,QAAnCF,EAAU,QAAVC,EAAGtwB,EAAK,UAAE,IAAAswB,EAAAA,EAAIlE,EAAO/mB,IAAI,kBAAU,IAAAgrB,EAAAA,EAAI,IAAIzH,IAAa,GAC1E,KAAM2H,aAAwB3H,IAC5B,MAAM,IAAI7qB,MAAM,2CAElB,OAAIikB,aAAmBiL,IAAkBsD,EAAazlB,QAAUkX,EAAQ2G,WAAW7d,MAC1E8gB,EAEF5J,CACT,CACA,GAAIA,aAAmByH,GAAY,CACjC,OAAQoG,GACN,IAAK,OAAQ,KAAAW,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EACX,MAAO7wB,EAAMosB,GAAUjuB,KAAK0wB,kBAAkBvrB,EAAOtD,KAAM2uB,GACrDjC,EAA6C,QAAtC8D,EAAa,QAAbC,EAAGzwB,EAAKwsB,GAAG,UAAE,IAAAiE,EAAAA,EAAIrE,EAAO/mB,IAAI,kBAAU,IAAAmrB,EAAAA,EAAI,IAAI5H,IAAa,GACxE,KAAM8D,aAAmB9D,IACvB,MAAM,IAAI7qB,MAAM,6BAElB,MAAMwuB,EAA0D,QAA7CmE,EAAa,QAAbC,EAAG3wB,EAAKwsB,GAAG,UAAE,IAAAmE,EAAAA,EAAIvE,EAAO/mB,IAAI,yBAAiB,IAAAqrB,EAAAA,EAAI,IAAI9H,IAAa,GACrF,KAAM2D,aAAyB3D,IAC7B,MAAM,IAAI7qB,MAAM,oCAElB,MAAM+yB,EAAiD,QAAxCF,EAAa,QAAbC,EAAG7wB,EAAKwsB,GAAG,UAAE,IAAAqE,EAAAA,EAAIzE,EAAO/mB,IAAI,oBAAY,IAAAurB,EAAAA,EAAI,IAAI/G,GAC/D,KAAMiH,aAAqB9H,IAAe8H,aAAqBjI,IAAgBiI,aAAqBjH,IAClG,MAAM,IAAI9rB,MAAM,gDAElB,MAAMgzB,EAAgBtgB,IACpB,GAAIqgB,aAAqBjH,GACvB,OAAOpZ,EAGT,OAAOid,GAAkBjd,EADRqgB,aAAqBjI,GAAexmB,OAAOyuB,EAAUhmB,OAASgmB,EAAUhmB,QAG3F,OAAO,IAAI2e,GACTzH,EAAQlX,MAAMyL,QAAQqW,KAAK,CAAC9V,EAAGC,KAC7B,MAEM5N,EAAS0jB,GAFFkE,EAAaja,GACbia,EAAaha,GACsBwV,EAAczhB,OAC9D,OAAO4hB,EAAQ5hB,OAAS3B,EAASA,IAGvC,CACA,IAAK,aACL,IAAK,aAAc,CACjB,MAAM6nB,EAAwB,eAAfnB,EACf,GAAI7N,EAAQlX,MAAM8M,KAAMpW,KAAQA,aAAagqB,KAC3C,MAAM,IAAIztB,MAAM,IAADpB,OAAMkzB,EAAU,8CAEjC,GAAIvsB,EAAOtD,KAAK4X,KAAMpW,GAAiB,kBAAXA,EAAE4L,MAC5B,MAAM,IAAIrP,MAAM,iBAADpB,OAAmBkzB,EAAU,sBAE9C,MAAOoB,EAAMC,EAAUpmB,GAASxH,EAAOtD,KAAKkD,IAAK1B,GAAMrD,KAAKqwB,SAAShtB,EAAGmtB,IACxE,IAAIwC,EACJ,GAAID,EAAU,CACZ,MAAMnpB,EAAO4mB,EAAYyC,MAAM/rB,IAAI6rB,EAASpmB,OAC5C,IAAK/C,EACH,MAAM,IAAIhK,MAAM,iBAADpB,OAAkBu0B,EAASpmB,QAE5CqmB,EAAeppB,CACjB,MACEopB,EAAe,mBAAAE,EAAA3xB,UAAAC,OAAI6B,EAAC,IAAApC,MAAAiyB,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAD9vB,EAAC8vB,GAAA5xB,UAAA4xB,GAAA,OAAK9vB,EAAE,GAAGmnB,WAAW7d,KAAK,EAEhD,MAAMymB,EAAWvP,EAAQlX,MAAMxH,OAAQmN,IACrC,MAAMqG,EAAIrG,EAAK3F,MAAMzF,IAAI4rB,EAAKnmB,OACxB3B,IAAS2N,GAAIqa,EAAara,EAAGhM,GACnC,OAAOkmB,EAAS7nB,GAAUA,IAE5B,OAAO,IAAIsgB,GAAW8H,EACxB,CACA,IAAK,MAAO,CACV,MAAO,CAAEnF,GAAUjuB,KAAK0wB,kBAAkBvrB,EAAOtD,KAAM2uB,GACvD,GAAIvC,EAAOhnB,IAAI,aAAc,CAC3B,MAAM6rB,EAAO7E,EAAO/mB,IAAI,aACxB,KAAM4rB,aAAgBjI,IACpB,MAAM,IAAIjrB,MAAM,8BAElB,MAAM6tB,EAAeQ,EAAO/mB,IAAI,WAC1BmsB,EAASxP,EAAQlX,MAAM5H,IAAKuN,IAChC,KAAMA,aAAgB+a,IACpB,MAAM,IAAIztB,MAAM,kCAElB,MAAM+M,EAAQ4iB,GAAkBjd,EAAMwgB,EAAKnmB,OAC3C,OAAOA,aAAiBmiB,GAA6B,OAAZrB,QAAY,IAAZA,EAAAA,EAAgB,IAAIqB,GAAmBniB,IAElF,OAAO,IAAI2e,GAAW+H,EACxB,CACE,MAAM,IAAIzzB,MAAM,yEAEpB,EAEF,MAAM,IAAIA,MAAM,8BAADpB,OAA+BkzB,GAChD,CAAO,GAAI7N,aAAmBgH,GAAa,CACzC,OAAQ6G,GACN,IAAK,SAAU,KAAA4B,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EACb,MAAO9xB,EAAMosB,GAAUjuB,KAAK0wB,kBAAkBvrB,EAAOtD,KAAM2uB,GACrDoD,EAAyC,QAApCN,EAAa,QAAbC,EAAG1xB,EAAKwsB,GAAG,UAAE,IAAAkF,EAAAA,EAAItF,EAAO/mB,IAAI,gBAAQ,IAAAosB,EAAAA,EAAI,IAAI5I,GAAa,GACpE,KAAMkJ,aAAiBlJ,IACrB,MAAM,IAAI9qB,MAAM,0BAElB,MAAMi0B,EAAyC,QAApCL,EAAa,QAAbC,EAAG5xB,EAAKwsB,GAAG,UAAE,IAAAoF,EAAAA,EAAIxF,EAAO/mB,IAAI,gBAAQ,IAAAssB,EAAAA,EAAI,IAAI/I,IAAa,GAC9DqJ,EAAyC,QAApCJ,EAAa,QAAbC,EAAG9xB,EAAKwsB,GAAG,UAAE,IAAAsF,EAAAA,EAAI1F,EAAO/mB,IAAI,gBAAQ,IAAAwsB,EAAAA,EAAI,IAAIjJ,IAAa,GAC9DsJ,EAAQlQ,EAAQlX,MAAMZ,MAAM,MAC5B6gB,EAAS,IAAIK,OAAO2G,EAAMjnB,OAC1BqnB,EAAWD,EAAMhvB,IACrB,CAAC1B,EAAG8R,KAAO0e,EAAMlnB,OAAe,IAANwI,IAAY2e,EAAMnnB,OAAsB,IAAbtJ,EAAE7B,OAAe6B,EAAIupB,EAASvpB,GAErF,OAAO,IAAIwnB,GAAYmJ,EAAS3vB,KAAK,MACvC,CACA,IAAK,UAAW,CACd,MAAM4vB,EAAYpQ,EAAQwN,SAASnqB,IAAI,WACvC,KAAM+sB,aAAqBnJ,IACzB,MAAM,IAAIlrB,MAAM,gCAElB,MAAOiC,EAAMosB,GAAUjuB,KAAK0wB,kBAAkBvrB,EAAOtD,KAAM2uB,GAC3D,OAAOyD,EAAUtnB,MAAM,IAAI9K,EAAM,IAAIssB,GAAsBF,IAAUuC,EACvE,EAEF,MAAM,IAAI5wB,MAAM,+BAADpB,OAAgCkzB,GACjD,CAAO,GAAI7N,aAAmBwJ,GAAa,CACzC,MAAM+D,EAAUvN,EAAQwN,SAASnqB,IAAIwqB,GACrC,GAAIN,GAAWA,aAAmBtG,GAAe,CAC/C,MAAOjpB,EAAMosB,GAAUjuB,KAAK0wB,kBAAkBvrB,EAAOtD,KAAM2uB,GAI3D,OAHIvC,EAAOU,KAAO,GAChB9sB,EAAKoC,KAAK,IAAIkqB,GAAsBF,IAE/BmD,EAAQzkB,MAAM9K,EAAM2uB,EAC7B,CACA,MAAM,IAAI5wB,MAAM,+BAADpB,OAAgCkzB,GACjD,CACE,MAAM,IAAI9xB,MAAM,wBAADpB,OAAyBkzB,EAAU,eAAAlzB,OAAcqlB,EAAQ5U,MAE5E,CACA,MAAM,IAAIrP,MAAM,mBAADpB,OAAoB8nB,EAAWrX,MAChD,CAIAilB,wBAAAA,CAAyB3D,EAAMC,GAC7B,MAAM3M,EAAU7jB,KAAKqwB,SAASE,EAAK1M,QAAS2M,GAC5C,OAAOxwB,KAAKgxB,YAAYnN,EAAS0M,EAAKprB,OAAQqrB,EAChD,CAIA2D,sBAAAA,CAAuB5D,EAAMC,GAC3B,MAAM3M,EAAU7jB,KAAKqwB,SAASE,EAAK1M,QAAS2M,GACtC5mB,EAAO4mB,EAAYyC,MAAM/rB,IAAIqpB,EAAK3mB,KAAK+C,OAC7C,IAAK/C,EACH,MAAM,IAAIhK,MAAM,iBAADpB,OAAkB+xB,EAAK3mB,KAAK+C,QAE7C,MAAM3B,EAASpB,EAAKia,GACpB,OAAO,IAAI4G,GAAa8F,EAAKrM,QAAUlZ,EAASA,EAClD,CAIAopB,wBAAAA,CAAyB7D,EAAMC,GAE7B,OADkBxwB,KAAKqwB,SAASE,EAAK3mB,KAAM4mB,GAC5BhG,WAAW7d,MAGnB3M,KAAKqwB,SAASE,EAAKvM,IAAKwM,GAFtB,IAAI1B,EAGf,CAIAuF,uBAAAA,CAAwB9D,EAAMC,GAC5B,MAAMpM,EAAWpkB,KAAKqwB,SAASE,EAAKnM,SAAUoM,GAC9C,GACO,QADCD,EAAK9M,SAAS9W,MAElB,OAAO,IAAI8d,IAAcrG,EAASzX,OAElC,MAAM,IAAI2Y,YAAY,qBAAD9mB,OAAsB+xB,EAAK9M,SAAS9W,OAE/D,CACA2nB,yBAAAA,CAA0B/D,EAAMC,GAE9B,OADaxwB,KAAKqwB,SAASE,EAAK3L,UAAW4L,GAC/BhG,WAAW7d,MAAQ3M,KAAKqwB,SAASE,EAAK1L,SAAU2L,GAAexwB,KAAKqwB,SAASE,EAAKzL,UAAW0L,EAC3G,CACA+D,WAAAA,CAAYvP,EAASwL,GACnB,OAAOxwB,KAAKw0B,cAAcxP,EAAQld,KAAM0oB,EAC1C,CACAgE,aAAAA,CAAcC,EAAYjE,GACxB,IAAIxlB,EAAS,GACb,IAAK,MAAM0pB,KAAaD,EAAY,CAClC,MAAME,EAAgB30B,KAAKqwB,SAASqE,EAAWlE,GACpB,cAAvBmE,EAAc1lB,MAA+C,mBAAvB0lB,EAAc1lB,OACtDjE,GAAU2pB,EAAc9wB,WAE5B,CACA,OAAO,IAAIgnB,GAAY7f,EACzB,CACA4pB,kBAAAA,CAAmBrE,EAAMC,GACvB,OAAOA,EAAYnB,eAAekB,EAAK5jB,MACzC,CACAkoB,sBAAAA,CAAuB5M,EAAMuI,GAC3B,MAAO3uB,EAAMosB,GAAUjuB,KAAK0wB,kBAAkBzI,EAAKpmB,KAAM2uB,GACrDvC,EAAOU,KAAO,GAChB9sB,EAAKoC,KAAK,IAAIkqB,GAAsBF,IAEtC,MAAM1O,EAAKvf,KAAKqwB,SAASpI,EAAKhF,OAAQuN,GACtC,GAAgB,kBAAZjR,EAAGtQ,KACL,MAAM,IAAIrP,MAAM,qDAADpB,OAAsD+gB,EAAGtQ,OAE1E,OAAOsQ,EAAG5S,MAAM9K,EAAM2uB,EACxB,CACAsE,uBAAAA,CAAwBjS,EAAQoF,EAAMuI,GACpC,KAAM3N,aAAkByI,IAAczI,aAAkBgI,IACtD,MAAM,IAAIjrB,MAAM,2CAElB,MAAM8Q,EAAQ1Q,KAAKqwB,SAASpI,EAAKvX,MAAO8f,GAClClM,EAAOtkB,KAAKqwB,SAASpI,EAAK3D,KAAMkM,GAChCziB,EAAO/N,KAAKqwB,SAASpI,EAAKla,KAAMyiB,GACtC,KAAM9f,aAAiBga,IAAgBha,aAAiBoe,IACtD,MAAM,IAAIlvB,MAAM,4CAElB,KAAM0kB,aAAgBoG,IAAgBpG,aAAgBwK,IACpD,MAAM,IAAIlvB,MAAM,2CAElB,KAAMmO,aAAgB2c,IAAgB3c,aAAgB+gB,IACpD,MAAM,IAAIlvB,MAAM,2CAElB,OAAIijB,aAAkByI,GACb,IAAIA,GAAWlT,GAAMyK,EAAOlW,MAAO+D,EAAM/D,MAAO2X,EAAK3X,MAAOoB,EAAKpB,QAEjE,IAAIke,GAAYzS,GAAMnX,MAAM2C,KAAKif,EAAOlW,OAAQ+D,EAAM/D,MAAO2X,EAAK3X,MAAOoB,EAAKpB,OAAOtI,KAAK,IAErG,CACA0wB,wBAAAA,CAAyB9M,EAAMuI,GAC7B,MAAM3N,EAAS7iB,KAAKqwB,SAASpI,EAAKpF,OAAQ2N,GAC1C,IAAI1N,EAUAnW,EATJ,GAAIsb,EAAKlF,SAAU,CACjB,GAA2B,oBAAvBkF,EAAKnF,SAAS7T,KAChB,OAAOjP,KAAK80B,wBAAwBjS,EAAQoF,EAAKnF,SAAU0N,GAE3D1N,EAAW9iB,KAAKqwB,SAASpI,EAAKnF,SAAU0N,EAE5C,MACE1N,EAAW,IAAI+H,GAAY5C,EAAKnF,SAASnW,OAG3C,GAAIkW,aAAkBwK,GAAa,KAAA2H,EACjC,KAAMlS,aAAoB+H,IACxB,MAAM,IAAIjrB,MAAM,+CAADpB,OAAgDskB,EAAS7T,OAE1EtC,EAAwC,QAAnCqoB,EAAGnS,EAAOlW,MAAMzF,IAAI4b,EAASnW,cAAM,IAAAqoB,EAAAA,EAAInS,EAAOwO,SAASnqB,IAAI4b,EAASnW,MAC3E,MAAO,GAAIkW,aAAkByI,IAAczI,aAAkBgI,GAC3D,GAAI/H,aAAoB4H,GACtB/d,EAAQkW,EAAOlW,MAAM0hB,GAAGvL,EAASnW,OAC7BkW,aAAkBgI,KACpBle,EAAQ,IAAIke,GAAYhI,EAAOlW,MAAM0hB,GAAGvL,EAASnW,aAE9C,MAAImW,aAAoB+H,IAG7B,MAAM,IAAIjrB,MAAM,0DAADpB,OAA2DskB,EAAS7T,OAFnFtC,EAAQkW,EAAOwO,SAASnqB,IAAI4b,EAASnW,MAGvC,KACK,CACL,KAAMmW,aAAoB+H,IACxB,MAAM,IAAIjrB,MAAM,+CAADpB,OAAgDskB,EAAS7T,OAE1EtC,EAAQkW,EAAOwO,SAASnqB,IAAI4b,EAASnW,MACvC,CACA,OAAOA,aAAiB4d,GAAe5d,EAAQ,IAAImiB,EACrD,CACAmG,WAAAA,CAAY1E,EAAMC,GAChB,MAAM0E,EAAM3E,EAAK5jB,MAAQ3M,KAAKqwB,SAASE,EAAK5jB,MAAO6jB,GAAexwB,KAAKw0B,cAAcjE,EAAKzoB,KAAM0oB,GAChG,GAA2B,eAAvBD,EAAK9N,SAASxT,KAAuB,CACvC,MAAMkmB,EAAe5E,EAAK9N,SAAS9V,MACnC6jB,EAAYpB,YAAY+F,EAAcD,EACxC,MAAO,GAA2B,iBAAvB3E,EAAK9N,SAASxT,KAAyB,CAChD,MAAMmmB,EAAQ7E,EAAK9N,SACnB,KAAMyS,aAAe5J,IACnB,MAAM,IAAI1rB,MAAM,2CAADpB,OAA4C02B,EAAIjmB,OAEjE,MAAMxL,EAAMyxB,EAAIvoB,MAChB,GAAIlJ,EAAIjC,SAAW4zB,EAAMzoB,MAAMnL,OAC7B,MAAM,IAAI5B,MAAM,OAADpB,OAAQ42B,EAAMzoB,MAAMnL,OAASiC,EAAIjC,OAAS,MAAQ,OAAM,4BAEzE,IAAK,IAAI2T,EAAI,EAAGA,EAAIigB,EAAMzoB,MAAMnL,SAAU2T,EAAG,CAC3C,MAAMpP,EAAOqvB,EAAMzoB,MAAMwI,GACzB,GAAkB,eAAdpP,EAAKkJ,KACP,MAAM,IAAIrP,MAAM,2CAADpB,OAA4CuH,EAAKkJ,OAElEuhB,EAAYpB,YAAYrpB,EAAK4G,MAAOlJ,EAAI0R,GAC1C,CACF,KAAO,IAA2B,qBAAvBob,EAAK9N,SAASxT,KAWvB,MAAM,IAAIrP,MAAM,6CAADpB,OAA8CuD,KAAKC,UAAUuuB,EAAK9N,YAX7B,CACpD,MAAM8F,EAASgI,EAAK9N,SACdI,EAAS7iB,KAAKqwB,SAAS9H,EAAO1F,OAAQ2N,GAC5C,KAAM3N,aAAkBwK,IACtB,MAAM,IAAIztB,MAAM,yCAElB,GAA6B,eAAzB2oB,EAAOzF,SAAS7T,KAClB,MAAM,IAAIrP,MAAM,wDAElBijB,EAAOlW,MAAM5D,IAAIwf,EAAOzF,SAASnW,MAAOuoB,EAC1C,CAEA,CACA,OAAO,IAAIxJ,EACb,CACA2J,UAAAA,CAAW9E,EAAMC,GACf,MAAM5mB,EAAO5J,KAAKqwB,SAASE,EAAK3mB,KAAM4mB,GACtC,OAAOxwB,KAAKw0B,cAAc5qB,EAAK4gB,WAAW7d,MAAQ4jB,EAAKzoB,KAAOyoB,EAAKtO,UAAWuO,EAChF,CACA8E,WAAAA,CAAY/E,EAAMC,GAChB,MAAM+E,EAAQ,IAAIxG,GAAYyB,GAC9B,IAAI5mB,EAAMwY,EACV,GAA2B,qBAAvBmO,EAAKnO,SAASnT,KAA6B,CAC7C,MAAM4jB,EAAStC,EAAKnO,SACpBA,EAAWpiB,KAAKqwB,SAASwC,EAAO7O,IAAKuR,GACrC3rB,EAAOipB,EAAOjpB,IAChB,MACEwY,EAAWpiB,KAAKqwB,SAASE,EAAKnO,SAAUmT,GAE1C,KAAMnT,aAAoBkJ,IAAclJ,aAAoBiL,IAC1D,MAAM,IAAIztB,MAAM,qDAADpB,OAAsD4jB,EAASnT,OAE5EmT,aAAoBiL,KACtBjL,EAAWA,EAASld,QAEtB,MAAMwoB,EAAQ,GACR8H,EAAuB,GAC7B,IAAK,IAAIrgB,EAAI,EAAGA,EAAIiN,EAASzV,MAAMnL,SAAU2T,EAAG,CAC9C,MAAMsgB,EAAY,IAAI1G,GAAYwG,GAC5BtQ,EAAU7C,EAASzV,MAAMwI,GAC/B,IAAIugB,EACJ,GAA0B,eAAtBnF,EAAKpO,QAAQlT,KACfymB,EAAuBC,GAAWA,EAAOvG,YAAYmB,EAAKpO,QAAQxV,MAAOsY,OACpE,IAA0B,iBAAtBsL,EAAKpO,QAAQlT,KAkBtB,MAAM,IAAIrP,MAAM,6BAADpB,OAA8B+xB,EAAKpO,QAAQlT,OAlBX,CAC/C,MAAMkT,EAAUoO,EAAKpO,QACrB,GAAqB,eAAjB8C,EAAQhW,KACV,MAAM,IAAIrP,MAAM,oCAADpB,OAAqCymB,EAAQhW,OAE9D,MAAMgc,EAAIhG,EACV,GAAI9C,EAAQxV,MAAMnL,SAAWypB,EAAEte,MAAMnL,OACnC,MAAM,IAAI5B,MAAM,OAADpB,OAAQ2jB,EAAQxV,MAAMnL,OAASypB,EAAEte,MAAMnL,OAAS,MAAQ,OAAM,qBAE/Ek0B,EAAuBC,IACrB,IAAK,IAAIC,EAAI,EAAGA,EAAIzT,EAAQxV,MAAMnL,SAAUo0B,EAAG,CAC7C,GAA8B,eAA1BzT,EAAQxV,MAAMipB,GAAG3mB,KACnB,MAAM,IAAIrP,MAAM,sCAADpB,OAAuC2jB,EAAQxV,MAAMipB,GAAG3mB,OAEzE0mB,EAAOvG,YAAYjN,EAAQxV,MAAMipB,GAAGjpB,MAAOse,EAAEte,MAAMipB,GACrD,EAEJ,CAEA,CACA,GAAIhsB,EAAM,CACR8rB,EAAoBD,GAEpB,IADkBz1B,KAAKqwB,SAASzmB,EAAM6rB,GACvBjL,WAAW7d,MACxB,QAEJ,CACA+gB,EAAMzpB,KAAKghB,GACXuQ,EAAqBvxB,KAAKyxB,EAC5B,CACA,IAAI1qB,EAAS,GACT6qB,GAAc,EAClB,IAAK,IAAI1gB,EAAI,EAAGA,EAAIuY,EAAMlsB,SAAU2T,EAAG,CACrC,MAAM2gB,EAAuB,IAAInvB,IAAI,CACnC,CAAC,QAAS,IAAI+jB,GAAavV,EAAI,IAC/B,CAAC,SAAU,IAAIuV,GAAavV,IAC5B,CAAC,WAAY,IAAIuV,GAAagD,EAAMlsB,OAAS2T,IAC7C,CAAC,YAAa,IAAIuV,GAAagD,EAAMlsB,OAAS2T,EAAI,IAClD,CAAC,QAAS,IAAIsV,GAAmB,IAANtV,IAC3B,CAAC,OAAQ,IAAIsV,GAAatV,IAAMuY,EAAMlsB,OAAS,IAC/C,CAAC,SAAU,IAAIkpB,GAAagD,EAAMlsB,SAClC,CAAC,WAAY2T,EAAI,EAAIuY,EAAMvY,EAAI,GAAK,IAAI2Z,IACxC,CAAC,WAAY3Z,EAAIuY,EAAMlsB,OAAS,EAAIksB,EAAMvY,EAAI,GAAK,IAAI2Z,MAEzDyG,EAAMnG,YAAY,OAAQ,IAAI/B,GAAYyI,IAC1CN,EAAqBrgB,GAAGogB,GACxB,IAEEvqB,GADkBhL,KAAKw0B,cAAcjE,EAAKzoB,KAAMytB,GAC5B5oB,KACtB,CAAE,MAAOopB,GACP,GAAIA,aAAezL,GACjB,SAEF,GAAIyL,aAAe1L,GACjB,MAEF,MAAM0L,CACR,CACAF,GAAc,CAChB,CACA,GAAIA,EAAa,CAEf7qB,GADyBhL,KAAKw0B,cAAcjE,EAAKlO,aAAckT,GACpC5oB,KAC7B,CACA,OAAO,IAAIke,GAAY7f,EACzB,CAIAgrB,aAAAA,CAAczF,EAAMC,GAgClB,OA/BAA,EAAYpB,YACVmB,EAAKtwB,KAAK0M,MACV,IAAIme,GAAc,CAACjpB,EAAM0zB,KAAU,IAAAU,EACjC,MAAMC,EAAa,IAAInH,GAAYwG,GAEnC,IAAItH,EACsB,2BAAX,QAAXgI,GAFJp0B,EAAOA,EAAKuW,SAEHiW,IAAI,UAAE,IAAA4H,OAAA,EAAXA,EAAahnB,QACfgf,EAASpsB,EAAKs0B,OAEhB,IAAK,IAAIhhB,EAAI,EAAGA,EAAIob,EAAK1uB,KAAKL,SAAU2T,EAAG,CACzC,MAAMihB,EAAU7F,EAAK1uB,KAAKsT,GACpBkhB,EAAYx0B,EAAKsT,GACvB,GAAqB,eAAjBihB,EAAQnnB,KAAuB,CACjC,MAAMqnB,EAAaF,EACnB,IAAKC,EACH,MAAM,IAAIz2B,MAAM,gCAADpB,OAAiC83B,EAAW3pB,QAE7DupB,EAAW9G,YAAYkH,EAAW3pB,MAAO0pB,EAC3C,KAAO,IAAqB,8BAAjBD,EAAQnnB,KAOjB,MAAM,IAAIrP,MAAM,0BAADpB,OAA2B43B,EAAQnnB,OAPK,KAAAsnB,EAAAC,EACvD,MAAMzF,EAAQqF,EACRzpB,EAC4B,QADvB4pB,EAAY,OAATF,QAAS,IAATA,EAAAA,EACR,QADqBG,EAC3BvI,SAAM,IAAAuI,OAAA,EAANA,EAAQ7pB,MAAMzF,IAAI6pB,EAAMvb,IAAI7I,cAAM,IAAA4pB,EAAAA,EAClCv2B,KAAKqwB,SAASU,EAAMpkB,MAAOupB,GAC3BA,EAAW9G,YAAY2B,EAAMvb,IAAI7I,MAAOA,EAC1C,CAEA,CACF,CACA,OAAO3M,KAAKw0B,cAAcjE,EAAKzoB,KAAMouB,MAGlC,IAAIxK,EACb,CACA+K,qBAAAA,CAAsBlG,EAAMC,GAC1B,MAAMkG,EAAW,IAAI5L,GAAc,CAACpG,EAAYiS,KAC9C,MAAMC,EAAe,IAAI7H,GAAY4H,GACrC,GAAIpG,EAAK7L,WACP,IAAK,IAAIvP,EAAI,EAAGA,EAAIob,EAAK7L,WAAWljB,SAAU2T,EAAG,KAAA0hB,EAC/C,MAAMC,EAAQvG,EAAK7L,WAAWvP,GAC9B,GAAmB,eAAf2hB,EAAM7nB,KACR,MAAM,IAAIrP,MAAM,+CAADpB,OAAgDs4B,EAAM7nB,OAEvE2nB,EAAaxH,YAAY0H,EAAMnqB,MAAoB,QAAfkqB,EAAEnS,EAAWvP,UAAE,IAAA0hB,EAAAA,EAAI,IAAI/H,GAC7D,CAEF,OAAO9uB,KAAKw0B,cAAcjE,EAAKzoB,KAAM8uB,MAEhCG,EAAWC,GAAeh3B,KAAK0wB,kBAAkBH,EAAKra,KAAKrU,KAAM2uB,GACxEuG,EAAU9yB,KAAK,IAAIkqB,GAAsB6I,IACzC,MAAMzX,EAAKvf,KAAKqwB,SAASE,EAAKra,KAAK+M,OAAQuN,GAC3C,GAAgB,kBAAZjR,EAAGtQ,KACL,MAAM,IAAIrP,MAAM,qDAADpB,OAAsD+gB,EAAGtQ,OAE1E,MAAMgoB,EAAS,IAAIlI,GAAYyB,GAE/B,OADAyG,EAAO7H,YAAY,SAAUsH,GACtBnX,EAAG5S,MAAMoqB,EAAWE,EAC7B,CACAC,uBAAAA,CAAwB3G,EAAMC,GAC5B,MAAM2G,EAAWn3B,KAAKw0B,cAAcjE,EAAKzoB,KAAM0oB,GAC/C,OAAOxwB,KAAKgxB,YAAYmG,EAAU5G,EAAKprB,OAAQqrB,EACjD,CACAH,QAAAA,CAASqE,EAAWlE,GAClB,IAAKkE,EACH,OAAO,IAAI5F,GACb,OAAQ4F,EAAUzlB,MAChB,IAAK,UACH,OAAOjP,KAAKu0B,YAAYG,EAAWlE,GACrC,IAAK,MACH,OAAOxwB,KAAKi1B,YAAYP,EAAWlE,GACrC,IAAK,KACH,OAAOxwB,KAAKq1B,WAAWX,EAAWlE,GACpC,IAAK,MACH,OAAOxwB,KAAKs1B,YAAYZ,EAAWlE,GACrC,IAAK,QACH,OAAOxwB,KAAKg2B,cAActB,EAAWlE,GACvC,IAAK,gBACH,OAAOxwB,KAAKy2B,sBAAsB/B,EAAWlE,GAC/C,IAAK,QACH,MAAM,IAAInG,GACZ,IAAK,WACH,MAAM,IAAIC,GACZ,IAAK,iBACH,OAAO,IAAII,GAAagK,EAAU/nB,OACpC,IAAK,eACH,OAAO,IAAIge,GAAW+J,EAAU/nB,OAClC,IAAK,gBACH,OAAO,IAAIke,GAAY6J,EAAU/nB,OACnC,IAAK,eACH,OAAO,IAAI2e,GAAWoJ,EAAU/nB,MAAM5H,IAAK1B,GAAMrD,KAAKqwB,SAAShtB,EAAGmtB,KACpE,IAAK,eACH,OAAO,IAAI3B,GAAW6F,EAAU/nB,MAAM5H,IAAK1B,GAAMrD,KAAKqwB,SAAShtB,EAAGmtB,KACpE,IAAK,gBAAiB,CACpB,MAAM/nB,EAA0B,IAAI9B,IACpC,IAAK,MAAO6O,EAAK7I,KAAU+nB,EAAU/nB,MAAO,CAC1C,MAAMyqB,EAAep3B,KAAKqwB,SAAS7a,EAAKgb,GACxC,KAAM4G,aAAwBvM,IAC5B,MAAM,IAAIjrB,MAAM,oCAADpB,OAAqC44B,EAAanoB,OAEnExG,EAAQM,IAAIquB,EAAazqB,MAAO3M,KAAKqwB,SAAS1jB,EAAO6jB,GACvD,CACA,OAAO,IAAInD,GAAY5kB,EACzB,CACA,IAAK,aACH,OAAOzI,KAAK40B,mBAAmBF,EAAWlE,GAC5C,IAAK,iBACH,OAAOxwB,KAAK60B,uBAAuBH,EAAWlE,GAChD,IAAK,mBACH,OAAOxwB,KAAK+0B,yBAAyBL,EAAWlE,GAClD,IAAK,kBACH,OAAOxwB,KAAKq0B,wBAAwBK,EAAWlE,GACjD,IAAK,mBACH,OAAOxwB,KAAKswB,yBAAyBoE,EAAWlE,GAClD,IAAK,mBACH,OAAOxwB,KAAKk0B,yBAAyBQ,EAAWlE,GAClD,IAAK,kBACH,OAAOxwB,KAAKk3B,wBAAwBxC,EAAWlE,GACjD,IAAK,iBACH,OAAOxwB,KAAKm0B,uBAAuBO,EAAWlE,GAChD,IAAK,mBACH,OAAOxwB,KAAKo0B,yBAAyBM,EAAWlE,GAClD,IAAK,UACH,OAAOxwB,KAAKs0B,0BAA0BI,EAAWlE,GACnD,IAAK,UACH,OAAO,IAAI9E,GACb,QACE,MAAM,IAAIpG,YAAY,sBAAD9mB,OAAuBk2B,EAAUzlB,OAE5D,GAEF,SAASigB,GAAuBxjB,GAC9B,cAAeA,GACb,IAAK,SACH,OAAOid,OAAOjH,UAAUhW,GAAS,IAAIgf,GAAahf,GAAS,IAAIif,GAAWjf,GAC5E,IAAK,SACH,OAAO,IAAImf,GAAYnf,GACzB,IAAK,UACH,OAAO,IAAI+e,GAAa/e,GAC1B,IAAK,YACH,OAAO,IAAIojB,GACb,IAAK,SACH,OAAc,OAAVpjB,EACK,IAAIggB,GACFzqB,MAAMC,QAAQwK,GAChB,IAAI4f,GAAW5f,EAAM3G,IAAImqB,KAEzB,IAAI7B,GACT,IAAI1mB,IAAI9B,OAAO0D,QAAQmD,GAAO3G,IAAIsyB,IAAA,IAAE7hB,EAAK7I,GAAM0qB,EAAA,MAAK,CAAC7hB,EAAK0Z,GAAuBviB,QAGvF,IAAK,WACH,OAAO,IAAIme,GAAc,CAACjpB,EAAMy1B,KAAW,IAAAC,EAEzC,OAAOrI,GAD0C,QAArCqI,EAAG7rB,KAAS7J,EAAKkD,IAAK1B,GAAMA,EAAEsJ,eAAO,IAAA4qB,EAAAA,EAAI,QAGzD,QACE,MAAM,IAAI33B,MAAM,oCAADpB,OAAqCkN,IAE1D,CAGA,IAAI8rB,GAAU,KAyBd,SAASC,KAAyB,QAAAC,EAAAn2B,UAAAC,OAANuG,EAAI,IAAA9G,MAAAy2B,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAJ5vB,EAAI4vB,GAAAp2B,UAAAo2B,GAC9B,MAzBmB,OAyBK5vB,EAAK1D,KAAK,KAxBd,MAyBtB,CACA,SAASuzB,GAAiBC,EAAOhL,EAAOiL,GACtC,OAAOD,EAAM9yB,IAAKgzB,GAEpB,SAAyBxH,EAAM1D,EAAOiL,GACpC,MAAME,EAAMF,EAAU7K,OAAOJ,GAC7B,OAAQ0D,EAAKthB,MACX,IAAK,UACH,OAAO2oB,GAAiBrH,EAAKzoB,KAAM+kB,EAAOiL,GAC5C,IAAK,KACH,OAqBN,SAAkBvH,EAAM1D,EAAOiL,GAC7B,MAAME,EAAMF,EAAU7K,OAAOJ,GACvBoL,EAAU,GAChB,IAAIhT,EAAUsL,EACd,KAAOtL,IACLgT,EAAQh0B,KAAK,CAAE2F,KAAMqb,EAAQrb,KAAM9B,KAAMmd,EAAQnd,OAChB,IAA7Bmd,EAAQhD,UAAUzgB,QAA8C,OAA9ByjB,EAAQhD,UAAU,GAAGhT,OACzDgW,EAAUA,EAAQhD,UAAU,GAKhC,IAAIxO,EAAMukB,EAAMP,GAAgB,KAAMS,GAAiBD,EAAQ,GAAGruB,OAAS4tB,GAAUI,GAAiBK,EAAQ,GAAGnwB,KAAM+kB,EAAQ,EAAGiL,GAClI,IAAK,IAAI3iB,EAAI,EAAGA,EAAI8iB,EAAQz2B,SAAU2T,EACpC1B,GAAO+jB,GAAUQ,EAAMP,GAAgB,OAAQS,GAAiBD,EAAQ9iB,GAAGvL,OAAS4tB,GAAUI,GAAiBK,EAAQ9iB,GAAGrN,KAAM+kB,EAAQ,EAAGiL,GAEzI7S,GAAWA,EAAQhD,UAAUzgB,OAAS,IACxCiS,GAAO+jB,GAAUQ,EAAMP,GAAgB,QAAUD,GAAUI,GAAiB3S,EAAQhD,UAAW4K,EAAQ,EAAGiL,IAG5G,OADArkB,GAAO+jB,GAAUQ,EAAMP,GAAgB,SAChChkB,CACT,CA1Ca0kB,CAAS5H,EAAM1D,EAAOiL,GAC/B,IAAK,MACH,OAyCN,SAAmBvH,EAAM1D,EAAOiL,GAC9B,MAAME,EAAMF,EAAU7K,OAAOJ,GAC7B,IAAIuL,EAAoB,GACxB,GAA2B,qBAAvB7H,EAAKnO,SAASnT,KAA6B,CAC7C,MAAMgG,EAAIsb,EAAKnO,SACfgW,EAAoB,GAAH55B,OAAM05B,GAAiBjjB,EAAE+O,KAAI,QAAAxlB,OAAO05B,GAAiBjjB,EAAErL,MAC1E,MACEwuB,EAAoBF,GAAiB3H,EAAKnO,UAE5C,IAAI3O,EAAMukB,EAAMP,GAAgB,MAAOS,GAAiB3H,EAAKpO,SAAU,KAAMiW,GAAqBZ,GAAUI,GAAiBrH,EAAKzoB,KAAM+kB,EAAQ,EAAGiL,GAC/IvH,EAAKlO,aAAa7gB,OAAS,IAC7BiS,GAAO+jB,GAAUQ,EAAMP,GAAgB,QAAUD,GAAUI,GAAiBrH,EAAKlO,aAAcwK,EAAQ,EAAGiL,IAG5G,OADArkB,GAAO+jB,GAAUQ,EAAMP,GAAgB,UAChChkB,CACT,CAxDa4kB,CAAU9H,EAAM1D,EAAOiL,GAChC,IAAK,MACH,OAuDN,SAAmBvH,EAAM1D,EAAOiL,GAC9B,MAAME,EAAMF,EAAU7K,OAAOJ,GACvBnJ,EAAOwU,GAAiB3H,EAAK9N,UAC7BkB,EAAQ4M,EAAK5jB,MAAQurB,GAAiB3H,EAAK5jB,OAAS,GACpDA,EAAQqrB,EAAMP,GAAgB,MAAO,GAAFj5B,OAAKklB,GAAIllB,OAAG+xB,EAAK5jB,MAAQ,MAAQgX,EAAQ,KAClF,GAAyB,IAArB4M,EAAKzoB,KAAKtG,OACZ,OAAOmL,EAET,OAAOA,EAAQ6qB,GAAUI,GAAiBrH,EAAKzoB,KAAM+kB,EAAQ,EAAGiL,GAAaN,GAAUQ,EAAMP,GAAgB,SAC/G,CAhEaa,CAAU/H,EAAM1D,EAAOiL,GAChC,IAAK,QACH,OA+DN,SAAqBvH,EAAM1D,EAAOiL,GAChC,MAAME,EAAMF,EAAU7K,OAAOJ,GACvBhrB,EAAO0uB,EAAK1uB,KAAKkD,IAAImzB,IAAkB7zB,KAAK,MAClD,OAAO2zB,EAAMP,GAAgB,QAAS,GAAFj5B,OAAK+xB,EAAKtwB,KAAK0M,MAAK,KAAAnO,OAAIqD,EAAI,MAAO21B,GAAUI,GAAiBrH,EAAKzoB,KAAM+kB,EAAQ,EAAGiL,GAAaN,GAAUQ,EAAMP,GAAgB,WACvK,CAnEac,CAAYhI,EAAM1D,EAAOiL,GAClC,IAAK,QACH,OAAOE,EAAMP,GAAgB,SAC/B,IAAK,WACH,OAAOO,EAAMP,GAAgB,YAC/B,IAAK,gBACH,OA8DN,SAA6BlH,EAAM1D,EAAOiL,GACxC,MAAME,EAAMF,EAAU7K,OAAOJ,GACvBnrB,EAAS6uB,EAAK7L,YAAc6L,EAAK7L,WAAWljB,OAAS,EAAI,IAAHhD,OAAO+xB,EAAK7L,WAAW3f,IAAImzB,IAAkB7zB,KAAK,MAAK,KAAM,GACnHgiB,EAAW6R,GAAiB3H,EAAKra,MACvC,IAAIzC,EAAMukB,EAAMP,GAAgB,OAADj5B,OAAQkD,GAAU2kB,GAAYmR,GAG7D,OAFA/jB,GAAOmkB,GAAiBrH,EAAKzoB,KAAM+kB,EAAQ,EAAGiL,GAAaN,GAC3D/jB,GAAOukB,EAAMP,GAAgB,WACtBhkB,CACT,CAtEa+kB,CAAoBjI,EAAM1D,EAAOiL,GAC1C,IAAK,kBACH,OAqEN,SAA+BvH,EAAM1D,EAAOiL,GAC1C,MAAME,EAAMF,EAAU7K,OAAOJ,GACvB4L,EAA4B,eAArBlI,EAAKprB,OAAO8J,KAAwBshB,EAAKprB,OAAOwH,MAAQurB,GAAiB3H,EAAKprB,QAC3F,IAAIsO,EAAMukB,EAAMP,GAAgB,SAAUgB,GAAQjB,GAGlD,OAFA/jB,GAAOmkB,GAAiBrH,EAAKzoB,KAAM+kB,EAAQ,EAAGiL,GAAaN,GAC3D/jB,GAAOukB,EAAMP,GAAgB,aACtBhkB,CACT,CA5EailB,CAAsBnI,EAAM1D,EAAOiL,GAC5C,IAAK,UACH,OAAOE,EAAM,MAAQzH,EAAK5jB,MAAQ,MACpC,QACE,OAAOqrB,EAAM,OAASE,GAAiB3H,GAAQ,OAErD,CA5B6BoI,CAAgBZ,EAAMlL,EAAOiL,IAAYzzB,KAAKmzB,GAC3E,CAkGA,SAASU,GAAiB3H,GAAuB,IAAjBqI,EAAUr3B,UAAAC,OAAA,QAAAb,IAAAY,UAAA,GAAAA,UAAA,IAAI,EAC5C,OAAQgvB,EAAKthB,MACX,IAAK,mBAEH,MAAO,IAAPzQ,OAAW05B,GADD3H,EACoBnM,WAEhC,IAAK,aACH,OAAOmM,EAAK5jB,MACd,IAAK,iBAEL,IAAK,eACH,MAAO,GAAPnO,OAAU+xB,EAAK5jB,OACjB,IAAK,gBACH,OAAO5K,KAAKC,UAAUuuB,EAAK5jB,OAC7B,IAAK,mBAAoB,CACvB,MAAMsI,EAAIsb,EACJsI,EA7IZ,SAAqC5Q,GACnC,OAAQA,EAAKxE,SAASxU,MACpB,IAAK,+BACH,OAAO,EACT,IAAK,yBACH,OAAO,EACT,IAAK,2BACH,OAAO,EACT,IAAK,aACH,MAA4B,QAAxBgZ,EAAKxE,SAAS9W,MACT,EACmB,OAAxBsb,EAAKxE,SAAS9W,OAA0C,WAAxBsb,EAAKxE,SAAS9W,MACzC,EACF,EAEX,OAAO,CACT,CA6H6BmsB,CAA4B7jB,GAC7CyO,EAAOwU,GAAiBjjB,EAAEyO,KAAMmV,GAChClV,EAAQuU,GAAiBjjB,EAAE0O,MAAOkV,EAAiB,GACnD5Q,EAAO,GAAHzpB,OAAMklB,EAAI,KAAAllB,OAAIyW,EAAEwO,SAAS9W,MAAK,KAAAnO,OAAImlB,GAC5C,OAAOkV,EAAiBD,EAAa,IAAHp6B,OAAOypB,EAAI,KAAMA,CACrD,CACA,IAAK,kBAAmB,CACtB,MAAMhT,EAAIsb,EAEV,OADYtb,EAAEwO,SAAS9W,OAA8B,QAArBsI,EAAEwO,SAAS9W,MAAkB,IAAM,IAAMurB,GAAiBjjB,EAAEmP,SAAUoI,IAExG,CACA,IAAK,iBAAkB,CACrB,MAAMvX,EAAIsb,EACJ1uB,EAAOoT,EAAEpT,KAAKkD,IAAImzB,IAAkB7zB,KAAK,MAC/C,MAAO,GAAP7F,OAAU05B,GAAiBjjB,EAAEgO,QAAO,KAAAzkB,OAAIqD,EAAI,IAC9C,CACA,IAAK,mBAAoB,CACvB,MAAMoT,EAAIsb,EACV,IAAIvvB,EAAMk3B,GAAiBjjB,EAAE4N,QACxB,CACH,aACA,mBACA,iBACA,gBACA,iBACA,eACA,eACA,eACA,iBACAre,SAASyQ,EAAE4N,OAAO5T,QAClBjO,EAAM,IAAHxC,OAAOwC,EAAG,MAEf,IAAIgE,EAAOkzB,GAAiBjjB,EAAE6N,UAI9B,OAHK7N,EAAE8N,UAAgC,eAApB9N,EAAE6N,SAAS7T,OAC5BjK,EAAO,IAAHxG,OAAOwG,EAAI,MAEViQ,EAAE8N,SAAW,GAAHvkB,OAAMwC,EAAG,KAAAxC,OAAIwG,EAAI,QAAAxG,OAASwC,EAAG,KAAAxC,OAAIwG,EACpD,CACA,IAAK,mBAAoB,CACvB,MAAMiQ,EAAIsb,EACJ1M,EAAUqU,GAAiBjjB,EAAE4O,QAAS2I,KAC5C,MAAsB,mBAAlBvX,EAAE9P,OAAO8J,KACJ,GAAPzQ,OAAUqlB,EAAO,OAAArlB,OAAM05B,GAAiBjjB,EAAE9P,SAErC,GAAP3G,OAAUqlB,EAAO,OAAArlB,OAAMyW,EAAE9P,OAAOwH,MAClC,CACA,IAAK,mBAAoB,CACvB,MAAMsI,EAAIsb,EACV,MAAO,GAAP/xB,OAAU05B,GAAiBjjB,EAAE+O,KAAI,QAAAxlB,OAAO05B,GAAiBjjB,EAAErL,MAC7D,CACA,IAAK,iBAAkB,CACrB,MAAMqL,EAAIsb,EACV,MAAO,GAAP/xB,OAAU05B,GAAiBjjB,EAAE4O,SAAQ,OAAArlB,OAAMyW,EAAEiP,OAAS,OAAS,GAAE,KAAA1lB,OAAIyW,EAAErL,KAAK+C,MAC9E,CACA,IAAK,eACL,IAAK,eAAgB,CACnB,MAAMosB,EAAQxI,EAAK5jB,MAAM5H,IAAImzB,IACvBc,EAAyB,iBAAdzI,EAAKthB,KAA0B,KAAO,KACvD,MAAO,GAAPzQ,OAAUw6B,EAAS,IAAEx6B,OAAGu6B,EAAM10B,KAAK,OAAK7F,OAAGw6B,EAAS,GACtD,CACA,IAAK,gBAAiB,CACpB,MAAMzwB,EAAUtH,MAAM2C,KAAK2sB,EAAK5jB,MAAMpE,WAAWxD,IAC/Ck0B,IAAA,IAAEtkB,EAAGpQ,GAAE00B,EAAA,SAAAz6B,OAAQ05B,GAAiBvjB,GAAE,MAAAnW,OAAK05B,GAAiB3zB,MAE1D,MAAO,IAAP/F,OAAW+J,EAAQlE,KAAK,MAAK,IAC/B,CACA,IAAK,kBAAmB,CACtB,MAAM4Q,EAAIsb,EACJja,EAAIrB,EAAEvE,MAAQwnB,GAAiBjjB,EAAEvE,OAAS,GAC1CqE,EAAIE,EAAEqP,KAAO4T,GAAiBjjB,EAAEqP,MAAQ,GACxC4U,EAAKjkB,EAAElH,KAAO,IAAHvP,OAAO05B,GAAiBjjB,EAAElH,OAAU,GACrD,MAAO,GAAPvP,OAAU8X,EAAC,KAAA9X,OAAIuW,GAACvW,OAAG06B,EACrB,CACA,IAAK,4BAA6B,CAChC,MAAMjkB,EAAIsb,EACV,MAAO,GAAP/xB,OAAUyW,EAAEO,IAAI7I,MAAK,KAAAnO,OAAI05B,GAAiBjjB,EAAEtI,OAC9C,CACA,IAAK,UAAW,CACd,MAAMsI,EAAIsb,EACJtI,EAAO,GAAHzpB,OAAM05B,GAAiBjjB,EAAE4P,UAAS,QAAArmB,OAAO05B,GAAiBjjB,EAAE2P,UAAW,GAAE,UAAApmB,OAAS05B,GAC1FjjB,EAAE6P,YAEJ,OAAO8T,GAAc,EAAI,IAAHp6B,OAAOypB,EAAI,KAAMA,CACzC,CACA,QACE,MAAM,IAAIroB,MAAM,4BAADpB,OAA6B+xB,EAAKthB,OAEvD,CAGA,IAAIkqB,GAAW,MAKbt5B,WAAAA,CAAYu5B,IAAU74B,EAAAA,EAAAA,GAAA,sBACpB,MAAMwkB,EAjiFV,SAAkBsU,GAChB,MAAMtU,EAAS,GACTuU,EAdR,SAAoBF,GAAwB,IAAdryB,EAAOxF,UAAAC,OAAA,QAAAb,IAAAY,UAAA,GAAAA,UAAA,GAAG,CAAC,EAUvC,OATI63B,EAAS5oB,SAAS,QACpB4oB,EAAWA,EAAShhB,MAAM,GAAI,IAE5BrR,EAAQwyB,gBACVH,EAAWA,EAAS/2B,QAAQ,oBAAqB,OAE/C0E,EAAQyyB,cACVJ,EAAWA,EAAS/2B,QAAQ,cAAe,OAEtC+2B,EAAS/2B,QAAQ,8BAAgC,GAC1D,CAGco3B,CAAWJ,EAFQ93B,UAAAC,OAAA,QAAAb,IAAAY,UAAA,GAAAA,UAAA,GAAG,CAAC,GAGnC,IAAIm4B,EAAiB,EACjBC,EAAoB,EACxB,MAAMC,EAAgBC,IACpB,IAAIzN,EAAM,GACV,KAAOyN,EAAUP,EAAII,KAAkB,CACrC,GAA4B,OAAxBJ,EAAII,GAA0B,CAEhC,KADEA,EACEA,GAAkBJ,EAAI93B,OACxB,MAAM,IAAI8jB,YAAY,2BACxB,MAAMwU,EAAUR,EAAII,KACdK,EAAYlY,GAAkB3a,IAAI4yB,GACxC,QAAkB,IAAdC,EACF,MAAM,IAAIzU,YAAY,iCAAD9mB,OAAkCs7B,IAEzD1N,GAAO2N,EACP,QACF,CAEA,GADA3N,GAAOkN,EAAII,KACPA,GAAkBJ,EAAI93B,OACxB,MAAM,IAAI8jB,YAAY,0BAC1B,CACA,OAAO8G,GAEH4N,EAA0BA,KAC9B,MAAMC,EAAYlV,EAAOsJ,IAAI,GACzB4L,GAAaA,EAAUhrB,OAAS2Q,GAAYE,OAC9Cma,EAAUttB,MAAQstB,EAAUttB,MAAMwe,UACV,KAApB8O,EAAUttB,OACZoY,EAAOoR,QAIP+D,EAAwBA,KAC5B,KAAOR,EAAiBJ,EAAI93B,QAAUmgB,GAAa2X,EAAII,OACnDA,GAGNS,EACE,KAAOT,EAAiBJ,EAAI93B,QAAQ,KAAA44B,EAClC,MAAMC,EAA6B,QAAhBD,EAAGrV,EAAOsJ,IAAI,UAAE,IAAA+L,OAAA,EAAbA,EAAenrB,KACrC,QAAsB,IAAlBorB,GAA4BA,IAAkBza,GAAYU,gBAAkB+Z,IAAkBza,GAAYY,iBAAmB6Z,IAAkBza,GAAY0B,QAAS,CACtK,IAAIvZ,EAAO,GACX,KAAO2xB,EAAiBJ,EAAI93B,SACF,MAAxB83B,EAAII,IAAwD,MAA5BJ,EAAII,EAAiB,IAA0C,MAA5BJ,EAAII,EAAiB,IAA0C,MAA5BJ,EAAII,EAAiB,KAC3H3xB,GAAQuxB,EAAII,KAEd,GAAI3xB,EAAKvG,OAAS,EAAG,CACnBujB,EAAO9gB,KAAK,IAAIsd,GAAMxZ,EAAM6X,GAAYE,OACxC,QACF,CACF,CACA,GAA4B,MAAxBwZ,EAAII,IAAuD,MAA5BJ,EAAII,EAAiB,GAAY,CAClEA,GAAkB,EAClB,MAAMY,EAAsC,MAAxBhB,EAAII,GACpBY,KACAZ,EAEJ,IAAIa,EAAU,GACd,KAA+B,MAAxBjB,EAAII,IAAuD,MAA5BJ,EAAII,EAAiB,IAAY,CACrE,GAAIA,EAAiB,GAAKJ,EAAI93B,OAC5B,MAAM,IAAI8jB,YAAY,8BAExBiV,GAAWjB,EAAII,IACjB,CACA,MAAMc,EAAaD,EAAQ/pB,SAAS,KAChCgqB,IACFD,EAAUA,EAAQniB,MAAM,GAAI,IAE1BkiB,GACFN,IAEFjV,EAAO9gB,KAAK,IAAIsd,GAAMgZ,EAAS3a,GAAY0B,UAC3CoY,GAAkB,EACdc,GACFN,IAEF,QACF,CACA,GAAsD,QAAlDZ,EAAIlhB,MAAMshB,EAAgBA,EAAiB,GAAc,CAC3DM,IACAjV,EAAO9gB,KAAK,IAAIsd,GAAM,KAAM3B,GAAYS,gBACxCqZ,GAAkB,EAClB,QACF,CACA,GAAsD,QAAlDJ,EAAIlhB,MAAMshB,EAAgBA,EAAiB,GAAc,CAC3DM,IACAjV,EAAO9gB,KAAK,IAAIsd,GAAM,KAAM3B,GAAYW,iBACxCoZ,EAAoB,EACpBD,GAAkB,EAClB,QACF,CAEA,GADAE,EAAajY,IACyC,QAAlD2X,EAAIlhB,MAAMshB,EAAgBA,EAAiB,GAAc,CAC3D3U,EAAO9gB,KAAK,IAAIsd,GAAM,KAAM3B,GAAYU,iBACxCoZ,GAAkB,EAClBQ,IACA,QACF,CACA,GAAsD,QAAlDZ,EAAIlhB,MAAMshB,EAAgBA,EAAiB,GAAc,CAC3D3U,EAAO9gB,KAAK,IAAIsd,GAAM,KAAM3B,GAAYY,kBACxCkZ,GAAkB,EAClBQ,IACA,QACF,CACA,MAAMzY,EAAO6X,EAAII,GACjB,GAAa,MAATjY,GAAyB,MAATA,EAAc,KAAAgZ,EAChC,MAAMC,EAA8B,QAAhBD,EAAG1V,EAAOsJ,IAAI,UAAE,IAAAoM,OAAA,EAAbA,EAAexrB,KACtC,GAAIyrB,IAAmB9a,GAAYE,WAA2B,IAAnB4a,EACzC,MAAM,IAAIpV,YAAY,yBAAD9mB,OAA0BijB,IAEjD,OAAQiZ,GACN,KAAK9a,GAAYK,WACjB,KAAKL,GAAYG,eACjB,KAAKH,GAAYI,cACjB,KAAKJ,GAAYQ,WACjB,KAAKR,GAAYc,mBACf,MACF,QAAS,GACLgZ,EACF,MAAMhR,EAAMkR,EAAalY,IACzBqD,EAAO9gB,KACL,IAAIsd,GAAM,GAAD/iB,OAAIijB,GAAIjjB,OAAGkqB,GAAOA,EAAIlnB,OAAS,EAAIoe,GAAYG,eAAiBH,GAAYyB,gBAEvF,QACF,EAEJ,CACA,IAAK,MAAOsZ,EAAK1rB,KAAS2S,GACxB,KAAY,OAAR+Y,GAAgBhB,EAAoB,IAGzBL,EAAIlhB,MAAMshB,EAAgBA,EAAiBiB,EAAIn5B,UAC/Cm5B,EAAK,CAClB5V,EAAO9gB,KAAK,IAAIsd,GAAMoZ,EAAK1rB,IACvBA,IAAS2Q,GAAYW,eACvBoZ,EAAoB,EACX1qB,IAAS2Q,GAAYe,mBAC5BgZ,EACO1qB,IAAS2Q,GAAYgB,qBAC5B+Y,EAEJD,GAAkBiB,EAAIn5B,OACtB,SAAS24B,CACX,CAEF,GAAa,MAAT1Y,GAAyB,MAATA,EAAc,GAC9BiY,EACF,MAAMtN,EAAMwN,EAAc3O,GAAMA,IAAMxJ,GACtCsD,EAAO9gB,KAAK,IAAIsd,GAAM6K,EAAKxM,GAAYI,kBACrC0Z,EACF,QACF,CACA,GAAIhY,GAAUD,GAAO,CACnB,IAAIiH,EAAMkR,EAAalY,IACvB,GAA4B,MAAxB4X,EAAII,IAA2BhY,GAAU4X,EAAII,EAAiB,IAAK,GACnEA,EACF,MAAMkB,EAAOhB,EAAalY,IAC1BgH,EAAM,GAAHlqB,OAAMkqB,EAAG,KAAAlqB,OAAIo8B,EAClB,CACA7V,EAAO9gB,KAAK,IAAIsd,GAAMmH,EAAK9I,GAAYG,iBACvC,QACF,CACA,GAAIyB,GAAOC,GAAO,CAChB,MAAMjQ,EAAOooB,EAAapY,IAC1BuD,EAAO9gB,KAAK,IAAIsd,GAAM/P,EAAMoO,GAAYK,aACxC,QACF,CACA,MAAM,IAAIqF,YAAY,yBAAD9mB,OAA0BijB,GACjD,CACF,OAAOsD,CACT,CAo3EmB8V,CAASzB,EAAU,CAChCG,eAAe,EACfC,aAAa,IAEfx5B,KAAK86B,OAAS5hB,GAAM6L,EACtB,CACAgW,MAAAA,CAAOrN,GACL,MAAMwC,EAAM,IAAInB,GAEhB,GA7pCJ,SAAsBmB,GACpBA,EAAInnB,IAAI,SAAS,GACjBmnB,EAAInnB,IAAI,QAAQ,GAChBmnB,EAAInnB,IAAI,OAAQ,MAChBmnB,EAAInnB,IAAI,kBAAoBlH,IAC1B,MAAM,IAAIjC,MAAMiC,KAElBquB,EAAInnB,IAAI,QAAS8f,IACjBqH,EAAInnB,IAAI,eAAgBqgB,IACxB8G,EAAInnB,IAAI,QAAQ,GAChBmnB,EAAInnB,IAAI,SAAS,GACjBmnB,EAAInnB,IAAI,OAAQ,KAClB,CAgpCIiyB,CAAa9K,GACTxC,EACF,IAAK,MAAOlY,EAAK7I,KAAU9H,OAAO0D,QAAQmlB,GACxCwC,EAAInnB,IAAIyM,EAAK7I,GAKjB,OAFoB,IAAIsjB,GAAYC,GACTE,IAAIpwB,KAAK86B,QACtBnuB,KAChB,CACAqd,MAAAA,CAAOjjB,GACL,OA/OJ,SAAgBie,GAAuB,IAAd4H,EAAMrrB,UAAAC,OAAA,QAAAb,IAAAY,UAAA,GAAAA,UAAA,GAAG,KAChC,MAAMu2B,EAA8B,kBAAXlL,EAAsB,IAAIK,OAAOL,GAAUA,EAEpE,OADagL,GAAiB5S,EAAQld,KAAM,EAAGgwB,GACnCz1B,QAAQ,MAAO,GAC7B,CA2OW2nB,CAAOhqB,KAAK86B,QAAe,OAAP/zB,QAAO,IAAPA,OAAO,EAAPA,EAAS6lB,SAAU,KAChD,GCzrFK,MAAMqO,GA8BK,CACV,uBACA,+BACA,mBACA,8BACA,qBACA,YACA,uBACA,2BACA,qBACA,iBACA,gBACA,qBACA,kBACA,mBACA,qBACA,gBACA,2BACA,sBACA,kBACA,gBACA,iBACA,uBACA,cACA,uBACA,4BACA,2BACA,iCACA,8BCpDFC,GAAa,IAAIv0B,IAAI,CACvB,CAAC,sBAAuB,CAAC,2BACzB,CACI,uBACA,CAAC,2CAAD,iGAMJ,CACI,2BACA,CACI,CACIoB,KAAM,wDACNozB,MAAO,CACHC,WAAY,CAAC,eAAgB,WAAY,cACzCC,MAAO,CAAC,MAAO,KAAM,MACrBC,aAAc,CAAC,IAAK,GAAI,IACxB,uBAAwB,CAAC,SAAU,SAAU,+BAK7D,CACI,qBACA,CACI,CACIvzB,KAAM,mBACNwzB,QAAS,4CAEb,CACIxzB,KAAM,mBACNwzB,QAAS,yCAEb,CACIxzB,KAAM,kBACNwzB,QAAS,4CAEb,CACIxzB,KAAM,wEACNwzB,QAAS,ujCAIrB,CACI,2BACA,CACI,CACIxzB,KAAM,kEACNyzB,iBAAkB,8CAClBC,aAAa,GAEjB,CACI1zB,KAAM,iHACNyzB,iBAAkB,2CAClBC,aAAa,GAEjB,CACI1zB,KAAM,gwCACNyzB,iBAAkB,yEAClBC,aAAa,KAIzB,CAAC,cAAe,CAAC,2CAAD,0CAChB,CACI,gBACA,CAAC,4uBAIL,CACI,iBACA,CAAC,iCAAD,uHAOJ,CACI,kBACA,CAAC,kCAAD,gGAOJ,CAAC,YAAa,CAAC,iCAAD,gCACd,CACI,sBACA,CACI,CACIC,gBAAiB,yBACjBC,UAAW,CAAC,sBAAuB,8BAA+B,6BAK5EC,GAAa,IAAIj1B,IAAI,CACvB,CAAC,sBAAuB,CAAC,sDACzB,CAAC,uBAAwB,CAAC,iFAAD,oKACzB,CACI,qBACA,CACI,CACIoB,KAAM,uCACNwzB,QAAS,kFAEb,CACIxzB,KAAM,uCACNwzB,QAAS,sEAEb,CACIxzB,KAAM,mDACNwzB,QAAS,oFAIrB,CAAC,cAAe,CAAC,iFAAD,uEAChB,CACI,2BACA,CACI,CACIxzB,KAAM,qEACNyzB,iBAAkB,gFAI9B,CACI,gBACA,CAAC,wpCAIL,CACI,kBACA,CAAC,yDAAD,8MAEJ,CAAC,YAAa,CAAC,yDAAD,qDACd,CACI,sBACA,CACI,CACIE,gBAAiB,8CACjBC,UAAW,CAAC,8CAAY,0DAAc,uCAKhDE,GAAa,IAAIl1B,IAAI,CACvB,CAAC,sBAAuB,CAAC,0CACzB,CAAC,uBAAwB,CAAC,+CAC1B,CACI,qBACA,CACI,CACIoB,KAAM,2BACNwzB,QAAS,gDAIrB,CAAC,cAAe,CAAC,+CACjB,CACI,gBACA,CAAC,i2BAIL,CAAC,kBAAmB,CAAC,+BAAD,+DACpB,CAAC,YAAa,CAAC,sCACf,CACI,sBACA,CACI,CACIG,gBAAiB,8BACjBC,UAAW,CACP,yBACA,sCACA,sDAMdG,GAAa,IAAIn1B,IAAI,CACvB,CAAC,sBAAuB,CAAC,uBACzB,CAAC,uBAAwB,CAAC,uCAC1B,CACI,qBACA,CACI,CACIoB,KAAM,qBACNwzB,QAAS,sCAEb,CACIxzB,KAAM,wCACNwzB,QAAS,2DAEb,CACIxzB,KAAM,6CACNwzB,QAAS,yGAIrB,CACI,cACA,CAAC,qCAAD,+EAKJ,CACI,gBACA,CAAC,01BAIL,CACI,kBACA,CAAC,6BAAD,gHAQJ,CAAC,YAAa,CAAC,4CAAD,uDACd,CACI,sBACA,CACI,CACIG,gBAAiB,2BACjBC,UAAW,CAAC,wBAAyB,+BAAgC,iCAK/EI,GAAa,IAAIp1B,IAAI,CACvB,CAAC,sBAAuB,CAAC,2JACzB,CAAC,uBAAwB,CAAC,4MAC1B,CACI,qBACA,CACI,CACIoB,KAAM,+CACNwzB,QAAS,6MAIrB,CAAC,cAAe,CAAC,4MACjB,CACI,gBACA,CAAC,4pHAIL,CAAC,kBAAmB,CAAC,sGAAD,mNACpB,CAAC,YAAa,CAAC,iOACf,CACI,sBACA,CACI,CACIG,gBAAiB,6HACjBC,UAAW,CAAC,uHAAyB,4JAAgC,mIAK/EK,GAAa,IAAIr1B,IAAI,CACvB,CAAC,cAAe,CAAC,6MACjB,CAAC,YAAa,CAAC,sEAEbs1B,GAAa,IAAIt1B,IAAI,CACvB,CAAC,sBAAuB,CAAC,qBACzB,CACI,uBACA,CAAC,sCAAD,uFAMJ,CACI,qBACA,CACI,CACIoB,KAAM,aACNwzB,QAAS,uCAEb,CACIxzB,KAAM,aACNwzB,QAAS,mCAEb,CACIxzB,KAAM,mBACNwzB,QAAS,wCAIrB,CAAC,cAAe,CAAC,sCAAD,oCAChB,CACI,gBACA,CAAC,2xBAIL,CACI,kBACA,CAAC,8BAAD,gIAQJ,CAAC,YAAa,CAAC,gCAAD,qCACd,CACI,sBACA,CACI,CACIG,gBAAiB,iCACjBC,UAAW,CAAC,6BAA2B,uCAAqC,uCAKtFO,GAAa,IAAIv1B,IAAI,CACvB,CACI,sBACA,CAAC,uMAAD,iSAEJ,CACI,uBACA,CAAC,sXAAD,msBAMJ,CACI,qBACA,CACI,CACIoB,KAAM,sGACNwzB,QAAS,uMAEb,CACIxzB,KAAM,wJACNwzB,QAAS,qOAEb,CACIxzB,KAAM,iEACNwzB,QAAS,0LAEb,CACIxzB,KAAM,kOACNwzB,QAAS,CACL,4hBACA,saACA,kZACFl3B,KAAK,SAInB,CACI,cACA,CACI,8ZACA,8YAGR,CACI,gBACA,CACI,CACI,qZACA,2VACA,sXACA,maACA,yZACA,6VACA,mYACA,2eACA,2YACA,mWACA,kVACA,wSACA,+XACA,sSACFA,KAAK,QAGf,CAAC,kBAAmB,CAAC,8GAA0B,wEAC/C,CACI,YACA,CAAC,sQAAD,ySAMF83B,GAAa,IAAIx1B,IAAI,CACvB,CAAC,sBAAuB,CAAC,6DACzB,CACI,uBACA,CAAC,+HAAD,6SAEJ,CACI,qBACA,CACI,CACIoB,KAAM,oDACNwzB,QAAS,gIAEb,CACIxzB,KAAM,oDACNwzB,QAAS,0HAEb,CACIxzB,KAAM,8CACNwzB,QAAS,2HAEb,CACIxzB,KAAM,oKACNwzB,QAAS,6nBAIrB,CAAC,cAAe,CAAC,+HAAD,2HAChB,CACI,gBACA,CAAC,0tCAIL,CACI,kBACA,CAAC,0FAAD,ytBAQJ,CAAC,YAAa,CAAC,wEAAD,6FACd,CACI,sBACA,CACI,CACIG,gBAAiB,iEACjBC,UAAW,CAAC,iEAAgB,oFAAoB,gGAK1DS,GAAa,IAAIz1B,IAAI,CACvB,CAAC,sBAAuB,CAAC,sKACzB,CACI,uBACA,CAAC,8LAAD,sVAEJ,CAAC,cAAe,CAAC,kLAAD,kIAChB,CACI,gBACA,CAAC,yiLAIL,CAAC,kBAAmB,CAAC,8EAAD,+KACpB,CAAC,YAAa,CAAC,0FAAD,yGACd,CACI,qBACA,CACI,CACIoB,KAAM,sSACNwzB,QAAS,y1FAEb,CACIxzB,KAAM,wTACNwzB,QAAS,ojCAEb,CACIxzB,KAAM,yOACNwzB,QAAS,ihFAIrB,CACI,sBACA,CACI,CACIG,gBAAiB,4GACjBC,UAAW,CAAC,mFAAmB,0FAAqB,0IAK9DU,GAAa,IAAI11B,IAAI,CACvB,CAAC,sBAAuB,CAAC,qFACzB,CACI,uBACA,CAAC,8OAAD,iXAMJ,CACI,qBACA,CACI,CACIoB,KAAM,mHACNwzB,QAAS,+OAEb,CACIxzB,KAAM,iGACNwzB,QAAS,+OAEb,CACIxzB,KAAM,sIACNwzB,QAAS,0NAIrB,CAAC,cAAe,CAAC,8OAAD,yNAChB,CACI,gBACA,CAAC,glFAIL,CACI,kBACA,CAAC,6GAAD,uVAEJ,CAAC,YAAa,CAAC,8OAAD,gKACd,CACI,+BACA,CACI,CACI51B,MAAO,6BACP2zB,IAAK,oFAET,CACI3zB,MAAO,4BACP2zB,IAAK,qFAIjB,CACI,iBACA,CAAC,mHAAD,4cAMJ,CACI,sBACA,CACI,CACIoC,gBAAiB,4IACjBC,UAAW,CAAC,wJAAiC,4KAAsC,gJAK7FW,GAAa,IAAI31B,IAAI,CACvB,CAAC,cAAe,CAAC,qIAAD,+LAChB,CAAC,YAAa,CAAC,gDAAD,wFAEZ41B,GAAa,IAAI51B,IAAI,CACvB,CACI,qBACA,CACI,CACIoB,KAAM,gBACNwzB,QAAS,iDAEb,CACIxzB,KAAM,2FACNwzB,QAAS,o9BAIrB,CACI,sBACA,CACI,CACIG,gBAAiB,oCACjBC,UAAW,CACP,kCACA,yCACA,mCAMda,GAAa,IAAI71B,IAAI,CACvB,CAAC,sBAAuB,CAAC,iLACzB,CACI,uBACA,CAAC,iUAAD,upBAMJ,CACI,qBACA,CACI,CACIoB,KAAM,uKACNwzB,QAAS,kUAEb,CACIxzB,KAAM,uKACNwzB,QAAS,sTAEb,CACIxzB,KAAM,mIACNwzB,QAAS,sTAEb,CACIxzB,KAAM,idACNwzB,QAAS,gjNAIrB,CACI,cACA,CAAC,iUAAD,uTAKJ,CACI,gBACA,CAAC,y2IAIL,CACI,kBACA,CAAC,sRAAD,imBAOJ,CAAC,YAAa,CAAC,iJAAD,sPCzoBLkB,ID2oByB,IAAI91B,IAAI,CAC1C,CAAC,KAAMu0B,IACP,CAAC,KAAMU,IACP,CAAC,KAAMC,IACP,CAAC,KAAMC,IACP,CAAC,KAAMC,IACP,CAAC,KAAMC,IACP,CAAC,KAAMC,IACP,CAAC,KAAMC,IACP,CAAC,KAAMC,IACP,CAAC,KAAMC,IACP,CAAC,KAAMC,IACP,CAAC,KAAMC,IACP,CAAC,KAAMC,IACP,CAAC,KAAMC,MCzpBkB,CACzB,sBAAuB,CACnBv8B,KAAM,sBACNy8B,SAAU,CACN,CACIztB,KAAM,+BACNhP,KAAM,gCAEV,CACIgP,KAAM,gCACNhP,KAAM,iCAEV,CACIgP,KAAM,gBACNhP,KAAM,iBAEV,CACIgP,KAAM,wBACNhP,KAAM,yBAEV,CACIgP,KAAM,0BACNhP,KAAM,2BAEV,CACIgP,KAAM,6BACNhP,KAAM,8BAEV,CACIgP,KAAM,6BACNhP,KAAM,8BAEV,CACIgP,KAAM,kCACNhP,KAAM,mCAEV,CACIgP,KAAM,6BACNhP,KAAM,8BAEV,CACIgP,KAAM,qCACNhP,KAAM,sCAEV,CACIgP,KAAM,2BACNhP,KAAM,4BAEV,CACIgP,KAAM,uBACNhP,KAAM,wBAEV,CACIgP,KAAM,8BACNhP,KAAM,+BAEV,CACIgP,KAAM,oBACNhP,KAAM,qBAEV,CACIgP,KAAM,qBACNhP,KAAM,sBAEV,CACIgP,KAAM,wBACNhP,KAAM,yBAEV,CACIgP,KAAM,eACNhP,KAAM,iBAGd08B,SAAU,OAEd,uBAAwB,CACpB18B,KAAM,uBACNy8B,SAAU,CACN,CACIztB,KAAM,2BACNhP,KAAM,4BAEV,CACIgP,KAAM,iBACNhP,KAAM,kBAEV,CACIgP,KAAM,UACNhP,KAAM,WAEV,CACIgP,KAAM,gBACNhP,KAAM,iBAEV,CACIgP,KAAM,4BACNhP,KAAM,6BAEV,CACIgP,KAAM,yBACNhP,KAAM,2BAGd08B,SAAU,OAEd,2BAA4B,CACxB18B,KAAM,2BACN08B,SAAU,OAEd,qBAAsB,CAClB18B,KAAM,qBACNy8B,SAAU,CACN,CACIztB,KAAM,gBACNhP,KAAM,iBAEV,CACIgP,KAAM,iBACNhP,KAAM,kBAEV,CACIgP,KAAM,mBACNhP,KAAM,qBAGd08B,SAAU,OAEd,2BAA4B,CACxB18B,KAAM,2BACN08B,SAAU,OAEdlrB,YAAa,CACTxR,KAAM,cACN08B,SAAU,OAEdhrB,cAAe,CACX1R,KAAM,gBACNy8B,SAAU,CACN,CACIztB,KAAM,8BACNhP,KAAM,+BAEV,CACIgP,KAAM,oCACNhP,KAAM,sCAGd08B,SAAU,OAEd,qBAAsB,CAClB18B,KAAM,qBACN08B,SAAU,OAEd,kBAAmB,CACf18B,KAAM,kBACNy8B,SAAU,CACN,CACIztB,KAAM,oBACNhP,KAAM,qBAEV,CACIgP,KAAM,sBACNhP,KAAM,uBAEV,CACIgP,KAAM,iBACNhP,KAAM,kBAEV,CACIgP,KAAM,oBACNhP,KAAM,qBAEV,CACIgP,KAAM,sBACNhP,KAAM,uBAEV,CACIgP,KAAM,yBACNhP,KAAM,0BAEV,CACIgP,KAAM,iBACNhP,KAAM,kBAEV,CACIgP,KAAM,6BACNhP,KAAM,8BAEV,CACIgP,KAAM,mBACNhP,KAAM,oBAEV,CACIgP,KAAM,eACNhP,KAAM,gBAEV,CACIgP,KAAM,iBACNhP,KAAM,kBAEV,CACIgP,KAAM,uBACNhP,KAAM,yBAGd08B,SAAU,OAEd,YAAa,CACT18B,KAAM,YACNy8B,SAAU,CACN,CACIztB,KAAM,eACNhP,KAAM,gBAEV,CACIgP,KAAM,2BACNhP,KAAM,6BAGd08B,SAAU,OAEd,sBAAuB,CACnB18B,KAAM,sBACN08B,SAAU,OAEd,iBAAkB,CACd18B,KAAM,iBACN08B,SAAU,SAEd,gBAAiB,CACb18B,KAAM,gBACN08B,SAAU,SAEd,+BAAgC,CAC5B18B,KAAM,+BACN08B,SAAU,SAEd,iBAAkB,CACd18B,KAAM,iBACN08B,SAAU,SAEd,uBAAwB,CACpB18B,KAAM,uBACNy8B,SAAU,CACN,CACIztB,KAAM,mBACNhP,KAAM,oBAEV,CACIgP,KAAM,yBACNhP,KAAM,0BAEV,CACIgP,KAAM,8BACNhP,KAAM,+BAEV,CACIgP,KAAM,4BACNhP,KAAM,6BAEV,CACIgP,KAAM,gCACNhP,KAAM,kCAGd08B,SAAU,SAEd,qBAAsB,CAClB18B,KAAM,qBACN08B,SAAU,aACVC,gBAAgB,GAEpB,2BAA4B,CACxB38B,KAAM,2BACN08B,SAAU,SAEd,mBAAoB,CAChB18B,KAAM,mBACN08B,SAAU,MAEd,uBAAwB,CACpB18B,KAAM,uBACNy8B,SAAU,CACN,CACIztB,KAAM,mCACNhP,KAAM,oCAEV,CACIgP,KAAM,mCACNhP,KAAM,qCAGd08B,SAAU,MAEd,mBAAoB,CAChB18B,KAAM,mBACNy8B,SAAU,CACN,CACIztB,KAAM,iBACNhP,KAAM,kBAEV,CACIgP,KAAM,oBACNhP,KAAM,sBAGd08B,SAAU,MAEd,qBAAsB,CAClB18B,KAAM,qBACNy8B,SAAU,CACN,CACIztB,KAAM,wBACNhP,KAAM,yBAEV,CACIgP,KAAM,wBACNhP,KAAM,yBAEV,CACIgP,KAAM,wBACNhP,KAAM,0BAGd08B,SAAU,MAEd,gBAAiB,CACb18B,KAAM,gBACN08B,SAAU,MAEd,gBAAiB,CACb18B,KAAM,gBACNy8B,SAAU,CACN,CACIztB,KAAM,mBACNhP,KAAM,qBAGd08B,SAAU,MAEd,iBAAkB,CACd18B,KAAM,iBACNy8B,SAAU,CACN,CACIztB,KAAM,mBACNhP,KAAM,oBAEV,CACIgP,KAAM,qBACNhP,KAAM,sBAEV,CACIgP,KAAM,mBACNhP,KAAM,qBAGd08B,SAAU,MAEd,iBAAkB,CACd18B,KAAM,iBACN08B,SAAU,MAEd,iCAAkC,CAC9B18B,KAAM,iCACN08B,SAAU,MAEd,uBAAwB,CACpB18B,KAAM,uBACN08B,SAAU,MAEd,yBAA0B,CACtB18B,KAAM,yBACN08B,SAAU,MAEdE,SAAU,CACN58B,KAAM,WACN08B,SAAU,KACVD,SAAU,CACN,CACIztB,KAAM,WACNhP,KAAM,YAEV,CACIgP,KAAM,gBACNhP,KAAM,mBAIlB,yBAA0B,CACtBA,KAAM,yBACN08B,SAAU,UACVD,SAAU,CACN,CACIztB,KAAM,qCACNhP,KAAM,sCAEV,CACIgP,KAAM,qCACNhP,KAAM,wCAIlB,qBAAsB,CAClBA,KAAM,qBACN08B,SAAU,UACVD,SAAU,CACN,CACIztB,KAAM,mCACNhP,KAAM,sCAIlB,kBAAmB,CACfA,KAAM,kBACN08B,SAAU,UACVD,SAAU,CACN,CACIztB,KAAM,cACNhP,KAAM,gBAGd68B,cAAc,GAElB,gBAAiB,CACb78B,KAAM,gBACN08B,SAAU,MACVG,cAAc,GAElB,kBAAmB,CACf78B,KAAM,kBACNy8B,SAAU,CACN,CACIztB,KAAM,qBACNhP,KAAM,sBAEV,CACIgP,KAAM,yCACNhP,KAAM,2CAGd08B,SAAU,MACVG,cAAc,GAElB,eAAgB,CACZ78B,KAAM,eACN08B,SAAU,OAEd,iBAAkB,CACd18B,KAAM,iBACNy8B,SAAU,CACN,CACIztB,KAAM,qBACNhP,KAAM,sBAEV,CACIgP,KAAM,sBACNhP,KAAM,uBAEV,CACIgP,KAAM,2BACNhP,KAAM,4BAEV,CACIgP,KAAM,0BACNhP,KAAM,4BAGd08B,SAAU,MACVG,cAAc,GAElB,0BAA2B,CACvB78B,KAAM,0BACN08B,SAAU,UACVD,SAAU,CACN,CACIztB,KAAM,qCACNhP,KAAM,sCAEV,CACIgP,KAAM,uCACNhP,KAAM,0CAIlB,gBAAiB,CACbA,KAAM,gBACN08B,SAAU,MAEd,qBAAsB,CAClB18B,KAAM,qBACN08B,SAAU,cAEd,sBAAuB,CACnB18B,KAAM,sBACN08B,SAAU,cAEd,sBAAuB,CACnB18B,KAAM,sBACN08B,SAAU,cAEd,4BAA6B,CACzB18B,KAAM,4BACNy8B,SAAU,CACN,CACIztB,KAAM,4BACNhP,KAAM,8BAGd08B,SAAU,cAEd,8BAA+B,CAC3B18B,KAAM,8BACNy8B,SAAU,CACN,CACIztB,KAAM,8BACNhP,KAAM,gCAGd08B,SAAU,aACVC,gBAAgB,GAEpB,iCAAkC,CAC9B38B,KAAM,iCACN08B,SAAU,MAEd,WAAY,CACR18B,KAAM,yBACN08B,SAAU,SAEd,kBAAmB,CACf18B,KAAM,kBACN08B,SAAU,MAEd,6BAA8B,CAC1B18B,KAAM,6BACN08B,SAAU,MAEd,aAAc,CACV18B,KAAM,aACN08B,SAAU,MAEd,cAAe,CACX18B,KAAM,cACN08B,SAAU,MAEd,2BAA4B,CACxB18B,KAAM,2BACN08B,SAAU,MAEd,qBAAsB,CAClB18B,KAAM,qBACN08B,SAAU,aACVC,gBAAgB,GAEpB,qBAAsB,CAClB38B,KAAM,qBACNy8B,SAAU,CACN,CACIztB,KAAM,kBACNhP,KAAM,oBAGd08B,SAAU,KACVC,gBAAgB,GAEpB,4BAA6B,CACzB38B,KAAM,4BACN08B,SAAU,cAEd,aAAc,CACV18B,KAAM,aACN08B,SAAU,cAEd,iBAAkB,CACd18B,KAAM,iBACN08B,SAAU,KACVC,gBAAgB,GAEpBG,MAAO,CACH98B,KAAM,QACN08B,SAAU,QACVG,cAAc,EACdF,gBAAgB,KAGXI,GAAiBn4B,OAAOK,KAAKu3B,ICnhB1C,IDohB6B53B,OAAO+jB,OAAO6T,IACtCQ,QAASn7B,GAAU,aAAcA,EAAOA,EAAK46B,SAAW,IACxD33B,IAAKuR,GAAMA,EAAErH,MACgB,IAAIiiB,IAAI8L,ICnmBzB,CACbE,SAAU,CACN,CACIC,YAAa,2CACbp6B,GAAI,gBAER,CACIo6B,YAAa,yDACbp6B,GAAI,wBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,YACVpuB,KAAM,UAGd3B,QAAS,CACL,CACIxL,KAAM,CACF,CACI6D,MAAO,KACPC,MAAO,IAEX,CACID,MAAO,OACPC,MAAO,KAGfqJ,KAAM,WAIlBquB,QAAS,CACL,CACIH,YAAa,GACbp6B,GAAI,YAER,CACIo6B,YAAa,GACbp6B,GAAI,UAER,CACIo6B,YAAa,GACbp6B,GAAI,aAER,CACIo6B,YAAa,GACbp6B,GAAI,OAGZmU,OAAQ,CACJ,CACIimB,YAAa,gDACbp6B,GAAI,6CAER,CACIo6B,YAAa,gCACbp6B,GAAI,6DAER,CACIo6B,YAAa,mCACbp6B,GAAI,yBAGZw6B,OAAQ,CACJ,CACIJ,YAAa,+DACbp6B,GAAI,oCAGZy6B,QAAS,kNACTC,aAAc,CAAC,2CACfC,UAAW,gBCVf,GAhEiB,CACbR,SAAU,CACN,CACIC,YAAa,4EACbp6B,GAAI,mBAER,CACIo6B,YAAa,+FACbp6B,GAAI,4BAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,YACVpuB,KAAM,SAEV,CACItJ,MAAO,cACPmM,QAAS,qCACT7C,KAAM,SAGd3B,QAAS,CACL,CACI3H,MAAO,iBACPmM,QAAS,uCACT7C,KAAM,UAIlBquB,QAAS,GACTpmB,OAAQ,CACJ,CACIimB,YAAa,8GACbp6B,GAAI,uCAER,CACIo6B,YAAa,kEACbp6B,GAAI,gCAER,CACIo6B,YAAa,0EACbp6B,GAAI,oCAER,CACIo6B,YAAa,iEACbp6B,GAAI,4BAGZw6B,OAAQ,CACJ,CACIJ,YAAa,yEACbp6B,GAAI,oBAER,CACIo6B,YAAa,0EACbp6B,GAAI,uCAGZy6B,QAAS,6WACTC,aAAc,GACdC,UAAW,ICHf,GA3DiB,CACbR,SAAU,CACN,CACIC,YAAa,uEACbp6B,GAAI,iCAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,YACVpuB,KAAM,UAGd3B,QAAS,CACL,CACI+vB,SAAU,cACVpuB,KAAM,SAEV,CACIouB,SAAU,cACVpuB,KAAM,WAIlBquB,QAAS,CACL,CACIH,YAAa,qNACbp6B,GAAI,QAER,CACIo6B,YAAa,uIACbp6B,GAAI,SAGZmU,OAAQ,CACJ,CACIimB,YAAa,8BACbp6B,GAAI,+BAER,CACIo6B,YAAa,2DACbp6B,GAAI,0BAGZw6B,OAAQ,CACJ,CACIJ,YAAa,wCACbp6B,GAAI,yCAER,CACIo6B,YAAa,2CACbp6B,GAAI,yCAGZy6B,QAAS,0LACTC,aAAc,CAAC,8BACfC,UAAW,eCgCf,GAzFiB,CACbR,SAAU,CACN,CACIC,YAAa,oEACbp6B,GAAI,wCAER,CACIo6B,YAAa,mEACbp6B,GAAI,0BAER,CACIo6B,YAAa,8FACbp6B,GAAI,sBAER,CACIo6B,YAAa,yDACbp6B,GAAI,iBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,aACVpuB,KAAM,UAGd3B,QAAS,CACL,CAEI3H,MAAO,aACPmM,QAAS,wEACT7C,KAAM,UAIlBquB,QAAS,CACL,CACIH,YAAa,GACbp6B,GAAI,OAER,CACIo6B,YAAa,GACbp6B,GAAI,QAGZmU,OAAQ,CACJ,CACIimB,YAAa,kCACbp6B,GAAI,2BAER,CACIo6B,YAAa,yDACbp6B,GAAI,yBAER,CACIo6B,YAAa,0EACbp6B,GAAI,kCAER,CACIo6B,YAAa,sEACbp6B,GAAI,oBAER,CACIo6B,YAAa,sCACbp6B,GAAI,qCAGZw6B,OAAQ,CACJ,CACIJ,YAAa,6DACbp6B,GAAI,6BAER,CACIo6B,YAAa,wCACbp6B,GAAI,yBAER,CACIo6B,YAAa,4DACbp6B,GAAI,yBAER,CACIo6B,YAAa,qEACbp6B,GAAI,qBAGZy6B,QAAS,sLACTC,aAAc,CAAC,2BACfC,UAAW,eCVf,GA7EiB,CACbR,SAAU,CACN,CACIC,YAAa,0CACbp6B,GAAI,0BAER,CACIo6B,YAAa,4GACbp6B,GAAI,mBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,WACPmM,QAAS,kEACT7C,KAAM,QAEV,CACIouB,SAAU,wCACVpuB,KAAM,QAGd3B,QAAS,CACL,CACI3H,MAAO,SACPmM,QAAS,wDACT7C,KAAM,UAIlBquB,QAAS,CACL,CACIH,YAAa,kOACbp6B,GAAI,QAER,CACIo6B,YAAa,uOACbp6B,GAAI,gBAGZmU,OAAQ,CACJ,CACIimB,YAAa,8CACbp6B,GAAI,+BAER,CACIo6B,YAAa,+DACbp6B,GAAI,4BAER,CACIo6B,YAAa,4DACbp6B,GAAI,wBAER,CACIo6B,YAAa,oDACbp6B,GAAI,mCAGZw6B,OAAQ,CACJ,CACIJ,YAAa,oDACbp6B,GAAI,mBAER,CACIo6B,YAAa,0DACbp6B,GAAI,mBAER,CACIo6B,YAAa,0EACbp6B,GAAI,gCAGZy6B,QAAS,0WACTC,aAAc,CAAC,4BACfC,UAAW,ICvBf,GApDiB,CACbR,SAAU,CACN,CACIC,YAAa,oHACbp6B,GAAI,cAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,QACPmM,QAAS,uEACT7C,KAAM,SAGd3B,QAAS,CACL,CACI6tB,MAAO,CACH,CAAC,cAAe,cAAe,eAC/B,CAAC,oBAAqB,oBAAqB,sBAC3C,CAAC,mBAAoB,qBAAsB,oBAC3C,CAAC,sBAAuB,qBAAsB,uBAC9C,CAAC,sBAAuB,qBAAsB,uBAElDlsB,KAAM,aAIlBquB,QAAS,GACTpmB,OAAQ,CACJ,CACIimB,YAAa,6EACbp6B,GAAI,sBAER,CACIo6B,YAAa,mDACbp6B,GAAI,wCAGZw6B,OAAQ,CACJ,CACIJ,YAAa,6EACbp6B,GAAI,oBAER,CACIo6B,YAAa,gFACbp6B,GAAI,eAGZy6B,QAAS,2EACTC,aAAc,CAAC,uBCsBnB,GAxEiB,CACbP,SAAU,CACN,CACIC,YAAa,oEACbp6B,GAAI,aAER,CACIo6B,YAAa,0DACbp6B,GAAI,OAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,QACPmM,QAAS,0BACT7C,KAAM,SAGd3B,QAAS,CACL,CACI2B,KAAM,QACNnN,KAAM,CACF,CACI6D,MAAO,OACPC,MAAO,MAEX,CACID,MAAO,MACPC,MAAO,MAEX,CACID,MAAO,MACPC,MAAO,MAEX,CACID,MAAO,MACPC,MAAO,MAEX,CACID,MAAO,WACPC,MAAO,UAM3B03B,QAAS,CACL,CACIH,YAAa,uKACbp6B,GAAI,iBAER,CACIo6B,YAAa,gLACbp6B,GAAI,eAGZmU,OAAQ,CACJ,CACIimB,YAAa,0CACbp6B,GAAI,gCAER,CACIo6B,YAAa,iDACbp6B,GAAI,gCAGZw6B,OAAQ,GACRC,QAAS,mQACTC,aAAc,CAAC,sBACfC,UAAW,eCYf,GAlFiB,CACbR,SAAU,CACN,CAEIC,YAAa,0FACbp6B,GAAI,YAER,CAEIo6B,YAAa,4CACbp6B,GAAI,kBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,kCACVpuB,KAAM,QAGd3B,QAAS,CACL,CACI2B,KAAM,QACNnN,KAAM,CACF,CACI6D,MAAO,eACPC,MAAO,MAEX,CACID,MAAO,YACPC,MAAO,MAEX,CACID,MAAO,YACPC,MAAO,UAM3B03B,QAAS,CACL,CACIH,YAAa,GACbp6B,GAAI,YAER,CACIo6B,YAAa,GACbp6B,GAAI,UAER,CACIo6B,YAAa,GACbp6B,GAAI,aAER,CACIo6B,YAAa,GACbp6B,GAAI,OAGZmU,OAAQ,CACJ,CACIimB,YAAa,uCACbp6B,GAAI,+BAER,CACIo6B,YAAa,uCACbp6B,GAAI,4CAER,CACIo6B,YAAa,uCACbp6B,GAAI,gCAGZw6B,OAAQ,CACJ,CACIJ,YAAa,mEACbp6B,GAAI,qBAGZy6B,QAAS,mQACTC,aAAc,CAAC,+BACfC,UAAW,eCrBf,GA3DiB,CACbR,SAAU,CACN,CACIC,YAAa,mHACbp6B,GAAI,gBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,4BACVpuB,KAAM,QAGd3B,QAAS,CACL,CACI6tB,MAAO,CACH,CAAC,cAAe,cAAe,eAC/B,CAAC,sBAAuB,qBAAsB,sBAC9C,CAAC,oBAAqB,uBAAwB,uBAC9C,CAAC,qBAAsB,sBAAuB,uBAC9C,CAAC,qBAAsB,uBAAwB,wBAEnDlsB,KAAM,aAIlBquB,QAAS,GACTpmB,OAAQ,CACJ,CACIimB,YAAa,6CACbp6B,GAAI,yCAER,CACIo6B,YAAa,2CACbp6B,GAAI,2BAER,CACIo6B,YAAa,2CACbp6B,GAAI,wBAER,CACIo6B,YAAa,+CACbp6B,GAAI,2CAER,CACIo6B,YAAa,kFACbp6B,GAAI,sCAGZw6B,OAAQ,CACJ,CACIJ,YAAa,qGACbp6B,GAAI,qBAGZy6B,QAAS,iGACTC,aAAc,IC+BlB,GAxFiB,CACbP,SAAU,CACN,CACIC,YAAa,0CACbp6B,GAAI,SAER,CACIo6B,YAAa,yEACbp6B,GAAI,uBAER,CACIo6B,YAAa,2BACbp6B,GAAI,mBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,4BACVpuB,KAAM,QAGd3B,QAAS,CACL,CACI+vB,SAAU,4BACVpuB,KAAM,SAIlB0uB,eAAe,EACfL,QAAS,CACL,CACIH,YAAa,yNACbp6B,GAAI,QAER,CACIo6B,YAAa,gPACbp6B,GAAI,QAER,CACIo6B,YAAa,qJACbp6B,GAAI,OAGZmU,OAAQ,CACJ,CACIimB,YAAa,uDACbp6B,GAAI,iBAER,CACIo6B,YAAa,gCACbp6B,GAAI,wCAER,CACIo6B,YAAa,wBACbp6B,GAAI,kBAER,CACIo6B,YAAa,2BACbp6B,GAAI,oDAER,CACIo6B,YAAa,+CACbp6B,GAAI,qCAER,CACIo6B,YAAa,mDACbp6B,GAAI,4CAGZw6B,OAAQ,CACJ,CACIJ,YAAa,6BACbp6B,GAAI,wCAER,CACIo6B,YAAa,gCACbp6B,GAAI,8BAER,CACIo6B,YAAa,sCACbp6B,GAAI,4CAGZy6B,QAAS,8LACTC,aAAc,CAAC,mBACfC,UAAW,IC7Bf,GAzDiB,CACbR,SAAU,CACN,CAEIC,YAAa,wCACbp6B,GAAI,YAER,CAEIo6B,YAAa,qCACbp6B,GAAI,iCAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,cACVpuB,KAAM,QAGd3B,QAAS,CACL,CACI3H,MAAO,uBACPmM,QAAS,mDACT7C,KAAM,UAIlBquB,QAAS,GACTpmB,OAAQ,CACJ,CACIimB,YAAa,oBACbp6B,GAAI,0BAER,CACIo6B,YAAa,mCACbp6B,GAAI,kDAGZw6B,OAAQ,CACJ,CACIJ,YAAa,iCACbp6B,GAAI,4BAER,CACIo6B,YAAa,sDACbp6B,GAAI,iCAER,CACIo6B,YAAa,0CACbp6B,GAAI,oCAGZy6B,QAAS,+KACTC,aAAc,CAAC,0CACfC,UAAW,ICyBf,GAhFiB,CACbR,SAAU,CACN,CACIC,YAAa,2CACbp6B,GAAI,kCAER,CACIo6B,YAAa,uDACbp6B,GAAI,mCAER,CACIo6B,YAAa,uDACbp6B,GAAI,8BAER,CACIo6B,YAAa,qDACbp6B,GAAI,2BAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,+BACVpuB,KAAM,OAEV,CACItJ,MAAO,cACPmM,QAAS,8CACT7C,KAAM,SAGd3B,QAAS,CACL,CACI3H,MAAO,SACPmM,QAAS,kKACT7C,KAAM,UAIlBquB,QAAS,GACTpmB,OAAQ,CACJ,CACIimB,YAAa,0DACbp6B,GAAI,kCAER,CACIo6B,YAAa,gDACbp6B,GAAI,oBAER,CACIo6B,YAAa,yEACbp6B,GAAI,0BAER,CACIo6B,YAAa,4BACbp6B,GAAI,+BAER,CACIo6B,YAAa,sDACbp6B,GAAI,uBAGZw6B,OAAQ,CACJ,CACIJ,YAAa,kDACbp6B,GAAI,oCAER,CACIo6B,YAAa,kGACbp6B,GAAI,0CAER,CACIo6B,YAAa,kDACbp6B,GAAI,iCAGZy6B,QAAS,0WACTC,aAAc,CAAC,oBACfC,UAAW,eC/Bf,GA/CiB,CACbR,SAAU,GACVE,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,iCACVpuB,KAAM,OAEV,CACItJ,MAAO,QACPmM,QAAS,sDACT7C,KAAM,SAGd3B,QAAS,CACL,CACI+vB,SAAU,iCACVpuB,KAAM,SAIlBquB,QAAS,CACL,CACIH,YAAa,kOACbp6B,GAAI,OAER,CACIo6B,YAAa,4KACbp6B,GAAI,SAGZmU,OAAQ,CACJ,CACIimB,YAAa,uDACbp6B,GAAI,iCAGZw6B,OAAQ,CACJ,CACIJ,YAAa,qDACbp6B,GAAI,iCAGZy6B,QAAS,mQACTC,aAAc,CAAC,gCACfC,eAAW/8B,GCEf,GA/CiB,CACbu8B,SAAU,GACVE,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,gCACVpuB,KAAM,OAEV,CACItJ,MAAO,QACPmM,QAAS,uCACT7C,KAAM,SAGd3B,QAAS,CACL,CACI+vB,SAAU,iCACVpuB,KAAM,SAIlBquB,QAAS,CACL,CACIH,YAAa,sKACbp6B,GAAI,OAER,CACIo6B,YAAa,oJACbp6B,GAAI,YAGZmU,OAAQ,CACJ,CACIimB,YAAa,uDACbp6B,GAAI,yBAGZw6B,OAAQ,CACJ,CACIJ,YAAa,qDACbp6B,GAAI,mCAGZy6B,QAAS,gSACTC,aAAc,CAAC,wBACfC,eAAW/8B,GC+Cf,GA5FiB,CACbu8B,SAAU,CACN,CACIC,YAAa,8BACbp6B,GAAI,oBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,gCACVpuB,KAAM,QAGd3B,QAAS,CACL,CACI+vB,SAAU,gCACVpuB,KAAM,SAIlBquB,QAAS,CACL,CACIH,YAAa,sHACbp6B,GAAI,qBAER,CACIo6B,YAAa,uEACbp6B,GAAI,0BAER,CACIo6B,YAAa,iIACbp6B,GAAI,gCAER,CACIo6B,YAAa,uGACbp6B,GAAI,aAGZmU,OAAQ,CACJ,CAEIimB,YAAa,qDACbp6B,GAAI,wCAER,CACIo6B,YAAa,4BACbp6B,GAAI,mBAER,CACIo6B,YAAa,sEACbp6B,GAAI,uBAER,CACIo6B,YAAa,mDACbp6B,GAAI,2BAER,CACIo6B,YAAa,4EACbp6B,GAAI,kDAGZw6B,OAAQ,CACJ,CACIJ,YAAa,wFACbp6B,GAAI,mBAER,CACIo6B,YAAa,kDACbp6B,GAAI,6BAER,CACIo6B,YAAa,sCACbp6B,GAAI,yBAER,CACIo6B,YAAa,8FACbp6B,GAAI,+CAER,CACIo6B,YAAa,uCACbp6B,GAAI,iCAER,CACIo6B,YAAa,uEACbp6B,GAAI,uCAGZy6B,QAAS,0NACTC,aAAc,CAAC,6CACfC,UAAW,eC0Bf,GApHiB,CACbR,SAAU,CACN,CACIC,YAAa,uEACbp6B,GAAI,4BAER,CACIo6B,YAAa,mDACbp6B,GAAI,uDAER,CACIo6B,YAAa,4DACbp6B,GAAI,4BAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,2BACVpuB,KAAM,OAEV,CACItJ,MAAO,uBACPmM,QAAS,0BACT7C,KAAM,SAGd3B,QAAS,CACL,CACI+vB,SAAU,4BACVpuB,KAAM,SAIlBquB,QAAS,CACL,CACIH,YAAa,iPACbp6B,GAAI,OAER,CACIo6B,YAAa,oRACbp6B,GAAI,cAER,CACIo6B,YAAa,mNACbp6B,GAAI,SAER,CACIo6B,YAAa,gUACbp6B,GAAI,yBAER,CACIo6B,YAAa,yRACbp6B,GAAI,iBAGZmU,OAAQ,CACJ,CACIimB,YAAa,qEACbp6B,GAAI,kCAER,CACIo6B,YAAa,wEACbp6B,GAAI,0BAER,CACIo6B,YAAa,kGACbp6B,GAAI,2CAER,CACIo6B,YAAa,4EACbp6B,GAAI,wCAER,CACIo6B,YAAa,2FACbp6B,GAAI,oCAER,CACIo6B,YAAa,oDACbp6B,GAAI,4BAER,CACIo6B,YAAa,sEACbp6B,GAAI,8BAER,CACIo6B,YAAa,2FACbp6B,GAAI,yCAGZw6B,OAAQ,CACJ,CACIJ,YAAa,0CACbp6B,GAAI,kCAER,CACIo6B,YAAa,wCACbp6B,GAAI,wBAER,CACIo6B,YAAa,qCACbp6B,GAAI,4BAER,CACIo6B,YAAa,2BACbp6B,GAAI,6BAER,CACIo6B,YAAa,oCACbp6B,GAAI,yCAGZy6B,QAAS,6KACTC,aAAc,GACdC,eAAW/8B,GCnDf,GA/DiB,CACbu8B,SAAU,CACN,CACIC,YAAa,2DACbp6B,GAAI,kBAER,CACIo6B,YAAa,wFACbp6B,GAAI,+BAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,4BACVpuB,KAAM,QAGd3B,QAAS,CACL,CACI+vB,SAAU,6BACVpuB,KAAM,SAIlBquB,QAAS,CACL,CACIH,YAAa,uFACbp6B,GAAI,kCAGZmU,OAAQ,CACJ,CACIimB,YAAa,4CACbp6B,GAAI,6BAER,CACIo6B,YAAa,qCACbp6B,GAAI,8BAGZw6B,OAAQ,CACJ,CACIJ,YAAa,mIACbp6B,GAAI,iBAER,CACIo6B,YAAa,6FACbp6B,GAAI,iBAER,CACIo6B,YAAa,6DACbp6B,GAAI,qCAER,CACIo6B,YAAa,6EACbp6B,GAAI,gCAGZy6B,QAAS,6QACTC,aAAc,GACdC,UAAW,ICsBf,GAnFiB,CACbR,SAAU,CACN,CACIC,YAAa,2DACbp6B,GAAI,kBAER,CACIo6B,YAAa,wCACbp6B,GAAI,qBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,6BACVpuB,KAAM,QAGd3B,QAAS,CACL,CACI+vB,SAAU,8BACVpuB,KAAM,SAIlBquB,QAAS,CACL,CACIH,YAAa,wHACbp6B,GAAI,qBAER,CACIo6B,YAAa,kFACbp6B,GAAI,0BAER,CACIo6B,YAAa,kHACbp6B,GAAI,aAGZmU,OAAQ,CACJ,CACIimB,YAAa,qEACbp6B,GAAI,2BAER,CACIo6B,YAAa,mCACbp6B,GAAI,oCAER,CACIo6B,YAAa,4CACbp6B,GAAI,2BAER,CACIo6B,YAAa,gDACbp6B,GAAI,sBAGZw6B,OAAQ,CACJ,CACIJ,YAAa,mCACbp6B,GAAI,oBAER,CACIo6B,YAAa,4EACbp6B,GAAI,sDAER,CACIo6B,YAAa,+CACbp6B,GAAI,6BAER,CACIo6B,YAAa,+DACbp6B,GAAI,yBAER,CACIo6B,YAAa,mEACbp6B,GAAI,gCAGZy6B,QAAS,kNACTC,aAAc,CAAC,2BACfC,UAAW,eCff,GAlEiB,CACbR,SAAU,CACN,CACIC,YAAa,iFACbp6B,GAAI,0BAER,CACIo6B,YAAa,uEACbp6B,GAAI,yBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,6BACVpuB,KAAM,QAGd3B,QAAS,CACL,CACI+vB,SAAU,8BACVpuB,KAAM,SAIlBquB,QAAS,GACTpmB,OAAQ,CACJ,CACIimB,YAAa,uCACbp6B,GAAI,0CAER,CACIo6B,YAAa,6CACbp6B,GAAI,+BAER,CACIo6B,YAAa,0DACbp6B,GAAI,wBAER,CACIo6B,YAAa,mCACbp6B,GAAI,sBAGZw6B,OAAQ,CACJ,CACIJ,YAAa,kGACbp6B,GAAI,0CAER,CACIo6B,YAAa,qDACbp6B,GAAI,qBAER,CACIo6B,YAAa,6DACbp6B,GAAI,wBAER,CACIo6B,YAAa,gDACbp6B,GAAI,2BAGZy6B,QAAS,uFACTC,aAAc,CAAC,IACfC,UAAW,IC/Cf,GAjBiB,CACbR,SAAU,GACVE,KAAM,CACFvxB,OAAQ,GACRyB,QAAS,IAEbqwB,eAAe,EACfL,QAAS,GACTpmB,OAAQ,GACRqmB,OAAQ,GACRC,QAAS,GACTC,aAAc,GACdC,eAAW/8B,EAGXi9B,iBAAaj9B,GCmDjB,GAlEiB,CACbu8B,SAAU,CACN,CACIC,YAAa,wFACbp6B,GAAI,+CAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,QACPmM,QAAS,oDACT7C,KAAM,SAGd3B,QAAS,CACL,CACI3H,MAAO,SACPmM,QAAS,gBACT7C,KAAM,QAEV,CACItJ,MAAO,aACPmM,QAAS,0CACT7C,KAAM,UAIlBquB,QAAS,CACL,CACIH,YAAa,mSACbp6B,GAAI,2BAER,CACIo6B,YAAa,6MACbp6B,GAAI,eAER,CACIo6B,YAAa,2UACbp6B,GAAI,yCAGZmU,OAAQ,CACJ,CACIimB,YAAa,wFACbp6B,GAAI,qDAER,CACIo6B,YAAa,4FACbp6B,GAAI,4CAGZw6B,OAAQ,CACJ,CACIJ,YAAa,mEACbp6B,GAAI,wBAER,CACIo6B,YAAa,6EACbp6B,GAAI,iCAGZy6B,QAAS,mMACTC,aAAc,GACdC,UAAW,eCIf,GApEiB,CACbR,SAAU,CACN,CAEIC,YAAa,gFACbp6B,GAAI,YAER,CAEIo6B,YAAa,wFACbp6B,GAAI,sBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,WACPmM,QAAS,wEACT7C,KAAM,QAEV,CACItJ,MAAO,UACPmM,QAAS,gFACT7C,KAAM,SAGd3B,QAAS,CACL,CACI3H,MAAO,SACPmM,QAAS,WACT7C,KAAM,UAIlBquB,QAAS,CACL,CACIH,YAAa,uOACbp6B,GAAI,eAER,CACIo6B,YAAa,4LACbp6B,GAAI,OAGZmU,OAAQ,CACJ,CACIimB,YAAa,+DACbp6B,GAAI,+BAER,CACIo6B,YAAa,oDACbp6B,GAAI,oDAER,CACIo6B,YAAa,yDACbp6B,GAAI,oCAGZw6B,OAAQ,CACJ,CACIJ,YAAa,iEACbp6B,GAAI,gCAGZy6B,QAAS,qNACTC,aAAc,CAAC,+BACfC,UAAW,eC8Bf,GAhGiB,CACbR,SAAU,CACN,CACIC,YAAa,gEACbp6B,GAAI,uBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,kBACPmM,QAAS,+BACT7C,KAAM,QAEV,CACItJ,MAAO,0BACPmM,QAAS,uCACT7C,KAAM,QAEV,CACItJ,MAAO,GACPmM,QAAS,6CACT7C,KAAM,QAEV,CACItJ,MAAO,GACPmM,QAAS,kDACT7C,KAAM,SAGd3B,QAAS,CACL,CACI2B,KAAM,QACNnN,KAAM,CACF,CACI6D,MAAO,uCACPC,MAAO,MAEX,CACID,MAAO,6CACPC,MAAO,MAEX,CACID,MAAO,kDACPC,MAAO,UAM3B03B,QAAS,CACL,CACIH,YAAa,6QACbp6B,GAAI,wBAER,CACIo6B,YAAa,gNACbp6B,GAAI,sBAGZmU,OAAQ,CACJ,CACIimB,YAAa,oHACbp6B,GAAI,2CAER,CACIo6B,YAAa,mDACbp6B,GAAI,eAER,CACIo6B,YAAa,sCACbp6B,GAAI,2DAGZw6B,OAAQ,CACJ,CACIJ,YAAa,6FACbp6B,GAAI,iDAER,CACIo6B,YAAa,8HACbp6B,GAAI,2CAER,CACIo6B,YAAa,uEACbp6B,GAAI,qCAER,CACIo6B,YAAa,mFACbp6B,GAAI,oEAGZy6B,QAAS,oUACTC,aAAc,CAAC,0CACfC,UAAW,eC5Bf,GAlEiB,CACbE,YAAa,kBACbV,SAAU,CACN,CACIC,YAAa,wIACbp6B,GAAI,SAER,CACIo6B,YAAa,4FACbp6B,GAAI,WAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,QACPmM,QAAS,sXACT7C,KAAM,SAGd3B,QAAS,CACL,CACI3H,MAAO,SACPmM,QAAS,uJACT7C,KAAM,UAIlBquB,QAAS,CACL,CACIH,YAAa,mPACbp6B,GAAI,UAGZmU,OAAQ,CACJ,CACIimB,YAAa,yGACbp6B,GAAI,2BAER,CACIo6B,YAAa,qDACbp6B,GAAI,oCAGZw6B,OAAQ,CACJ,CACIJ,YAAa,qDACbp6B,GAAI,gCAER,CACIo6B,YAAa,oEACbp6B,GAAI,2CAER,CACIo6B,YAAa,iDACbp6B,GAAI,mCAER,CACIo6B,YAAa,sEACbp6B,GAAI,0CAGZy6B,QAAS,8NACTC,aAAc,CAAC,2BACfC,UAAW,eCbf,GAnDiB,CACbR,SAAU,CACN,CACIC,YAAa,wHACbp6B,GAAI,sBAER,CACIo6B,YAAa,qIACbp6B,GAAI,YAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIsvB,MAAO,CACH,CAAC,OAAQ,OAAQ,eAAgB,iBACjC,CAAC,IAAK,YAAa,IAAK,QACxB,CAAC,IAAK,YAAa,IAAK,QACxB,CAAC,IAAK,cAAe,IAAK,SAE9BlsB,KAAM,WAEV,CAAEtJ,MAAO,WAAYmM,QAAS,gDAAiD7C,KAAM,SAEzF3B,QAAS,CAAC,CAAE3H,MAAO,SAAUmM,QAAS,IAAK7C,KAAM,UAErDquB,QAAS,CACL,CACIH,YAAa,oFACbp6B,GAAI,wBAGZmU,OAAQ,CACJ,CACIimB,YAAa,wIACbp6B,GAAI,wBAER,CACIo6B,YAAa,2CACbp6B,GAAI,oCAGZw6B,OAAQ,CACJ,CACIJ,YAAa,kEACbp6B,GAAI,yBAGZy6B,QAAS,yGACTC,aAAc,CAAC,oCCenB,GAhEiB,CACbP,SAAU,CACN,CACIC,YAAa,gEACbp6B,GAAI,iCAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIsvB,MAAO,CACH,CAAC,UAAW,kBAAmB,iBAAkB,UAAW,OAC5D,CAAC,MAAO,KAAM,KAAM,IAAK,QACzB,CAAC,MAAO,KAAM,KAAM,IAAK,QACzB,CAAC,MAAO,KAAM,KAAM,IAAK,SAE7BlsB,KAAM,YAGd3B,QAAS,CACL,CACI6tB,MAAO,CAAC,CAAC,YAAa,CAAC,KAAM,CAAC,KAAM,CAAC,MACrClsB,KAAM,aAIlBquB,QAAS,CACL,CACIH,YAAa,GACbp6B,GAAI,YAER,CACIo6B,YAAa,GACbp6B,GAAI,UAER,CACIo6B,YAAa,GACbp6B,GAAI,aAER,CACIo6B,YAAa,GACbp6B,GAAI,OAGZmU,OAAQ,CACJ,CACIimB,YAAa,0DACbp6B,GAAI,yCAGZw6B,OAAQ,CACJ,CACIJ,YAAa,2EACbp6B,GAAI,mCAER,CACIo6B,YAAa,gGACbp6B,GAAI,gCAGZy6B,QAAS,4GACTC,aAAc,CAAC,mCACfC,UAAW,ICVf,GApDiB,CACbR,SAAU,CACN,CACIC,YAAa,gEACbp6B,GAAI,iCAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIsvB,MAAO,CACH,CAAC,WAAY,aAAc,UAC3B,CAAC,cAAe,MAAO,SACvB,CAAC,aAAc,KAAM,SACrB,CAAC,iBAAkB,KAAM,UAE7BlsB,KAAM,YAGd3B,QAAS,CACL,CACI6tB,MAAO,CAAC,CAAC,0BAA2B,CAAC,MAAO,CAAC,MAAO,CAAC,OACrDlsB,KAAM,aAIlBquB,QAAS,CACL,CACIH,YAAa,GACbp6B,GAAI,OAER,CACIo6B,YAAa,6IACbp6B,GAAI,cAGZmU,OAAQ,CACJ,CACIimB,YAAa,mEACbp6B,GAAI,6BAGZw6B,OAAQ,CACJ,CACIJ,YAAa,+EACbp6B,GAAI,wCAGZy6B,QAAS,4FACTC,aAAc,CAAC,4BACfC,UAAW,IC8Cf,GAhGiB,CACbR,SAAU,CACN,CACIC,YAAa,kFACbp6B,GAAI,YAER,CACIo6B,YAAa,uFACbp6B,GAAI,uBAER,CACIo6B,YAAa,2BACbp6B,GAAI,mBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,QACPmM,QAAS,sDACT7C,KAAM,SAGd3B,QAAS,CACL,CACI+vB,SAAU,aACVpuB,KAAM,SAIlBquB,QAAS,CACL,CACIH,YAAa,8LACbp6B,GAAI,MAER,CACIo6B,YAAa,kOACbp6B,GAAI,OAER,CACIo6B,YAAa,mZACbp6B,GAAI,gBAGZmU,OAAQ,CACJ,CACIimB,YAAa,wFACbp6B,GAAI,qCAER,CACIo6B,YAAa,qCACbp6B,GAAI,mBAER,CACIo6B,YAAa,4CACbp6B,GAAI,4BAER,CACIo6B,YAAa,kCACbp6B,GAAI,uBAGZw6B,OAAQ,CACJ,CACIJ,YAAa,wCACbp6B,GAAI,yCAER,CACIo6B,YAAa,kDACbp6B,GAAI,+BAER,CACIo6B,YAAa,mEACbp6B,GAAI,+BAER,CACIo6B,YAAa,yDACbp6B,GAAI,wCAER,CACIo6B,YAAa,qDACbp6B,GAAI,iCAER,CACIo6B,YAAa,6EACbp6B,GAAI,4CAER,CACIo6B,YAAa,qFACbp6B,GAAI,uBAGZy6B,QAAS,oJACTC,aAAc,CAAC,gCACfC,UAAW,ICbf,GAjFiB,CACbE,YAAa,gBACbV,SAAU,CACN,CACIC,YAAa,8CACbp6B,GAAI,0BAER,CACIo6B,YAAa,iCACbp6B,GAAI,6BAER,CACIo6B,YAAa,yBACbp6B,GAAI,sCAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,QACPmM,QAAS,kCACT7C,KAAM,SAGd3B,QAAS,CACL,CACI+vB,SAAU,YACVpuB,KAAM,WAIlBquB,QAAS,CACL,CACIH,YAAa,iGACbp6B,GAAI,4BAGZmU,OAAQ,CACJ,CACIimB,YAAa,gCACbp6B,GAAI,gCAER,CACIo6B,YAAa,2BACbp6B,GAAI,yBAER,CACIo6B,YAAa,uCACbp6B,GAAI,6BAER,CACIo6B,YAAa,4BACbp6B,GAAI,4BAGZw6B,OAAQ,CACJ,CACIJ,YAAa,0EACbp6B,GAAI,sBAER,CACIo6B,YAAa,6CACbp6B,GAAI,2BAER,CACIo6B,YAAa,8BACbp6B,GAAI,yBAER,CACIo6B,YAAa,kDACbp6B,GAAI,wBAER,CACIo6B,YAAa,kDACbp6B,GAAI,oCAGZy6B,QAAS,iNACTC,aAAc,CAAC,aACfC,UAAW,eCKf,GApFiB,CACbR,SAAU,CACN,CACIC,YAAa,6EACbp6B,GAAI,qBAER,CACIo6B,YAAa,uHACbp6B,GAAI,wBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,QACPmM,QAAS,2CACT7C,KAAM,SAGd3B,QAAS,CACL,CACIvF,KAAM,2CACNgd,OAAQ,CACJ,CACI9V,KAAM,SACNyB,MAAO,GACPD,IAAK,IAET,CACIxB,KAAM,MACNyB,MAAO,GACPD,IAAK,KAGbxB,KAAM,sBAIlBquB,QAAS,CACL,CACIH,YAAa,GACbp6B,GAAI,YAER,CACIo6B,YAAa,GACbp6B,GAAI,UAER,CACIo6B,YAAa,GACbp6B,GAAI,aAER,CACIo6B,YAAa,GACbp6B,GAAI,OAGZmU,OAAQ,CACJ,CACIimB,YAAa,+GACbp6B,GAAI,uBAER,CACIo6B,YAAa,+FACbp6B,GAAI,0DAER,CACIo6B,YAAa,0EACbp6B,GAAI,wBAER,CACIo6B,YAAa,qFACbp6B,GAAI,sBAGZw6B,OAAQ,CACJ,CACIJ,YAAa,8HACbp6B,GAAI,qCAGZy6B,QAAS,+bACTC,aAAc,CAAC,0DACfC,UAAW,eCpBf,GA9DiB,CACbE,YAAa,kBACbV,SAAU,CACN,CACIC,YAAa,4EACbp6B,GAAI,2BAER,CACIo6B,YAAa,8GACbp6B,GAAI,6CAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,QACPmM,QAAS,2CACT7C,KAAM,SAGd3B,QAAS,CACL,CACI3H,MAAO,SACPmM,QAAS,iDACT7C,KAAM,UAIlBquB,QAAS,CACL,CACIH,YAAa,sZACbp6B,GAAI,QAER,CACIo6B,YAAa,GACbp6B,GAAI,cAGZmU,OAAQ,CACJ,CACIimB,YAAa,+GACbp6B,GAAI,0BAER,CACIo6B,YAAa,2GACbp6B,GAAI,sBAGZw6B,OAAQ,CACJ,CACIJ,YAAa,2DACbp6B,GAAI,gCAER,CACIo6B,YAAa,4DACbp6B,GAAI,iCAGZy6B,QAAS,2EACTC,aAAc,CAAC,4CACfC,UAAW,eCqCf,GAjGiB,CACbR,SAAU,CACN,CACIC,YAAa,oFACbp6B,GAAI,gBAER,CACIo6B,YAAa,oFACbp6B,GAAI,qBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,QACPmM,QAAS,uBACT7C,KAAM,SAGd3B,QAAS,CACL,CACI2B,KAAM,QACNnN,KAAM,CACF,CACI6D,MAAO,WACPC,MAAO,IAEX,CACID,MAAO,UACPC,MAAO,IAEX,CACID,MAAO,WACPC,MAAO,OAM3B03B,QAAS,CACL,CACIH,YAAa,GACbp6B,GAAI,YAER,CACIo6B,YAAa,GACbp6B,GAAI,UAER,CACIo6B,YAAa,GACbp6B,GAAI,aAER,CACIo6B,YAAa,gJACbp6B,GAAI,OAGZmU,OAAQ,CACJ,CACIimB,YAAa,iDACbp6B,GAAI,8DAER,CACIo6B,YAAa,iEACbp6B,GAAI,oBAER,CACIo6B,YAAa,8DACbp6B,GAAI,oDAER,CACIo6B,YAAa,uCACbp6B,GAAI,+CAER,CACIo6B,YAAa,qDACbp6B,GAAI,gCAGZw6B,OAAQ,CACJ,CACIJ,YAAa,wDACbp6B,GAAI,2CAER,CACIo6B,YAAa,+DACbp6B,GAAI,+BAER,CACIo6B,YAAa,2DACbp6B,GAAI,yBAGZy6B,QAAS,2LACTC,aAAc,CAAC,8DACfC,UAAW,eC2Bf,GA1HiB,CACbR,SAAU,CACN,CACIC,YAAa,gEACbp6B,GAAI,2BAER,CACIo6B,YAAa,uEACbp6B,GAAI,2BAER,CACIo6B,YAAa,2DACbp6B,GAAI,gCAER,CACIo6B,YAAa,uBACbp6B,GAAI,kCAER,CACIo6B,YAAa,2EACbp6B,GAAI,8BAER,CACIo6B,YAAa,qEACbp6B,GAAI,0BAER,CACIo6B,YAAa,6EACbp6B,GAAI,2BAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,QACPmM,QAAS,oBACT7C,KAAM,SAGd3B,QAAS,CACL,CACI3H,MAAO,SACPmM,QAAS,4OACT7C,KAAM,UAIlBquB,QAAS,CACL,CACIH,YAAa,uKACbp6B,GAAI,iBAER,CACIo6B,YAAa,2LACbp6B,GAAI,eAGZmU,OAAQ,CACJ,CAAEimB,YAAa,0DAA2Dp6B,GAAI,wBAC9E,CACIo6B,YAAa,6CACbp6B,GAAI,uCAER,CACIo6B,YAAa,wEACbp6B,GAAI,uBAER,CACIo6B,YAAa,kCACbp6B,GAAI,mBAER,CACIo6B,YAAa,sDACbp6B,GAAI,+BAER,CACIo6B,YAAa,oEACbp6B,GAAI,+BAER,CACIo6B,YAAa,4CACbp6B,GAAI,mCAER,CACIo6B,YAAa,sDACbp6B,GAAI,4BAGZw6B,OAAQ,CACJ,CACIJ,YAAa,gGACbp6B,GAAI,oBAER,CACIo6B,YAAa,qEACbp6B,GAAI,qBAER,CACIo6B,YAAa,sEACbp6B,GAAI,gCAER,CACIo6B,YAAa,8EACbp6B,GAAI,oCAER,CACIo6B,YAAa,sEACbp6B,GAAI,6BAER,CACIo6B,YAAa,oFACbp6B,GAAI,mCAER,CACIo6B,YAAa,qEACbp6B,GAAI,2BAGZy6B,QAAS,+IACTC,aAAc,CAAC,wCACfC,UAAW,eCrCf,GAnFiB,CACbR,SAAU,CACN,CACIC,YAAa,gEACbp6B,GAAI,uBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,kBACPmM,QAAS,+BACT7C,KAAM,QAEV,CACItJ,MAAO,0BACPmM,QAAS,uCACT7C,KAAM,QAEV,CACItJ,MAAO,GACPmM,QAAS,6CACT7C,KAAM,QAEV,CACItJ,MAAO,GACPmM,QAAS,kDACT7C,KAAM,SAGd3B,QAAS,CACL,CACI2B,KAAM,QACNnN,KAAM,CACF,CACI6D,MAAO,uCACPC,MAAO,WAEX,CACID,MAAO,6CACPC,OAAQ,WAEZ,CACID,MAAO,kDACPC,OAAQ,eAM5B03B,QAAS,CACL,CACIH,YAAa,8NACbp6B,GAAI,yCAER,CACIo6B,YAAa,6QACbp6B,GAAI,wBAER,CACIo6B,YAAa,6IACbp6B,GAAI,2BAGZmU,OAAQ,CACJ,CACIimB,YAAa,6EACbp6B,GAAI,uCAER,CACIo6B,YAAa,6CACbp6B,GAAI,8CAER,CACIo6B,YAAa,iEACbp6B,GAAI,6CAGZw6B,OAAQ,GACRC,QAAS,2UACTC,aAAc,CAAC,uCACfC,UAAW,ICef,GAhGiB,CACbR,SAAU,CACN,CACIC,YAAa,6FACbp6B,GAAI,uBAER,CACIo6B,YAAa,8FACbp6B,GAAI,yBAER,CACIo6B,YAAa,yEACbp6B,GAAI,oBAER,CACIo6B,YAAa,iGACbp6B,GAAI,wCAER,CACIo6B,YAAa,0GACbp6B,GAAI,wBAER,CACIo6B,YAAa,8FACbp6B,GAAI,uBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,QACPmM,QAAS,uCACT7C,KAAM,SAGd3B,QAAS,CACL,CACI+vB,SAAU,2BACVpuB,KAAM,SAIlBquB,QAAS,CACL,CACIH,YAAa,yLACbp6B,GAAI,MAER,CACIo6B,YAAa,+OACbp6B,GAAI,OAER,CACIo6B,YAAa,sKACbp6B,GAAI,OAER,CACIo6B,YAAa,oJACbp6B,GAAI,YAGZmU,OAAQ,CACJ,CACIimB,YAAa,kDACbp6B,GAAI,wBAER,CACIo6B,YAAa,+EACbp6B,GAAI,wBAER,CACIo6B,YAAa,8EACbp6B,GAAI,6CAER,CACIo6B,YAAa,wCACbp6B,GAAI,6CAGZw6B,OAAQ,CACJ,CACIJ,YAAa,iDACbp6B,GAAI,6BAER,CACIo6B,YAAa,2CACbp6B,GAAI,iBAER,CACIo6B,YAAa,+CACbp6B,GAAI,8BAGZy6B,QAAS,yHACTC,aAAc,CAAC,yBACfC,eAAW/8B,GChCf,GA9DiB,CACbu8B,SAAU,CACN,CACIC,YAAa,yGACbp6B,GAAI,YAER,CACIo6B,YAAa,0EACbp6B,GAAI,WAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,OACPmM,QAAS,KACT7C,KAAM,QAEV,CACItJ,MAAO,gCACPmM,QAAS,IACT7C,KAAM,SAGd3B,QAAS,CACL,CACI+vB,SAAU,6CACVpuB,KAAM,SAIlBquB,QAAS,CACL,CACIH,YAAa,ySACbp6B,GAAI,wBAER,CACIo6B,YAAa,2LACbp6B,GAAI,0CAGZmU,OAAQ,CACJ,CACIimB,YAAa,gRACbp6B,GAAI,0BAER,CACIo6B,YAAa,sPACbp6B,GAAI,6BAGZw6B,OAAQ,CACJ,CACIJ,YAAa,oDACbp6B,GAAI,oCAGZy6B,QAAS,mOACTC,aAAc,CAAC,IAEfC,UAAW,ICmBf,GA/EiB,CACbR,SAAU,CACN,CAEIC,YAAa,0FACbp6B,GAAI,gBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,iCACVpuB,KAAM,QAGd3B,QAAS,CACL,CACI2B,KAAM,QACNnN,KAAM,CACF,CACI6D,MAAO,iBACPC,MAAO,MAEX,CACID,MAAO,iBACPC,MAAO,MAEX,CACID,MAAO,UACPC,MAAO,UAM3B03B,QAAS,CACL,CACIH,YAAa,GACbp6B,GAAI,YAER,CACIo6B,YAAa,GACbp6B,GAAI,UAER,CACIo6B,YAAa,GACbp6B,GAAI,aAER,CACIo6B,YAAa,GACbp6B,GAAI,OAGZmU,OAAQ,CACJ,CAEIimB,YAAa,yEACbp6B,GAAI,mCAER,CAEIo6B,YAAa,yEACbp6B,GAAI,iCAGZw6B,OAAQ,CACJ,CACIJ,YAAa,gEACbp6B,GAAI,kBAER,CACIo6B,YAAa,wCACbp6B,GAAI,iCAGZy6B,QAAS,kQACTC,aAAc,GACdC,UAAW,ICPf,GAtEiB,CACbR,SAAU,CACN,CACIC,YAAa,kEACbp6B,GAAI,6BAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,YACVpuB,KAAM,OAEV,CACItJ,MAAO,WACPmM,QAAS,wDACT7C,KAAM,SAGd3B,QAAS,CACL,CACI2B,KAAM,QACNnN,KAAM,CACF,CACI6D,MAAO,UACPC,MAAO,IAEX,CACID,MAAO,UACPC,MAAO,KAEX,CACID,MAAO,SACPC,MAAO,UAM3B+3B,eAAe,EACfL,QAAS,CACL,CACIH,YAAa,8FACbp6B,GAAI,+CAGZmU,OAAQ,CACJ,CACIimB,YAAa,wFACbp6B,GAAI,wBAER,CACIo6B,YAAa,6GACbp6B,GAAI,4BAGZw6B,OAAQ,CACJ,CACIJ,YAAa,qDACbp6B,GAAI,6BAER,CACIo6B,YAAa,sEACbp6B,GAAI,2BAGZy6B,QAAS,iPACTC,aAAc,CAAC,IACfC,UAAW,ICsBf,GA1FiB,CACbR,SAAU,CACN,CACIC,YAAa,0EACbp6B,GAAI,iBAER,CACIo6B,YAAa,mEACbp6B,GAAI,qBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,gBACVpuB,KAAM,OAEV,CACItJ,MAAO,WACPmM,QAAS,yBACT7C,KAAM,SAGd3B,QAAS,CACL,CACI2B,KAAM,QACNnN,KAAM,CACF,CACI6D,MAAO,WACPC,MAAO,KAEX,CACID,MAAO,YACPC,MAAO,KAEX,CACID,MAAO,SACPC,MAAO,UAM3B+3B,eAAe,EACfL,QAAS,CACL,CACIH,YAAa,GACbp6B,GAAI,YAER,CACIo6B,YAAa,wHACbp6B,GAAI,yBAGZmU,OAAQ,CACJ,CACIimB,YAAa,iFACbp6B,GAAI,iBAER,CACIo6B,YAAa,0GACbp6B,GAAI,sBAER,CACIo6B,YAAa,8EACbp6B,GAAI,mCAGZw6B,OAAQ,CACJ,CACIJ,YAAa,wFACbp6B,GAAI,oBAER,CACIo6B,YAAa,4DACbp6B,GAAI,mBAER,CACIo6B,YAAa,oFACbp6B,GAAI,mBAER,CACIo6B,YAAa,oFACbp6B,GAAI,yBAGZy6B,QAAS,mKACTC,aAAc,CAAC,mCACfC,UAAW,ICrBf,GAnEiB,CACbR,SAAU,CACN,CACIC,YAAa,oFACbp6B,GAAI,gBAER,CACIo6B,YAAa,mKACbp6B,GAAI,qBAER,CACIo6B,YAAa,sGACbp6B,GAAI,gBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,aACPmM,QAAS,+BACT7C,KAAM,QAEV,CACItJ,MAAO,mBACPmM,QAAS,qBACT7C,KAAM,SAGd3B,QAAS,CACL,CACI2B,KAAM,QACNnN,KAAM,CACF,CACI6D,MAAO,SACPC,MAAO,IAEX,CACID,MAAO,MACPC,MAAO,IAEX,CACID,MAAO,QACPC,MAAO,OAM3B03B,QAAS,GACTpmB,OAAQ,CACJ,CACIimB,YAAa,gDACbp6B,GAAI,4BAER,CACIo6B,YAAa,iEACbp6B,GAAI,+CAER,CACIo6B,YAAa,+FACbp6B,GAAI,gDAGZw6B,OAAQ,GACRC,QAAS,yMACTC,aAAc,CAAC,6BCiBnB,GAlFiB,CACbP,SAAU,CACN,CAEIC,YAAa,GACbp6B,GAAI,KAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,kCACVpuB,KAAM,OAEV,CACItJ,MAAO,UACPmM,QAAS,iBACT7C,KAAM,SAGd3B,QAAS,CACL,CACI2B,KAAM,QACNnN,KAAM,CACF,CACI6D,MAAO,MACPC,MAAO,MAEX,CACID,MAAO,MACPC,MAAO,MAEX,CACID,MAAO,OACPC,MAAO,UAM3B03B,QAAS,CACL,CACIH,YAAa,mFACbp6B,GAAI,mBAGZmU,OAAQ,CACJ,CACIimB,YAAa,4DACbp6B,GAAI,2BAER,CACIo6B,YAAa,+CACbp6B,GAAI,mCAER,CACIo6B,YAAa,+CACbp6B,GAAI,qCAER,CACIo6B,YAAa,yEACbp6B,GAAI,uBAER,CACIo6B,YAAa,2DACbp6B,GAAI,6DAGZw6B,OAAQ,CACJ,CACIJ,YAAa,4GACbp6B,GAAI,4BAER,CACIo6B,YAAa,8EACbp6B,GAAI,8BAGZy6B,QAAS,kHACTC,aAAc,CAAC,oCACfC,UAAW,ICrBf,GA3DiB,CACbR,SAAU,GACVE,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,uCACVpuB,KAAM,OAEV,CACItJ,MAAO,UACPmM,QAAS,iBACT7C,KAAM,SAGd3B,QAAS,CACL,CACI+vB,SAAU,wCACVpuB,KAAM,SAIlBquB,QAAS,CACL,CACIH,YAAa,wHACbp6B,GAAI,qBAER,CACIo6B,YAAa,kFACbp6B,GAAI,0BAER,CACIo6B,YAAa,kHACbp6B,GAAI,aAGZmU,OAAQ,CACJ,CACIimB,YAAa,0CACbp6B,GAAI,mDAER,CACIo6B,YAAa,iDACbp6B,GAAI,kBAGZw6B,OAAQ,CACJ,CACIJ,YAAa,wFACbp6B,GAAI,0BAER,CACIo6B,YAAa,0GACbp6B,GAAI,iBAGZy6B,QAAS,kVACTC,aAAc,GACdC,UAAW,ICcf,GAvEiB,CACbR,SAAU,CACN,CACIC,YAAa,iDACbp6B,GAAI,wBAER,CACIo6B,YAAa,yEACbp6B,GAAI,qBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,8BACVpuB,KAAM,QAGd3B,QAAS,CACL,CACI3H,MAAO,SACPmM,QAAS,qCACT7C,KAAM,UAIlBquB,QAAS,GACTpmB,OAAQ,CACJ,CACIimB,YAAa,0CACbp6B,GAAI,0BAER,CACIo6B,YAAa,6BACbp6B,GAAI,0BAER,CACIo6B,YAAa,2DACbp6B,GAAI,kBAER,CACIo6B,YAAa,2CACbp6B,GAAI,sCAGZw6B,OAAQ,CACJ,CACIJ,YAAa,8CACbp6B,GAAI,uBAER,CACIo6B,YAAa,sCACbp6B,GAAI,0BAER,CACIo6B,YAAa,oBACbp6B,GAAI,qCAER,CACIo6B,YAAa,sCACbp6B,GAAI,kBAER,CACIo6B,YAAa,uCACbp6B,GAAI,wBAGZy6B,QAAS,gEACTC,aAAc,GACdC,UAAW,ICjBf,GApDiB,CACbR,SAAU,CACN,CACIC,YAAa,iDACbp6B,GAAI,wBAER,CACIo6B,YAAa,oDACbp6B,GAAI,iBAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIlG,MAAO,SACPmM,QAAS,eACT7C,KAAM,SAGd3B,QAAS,CACL,CACI3H,MAAO,SACPmM,QAAS,oCACT7C,KAAM,UAIlBquB,QAAS,GACTpmB,OAAQ,CACJ,CACIimB,YAAa,kCACbp6B,GAAI,iBAER,CACIo6B,YAAa,0CACbp6B,GAAI,iBAGZw6B,OAAQ,CACJ,CACIJ,YAAa,qCACbp6B,GAAI,gBAER,CACIo6B,YAAa,4CACbp6B,GAAI,iBAGZy6B,QAAS,8DACTC,aAAc,GACdC,UAAW,ICIf,GAtDiB,CACbR,SAAU,CACN,CACIC,YAAa,qDACbp6B,GAAI,uCAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,+BACVpuB,KAAM,QAGd3B,QAAS,CACL,CACI+vB,SAAU,gCACVpuB,KAAM,SAIlBquB,QAAS,GACTpmB,OAAQ,CACJ,CACIimB,YAAa,qCACbp6B,GAAI,mCAER,CACIo6B,YAAa,oCACbp6B,GAAI,0CAER,CACIo6B,YAAa,6DACbp6B,GAAI,2BAER,CACIo6B,YAAa,oCACbp6B,GAAI,2BAGZw6B,OAAQ,CACJ,CACIJ,YAAa,2DACbp6B,GAAI,oDAER,CACIo6B,YAAa,sDACbp6B,GAAI,sBAGZy6B,QAAS,uGACTC,aAAc,GACdC,UAAW,ICgBf,GApEiB,CACbR,SAAU,CACN,CACIC,YAAa,sDACbp6B,GAAI,sBAER,CACIo6B,YAAa,oEACbp6B,GAAI,yBAER,CACIo6B,YAAa,qCACbp6B,GAAI,4BAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,+BACVpuB,KAAM,OAEV,CACItJ,MAAO,cACPmM,QAAS,mCACT7C,KAAM,SAGd3B,QAAS,CACL,CACI3H,MAAO,SACPmM,QAAS,6IACT7C,KAAM,UAIlBquB,QAAS,GACTpmB,OAAQ,CACJ,CACIimB,YAAa,qCACbp6B,GAAI,+BAER,CACIo6B,YAAa,+DACbp6B,GAAI,yCAER,CACIo6B,YAAa,mCACbp6B,GAAI,yCAGZw6B,OAAQ,CACJ,CACIJ,YAAa,0DACbp6B,GAAI,wBAER,CACIo6B,YAAa,uDACbp6B,GAAI,yCAER,CACIo6B,YAAa,sDACbp6B,GAAI,8CAGZy6B,QAAS,mIACTC,aAAc,CAAC,IACfC,UAAW,ICJf,GA9DiB,CACbR,SAAU,CACN,CACIC,YAAa,0FACbp6B,GAAI,iBAER,CACIo6B,YAAa,yEACbp6B,GAAI,0BAER,CACIo6B,YAAa,yFACbp6B,GAAI,+BAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,YACVpuB,KAAM,QAGd3B,QAAS,CACL,CACI+vB,SAAU,aACVpuB,KAAM,SAIlBquB,QAAS,GACTpmB,OAAQ,CACJ,CACIimB,YAAa,+DACbp6B,GAAI,2BAER,CACIo6B,YAAa,6EACbp6B,GAAI,2BAER,CACIo6B,YAAa,sFACbp6B,GAAI,gCAER,CACIo6B,YAAa,8EACbp6B,GAAI,yBAGZw6B,OAAQ,CACJ,CACIJ,YAAa,0DACbp6B,GAAI,2BAER,CACIo6B,YAAa,wEACbp6B,GAAI,8BAGZy6B,QAAS,wPACTC,aAAc,GACdC,UAAW,ICRFG,GAAwB,CACjC,uBAAwB,CAAC,cAAe,eAAgB,mBACxD,iBAAkB,CAAC,WAAY,UAAW,eAC1C,+BAAgC,CAAC,SAAU,OAAQ,cAAe,eAAgB,mBAClF,qBAAsB,CAAC,gBACvB,mBAAoB,CAAC,eAAgB,mBACrC,8BAA+B,CAAC,eAAgB,mBAChD,qBAAsB,CAAC,wBAAyB,eAAgB,mBAChE,YAAa,CAAC,eAAgB,mBAC9B,WAAY,CAAC,gBACb,uBAAwB,CAAC,QAAS,OAAQ,eAAgB,mBAC1D,2BAA4B,CAAC,OAAQ,gBACrC,qBAAsB,CAAC,eAAgB,mBACvC,qBAAsB,CAAC,gBACvB,sBAAuB,CAAC,aACxB,sBAAuB,CAAC,aACxB,iBAAkB,CAAC,YAAa,eAAgB,mBAChD,gBAAiB,CAAC,eAAgB,mBAClC,iBAAkB,CAAC,aACnB,qBAAsB,CAAC,gBACvB,uBAAwB,CAAC,gBACzB,kBAAmB,CAAC,gBACpB,kBAAmB,CAAC,gBACpB,mBAAoB,CAAC,eAAgB,kBAAmB,eACxDd,MAAO,GACP,qBAAsB,CAAC,uBAAwB,WAAY,eAAgB,mBAC3EF,SAAU,GACV,yBAA0B,CAAC,eAAgB,oBAAqB,YAAa,kBAC7E,sBAAuB,CAAC,wBAAyB,QAAS,mBAC1DlrB,cAAe,CAAC,eAAgB,mBAChC,2BAA4B,CAAC,gBAC7B,gBAAiB,CAAC,gBAClB,yBAA0B,CAAC,WAC3B,qBAAsB,CAAC,WACvB,kBAAmB,CAAC,gBACpB,sBAAuB,CAAC,uBAAwB,SAAU,QAAS,eAAgB,mBACnF,kBAAmB,CAAC,eAAgB,mBACpC,eAAgB,CAAC,wBAAyB,gBAC1C,iBAAkB,GAClB,gBAAiB,CAAC,aAClB,iBAAkB,CAAC,SAAU,gBAAiB,eAAgB,mBAC9D,gBAAiB,CAAC,eAAgB,mBAClC,gBAAiB,CAAC,aAClB,0BAA2B,GAC3B,uBAAwB,CACpB,uBACA,QACA,QACA,cACA,SACA,eACA,mBAEJF,YAAa,CAAC,eAAgB,mBAC9B,iCAAkC,CAAC,aACnC,qBAAsB,CAAC,gBACvB,4BAA6B,CAAC,eAAgB,mBAC9C,2BAA4B,GAC5B,2BAA4B,CAAC,eAAgB,mBAC7C,iCAAkC,CAAC,eAAgB,mBACnD,6BAA8B,CAAC,eAAgB,mBAC/C,aAAc,CAAC,aACf,cAAe,CAAC,aAChB,aAAc,CAAC,gBACf,4BAA6B,CAAC,gBAC9B,iBAAkB,CAAC,cAOvB,SAASqsB,GAAQ7uB,GAAqC,IAA/B8uB,EAAex8B,UAAAC,OAAA,QAAAb,IAAAY,UAAA,GAAAA,UAAA,GAAGy8B,GACrC,OAAAx9B,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACOu9B,GAAe,IAClBh7B,GAAIkM,EACJtJ,MAAO82B,GAAcxtB,GAAMhP,KAC3Bg+B,UAAWJ,GAAsB5uB,IAEzC,CAMkB6uB,GAAQ,aCzIT,CACbZ,SAAU,CACN,CACIC,YAAa,2DACbp6B,GAAI,iCAGZq6B,KAAM,CACFvxB,OAAQ,CACJ,CACIwxB,SAAU,uBACVpuB,KAAM,OAEV,CACItJ,MAAO,cACPmM,QAAS,0CACT7C,KAAM,SAGd3B,QAAS,CACL,CACI3H,MAAO,iBACPmM,QAAS,weACT7C,KAAM,QAEV,CACIouB,SAAU,wBACVpuB,KAAM,WAIlBquB,QAAS,GACTpmB,OAAQ,CACJ,CACIimB,YAAa,8FACbp6B,GAAI,wBAER,CACIo6B,YAAa,4EACbp6B,GAAI,qBAER,CACIo6B,YAAa,yFACbp6B,GAAI,yBAER,CACIo6B,YAAa,0EACbp6B,GAAI,gCAGZw6B,OAAQ,CACJ,CACIJ,YAAa,kEACbp6B,GAAI,sBAGZy6B,QAAS,6FACTC,aAAc,GACdC,UAAW,KDgFaI,GAAQ,uBAAwB3gB,IACtC2gB,GAAQ,iBAAkB1gB,IACtB0gB,GAAQ,qBAAsBI,IACpBJ,GAAQ,+BAAgCzgB,IACpDygB,GAAQ,mBAAoBK,IACjBL,GAAQ,8BAA+B/e,IACzC+e,GAAQ,4BAA6BM,IAC5CN,GAAQ,qBAAsB1f,IACvC0f,GAAQ,YAAazf,IAEVyf,GAAQ,uBAAwBvgB,IAC5BugB,GAAQ,2BAA4BO,IAC1CP,GAAQ,qBAAsBtgB,IAClCsgB,GAAQ,iBAAkBrgB,IACtBqgB,GAAQ,qBAAsBQ,IAC7BR,GAAQ,sBAAuBlgB,IAC/BkgB,GAAQ,sBAAuBjgB,IACrCigB,GAAQ,gBAAiBpgB,IACxBogB,GAAQ,iBAAkBngB,IACtBmgB,GAAQ,qBAAsBS,IACjCT,GAAQ,kBAAmBU,IAE1BV,GAAQ,mBAAoBhgB,IACxBggB,GAAQ,uBAAwBW,IAElCX,GAAQ,qBAAsBxf,IAC1Bwf,GAAQ,yBAA0BY,IAErCZ,GAAQ,sBAAuBvf,IACvCuf,GAAQ,gBAAiBnsB,IACZmsB,GAAQ,2BAA4Btf,IAEtCsf,GAAQ,yBAA0B3e,IACtC2e,GAAQ,qBAAsB1e,IAE7B0e,GAAQ,sBAAuBrf,IACnCqf,GAAQ,kBAAmBpf,IAC9Bof,GAAQ,eAAgBa,IAEvBb,GAAQ,gBAAiB/f,IACxB+f,GAAQ,iBAAkBxgB,IAE3BwgB,GAAQ,gBAAiB9f,IAElB8f,GAAQ,uBAAwBjf,IAC3Cif,GAAQ,cAAersB,IACFqsB,GAAQ,iCAAkCc,IACtDd,GAAQ,qBAAsBe,IAClCf,GAAQ,iBAAkBgB,IACfhB,GAAQ,4BAA6B5e,IAEtC4e,GAAQ,2BAA4Bhf,IAC9Bgf,GAAQ,iCAAkC7f,IAC9C6f,GAAQ,6BAA8BiB,IACtDjB,GAAQ,aAAckB,IACrBlB,GAAQ,cAAemB,IAzDnC,ME9GDC,GAAwBx8B,GACtBA,EAAMy8B,KAAK36B,SAAS,kBACU,oBAAvB9B,EAAM08B,aACP,CAAC,CAAErtB,KAAM,OAAQD,QAAS,mCAC1B,CACE,CACIC,KAAM,OACND,QAAS,CACL,CACI7C,KAAM,OACNlH,KAAM,wCAEV,CACIkH,KAAM,YACNE,UAAW,CACP9H,IAAK,kGAO1B,wDAuCLg4B,GAA0BA,IAAA,wGAE1BC,GAAqB,CACvB,iBAVuBC,IAAA,iBAWvB,uBAV8BC,IAAA,iBAW9B,+BANqCC,IAAA,iBAOrC,8BA7EkCC,IAAA,sFA8ElC,qBAnC4BC,IAAA,wDAoC5B,YA7CoBj9B,GAAK,kCAAAlE,OAAuCkE,EAAMk9B,WAAU,MA8ChF,uBApC8BC,IAAA,aAqC9B,gBApCsBC,IAAA,aAqCtB,iBApCuBC,IAAA,4EAqCvB,iBAjCuBC,IAAA,yEAkCvB,sBA9B2BC,IAAA,4EA+B3B,sBA3B2BC,IAAA,yEA4B3B,qBAxB4BC,IAAA,aAyB5B,mBAxB0BC,IAAA,aAyB1B,qBApF4BC,IAAA,uGAqF5B,sBAtD6BC,IAAA,4LAuD7B3uB,cAxGwB4uB,IAAA,4uBAyGxB,2BAxGiCC,IAAA,sYAyGjC,qBAAsBnB,GACtB,yBAA0BA,GAC1B,sBAtF6BoB,IAAA,2BAuF7B,kBAAmBvB,GACnB,qBAAsBA,GACtB,gBA/BsBwB,IAAA,6BAgCtB,gBA/BsBC,IAAA,sCAgCtB,iBA/BuBC,IAAA,qCAgCvB,gBA/BsBC,IAAA,0DAgCtB,uBA5F8BC,IAAA,gEA6F9BrvB,YArHsBsvB,IAAA,4MAsHtB,2BAvHiCC,IAAA,6HAwHjC,iCAhCsCC,IAAA,cAoCnC,SAASC,GAAqBx+B,GAAyC,IAAlCy+B,EAAM5/B,UAAAC,OAAA,QAAAb,IAAAY,UAAA,IAAAA,UAAA,GAAU6/B,EAAQ7/B,UAAAC,OAAA,QAAAb,IAAAY,UAAA,IAAAA,UAAA,GAChE,GAAImB,EAAM08B,aAAc,CACpB,MAAMvzB,EAASyzB,GAAmB58B,EAAM08B,cACxC,GAAIvzB,EAAQ,CACR,IAAIb,EAASa,EAAOnJ,GACpB,GAAsB,kBAAXsI,IACHm2B,IACAn2B,EAASA,EAAO3I,QAAQ,2BAA4B,MAEpD++B,GAAU,CACV,MAAMC,EAAe,aACfzV,EAAQ5gB,EAAO4gB,MAAMyV,GAC3Br2B,EAAS4gB,EAAQA,EAAM,GAAK5gB,CAChC,CAEJ,OAAOA,CACX,CACJ,CACA,MAAO,wDACX,CC/IO,SAASs2B,GAAkBzvB,EAAU0vB,GACxC,IAAIC,EAAcz/B,KAAKC,UAAU6P,EAAU,KAAM,MAUjD,OATQ,OAAJ0vB,QAAI,IAAJA,GAAAA,EAAM3U,SACN4U,EAAcA,EAAY9U,WAAW,KAAM,KAAFluB,OAAO+iC,EAAK3U,UAEhD,OAAJ2U,QAAI,IAAJA,GAAAA,EAAME,qBACPD,EAAcA,EAAYn/B,QAAQ,cAAe,QAE7C,OAAJk/B,QAAI,IAAJA,GAAAA,EAAMG,uBACNF,EAAcD,EAAKG,qBAAqBF,IAErCA,CACX,CCTA,MAAMG,GAAkB,cACxB,SAASC,GAAqB96B,GAC1B,MAAM+6B,EAAW/6B,EAAQiF,MAAM,KAC/B,OAA2B,IAApB81B,EAASrgC,OAAeqgC,EAAS,GAAKA,EAAS,EAC1D,CAyDA,SAASC,GAAyBp/B,GAAO,IAAAq/B,EAAAC,EACrC,OAA6C,QAA7CD,EAAqB,QAArBC,EAAOt/B,EAAMu/B,gBAAQ,IAAAD,GAAY,QAAZA,EAAdA,EAAgBE,kBAAU,IAAAF,OAAA,EAA1BA,EAA4Bn+B,kBAAU,IAAAk+B,EAAAA,EAAI,oBACrD,CACA,SAASI,GAAgCz/B,GAAO,IAAA0/B,EAAAC,EAAAC,EAC5C,MAAM12B,EAAoC,QAA9Bw2B,EAAmB,QAAnBC,EAAG3/B,EAAM6/B,kBAAU,IAAAF,GAAK,QAALA,EAAhBA,EAAmB,UAAE,IAAAA,OAAA,EAArBA,EAAuBt6B,YAAI,IAAAq6B,EAAAA,EAAkB,QAAlBE,EAAI5/B,EAAMu/B,gBAAQ,IAAAK,OAAA,EAAdA,EAAgBE,gBAC9D,GAAI52B,EACA,OA9DqBwgB,EA8DMxgB,EA9DE7J,KAAKC,UAAUoqB,GAAKhU,MAAM,GAAI,GAAtCgU,KAgE7B,CACO,MA0PDqW,GAAyB,wEACzBC,GAAgC,2BAChCC,GAA8B,0DAiKvBC,GAAalgC,IACtB,IAAImgC,EAqCJ,OAlCIA,EAFAngC,EAAMy8B,KAAK36B,SAAS,mCACpB9B,EAAMy8B,KAAK36B,SAAS,oCA9BE9B,IAAU,CAAC,mMAADlE,OAMYkE,EAAMK,GAAE,yzBAyBrC+/B,CAAqBpgC,GAE/BA,EAAMy8B,KAAK36B,SAAS,cA9HH9B,IAAU,CAAC,6HAADlE,OAGQkE,EAAMK,GAAE,sEAAAvE,OAEpDsjC,GAAyBp/B,GAAM,gCA0HZqgC,CAAqBrgC,GAE/BA,EAAMy8B,KAAK36B,SAAS,QACE,mBAAvB9B,EAAM08B,aA/GqB18B,KAAK,IAAAsgC,EAAA,MAAK,CAAC,mLAADxkC,OAMLsjC,GAAyBp/B,GAAM,yEAAAlE,OACjDkE,EAAMK,GAAE,oBAAAvE,OAEgB,QAFhBwkC,EAEtBb,GAAgCz/B,UAAM,IAAAsgC,EAAAA,EAAIN,GAA6B,gMAuGxDO,CAA8BvgC,GAEjB,mBAAvBA,EAAM08B,aAtFgB18B,KAAK,IAAAwgC,EAAA,MAAK,CAAC,oMAAD1kC,OAMLsjC,GAAyBp/B,GAAM,yEAAAlE,OACjDkE,EAAMK,GAAE,oBAAAvE,OAEgB,QAFhB0kC,EAEtBf,GAAgCz/B,UAAM,IAAAwgC,EAAAA,EAAIP,GAA2B,8OA8EtDQ,CAA8BzgC,GAEjB,kBAAvBA,EAAM08B,aAvGe18B,KAAK,IAAA0gC,EAAA,MAAK,CAAC,wLAAD5kC,OAMJsjC,GAAyBp/B,GAAM,yEAAAlE,OACjDkE,EAAMK,GAAE,oBAAAvE,OAEgB,QAFhB4kC,EAEtBjB,GAAgCz/B,UAAM,IAAA0gC,EAAAA,EAAIT,GAA2B,wFA+FtDU,CAA6B3gC,GAjIhCA,KAAK,IAAA4gC,EAAA,MAAK,CAAC,2IAAD9kC,OAKUsjC,GAAyBp/B,GAAM,yEAAAlE,OACjDkE,EAAMK,GAAE,oBAAAvE,OAEgB,QAFhB8kC,EAEtBnB,GAAgCz/B,UAAM,IAAA4gC,EAAAA,EAAIb,GAAsB,uCA4HjDc,CAAe7gC,GAG7BA,EAAMy8B,KAAK36B,SAAS,qBAjFI9B,IAAU,CAAC,2IAADlE,OAKHsjC,GAAyBp/B,GAAM,8EAAAlE,OAC5CkE,EAAMK,GAAE,OA4EhBygC,CAA4B9gC,GAEtCA,EAAMy8B,KAAK36B,SAAS,oBA5EJ9B,IAAU,CAAC,+YAADlE,OASIkE,EAAMK,GAAE,kWAoE5B0gC,CAAoB/gC,GAEP,mBAAvBA,EAAM08B,aAtKe18B,KAAK,IAAAghC,EAAA,MAAK,CAAC,oMAADllC,OAMAkE,EAAMK,GAAE,8EAAAvE,OAGF,QAHEklC,EAGxCvB,GAAgCz/B,UAAM,IAAAghC,EAAAA,EAAIf,GAA2B,2OA8J1DgB,CAAyBjhC,GAEZ,mBAAvBA,EAAM08B,aAtLe18B,KAAK,IAAAkhC,EAAA,MAAK,CAAC,mLAADplC,OAMAkE,EAAMK,GAAE,6DAAAvE,OAEF,QAFEolC,EAExCzB,GAAgCz/B,UAAM,IAAAkhC,EAAAA,EAAIlB,GAA6B,gMA+K5DmB,CAAyBnhC,GAjMrBA,KAAK,IAAAohC,EAAA,MAAK,CAAC,2IAADtlC,OAKOkE,EAAMK,GAAE,6DAAAvE,OAEF,QAFEslC,EAExC3B,GAAgCz/B,UAAM,IAAAohC,EAAAA,EAAIrB,GAAsB,uCA6LrDsB,CAAkBrhC,GAE9B,CA1Me,sDA0MQmgC,IAgP5BmB,GAAgC,CAClCC,SAlD0Bn9B,GAAO,qJAAAtI,OAIqBsI,EAAO,iLA+C7Do9B,YAzC8Bp9B,GAAO,+JAAAtI,OAIwBsI,EAAO,0HAsCpEq9B,eAjCgCr9B,GAAO,gIAAAtI,OAK/BsI,EAAO,6LA6Bfs9B,gBArBiCt9B,GAAO,iJAAAtI,OAMhCsI,EAAO,mQAiBbu9B,GAAkCA,CAAC9+B,EAAMuB,IAAY,oCAALtI,OAGzC+G,EAAI,oCAAA/G,OACS+G,EAAI,uBAAA/G,OAAsBsI,EAAO,QA2kBpD,MA6HMw9B,GAAgB5hC,IAAU,IAAA6hC,EACnC,MAAMpsB,EAAOzV,EAAM8hC,iBACnB,IAAKrsB,EACD,MAAO,CAAC,wCAEZ,MAAMssB,EAAsB/hC,EAAMy8B,KAAK36B,SAASm9B,IAAmB,2BAA6B,GAC1F+C,EAAc,GACpB,GAAIvsB,EAAKwsB,UAAW,CAChB,MAAMC,EAAsC,kBAAnBzsB,EAAKwsB,UACxB,YACmB,yBAAnBxsB,EAAKwsB,UACD,YACA,YACVD,EAAYzgC,KAAK,wBAAyB,4BAAFzF,OAA8B2Z,EAAKwsB,UAAS,MAAAnmC,OAAK2Z,EAAK0sB,YAAc,GAAI,GAAArmC,OAAGomC,EAAgB,OAAApmC,OAAM2Z,EAAKwsB,UAAS,sBAAAnmC,OAAqBkE,EAAMK,GAAE,KAAM0hC,EAAsB,IAAK,WAAAjmC,OAAW2Z,EAAK0sB,WAAU,sBAAArmC,OAAqBkE,EAAMK,GAAE,KAAM0hC,EAAsB,KACpS/hC,EAAMy8B,KAAK36B,SAAS,mBAjBP9B,KAAK,IAAAoiC,EAAAC,EAAAC,EAAA,YAAuDrkC,KAAtC,QAAZmkC,EAAApiC,EAAMuiC,cAAM,IAAAH,GAAkB,QAAlBA,EAAZA,EAAcI,wBAAgB,IAAAJ,OAAA,EAA9BA,EAAgCK,qBACbxkC,KAAtC,QAAZokC,EAAAriC,EAAMuiC,cAAM,IAAAF,GAAkB,QAAlBA,EAAZA,EAAcK,wBAAgB,IAAAL,OAAA,EAA9BA,EAAgCI,qBACMxkC,KAA1B,QAAZqkC,EAAAtiC,EAAMuiC,cAAM,IAAAD,OAAA,EAAZA,EAAcK,sBAemCC,CAAgB5iC,KACrDA,EAAMy8B,KAAK36B,SAAS,sBACpBkgC,EAAYzgC,KAAK,eAAgB,CAC7B,QACA,0BACA,uBACA,0IACA,uEACA,YACA,UACFI,KAAK,MAAO,KAGdqgC,EAAYzgC,KAAK,eAAgB,mDAAoD,KAEzFygC,EAAYzgC,KAAK,YAADzF,OAAaomC,EAAgB,yBAAyB,cAAc,gCAAgC,mBAAmB,sBAAsB,yBAAyB,qBAAsB,GAAI,wDAAyD,SAAFpmC,OAAWomC,EAAgB,yDAE1S,MAEIF,EAAYzgC,KAAK,wBAAyB,4BAAFzF,OAA8B2Z,EAAK0sB,YAAc,WAAArmC,OAAW2Z,EAAK0sB,WAAU,sBAAArmC,OAAqBkE,EAAMK,GAAE,KAAM0hC,EAAsB,mBAEhL,GAAI/hC,EAAM08B,cAAiD,QAArCmF,EAAItJ,UAAiC,IAAAsJ,GAAjCA,EAAmC//B,SAAS9B,EAAM08B,cAAe,CACvF,MAAMmG,EAAkB,CACpB,0CACA,oCACA,GACA,oBAAA/mC,OAAoBkE,EAAM08B,aAAY,cAAA5gC,OAAakE,EAAMK,GAAE,KAAM0hC,EAAsB,KA0B3F,OAxBI/hC,EAAMy8B,KAAK36B,SAAS,kBAChB9B,EAAMy8B,KAAK36B,SAAS,uBACpB+gC,EAAgBthC,KAAK,eAAgB,CACjC,QACA,0BACA,uBACA,0IACA,uEACA,YACA,UACFI,KAAK,MAAO,KACdkhC,EAAgBthC,KAAK,yBAGrBshC,EAAgBthC,KAAK,eAAgB,mDAAoD,KACzFshC,EAAgBthC,KAAK,mBAGG,mCAAvBvB,EAAM08B,aACXmG,EAAgBthC,KAAK,QAAS,uGAAwG,2DAA4D,KAEtK,yBAAvBvB,EAAM08B,cACXmG,EAAgBthC,KAAK,yGAElB,CAACshC,EAAgBlhC,KAAK,MAAOqgC,EAAYrgC,KAAK,MACzD,CACA,MAAO,CAACqgC,EAAYrgC,KAAK,QA8MhBmhC,GAAe9iC,IAExB,MAAM+iC,EAAa/iC,EAAMy8B,KAAK7nB,KAAMouB,GAAQA,EAAI9Z,MAAM,eAChD+Z,EAAYF,EAAa,QAAHjnC,OAAWinC,EAAWrtB,MAAM,IAAO,UAI/D,MAAO,EAHQqtB,EACT,GAAE,uFAGE,2BAAAjnC,OACyBmnC,EAAS,gBAAAnnC,OAEtCmnC,EAAS,sBAAAnnC,OAAqBkE,EAAMK,GAAE,qHA4J1C6iC,GAAmBljC,GACKkgC,GAAUlgC,GACXqC,IAAK8gC,GAAYA,EAErCxjC,QAAQ,sBAAuB,cAE/BA,QAAQ,oDAAqD,IAC7DA,QAAQ,kEAAmE,4BAC3EA,QAAQ,kCAAmC,IAE3CA,QAAQ,oCAAqC,gCAC7CA,QAAQ,+CAAgD,4BACxDA,QAAQ,+CAAgD,4BAExDA,QAAQ,SAAU,MAClBkO,QAEHu1B,GAAsBpjC,IACxB,MAAMyV,EAAOzV,EAAM8hC,iBAGnB,IAAIuB,EAFyBzB,GAAa5hC,GAEGqC,IAAK8gC,GAAYA,EACzDxjC,QAAQ,qCAAsC,gCAC9CA,QAAQ,qBAAsB,+BAAF7D,OAAiCkE,EAAMK,GAAE,QAQ1E,OANQ,OAAJoV,QAAI,IAAJA,GAAAA,EAAM0sB,aACNkB,EAAoBA,EAAkBhhC,IAAK8gC,GAAYA,EAClDxjC,QAAQ,IAAIoqB,OAAO,4BAADjuB,OAA6B2Z,EAAK0sB,WAAU,OAAO,KAAM,IAC3ExiC,QAAQ,IAAIoqB,OAAO,GAADjuB,OAAI2Z,EAAK0sB,WAAU,oBAAoB,KAAM,8BAC/DxiC,QAAQ,IAAIoqB,OAAO,wBAADjuB,OAAyB2Z,EAAK0sB,WAAU,SAAS,MAAQzoB,GAASA,EAAK/Z,QAAQ,IAAIoqB,OAAO,MAADjuB,OAAO2Z,EAAK0sB,YAAc,KAAM,OAE7IkB,GAELC,GAAiBtjC,GAAU,CAAC,qEAADlE,OAEKkE,EAAMK,GAAE,SC35DjCkjC,GAA8B,CACvCC,QAAS,CACLC,YAAa,WACbC,SAAU,WACVC,QAAS,uCACTlhC,QAAQ,EACRmhC,eAAgB,2CAEpB,uBAAwB,CACpBH,YAAa,WACbC,SAAU,WACVC,QAAS,0CACTE,QAAS,2CACTC,SDlBiB9jC,IAAK,IAAA+jC,EAAA,MAAK,CAAC,sFAADjoC,OAGqB,QAHrBioC,EAGS/jC,EAAMuiC,cAAM,IAAAwB,GAAsB,QAAtBA,EAAZA,EAAcC,4BAAoB,IAAAD,OAAA,EAAlCA,EAAoCp4B,WAAU,4BAAA7P,OACpEkE,EAAMK,GAAE,yBCetBoC,QAAQ,EACRmhC,eAAgB,8BAEpBK,SAAU,CACNR,YAAa,WACbC,SAAU,WACVC,QAAS,sCACTE,QAAS,2CACTC,SDPiB9jC,GACjBA,EAAMy8B,KAAK36B,SAAS,sBATO9B,IAAU,CAAC,wHAADlE,OAILkE,EAAMK,GAAE,yKAMjC6jC,CAA0BlkC,GAhBhBA,IAAU,CAAC,wHAADlE,OAIKkE,EAAMK,GAAE,OAcrC8jC,CAAgBnkC,GCInByC,QAAQ,GAEZ2hC,OAAQ,CACJX,YAAa,SACbC,SAAU,SACVC,QAAS,4CACTE,QAAS,2CACTphC,QAAQ,EACRmhC,eAAgB,wBAChBE,SDg8De9jC,GAAU,CAAC,wMAADlE,OAIwBkE,EAAMK,GAAE,wDCl8D7DgkC,QAAS,CACLZ,YAAa,UACbC,SAAU,UACVC,QAAS,6CACTlhC,QAAQ,EACRqhC,SDlBgB9jC,GAAU,CAAC,mEAADlE,OAGCkE,EAAMK,GAAE,QCiBvCikC,SAAU,CACNb,YAAa,WACbC,SAAU,WACVC,QAAS,4CACTE,QAAS,2CACTC,SDpBiB9jC,GAAU,CAAC,+EAADlE,OAGEkE,EAAMK,GAAE,OCkBrCoC,QAAQ,EACRmhC,eAAgB,4BAEpBW,WAAY,CACRd,YAAa,aACbC,SAAU,aACVC,QAAS,iDACTG,SDk7DmB9jC,GACnBA,EAAMy8B,KAAK36B,SAAS,YAjCV9B,IAAU,CAAC,8EAADlE,OAGOkE,EAAMK,GAAE,kIA+B5BmkC,CAASxkC,GAEXA,EAAMy8B,KAAK36B,SAAS,YApBf9B,IAAU,CAAC,gFAADlE,OAGOkE,EAAMK,GAAE,iOAkB5BokC,CAASzkC,GAEXA,EAAMy8B,KAAK36B,SAAS,UA/BjB9B,IAAU,CAAC,4EAADlE,OAGOkE,EAAMK,GAAE,sIA6B1BqkC,CAAO1kC,GAGP,CAAC,4BC57DRyC,QAAQ,EACRmhC,eAAgB,yBAEpBe,UAAW,CACPlB,YAAa,YACbC,SAAU,YACVC,QAAS,gDACTlhC,QAAQ,EACRmhC,eAAgB,uBAChBE,SDjCkB9jC,GAgBf,CAfkB,+FAAHlE,OAGUkE,EAAMK,GAAE,0MAMhB,gGAAHvE,OAGakE,EAAMK,GAAE,gFCsB1C,YAAa,CACTojC,YAAa,QACbC,SAAU,QACVC,QAAS,2CACTlhC,QAAQ,EACRmhC,eAAgB,0BAEpBgB,aAAc,CACVnB,YAAa,eACbC,SAAU,eACVC,QAAS,gDACTlhC,QAAQ,EACRmhC,eAAgB,wBAEpBiB,KAAM,CACFpB,YAAa,OACbC,SAAU,OACVC,QAAS,mCACTG,SD1Ba9jC,GAAU,CAAC,4PAADlE,OAQMkE,EAAMK,GAAE,uECmBrCoC,QAAQ,GAEZqiC,SAAU,CACNrB,YAAa,WACbC,SAAU,WACVC,QAAS,wCACTG,SDpBiB9jC,GAAU,CAAC,2DAADlE,OAGVkE,EAAMK,GAAE,OCkBzBoC,QAAQ,GAEZsiC,WAAY,CACRtB,YAAa,aACbC,SAAU,aACVC,QAAS,gDACTlhC,QAAQ,EACRmhC,eAAgB,wBAEpBoB,OAAQ,CACJvB,YAAa,SACbC,SAAU,SACVC,QAAS,mCACTlhC,QAAQ,EACRmhC,eAAgB,uBAEpBqB,SAAU,CACNxB,YAAa,WACbC,SAAU,WACVC,QAAS,yCACTG,SDinDiB9jC,GAAU,CAAC,0JAADlE,OAIyBkE,EAAMK,GAAE,qMAAAvE,OAOhCkE,EAAMK,GAAE,OC3nDpCoC,QAAQ,GAEZyiC,MAAO,CACHzB,YAAa,QACbC,SAAU,QACVC,QAAS,kCACTG,SD3Cc9jC,GAAU,CAAC,oEAADlE,OAGIkE,EAAMK,GAAE,OCyCpCoC,QAAQ,EACRmhC,eAAgB,4BAEpBuB,SAAU,CACN1B,YAAa,WACbC,SAAU,WACVC,QAAS,0CACTlhC,QAAQ,EACRmhC,eAAgB,iCAEpBwB,gBAAiB,CACb3B,YAAa,gBACbC,SAAU,gBACVC,QAAS,mDACTlhC,QAAQ,EACRmhC,eAAgB,iBAEpByB,iBAAkB,CACd5B,YAAa,mBACbC,SAAU,mBACVC,QAAS,kDACTG,SDuZyB9jC,GAAU,CAAC,sLAADlE,OAKAkE,EAAMK,GAAE,8VC1Z/CilC,aAAc,CACV7B,YAAa,eACbC,SAAU,eACVC,QAAS,8CACTG,SDkaqB9jC,GAAU,CAAC,qFAADlE,OAIRkE,EAAMK,GAAE,qQCpanCklC,MAAO,CACH9B,YAAa,QACbC,SAAU,QACVC,QAAS,mDACTC,eAAgB,kCAEpB4B,WAAY,CACR/B,YAAa,aACbC,SAAU,aACVC,QAAS,4CACTG,SD9EkB0B,IAAM,CAAC,yjBC+EzB5B,eAAgB,wBAChBnhC,QAAQ,GAEZgjC,SAAU,CACNhC,YAAa,WACbC,SAAU,WACVC,QAAS,8CACTC,eAAgB,qBAChBnhC,QAAQ,GAEZijC,SAAU,CACNjC,YAAa,UACbC,SAAU,UACVC,QAAS,wCACTG,SDshDe6B,IAAM,CAAC,yQCrhDtBljC,QAAQ,EACRmhC,eAAgB,uBAEpB,sBAAuB,CACnBH,YAAa,UACbC,SAAU,UACVC,QAAS,wDACTG,SDrF4B9jC,GAmBzB,CAlBgB,kCACA,mHAAHlE,OAG0BkE,EAAMK,GAAE,olBCkFtDulC,MAAO,CACHnC,YAAa,QACbC,SAAU,QACVjhC,QAAQ,EACRkhC,QAAS,kCACTC,eAAgB,+CAEpBiC,UAAW,CACPpC,YAAa,YACbC,SAAU,YACVC,QAAS,gDACTlhC,QAAQ,EACRmhC,eAAgB,uBAEpB,eAAgB,CACZH,YAAa,eACbC,SAAU,eACVC,QAAS,iDACTlhC,QAAQ,EACRmhC,eAAgB,mBAEpBkC,UAAW,CACPrC,YAAa,YACbC,SAAU,YACVC,QAAS,2CACTlhC,QAAQ,EACRmhC,eAAgB,gDAEpBmC,UAAW,CACPtC,YAAa,YACbC,SAAU,YACVC,QAAS,iDACTlhC,QAAQ,EACRmhC,eAAgB,wBAEpBoC,QAAS,CACLvC,YAAa,UACbC,SAAU,UACVC,QAAS,uCACTlhC,QAAQ,EACRmhC,eAAgB,8BAEpBqC,MAAO,CACHxC,YAAa,QACbC,SAAU,QACVC,QAAS,oCACTC,eAAgB,uBAEpBsC,OAAQ,CACJzC,YAAa,SACbC,SAAU,SACVC,QAAS,mCACTC,eAAgB,6CAEpB,iBAAkB,CACdH,YAAa,iBACbC,SAAU,iBACVC,QAAS,kDACTG,SD1EsBqC,IAAM,CAAC,4mBC2E7B1jC,QAAQ,EACRmhC,eAAgB,0FAEpBwC,WAAY,CACR3C,YAAa,aACbC,SAAU,aACVG,QAAS,+CACTF,QAAS,2CAEb,oBAAqB,CACjBF,YAAa,kBACbC,SAAU,oBACVC,QAAS,qDACTG,SDzE0B9jC,IAC9B,IAAIqmC,EACAC,EACAC,EAmBJ,OAlBAF,EAAU,YACVC,EAAW,uBACXC,EAAe,iBACE,2CAAbvmC,EAAMK,IACNgmC,EAAU,OACVC,EAAW,KACXC,EAAe,sBAEG,0CAAbvmC,EAAMK,IACXgmC,EAAU,OACVC,EAAW,MACXC,EAAe,uBAEG,2CAAbvmC,EAAMK,KACXgmC,EAAU,OACVC,EAAW,MACXC,EAAe,yBAEZ,CAAC,qQAADzqC,OAWwBuqC,EAAO,gBAAAvqC,OAAewqC,EAAQ,mBAAAxqC,OAAkByqC,EAAY,iEAAAzqC,OAGzDkE,EAAMK,GAAE,mCAAAvE,OAAkCuqC,EAAO,kPCsC/E5jC,QAAQ,EACRmhC,eAAgB,wBAEpB,YAAa,CACTH,YAAa,YACbC,SAAU,YACVC,QAAS,wCACTC,eAAgB,sBAChBE,SDrCkB9jC,GAqBf,CApBgB,wGAAHlE,OAE2BkE,EAAMK,IAC5B,8cCkCrBoC,QAAQ,GAEZ,kBAAmB,CACfghC,YAAa,kBACbC,SAAU,kBACVC,QAAS,mDACTG,SDrBuB0C,IAAM,CAAC,usBCsB9B/jC,QAAQ,EACRmhC,eAAgB,2EAEpB,oBAAqB,CACjBH,YAAa,oBACbC,SAAU,oBACVC,QAAS,8CACTG,SDc0B9jC,GAAU,CAAC,4KAADlE,OAKxBkE,EAAMK,GAAE,iJClBpBoC,QAAQ,GAEZ,UAAW,CACPghC,YAAa,MACbC,SAAU,MACVC,QAAS,mCACTG,SDfY9jC,GAAU,CAAC,qFAADlE,OAICkE,EAAMK,GAAE,wQCY/BoC,QAAQ,GAEZgkC,KAAM,CACFhD,YAAa,OACbC,SAAU,OACVC,QAAS,oCACTG,SDZa9jC,GAAU,CAAC,oFAADlE,OAGPkE,EAAMK,GAAE,6QCUxBoC,QAAQ,GAEZ,6BAA8B,CAC1BghC,YAAa,6BACbC,SAAU,6BACVC,QAAS,yDACTlhC,QAAQ,EACRmhC,eAAgB,uBAEpB8C,QAAS,CACLjD,YAAa,UACbC,SAAU,UACVC,QAAS,uCACTlhC,QAAQ,EACRmhC,eAAgB,sCAEpB1D,UAAW,CACPuD,YAAa,YACbC,SAAU,yBACVC,QAAS,2CACTE,QAAS,4CACTC,SAAUA,GACVrhC,QAAQ,GAGZkkC,aAAc,CACVlD,YAAa,eACbC,SAAU,eACVC,QAAS,4CACTG,SD2LqB9jC,IACzB,MAAM4mC,EAAa,sKAAH9qC,OAMHkE,EAAMK,GAAE,2DAKfwmC,EAAc,6HAAH/qC,OAKHkE,EAAMK,GAAE,2DAKhBymC,EAAkB,8DAAHhrC,OAGXkE,EAAMy8B,KAAK36B,SAAS,QAAU,EAAI,GAAE,mBAAAhG,OACnCkE,EAAMy8B,KAAK36B,SAAS,QAAU,EAAI,EAAC,iKAS9C,MAAO,CADiB9B,EAAMy8B,KAAK36B,SAAS,QAAU+kC,EAAcD,EAC3CE,KC5NzB,kBAAmB,CACfrD,YAAa,eACbC,SAAU,eACVC,QAAS,kDACTlhC,QAAQ,EACRmhC,eAAgB,mBAEpBmD,MAAO,CACHtD,YAAa,QACbC,SAAU,QACVC,QAAS,mCAEbqD,OAAQ,CACJvD,YAAa,UACbC,SAAU,SACVC,QAAS,iCACTE,QAAS,wCACTphC,QAAQ,EACRqhC,SDiPe9jC,IACnB,MAAMinC,EAAc/H,GAAqBl/B,EAAMK,IAAI2pB,WAAW,IAAK,KACnE,MAAO,CAAC,sEAADluB,OAGUkE,EAAMK,GAAE,iFAAAvE,OAGakE,EAAMK,GAAE,4CAAAvE,OAGzCmrC,EAAW,cAAAnrC,OAEZmrC,EAAW,+BAAAnrC,OAA8BmrC,EAAW,UC7PpDrD,eAAgB,mDAEpBsD,IAAK,CACDzD,YAAa,MACbC,SAAU,MACVC,QAAS,mCACTlhC,QAAQ,EACRmhC,eAAgB,+DAEpBuD,OAAQ,CACJ1D,YAAa,SACbC,SAAU,SACVC,QAAS,mCACTE,QAAS,yCACTC,SDqQe9jC,GACfA,EAAMy8B,KAAK36B,SAAS,kBAnBF9B,IAAU,CAAC,6FAADlE,OAGGkE,EAAMK,GAAE,6DAiBhC+mC,CAAUpnC,GAEZA,EAAMy8B,KAAK36B,SAAS,gCAfP9B,IAAU,CAAC,iGAADlE,OAI/BkE,EAAMK,GAAE,qFAYEgnC,CAAUrnC,GANG,CAAC,+ECnQrByC,QAAQ,GAEZ6kC,QAAS,CACL7D,YAAa,UACbC,SAAU,UACVC,QAAS,qCACTG,SDuQgB9jC,GAAU,CAAC,wJAADlE,OAI3BkE,EAAMK,GAAE,SC1QPoC,QAAQ,GAEZ8kC,OAAQ,CACJ9D,YAAa,SACbC,SAAU,SACVC,QAAS,mCACTE,QAAS,yCACTC,SDg5Be9jC,GAAU,CAAC,yFAADlE,OAGCkE,EAAMK,GAAE,OCl5BlCoC,QAAQ,GAEZ+kC,UAAW,CACP/D,YAAa,aACbC,SAAU,aACVC,QAAS,8CACTC,eAAgB,uBAEpB6D,SAAU,CACNhE,YAAa,WACbC,SAAU,WACVC,QAAS,uBACTG,SD8qCiB9jC,GAAU,CAAC,gHAADlE,OAIYkE,EAAMK,GAAE,qBCjrC/CoC,QAAQ,EACRmhC,eAAgB,wBAEpB8D,MAAO,CACHjE,YAAa,QACbC,SAAU,QACVC,QAAS,oCACTlhC,QAAQ,EACRmhC,eAAgB,0CAEpB+D,MAAO,CACHlE,YAAa,QACbC,SAAU,QACVC,QAAS,oCACTE,QAAS,wCACTC,SDyOc9jC,GAAU,CAAC,4EAADlE,OAGAkE,EAAMK,GAAE,OC3OhCoC,QAAQ,EACRmhC,eAAgB,4BAEpBgE,IAAK,CACDnE,YAAa,uBACbC,SAAU,uBACVC,QAAS,+BACTE,QAAS,yDACTphC,QAAQ,EACRmhC,eAAgB,wBAEpB,YAAa,CACTH,YAAa,YACbC,SAAU,YACVC,QAAS,sCACTlhC,QAAQ,EACRmhC,eAAgB,wBAEpB,mBAAoB,CAChBH,YAAa,kBACbC,SAAU,kBACVC,QAAS,gDACTC,eAAgB,4DAEpBiE,OAAQ,CACJpE,YAAa,SACbC,SAAU,SACVC,QAAS,oCACTG,SDiNe9jC,GAAU,CAAC,gEAADlE,OAGCkE,EAAMK,GAAE,OCnNlCoC,QAAQ,EACRmhC,eAAgB,6BAEpBkE,QAAS,CACLrE,YAAa,UACbC,SAAU,UACVC,QAAS,wCACTG,SD8MgB9jC,GAAU,CAAC,mEAADlE,OAGCkE,EAAMK,GAAE,gNChNnCoC,QAAQ,GAEZ,aAAc,CACVghC,YAAa,aACbC,SAAU,aACVC,QAAS,wCACTlhC,QAAQ,EACRmhC,eAAgB,oCAEpBmE,KAAM,CACFtE,YAAa,OACbC,SAAU,OACVC,QAAS,oCACTlhC,QAAQ,EACRmhC,eAAgB,gEAEpBoE,MAAO,CACHvE,YAAa,QACbC,SAAU,QACVC,QAAS,mDACTC,eAAgB,wBAEpBqE,OAAQ,CACJxE,YAAa,SACbC,SAAU,SACVC,QAAS,oCACTlhC,QAAQ,EACRmhC,eAAgB,gCAEpBsE,MAAO,CACHzE,YAAa,QACbC,SAAU,QACVC,QAAS,mCACTE,QAAS,kCACTD,eAAgB,sEAEpBuE,QAAS,CACL1E,YAAa,UACbC,SAAU,UACVC,QAAS,4CACTE,QAAS,2CACTC,SDgMgB9jC,GAAU,CAAC,sKAAD,oPAAAlE,OAYGkE,EAAMK,GAAE,gCC1MzC,cAAe,CACXojC,YAAa,aACbC,SAAU,aACVC,QAAS,wCACTC,eAAgB,kEAEpB,cAAe,CACXH,YAAa,cACbC,SAAU,cACVC,QAAS,yCACTC,eAAgB,yDAEpB,uBAAwB,CACpBH,YAAa,uBACbC,SAAU,uBACVC,QAAS,2DAEb,eAAgB,CACZF,YAAa,eACbC,SAAU,eACVC,QAAS,kDACTlhC,QAAQ,EACRmhC,eAAgB,yBAEpB,wBAAyB,CACrBH,YAAa,wBACbC,SAAU,wBACVC,QAAS,sDACTlhC,QAAQ,EACRmhC,eAAgB,gCAEpBwE,UAAW,CACP3E,YAAa,aACbC,SAAU,aACVC,QAAS,iDACTC,eAAgB,uEAEpB,YAAa,CACTH,YAAa,WACbC,SAAU,WACVC,QAAS,yCACTG,SDoIiB9jC,GAAU,CAAC,wFAADlE,OAIfkE,EAAMK,GAAE,kZCvIpBoC,QAAQ,GAEZ4lC,aAAc,CACV5E,YAAa,eACbC,SAAU,eACVC,QAAS,4CACTlhC,QAAQ,EACRmhC,eAAgB,gCAEpB,eAAgB,CACZH,YAAa,cACbC,SAAU,cACVC,QAAS,2CACTlhC,QAAQ,EACRmhC,eAAgB,kHAEpB0E,MAAO,CACH7E,YAAa,QACbC,SAAU,QACVC,QAAS,sCACTE,QAAS,wCACTC,SD+Ic9jC,GAAU,CAAC,6KAADlE,OAOQkE,EAAMK,GAAE,SCrJxCoC,QAAQ,EACRmhC,eAAgB,gDAEpB,WAAY,CAERH,YAAa,WACbC,SAAU,WACVC,QAAS,yCACTE,QAAS,2CACTC,SD0XiB9jC,GAAU,CAAC,sNAADlE,OAKFkE,EAAMK,GAAE,SC9XjCujC,eAAgB,yBAEpB,YAAa,CACTH,YAAa,WACbC,SAAU,WACVC,QAAS,0CACTE,QAAS,8BACTC,SD0MkB9jC,IAAU,IAAAuoC,EAAAC,EAChC,MAAMpkC,EAAUpE,EAAMK,GAChByT,EAAsC,QAAjCy0B,EAAe,QAAfC,EAAGxoC,EAAMuiC,cAAM,IAAAiG,GAAW,QAAXA,EAAZA,EAAcC,iBAAS,IAAAD,OAAA,EAAvBA,EAAyB10B,aAAK,IAAAy0B,EAAAA,EAAI,GAC1CzE,EAAW,GAEjB,IAAK,MAAOjhC,EAAMsgC,KAAYhhC,OAAO0D,QAAQy7B,IACrCxtB,EAAMhS,SAASe,IACfihC,EAASviC,KAAK4hC,EAAQ/+B,IAI9B,IAAK,MAAMvB,KAAQiR,EACV3R,OAAOK,KAAK8+B,IAA+Bx/B,SAASe,IACrDihC,EAASviC,KAAKogC,GAAgC9+B,EAAMuB,IAK5D,OADA0/B,EAASviC,KAvBwB6C,IAAO,sIAAAtI,OAIasI,EAAO,QAmB9CskC,CAA4BtkC,IACnC0/B,GC3NHrhC,QAAQ,GAEZkmC,QAAS,CACLlF,YAAa,UACbC,SAAU,UACVC,QAAS,yCACTE,QAAS,sCACTC,SDsNgB9jC,GAAU,CAAC,oFAADlE,OAKXkE,EAAMK,GAAE,OC1NvBujC,eAAgB,gDAEpB,aAAc,CACVH,YAAa,YACbC,SAAU,YACVC,QAAS,2CACTG,SDsNmB9jC,GAAU,CAAC,iLAADlE,OAMLkE,EAAMK,GAAE,uwBC3NhCoC,QAAQ,GAEZmmC,UAAW,CACPnF,YAAa,YACbC,SAAU,YACVC,QAAS,wCACTG,SD+OkB9jC,GAAU,CAAC,mDAADlE,OAEnBkE,EAAMK,GAAE,qKC/OrBwoC,OAAQ,CACJpF,YAAa,SACbC,SAAU,SACVC,QAAS,uCACTlhC,QAAQ,EACRmhC,eAAgB,uBAEpBkF,GAAI,CACArF,YAAa,KACbC,SAAU,KACVC,QAAS,gCAEb,eAAgB,CACZF,YAAa,eACbC,SAAU,eACVC,QAAS,2CACTG,SDuOqB9jC,GACrBA,EAAMy8B,KAAK36B,SAAS,cACb,CAAC,gIAADhG,OAIYkE,EAAMK,GAAE,yDAKtBL,EAAMy8B,KAAK36B,SAAS,iBAClB,CAAC,sIAADhG,OAIekE,EAAMK,GAAE,yDAK3B,CAAC,uOAADvE,OAMgBkE,EAAMK,GAAE,uCAAAvE,OACHkE,EAAMK,GAAE,0DCjQpC0oC,OAAQ,CACJtF,YAAa,SACbC,SAAU,SACVC,QAAS,2CACTlhC,QAAQ,EACRmhC,eAAgB,2BAEpB,YAAa,CACTH,YAAa,YACbC,SAAU,YACVC,QAAS,8CACTlhC,QAAQ,EACRmhC,eAAgB,sDAEpBoF,QAAS,CACLvF,YAAa,UACbC,SAAU,UACVC,QAAS,yCACTE,QAAS,sCACTphC,QAAQ,EACRqhC,SD8QgB9jC,IACpB,GAAIA,EAAMy8B,KAAK36B,SAAS,WAAY,CAChC,MAAMmnC,EAAkB,CACpB,6LAKA,0FAAAntC,OAGIkE,EAAMK,GAAE,6NAuBhB,MAdiB,yBAAbL,EAAMK,IAEN4oC,EAAgB1nC,KAAK,spBAADzF,OAUdkE,EAAMK,KAET4oC,CACX,CACA,MAAO,KChTPC,UAAW,CACPzF,YAAa,YACbC,SAAU,YACVC,QAAS,mCACTlhC,QAAQ,EACRmhC,eAAgB,8CAEpBuF,aAAc,CACV1F,YAAa,eACbC,SAAU,eACVC,QAAS,0CACTlhC,QAAQ,EACRmhC,eAAgB,qCAEpB,mBAAoB,CAChBH,YAAa,mBACbC,SAAU,mBACVC,QAAS,8CACTG,SD8NyB9jC,IAC7B,MAAM8jC,EAAW,CAAC,8GAADhoC,OAMTkE,EAAMK,GAAE,yCAKhB,GAAIL,EAAMy8B,KAAK36B,SAAS,kBAAmB,CACvC,MAAMqN,EAAWqvB,GAAqBx+B,GACtC8jC,EAASviC,KAAK,6CAADzF,OACP8iC,GAAkBzvB,EAAU,CAAE4vB,oBAAoB,EAAM7U,OAAQ,OAAO,OAEjF,MAEI4Z,EAASviC,KAAK,2FAOlB,OAAOuiC,ICtPP,aAAc,CACVL,YAAa,aACbC,SAAU,aACVC,QAAS,yCACTC,eAAgB,4BAEpBwF,UAAW,CACP3F,YAAa,YACbC,SAAU,YACVC,QAAS,6CAEb,SAAU,CACNF,YAAa,SACbC,SAAU,SACVC,QAAS,uCACTC,eAAgB,+BAEpB,mBAAoB,CAChBH,YAAa,aACbC,SAAU,aACVC,QAAS,8CACTC,eAAgB,yJAEpB,YAAa,CACTH,YAAa,WACbC,SAAU,WACVC,QAAS,wCACTlhC,QAAQ,EACRqhC,SD0QkB9jC,GAAU,CAAC,uFAADlE,OAGQkE,EAAMK,GAAE,QC3QhD,YAAa,CACTojC,YAAa,YACbC,SAAU,YACVC,QAAS,uCACTlhC,QAAQ,EACRmhC,eAAgB,8BAChBE,SDuQkB9jC,GAAU,CAAC,4HAADlE,OAIAkE,EAAMK,GAAE,QCzQxCgpC,UAAW,CACP5F,YAAa,YACbC,SAAU,YACVC,QAAS,uCACTG,SDuQkB9jC,GAAU,CAAC,kJAADlE,OAICkE,EAAMK,GAAE,2EAAAvE,OAGhBkE,EAAMK,GAAE,OC7Q7BoC,QAAQ,GAEZ,gBAAiB,CACbghC,YAAa,eACbC,SAAU,eACVC,QAAS,0CACTlhC,QAAQ,EACRmhC,eAAgB,+BAChBE,SDuQqBwF,IAAM,CAAC,0UCrQhCC,OAAQ,CACJ9F,YAAa,SACbC,SAAU,SACVC,QAAS,yCACTlhC,QAAQ,EACRmhC,eAAgB,uBAEpB4F,OAAQ,CACJ/F,YAAa,SACbC,SAAU,SACVC,QAAS,yCACTlhC,QAAQ,EACRmhC,eAAgB,yBAEpB6F,MAAO,CACHhG,YAAa,QACbC,SAAU,QACVC,QAAS,mCACTC,eAAgB,gDAEpB,YAAa,CACTH,YAAa,YACbC,SAAU,YACVC,QAAS,kDACTE,QAAS,4CACTC,SDo3BiB9jC,GAAU,CAAC,oCAADlE,OACKkE,EAAMK,GAAE,0CCp3BxCoC,QAAQ,EACRmhC,eAAgB,yBAEpB,WAAY,CACRH,YAAa,QACbC,SAAU,QACVC,QAAS,oCACTlhC,QAAQ,EACRmhC,eAAgB,uBAEpB8F,IAAK,CACDjG,YAAa,MACbC,SAAU,MACVC,QAAS,uDACTG,SDwmCY9jC,GACW,uBAAvBA,EAAM08B,aA/BE18B,IAAU,CAAC,sPAADlE,OASCkE,EAAMK,GAAE,8BAAAvE,OACXkE,EAAMK,GAAE,mVAsBjBspC,CAAO3pC,GAES,oBAAvBA,EAAM08B,aACF18B,EAAMy8B,KAAK36B,SAAS,kBApDf9B,IAAU,CAAC,iKAADlE,OAOAkE,EAAMK,GAAE,4PA8ChBupC,CAAQ5pC,GAlEZA,IAAU,CAAC,oNAADlE,OAQEkE,EAAMK,GAAE,yGA6DhBwpC,CAAM7pC,GA3EJA,IAAU,CAAC,kHAADlE,OAIQojC,GAAqBl/B,EAAMK,IAAG,KAAAvE,OAAIkE,EAAMK,KA0EpEypC,CAAY9pC,GCnnCfyC,QAAQ,GAEZ,YAAa,CACTghC,YAAa,YACbC,SAAU,YACVC,QAAS,+CACTE,QAAS,4CACTC,SD2lCc9jC,GAAU,CAAC,gEAADlE,OAGTkE,EAAMK,GAAE,MC7lCvBoC,QAAQ,EACRmhC,eAAgB,4BAEpB,UAAW,CACPH,YAAa,UACbC,SAAU,UACVC,QAAS,oCACTE,QAAS,2BACTphC,QAAQ,EACRmhC,eAAgB,+BAEpBmG,UAAW,CACPtG,YAAa,YACbC,SAAU,YACVC,QAAS,yCACTG,SD8lCkB9jC,GAAU,CAAC,6EAADlE,OAGGkE,EAAMK,GAAE,OChmCvCoC,QAAQ,GAEZunC,MAAO,CACHvG,YAAa,QACbC,SAAU,QACVC,QAAS,uCACTlhC,QAAQ,EACRmhC,eAAgB,uDAEpBqG,SAAU,CACNxG,YAAa,WACbC,SAAU,WACVC,QAAS,yCACTlhC,QAAQ,EACRmhC,eAAgB,wBAEpBsG,KAAM,CACFzG,YAAa,OACbC,SAAU,OACVC,QAAS,iCACTG,SD2oCa9jC,IACjB,IAAImqC,EAKJ,OAHInqC,EAAMy8B,KAAK36B,SAAS,kCACpBqoC,EApWmBC,EAACC,EAAQrqC,KAChC,GACS,QADDqqC,EAEA,MAAO,CAAC,kGAADvuC,OAEqCkE,EAAMK,GAAE,+DA+V9C+pC,CAAmB,MAAOpqC,IAE1B,OAAPmqC,QAAO,IAAPA,EAAAA,EAAW,CAAC,qDChpCf1nC,QAAQ,EACRmhC,eAAgB,8EAEpB,aAAc,CACVH,YAAa,aACbC,SAAU,aACVC,QAAS,0CACTC,eAAgB,gCAEpB0G,UAAW,CACP7G,YAAa,WACbC,SAAU,WACVC,QAAS,6CACTG,SD2KkB9jC,GAAU,CAAC,+GAADlE,OAGsDkE,EAAMK,GAAE,oDAAAvE,OACpDkE,EAAMK,GAAE,OC9K9CoC,QAAQ,EACRmhC,eAAgB,yJAKpB2G,YAAa,CACT9G,YAAa,cACbC,SAAU,cACVC,QAAS,gDACTE,QAAS,oEACTD,eAAgB,gCAChBnhC,QAAQ,GAEZ,YAAa,CACTghC,YAAa,YACbC,SAAU,YACVC,QAAS,yCACTlhC,QAAQ,EACRmhC,eAAgB,mCAEpB4G,QAAS,CACL/G,YAAa,UACbC,SAAU,UACVC,QAAS,mCACTG,SD2mCgB9jC,IAAU,IAAAyqC,EAE9B,MAAMp4B,EAAc,QAAbo4B,EAAGzqC,EAAMy8B,YAAI,IAAAgO,EAAAA,EAAI,GACxB,OAAIp4B,EAAEvQ,SAAS,SAAWuQ,EAAEvQ,SAAS,QAC1B,GAEJ,CAAC,oDAADhG,OAIgBkE,EAAMK,GAAE,qXCpnC3BoC,QAAQ,GAEZioC,UAAW,CACPjH,YAAa,YACbC,SAAU,YACVC,QAAS,4CACTE,QAAS,4CACTC,SD+IkB9jC,IAAU,IAAA2qC,EAChC,GAAgB,QAAhBA,EAAI3qC,EAAMuiC,cAAM,IAAAoI,GAAe,QAAfA,EAAZA,EAAcC,qBAAa,IAAAD,GAA3BA,EAA8B,GAAI,CAClC,MAAME,EAAe7qC,EAAMuiC,OAAOqI,cAAc,GAChD,MAAO,CACH,CAAC,qDAAD9uC,OACyD+uC,GACrD,GAAE,8CAAA/uC,OAC4CkE,EAAMK,GAAE,mCAAAvE,OAC3C+uC,EAAY,sBAAA/uC,OAAqBkE,EAAMK,GAAE,yBACtDsB,KAAK,MAEf,CAEI,MAAO,CACH,CAAC,uCAAD,8DAGI,GAAE,8CAAA7F,OAC4CkE,EAAMK,GAAE,8DAAAvE,OAChBkE,EAAMK,GAAE,yBAChDsB,KAAK,QClKXc,QAAQ,EACRmhC,eAAgB,4BAEpBkH,UAAW,CACPrH,YAAa,YACbC,SAAU,YACVC,QAAS,4CACTE,QAAS,4BACTC,SD8JkB9jC,IACtB,MAAM+F,EAAU,CACZglC,mBAAoB,CAAE9H,UAAW,iBACjC+H,qBAAsB,CAAE/H,UAAW,mBACnCgI,oBAAqB,CAAEhI,UAAW,qBAClCiI,kBAAmB,CAAEjI,UAAW,sBAChCkI,mCAAoC,CAAElI,UAAW,mCACjDmI,oCAAqC,CAAEnI,UAAW,qCAClDoI,cAAe,CAAEpI,UAAW,gBAC5BqI,oBAAqB,CAAErI,UAAW,sBAClCsI,iBAAkB,CAAEtI,UAAW,mBAC/BuI,sBAAuB,CAAEvI,UAAW,uBACpCwI,2BAA4B,CAAExI,UAAW,uBACzCyI,4BAA6B,CAAEzI,UAAW,8BAE9C,GAAIjjC,EAAMy8B,KAAK36B,SAAS,WACpB,MAAO,CAAC,uKAADhG,OAKcojC,GAAqBl/B,EAAMK,IAAG,oQAUvD,GAAIL,EAAMy8B,KAAK36B,SAAS,kBACpB,MAAO,CAAC,oVAYZ,IAAK,MAAMkhC,KAAOhjC,EAAMy8B,KACpB,GAAIuG,KAAOj9B,EAAS,CAChB,MAAM,UAAEk9B,GAAcl9B,EAAQi9B,GAC9B,MAAO,CAAC,oIAADlnC,OAIKmnC,EAAS,cAAAnnC,OACvBmnC,EAAS,iBAAAnnC,OAAgBojC,GAAqBl/B,EAAMK,IAAG,6MAOzD,CAEJ,MAAO,CAAC,gLC1NJoC,QAAQ,EACRmhC,eAAgB,8DAEpB+H,KAAM,CACFlI,YAAa,OACbC,SAAU,OACVC,QAAS,sCACTG,SD4sBa9jC,IAAU,IAAA4rC,EAAAC,EAC3B,MAAQC,wBAAyBC,EAAeC,UAAWC,GAAmC,QAArBL,EAAe,QAAfC,EAAG7rC,EAAMuiC,cAAM,IAAAsJ,OAAA,EAAZA,EAAcF,YAAI,IAAAC,EAAAA,EAAI,CAAC,EAC7FM,EAhBQD,KACd,OAAQA,GACJ,IAAK,YACD,MAAO,WACX,IAAK,eACD,MAAO,YACX,IAAK,YACD,MAAO,sBACX,IAAK,UACD,MAAO,yBACX,QACI,SAKSE,CAASF,GAC1B,OAAKC,EAGAH,EAGE,CAAC,oEAADjwC,OAE4BowC,EAAQ,iCAAApwC,OAEpBowC,EAAQ,sBAAApwC,OAAqBiwC,EAAa,uDAAAjwC,OACpBkE,EAAMK,GAAE,OAP1C,CAAC,4BAHD,CAAC,0BC/sBRoC,QAAQ,EACRmhC,eAAgB,8BAEpB,qBAAsB,CAClBH,YAAa,oBACbC,SAAU,mBACVC,QAAS,wDACTlhC,QAAQ,EACRqhC,SD+M2B9jC,IAC/B,MAAMosC,EAAa,4GAAHtwC,OAGWkE,EAAMK,GAAE,uBAC7BgsC,EAAiB,4HAAHvwC,OAGoBkE,EAAMK,GAAE,uBAChD,OAAIL,EAAMK,GAAGyB,SAAS,QACX,CAACsqC,EAAYC,GAGb,CAACA,IC3NRzI,eAAgB,uBAEpB,cAAe,CACXH,YAAa,UACbC,SAAU,UACVC,QAAS,2CACTG,SDwNoB9jC,GAAU,CAAC,iIAADlE,OAIAkE,EAAMK,GAAE,4LC3NtCoC,QAAQ,EACRmhC,eAAgB,wBAEpB,WAAY,CACRH,YAAa,WACbC,SAAU,WACVC,QAAS,mCACTG,SDq/Bc9jC,IAClB,IAAI8jC,EAEAA,EADA9jC,EAAMy8B,KAAK36B,SAAS,aACTohC,GAAgBljC,GAEtBA,EAAMy8B,KAAK36B,SAAS,gBACdshC,GAAmBpjC,GAGnBsjC,GAActjC,GAS7B,OADA8jC,EAAWA,EAASzhC,IANY8gC,GACvB,iCAAiCj8B,KAAKi8B,GAGpCA,EAFI,iCAAPrnC,OAAwCqnC,IAK5CnjC,EAAMy8B,KAAK36B,SAAS,gBACbgiC,EAASzhC,IAAK8gC,GAAYA,EAAQxjC,QAAQ,aAAc,aAAaA,QAAQ,kBAAmB,kBAEpGmkC,GCzgCHD,QAAS,yBAEbyI,KAAM,CACF7I,YAAa,OACbC,SAAU,OACVC,QAAS,mCACTG,SD2kCa9jC,GAAU,CAAC,oEAADlE,OAGMkE,EAAMK,GAAE,OC7kCrCoC,QAAQ,GAEZ,iBAAkB,CACdghC,YAAa,iBACbC,SAAU,iBACVC,QAAS,6CACTG,SD2OuB9jC,GACvBA,EAAMy8B,KAAK36B,SAAS,2BA/BY9B,IAAU,CAAC,iFAADlE,OAGXkE,EAAMK,GAAE,kUA6BhCksC,CAAwBvsC,GAhBTA,IAAU,CAAC,iFAADlE,OAGPkE,EAAMK,GAAE,yOAe9BmsC,CAAqBxsC,GC9OxByC,QAAQ,GAEZ,UAAW,CACPghC,YAAa,UACbC,SAAU,UACVC,QAAS,sCACTE,QAAS,uBACTphC,QAAQ,GAEZgqC,OAAQ,CACJhJ,YAAa,SACbC,SAAU,SACVC,QAAS,mDACTG,SD2jCe9jC,GAAU,CAAC,8EAADlE,OAGKkE,EAAMK,GAAE,OC7jCtCoC,QAAQ,GAEZiqC,YAAa,CACTjJ,YAAa,cACbC,SAAU,cACVC,QAAS,6CACTlhC,QAAQ,EACRmhC,eAAgB,6BAEpB+I,eAAgB,CACZlJ,YAAa,iBACbC,SAAU,iBACVC,QAAS,oDACTlhC,QAAQ,EACRmhC,eAAgB,0BAEpBgJ,MAAO,CACHnJ,YAAa,QACbC,SAAU,QACVC,QAAS,uCACTG,SD8Mc9jC,GAAU,CAAC,8DAADlE,OAGCkE,EAAMK,GAAE,OChNjCoC,QAAQ,GAEZoqC,SAAU,CACNpJ,YAAa,WACbC,SAAU,WACVC,QAAS,2CACTE,QAAS,qBACTphC,QAAQ,EACRmhC,eAAgB,4BAEpBkJ,aAAc,CACVrJ,YAAa,eACbC,SAAU,eACVC,QAAS,4CACTG,SDoMqB9jC,GAAU,CAAC,iLAADlE,OAIqBkE,EAAMK,GAAE,OCvM5DoC,QAAQ,GAEZsqC,OAAQ,CACJtJ,YAAa,SACbC,SAAU,SACVC,QAAS,sCACTlhC,QAAQ,GAEZuqC,MAAO,CACHvJ,YAAa,QACbC,SAAU,QACVC,QAAS,yCACTC,eAAgB,0BAEpBqJ,QAAS,CACLxJ,YAAa,UACbC,SAAU,UACVC,QAAS,uCACTG,SDyNemJ,IAA6B,CAAC,8VCxN7CxqC,QAAQ,GAEZyqC,KAAM,CACFzJ,YAAa,OACbC,SAAU,OACVC,QAAS,yDACTlhC,QAAQ,EACRqhC,SDoUa9jC,GAyBV,CAxBiB,oJAAHlE,OAIwBkE,EAAMK,GAAE,gLAK7B,sJAAHvE,OAIwBkE,EAAMK,GAAE,gcCjVjDujC,eAAgB,uBAEpB,cAAe,CACXH,YAAa,cACbC,SAAU,cACVC,QAAS,kDACTlhC,QAAQ,EACRqhC,SDmWoB9jC,GAAU,CAAC,iFAADlE,OAGNkE,EAAMK,GAAE,2HCrWhCujC,eAAgB,4BAEpB,iBAAkB,CACdH,YAAa,iBACbC,SAAU,iBACVC,QAAS,qDACTlhC,QAAQ,EACRqhC,SD+UuB9jC,GAAU,CAAC,yIAADlE,OAIfkE,EAAMK,GAAE,yMClV1BujC,eAAgB,oCAEpBuJ,KAAM,CACF1J,YAAa,OACbC,SAAU,OACVC,QAAS,qCACTlhC,QAAQ,EACRmhC,eAAgB,mEAEpB,iBAAkB,CACdH,YAAa,iBACbC,SAAU,iBACVC,QAAS,kDACTE,QAAS,iDACTC,SDmVsB9jC,GAAU,CAAC,yDAADlE,OACqBkE,EAAMK,GAAE,oBCnV7DoC,QAAQ,EACRmhC,eAAgB,mBAEpB,gBAAiB,CACbH,YAAa,gBACbC,SAAU,gBACVC,QAAS,+CACTC,eAAgB,sBAChBE,SDz3BuBsJ,IAgDpB,CA/CgB,+DACO,+wBAqBH,wxBCo2B3BC,QAAS,CACL5J,YAAa,UACbC,SAAU,UACVC,QAAS,8CACTlhC,QAAQ,EACRmhC,eAAgB,yEAEpB0J,OAAQ,CACJ7J,YAAa,SACbC,SAAU,SACVC,QAAS,2CACTlhC,QAAQ,EACRmhC,eAAgB,wBAEpB,eAAgB,CACZH,YAAa,cACbC,SAAU,cACVC,QAAS,4CACTlhC,QAAQ,EACRmhC,eAAgB,uBAEpB,wBAAyB,CACrBH,YAAa,wBACbC,SAAU,wBACVC,QAAS,kDACTE,QAAS,wDACTC,SDuT6B9jC,IAAU,IAAAutC,EAC3C,MAAMxL,EAAsB/hC,EAAMy8B,KAAK36B,SAASm9B,IAAmB,2BAA6B,GAChG,GAAIj/B,EAAMy8B,KAAK36B,SAAS,UACpB,MAAO,CAAC,qVAADhG,OAa8BkE,EAAMK,GAAE,iHAMjD,GAAIL,EAAMy8B,KAAK36B,SAAS,kBAA0C,gBAAtB9B,EAAM08B,aAC9C,MAAO,CAAC,2EAAD5gC,OAGSkE,EAAMK,GAAE,KAAAvE,OAAIimC,EAAmB,2eAcnD,MAAMyL,EAA2D,QAA3CD,EA9C1B,SAA2CvtC,GAAO,IAAAytC,EAAAC,EAC9C,MAAMC,EAAgC,QAAnBF,EAAGztC,EAAM6/B,kBAAU,IAAA4N,OAAA,EAAhBA,EAAmB,GACzC,GAAiB,OAAbE,QAAa,IAAbA,GAAAA,EAAe3U,iBAAgC,OAAb2U,QAAa,IAAbA,GAAwB,QAAXD,EAAbC,EAAe1U,iBAAS,IAAAyU,GAAxBA,EAA0B5uC,OAC5D,MAAO,CAAC6uC,EAAc3U,mBAAoB2U,EAAc1U,UAEhE,CAyC6B2U,CAAkC5tC,UAAM,IAAAutC,EAAAA,EAAI,CACjE,+BACA,yBACA,4BAEJ,MAAO,CAAC,yFAADzxC,OAGoBkE,EAAMK,GAAE,KAAAvE,OAAIimC,EAAmB,qBAAAjmC,OAEhDuD,KAAKC,UAAUkuC,EAAkB,KAAM,GAAE,qIAAA1xC,OAKlD0xC,EAAiB1uC,OAAM,MAAAhD,OAAK0xC,EAAiB1uC,OAAM,OC7WhD2D,QAAQ,GAEZorC,OAAQ,CACJpK,YAAa,SACbC,SAAU,SACVC,QAAS,wCACTE,QAAS,yCACTC,SDyWe9jC,GAAU,CAAC,0EAADlE,OAGMkE,EAAMK,GAAE,OC3WvCoC,QAAQ,GAEZqrC,QAAS,CACLrK,YAAa,eACbC,SAAU,eACVC,QAAS,+CACTG,SDsLgB9jC,IACpB,GAAIA,EAAMy8B,KAAK36B,SAAS,SAAU,KAAAisC,EAAAC,EAC9B,MAAMC,EAA6B,QAAfF,EAAG/tC,EAAMuiC,cAAM,IAAAwL,GAAS,QAATA,EAAZA,EAAcD,eAAO,IAAAC,GAAO,QAAPA,EAArBA,EAAuB/tC,aAAK,IAAA+tC,OAAA,EAA5BA,EAA8BG,KAC/CC,EAA8B,QAAfH,EAAGhuC,EAAMuiC,cAAM,IAAAyL,GAAS,QAATA,EAAZA,EAAcF,eAAO,IAAAE,OAAA,EAArBA,EAAuBI,aAC/C,OAAKH,EAGmB,WAApBE,EAxCQE,EAACruC,EAAOsuC,IACjB,CAAC,kEAADxyC,OAGCkE,EAAMK,GAAE,mDAAAvE,OAEhBwyC,EAAS,6IAmCMD,CAAYruC,EAAOiuC,GA7BlBM,EAACvuC,EAAOsuC,IACjB,CAAC,8EAADxyC,OAGCkE,EAAMK,GAAE,wKAAAvE,OAGWwyC,EAAS,OAyBrBC,CAAYvuC,EAAOiuC,GANnB,CAAC,6DAQhB,CAEI,MA1BajuC,IACV,CAAC,wGAADlE,OAISkE,EAAMK,GAAE,sKAqBbmuC,CAAYxuC,ICpMnByC,QAAQ,EACRmhC,eAAgB,+BAEpB6K,MAAO,CACHhL,YAAa,QACbC,SAAU,QACVC,QAAS,qCACTE,QAAS,wCACTC,SD8Vc9jC,GAAU,CAAC,uCAADlE,OACWkE,EAAMK,GAAE,kBAAAvE,OAAiBojC,GAAqBl/B,EAAMK,IAAG,oFAAAvE,OAI9EojC,GAAqBl/B,EAAMK,IAAG,yCAAAvE,OAGzCojC,GAAqBl/B,EAAMK,IAAG,YAAAvE,OAC/BojC,GAAqBl/B,EAAMK,IAAG,YCtW9BoC,QAAQ,EACRmhC,eAAgB,wBAEpB,cAAe,CACXH,YAAa,aACbC,SAAU,gBACVC,QAAS,6CACTE,QAAS,8CACTC,SDgWoB9jC,GAAU,CAAC,uFAADlE,OAGKkE,EAAMK,GAAE,OClW3CoC,QAAQ,GAEZisC,YAAa,CACTjL,YAAa,cACbC,SAAU,cACVC,QAAS,6CACTE,QAAS,8CACTC,SDkXoB9jC,IAAU,IAAA2uC,EAClC,MAAMC,EAAmC,QAAfD,EAAG3uC,EAAMuiC,cAAM,IAAAoM,GAAa,QAAbA,EAAZA,EAAcD,mBAAW,IAAAC,OAAA,EAAzBA,EAA2BE,sBACxD,QAA6B5wC,IAAzB2wC,EACA,MAAO,CAAC,4CAEZ,MAAME,EApBiBF,KACvB,OAAQA,GACJ,IAAK,oBACD,MAAO,gBACX,IAAK,oBACL,IAAK,aACD,MAAO,kBACX,IAAK,0BACD,MAAO,eACX,IAAK,sBACD,MAAO,gBACX,QACI,SAQkBG,CAAkBH,GAC5C,YAA0B3wC,IAAtB6wC,EACO,CAAC,sCAEL,CAAC,sCAADhzC,OACmC8yC,EAAoB,cAAA9yC,OACxD8yC,EAAoB,uBAAA9yC,OACzBkE,EAAMK,GAAE,gBAAAvE,OAELgzC,EAAiB,kBC/XjBrsC,QAAQ,EACRmhC,eAAgB,2BAEpB,aAAc,CACVH,YAAa,aACbC,SAAU,aACVC,QAAS,8CACTlhC,QAAQ,EACRmhC,eAAgB,yBAEpB,qBAAsB,CAClBH,YAAa,qBACbC,SAAU,qBACVC,QAAS,yDACTlhC,QAAQ,EACRmhC,eAAgB,2BAChBE,SD6J2B9jC,GAAU,CAAC,+TAADlE,OAUCkE,EAAMK,GAAE,ksBCrKlD2uC,UAAW,CACPvL,YAAa,YACbC,SAAU,YACVC,QAAS,2CACTlhC,QAAQ,EACRmhC,eAAgB,kCAEpB,wBAAyB,CACrBH,YAAa,wBACbC,SAAU,wBACVC,QAAS,4CACTlhC,QAAQ,EACRmhC,eAAgB,gCAEpB,aAAc,CACVH,YAAa,aACbC,SAAU,aACVC,QAAS,2CACTlhC,QAAQ,EACRmhC,eAAgB,+CAChBE,SDsEkBmL,IAAM,CAAC,kjBCpE7BC,UAAW,CACPzL,YAAa,YACbC,SAAU,YACVC,QAAS,6CACTlhC,QAAQ,EACRmhC,eAAgB,0BAEpBuL,UAAW,CACP1L,YAAa,YACbC,SAAU,YACVC,QAAS,4CACTlhC,QAAQ,EACRmhC,eAAgB,uBAEpB,oBAAqB,CACjBH,YAAa,oBACbC,SAAU,oBACVC,QAAS,iDACTE,QAAS,oDACTC,SDucyB9jC,GAAU,CAAC,sFAADlE,OAG/BkE,EAAMK,GAAE,8CCzcZoC,QAAQ,EACRmhC,eAAgB,wBAEpBwL,OAAQ,CACJ3L,YAAa,SACbC,SAAU,SACVC,QAAS,wCACTE,QAAS,yCACTC,SDwRe9jC,GAAU,CAAC,qCAADlE,OAGdojC,GAAqBl/B,EAAMK,IAAIV,QAAQ,UAAW,IAAG,+BAAA7D,OAC/CojC,GAAqBl/B,EAAMK,IAAIV,QAAQ,UAAW,IAAG,OC3RtE8C,QAAQ,EACRmhC,eAAgB,6BAEpByL,WAAY,CACR5L,YAAa,aACbC,SAAU,aACVC,QAAS,8CACTG,SD6mBkBuL,IAAM,CAAC,gTC5mBzB5sC,QAAQ,GAEZ6sC,YAAa,CACT7L,YAAa,cACbC,SAAU,cACVC,QAAS,2CACTG,SDknBoB9jC,GAAU,CAAC,yFAADlE,OAGMkE,EAAMK,GAAE,SCpnB5CoC,QAAQ,GAEZ,SAAU,CACNghC,YAAa,SACbC,SAAU,SACVC,QAAS,mCACTlhC,QAAQ,EACRmhC,eAAgB,uDAEpB2L,MAAO,CACH9L,YAAa,QACbC,SAAU,QACVC,QAAS,oCACTlhC,QAAQ,EACRmhC,eAAgB,yBAEpB,0BAA2B,CACvBH,YAAa,iBACbC,SAAU,iBACVC,QAAS,kDACTlhC,QAAQ,EACRmhC,eAAgB,4CAEpB4L,cAAe,CACX/L,YAAa,gBACbC,SAAU,gBACVC,QAAS,gDACTG,SD1BsB9jC,GACtBA,EAAMy8B,KAAK36B,SAAS,eArBI9B,IAAU,CAAC,iHAADlE,OAGGkE,EAAMK,GAAE,6CAAAvE,OACdkE,EAAMK,GAAE,SAkBhCovC,CAAuBzvC,GAEzBA,EAAMy8B,KAAK36B,SAAS,cAjBF9B,IAAU,CAAC,4FAADlE,OAGFkE,EAAMK,GAAE,yCAehCqvC,CAAsB1vC,GAXPA,IAAU,CAAC,4FAADlE,OAGDkE,EAAMK,GAAE,SAUpCsvC,CAAqB3vC,ICqB5B4vC,SAAU,CACNnM,YAAa,WACbC,SAAU,WACVC,QAAS,qCACTC,eAAgB,yBAEpBiM,OAAQ,CACJpM,YAAa,SACbC,SAAU,SACVC,QAAS,uCAEbmM,WAAY,CACRrM,YAAa,aACbC,SAAU,aACVC,QAAS,oCACTE,QAAS,oCACTphC,QAAQ,EACRmhC,eAAgB,+CAChBE,SD+PmB9jC,GAAU,CAAC,yFAADlE,OAGFkE,EAAMK,GAAE,QChQvC,WAAY,CACRojC,YAAa,WACbC,SAAU,WACVC,QAAS,uCACTlhC,QAAQ,EACRmhC,eAAgB,sDAEpBmM,QAAS,CACLtM,YAAa,UACbC,SAAU,UACVC,QAAS,6CACTlhC,QAAQ,EACRmhC,eAAgB,6IAEpBoM,KAAM,CACFvM,YAAa,OACbC,SAAU,uBACVC,QAAS,oDACTE,QAAS,uCACTC,SD1Da9jC,GAAU,CAAC,oDAADlE,OAGKkE,EAAMK,GAAE,wBCwDpCoC,QAAQ,EACRmhC,eAAgB,wDAEpBqM,MAAO,CACHxM,YAAa,QACbC,SAAU,QACVC,QAAS,iCACTC,eAAgB,yBAEpBsM,SAAU,CACNzM,YAAa,WACbC,SAAU,WACVC,QAAS,wCACTE,QAAS,mCACTphC,QAAQ,EACRmhC,eAAgB,+CAEpBhC,aAAc,CACV6B,YAAa,eACbC,SAAU,4BACVC,QAAS,8CACTE,QAAS,+CACTC,SAAUA,GACVrhC,QAAQ,GAEZ,kBAAmB,CACfghC,YAAa,kBACbC,SAAU,kBACVC,QAAS,iDACTE,QAAS,kDACTC,SDyRuB9jC,IAC3B,IAAKA,EAAM08B,aACP,MAAO,CAAC,wCAEZ,MAAMyT,EAAU,4BAChB,MAAO,CAAC,YAADr0C,OACSq0C,EAAO,gCAAAr0C,OACCq0C,EAAO,6DAAAr0C,OAGJkE,EAAM08B,aAAY,QAAA5gC,OAAOkE,EAAMK,GAAE,SClSxDoC,QAAQ,GAEZ2tC,QAAS,CACL3M,YAAa,UACbC,SAAU,UACVC,QAAS,uCACTC,eAAgB,gCAEpBd,YAAa,CACTW,YAAa,cACbC,SAAU,cACVC,QAAS,6CACTE,QAAS,6CACTphC,QAAQ,EACRmhC,eAAgB,sBAChBE,SAAUA,IAEduM,MAAO,CACH5M,YAAa,QACbC,SAAU,QACVC,QAAS,+CACTG,SD8fc9jC,GAAU,CAAC,yQAADlE,OAKrBkE,EAAMK,GAAE,8JAAAvE,OAI2BkE,EAAMK,GAAE,SCtgB9CoC,QAAQ,EACRmhC,eAAgB,sBAEpB,WAAY,CACRH,YAAa,WACbC,SAAU,WACVC,QAAS,0CACTE,QAAS,0CACTD,eAAgB,uBAEpB,eAAgB,CACZH,YAAa,eACbC,SAAU,eACVC,QAAS,uDACTG,SD6TcwM,IAA6B,CAAC,2QC5T5C7tC,QAAQ,EACRmhC,eAAgB,2BAEpB2M,KAAM,CACF9M,YAAa,OACbC,SAAU,OACVC,QAAS,iCACTC,eAAgB,uBAChBE,SD2Ta9jC,GAAU,CAAC,6PAADlE,OAQFkE,EAAMK,GAAE,sNCjUjCmwC,WAAY,CACR/M,YAAa,aACbC,SAAU,aACVC,QAAS,gDACTC,eAAgB,uBAChBE,SD6VmB9jC,GAAU,CAAC,+IAADlE,OAKRkE,EAAMK,GAAE,mDAAAvE,OACQkE,EAAMK,GAAE,wHCjWjD,YAAa,CACTojC,YAAa,WACbC,SAAU,WACVC,QAAS,sCACTC,eAAgB,uBAChBE,SDkWiB9jC,GAAU,CAAC,wEAADlE,OAGFkE,EAAMK,GAAE,QCnWrCowC,OAAQ,CACJhN,YAAa,SACbC,SAAU,SACVC,QAAS,sCACTC,eAAgB,+CAChBE,SDgWe9jC,GAAU,CAAC,oIAADlE,OAIDkE,EAAMK,GAAE,sNClWpCqwC,WAAY,CACRjN,YAAa,aACbC,SAAU,aACVC,QAAS,yCACTE,QAAS,yCACTC,SDkWmB9jC,GAAU,CAAC,4EAADlE,OAGCkE,EAAMK,GAAE,QCnW1CswC,OAAQ,CACJlN,YAAa,SACbC,SAAU,SACVC,QAAS,oCACTG,SDiWe9jC,GAAU,CAAC,wFAADlE,OAICkE,EAAMK,GAAE,s/BCpWlCoC,QAAQ,GAEZmuC,IAAK,CACDnN,YAAa,MACbC,SAAU,MACVC,QAAS,gCACTC,eAAgB,sBAChBE,SD+WW8M,IAAM,CAAC,qaC7WtBC,UAAW,CACPpN,YAAa,YACbC,SAAU,YACVC,QAAS,yCACTG,SD8RkB9jC,GAAU,CAAC,meAADlE,OAUckE,EAAMK,GAAE,kFAAAvE,OAEnDkE,EAAMK,GAAE,6ZCzSPoC,QAAQ,GAEZquC,WAAY,CACRrN,YAAa,aACbC,SAAU,aACVC,QAAS,0CACTlhC,QAAQ,EACRmhC,eAAgB,gCAEpB,SAAU,CACNH,YAAa,SACbC,SAAU,SACVC,QAAS,sCACTC,eAAgB,oDAEpBmN,KAAM,CACFtN,YAAa,OACbC,SAAU,OACVC,QAAS,wCACTE,QAAS,4DACTD,eAAgB,yBAEpBoN,WAAY,CACRvN,YAAa,aACbC,SAAU,aACVC,QAAS,0CACTE,QAAS,sEACTC,SDgpBkBkN,IAAM,CAAC,uaC/oBzBpN,eAAgB,6EAEpBqN,QAAS,CAELxN,YAAa,UACbC,SAAU,UACVC,QAAS,qCACTE,QAAS,qCACTD,eAAgB,sDAChBE,SAAUA,IAEdoN,MAAO,CACHzN,YAAa,QACbC,SAAU,QACVC,QAAS,kCACTE,QAAS,kCACTC,SDupBc9jC,GAAU,CAAC,4LAADlE,OAMCkE,EAAMK,GAAE,8ZC5pBjCoC,QAAQ,GAEZ,aAAc,CACVghC,YAAa,aACbC,SAAU,aACVC,QAAS,wCACTlhC,QAAQ,EACRmhC,eAAgB,2BAChBE,SDmoBuB9jC,GAAU,CAAC,+FAADlE,OAGCkE,EAAMK,GAAE,mDCnoBZ8B,OAAOK,KAAK+gC,IACJphC,OAAO0D,QAAQ09B,IAExD9gC,OAAOqD,IAAA,IAAEqrC,EAAGtvC,GAAEiE,EAAA,OAAKjE,EAAEY,SACrBJ,IAAIuoB,IAAA,IAAE3Y,GAAE2Y,EAAA,OAAK3Y,ICn5CX,IAAIm/B,IACX,SAAWA,GACPA,EAAyBA,EAA8B,IAAI,GAAK,MAChEA,EAAyBA,EAA8B,IAAI,GAAK,MAChEA,EAAyBA,EAA+B,KAAI,GAAK,OACjEA,EAAyBA,EAA+B,KAAI,GAAK,OACjEA,EAAyBA,EAAwC,cAAI,GAAK,gBAC1EA,EAAyBA,EAA+B,KAAI,GAAK,OACjEA,EAAyBA,EAA+B,KAAI,GAAK,OACjEA,EAAyBA,EAA+B,KAAI,GAAK,OACjEA,EAAyBA,EAA+B,KAAI,GAAK,OACjEA,EAAyBA,EAA+B,KAAI,GAAK,OACjEA,EAAyBA,EAA+B,KAAI,IAAM,OAClEA,EAAyBA,EAAiC,OAAI,IAAM,SACpEA,EAAyBA,EAAiC,OAAI,IAAM,SACpEA,EAAyBA,EAAiC,OAAI,IAAM,SACpEA,EAAyBA,EAAiC,OAAI,IAAM,SACpEA,EAAyBA,EAAiC,OAAI,IAAM,SACpEA,EAAyBA,EAAiC,OAAI,IAAM,SACpEA,EAAyBA,EAAiC,OAAI,IAAM,SACpEA,EAAyBA,EAA+B,KAAI,IAAM,OAClEA,EAAyBA,EAAkC,QAAI,IAAM,UACrEA,EAAyBA,EAAiC,OAAI,IAAM,SACpEA,EAAyBA,EAAiC,OAAI,IAAM,SACpEA,EAAyBA,EAAiC,OAAI,IAAM,SACpEA,EAAyBA,EAAkC,QAAI,IAAM,UACrEA,EAAyBA,EAAgC,MAAI,IAAM,QACnEA,EAAyBA,EAAiC,OAAI,IAAM,SACpEA,EAAyBA,EAAgC,MAAI,IAAM,QACnEA,EAAyBA,EAAgC,MAAI,IAAM,QACnEA,EAAyBA,EAAgC,MAAI,IAAM,QACnEA,EAAyBA,EAAgC,MAAI,IAAM,QACnEA,EAAyBA,EAAiC,OAAI,IAAM,SACpEA,EAAyBA,EAAgC,MAAI,IAAM,QACnEA,EAAyBA,EAA+B,KAAI,IAAM,OAClEA,EAAyBA,EAAmC,SAAI,IAAM,WACtEA,EAAyBA,EAAmC,SAAI,IAAM,WACtEA,EAAyBA,EAAmC,SAAI,IAAM,WACtEA,EAAyBA,EAAgC,MAAI,IAAM,QACnEA,EAAyBA,EAAgC,MAAI,IAAM,QACnEA,EAAyBA,EAAoC,UAAI,IAAM,YAGvEA,EAAyBA,EAAkC,QAAI,KAAQ,UACvEA,EAAyBA,EAAkC,QAAI,MAAQ,UACvEA,EAAyBA,EAAkC,QAAI,MAAQ,UACvEA,EAAyBA,EAAkC,QAAI,MAAQ,UACvEA,EAAyBA,EAAkC,QAAI,MAAQ,UACvEA,EAAyBA,EAAkC,QAAI,MAAQ,SAC1E,CAhDD,CAgDGA,KAA6BA,GAA2B,CAAC,IAC5D,MAAMC,GAAalvC,OAAO+jB,OAAOkrB,IAA0B3uC,OAAQZ,GAAmB,kBAANA,GACnEyvC,GAAgB,IAAIvnB,OAAO,YAAAjuB,OAAYu1C,GAAW1vC,KAAK,KAAI,KAAM,gCAC1C,IAAIooB,OAAOunB,GAAe,KAS1DF,GAAyBG,IACzBH,GAAyBI,KACzBJ,GAAyBK,IACzBL,GAAyBM,QACzBN,GAAyBO,KAEzBP,GAAyBQ,QACzBR,GAAyBS,KAEzBT,GAAyBU,QACzBV,GAAyBW,OACzBX,GAAyBY,OACzBZ,GAAyBa,KACzBb,GAAyBc,KAEzBd,GAAyBe,QACzBf,GAAyBgB,OACzBhB,GAAyBiB,OACzBjB,GAAyBkB,OACzBlB,GAAyBmB,OACzBnB,GAAyBoB,SACzBpB,GAAyBqB,SACzBrB,GAAyBsB,SACzBtB,GAAyBuB,cACzBvB,GAAyBwB,KACzBxB,GAAyByB,KACzBzB,GAAyB0B,KACzB1B,GAAyB2B,KACzB3B,GAAyB4B,UAEzB5B,GAAyB6B,QACzB7B,GAAyB8B,OACzB9B,GAAyB+B,OACzB/B,GAAyBgC,OACzBhC,GAAyBiC,MACzBjC,GAAyBkC,MACzBlC,GAAyBmC,OACzBnC,GAAyBoC,QAEzBpC,GAAyBqC,QACzBrC,GAAyBsC,KACzBtC,GAAyBuC,OACzBvC,GAAyBwC,MACzBxC,GAAyByC,MACzBzC,GAAyB0C,OACzB1C,GAAyB2C,QAEzB3C,GAAyB4C,MACzB5C,GAAyB6C,MACzB7C,GAAyB8C,MACzB9C,GAAyB+C,MAoCtB,IAAIC,IACX,SAAWA,GACPA,EAAqBA,EAA0B,IAAI,GAAK,MACxDA,EAAqBA,EAA0B,IAAI,GAAK,MACxDA,EAAqBA,EAA2B,KAAI,GAAK,OACzDA,EAAqBA,EAA2B,KAAI,GAAK,OACzDA,EAAqBA,EAA2B,KAAI,GAAK,OACzDA,EAAqBA,EAA2B,KAAI,GAAK,OACzDA,EAAqBA,EAA2B,KAAI,GAAK,OACzDA,EAAqBA,EAA2B,KAAI,GAAK,OACzDA,EAAqBA,EAA2B,KAAI,IAAM,OAC1DA,EAAqBA,EAA2B,KAAI,IAAM,OAC1DA,EAAqBA,EAA2B,KAAI,IAAM,OAC1DA,EAAqBA,EAA2B,KAAI,IAAM,OAC1DA,EAAqBA,EAA2B,KAAI,IAAM,OAC1DA,EAAqBA,EAA2B,KAAI,IAAM,OAC1DA,EAAqBA,EAA8B,QAAI,IAAM,UAC7DA,EAAqBA,EAA6B,OAAI,IAAM,SAC5DA,EAAqBA,EAA8B,QAAI,IAAM,UAC7DA,EAAqBA,EAA4B,MAAI,IAAM,QAC3DA,EAAqBA,EAA6B,OAAI,IAAM,SAC5DA,EAAqBA,EAA4B,MAAI,IAAM,QAC3DA,EAAqBA,EAA4B,MAAI,IAAM,QAC3DA,EAAqBA,EAA6B,OAAI,IAAM,SAC5DA,EAAqBA,EAAyB,GAAI,IAAM,KACxDA,EAAqBA,EAA0B,IAAI,IAAM,MACzDA,EAAqBA,EAA0B,IAAI,IAAM,MACzDA,EAAqBA,EAA0B,IAAI,IAAM,MACzDA,EAAqBA,EAA0B,IAAI,IAAM,MACzDA,EAAqBA,EAA4B,MAAI,IAAM,QAC3DA,EAAqBA,EAA2B,KAAI,IAAM,OAC1DA,EAAqBA,EAA4B,MAAI,IAAM,QAC3DA,EAAqBA,EAA4B,MAAI,IAAM,QAC3DA,EAAqBA,EAA4B,MAAI,IAAM,OAC9D,CAjCD,CAiCGA,KAAyBA,GAAuB,CAAC,ICvL7C,MAAMC,GAA4B,CAAC,SAAU,KAAM,MCqC1D,MCrCaC,GAAY,CACrB,GAAM,CACF,MAAS,CACL,MAAS,miBACT,WAAc,6hBACd,WAAc,6hBACd,eAAkB,whBAClB,aAAgB,wvBAChB,aAAgB,gsBAChB,YAAe,wmCACf,YAAe,igBACf,aAAgB,olCAChB,uBAA0B,kqBAE9B,iBAAkB,CACd,MAAS,6aACT,WAAc,0cACd,WAAc,0cACd,eAAkB,6hBAClB,qBAAwB,olBACxB,aAAgB,8mBAChB,aAAgB,+mBAChB,YAAe,4eACf,aAAgB,icAChB,YAAe,icAEnB,OAAU,CACN,eAAkB,sZAClB,qBAAwB,ieAGhC,OAAU,CACN,WAAc,CACV,aAAgB,4oBAChB,aAAgB,koBAChB,YAAe,ghBAEnB,gBAAmB,CACf,MAAS,oGACT,WAAc,sFACd,WAAc,sFACd,eAAkB,0OAClB,qBAAwB,6MACxB,0BAA6B,8JAC7B,aAAgB,4QAChB,aAAgB,6OAChB,sBAAyB,8UACzB,kBAAqB,+JACrB,uBAA0B,yJAC1B,YAAe,iIACf,aAAgB,kIAChB,YAAe,kGAEnB,OAAU,CACN,eAAkB,qXAClB,qBAAwB,saAE5B,SAAY,CACR,MAAS,mMACT,WAAc,2QACd,WAAc,2QACd,eAAkB,6NAClB,qBAAwB,igBACxB,0BAA6B,mZAC7B,aAAgB,6cAChB,aAAgB,8TAChB,eAAkB,sRAClB,QAAW,gOACX,YAAe,ssBACf,YAAe,kYACf,aAAgB,ksBAChB,uBAA0B,wQAC1B,4BAA+B,ycAGvC,GAAM,CACF,KAAQ,CACJ,MAAS,sQACT,WAAc,gQACd,WAAc,gQACd,eAAkB,8QAClB,qBAAwB,6QACxB,uBAA0B,mVCzEhCC,GAAU,CACZC,GAAI,CAHY,SAAU,iBAAkB,SAI5CC,OAAQ,CALY,SAAU,kBAAmB,aAAc,YAM/DC,GAAI,CAJY,SAQdC,GAAyC,CAC3CH,GAAI,CAAC,kBACLC,OAAQ,CAAC,oBAIPG,GAAeA,CAACC,EAAUC,EAAQC,KAAiB,IAAAC,EACrD,MAAMte,EAA8B,QAAtBse,EAAGV,GAAUO,UAAS,IAAAG,GAAU,QAAVA,EAAnBA,EAAsBF,UAAO,IAAAE,OAAA,EAA7BA,EAAgCD,GACjD,IAAKre,EACD,MAAM,IAAIx5B,MAAM,uBAADpB,OAAwB+4C,EAAQ,KAAA/4C,OAAIg5C,EAAM,KAAAh5C,OAAIi5C,IAEjE,OAAQ31C,GAAS,IAAIq3B,GAASC,GAAU2B,QAAMv6B,EAAAA,EAAAA,GAAC,CAAC,EAAIsB,KAElD61C,GAAqCL,GAAa,SAAU,kBAAmB,yBAC/EM,GAAwBN,GAAa,SAAU,WAAY,kBAE3DO,GAAoB,CACtB,uBAAwB,uBACxB,iBAAkB,iBAClB,+BAAgC,+BAChC,8BAA+B,8BAC/B,qBAAsB,qBACtB,YAAa,YACb,uBAAwB,uBACxB,qBAAsB,qBACtB,iBAAkB,iBAClB,iBAAkB,iBAClB,gBAAiB,gBACjB,sBAAuB,sBACvB,sBAAuB,sBACvB,mBAAoB,mBACpB,qBAAsB,qBACtB,sBAAuB,sBACvBlmC,cAAe,gBACf,2BAA4B,2BAC5B,yBAA0B,yBAC1B,qBAAsB,qBACtB,sBAAuB,sBACvB,kBAAmB,kBACnB,gBAAiB,gBACjB,iBAAkB,iBAClB,gBAAiB,gBACjB,uBAAwB,uBACxBF,YAAa,cACb,4BAA6B,4BAC7B,2BAA4B,2BAC5B,iCAAkC,kCAGhCqmC,GAAgB,CAClB,+BAAgC,6BAChC,qBAAsB,oBACtB,YAAa,WACb,uBAAwB,sBACxB,qBAAsB,oBACtB,sBAAuB,qBACvBnmC,cAAe,gBACf,2BAA4B,yBAC5B,sBAAuB,qBACvB,kBAAmB,iBACnB,uBAAwB,sBACxB,iBAAkB,eAClBF,YAAa,eAOXsmC,GAAmBA,CAACN,EAAcO,IAC7B,CAACt1C,EAAOtB,EAAU4F,EAA0Bu6B,KAAS,IAAA0W,EAAAC,EAAAC,EAAAC,EACxD,MAAMlvC,EAASzC,IACT4xC,EAAsD,QAAvCJ,EAA2B,OAAxBjxC,QAAwB,IAAxBA,OAAwB,EAAxBA,EAA0B2B,kBAAU,IAAAsvC,EAAAA,EAAIv1C,EAAMK,GAEtE,IAQI2T,EARAnR,EAAO7C,EAAM08B,aACb18B,EAAM08B,cACN,CAAC,kBAAmB,sBAAsB56B,SAAS9B,EAAM08B,eACzD18B,EAAMy8B,KAAK36B,SAAS,oBACpBizC,EAAmB,OAAJlW,QAAI,IAAJA,GAAAA,EAAM+W,UAAY,uBAAyB,iBAC1DN,EAAqBO,GACrBhzC,EAAO,kBAGX,IACImR,EAAiBpC,GAAkBlT,EAAUmE,EACjD,CACA,MAAOkP,GAEH,OADAvL,EAAOlB,MAAM,qCAADxJ,OAAsC4C,EAAQ,MAAA5C,OAAK+G,EAAI,KAAKkP,GACjE,EACX,CACA,MAAMupB,EAAkB,OAAJuD,QAAI,IAAJA,GAAAA,EAAMiX,cAvBc,2BADP,uBA2B3BC,EAA4C,QAApBP,EAAO,OAAJ3W,QAAI,IAAJA,OAAI,EAAJA,EAAM/+B,mBAAW,IAAA01C,EAAAA,EAAIla,EAEhDnyB,EAAa,OAAJ01B,QAAI,IAAJA,GAAAA,EAAM11B,OACf,CAAEA,OAAQ01B,EAAK11B,QACfmsC,EACIA,EAAmBt1C,EAAO6+B,GAC1B,CAAE11B,OAAQq1B,GAAqBx+B,IACnCsa,EAAUpG,GAAoCyhC,EAAiB3hC,GAAclW,EAAAA,EAAAA,GAAA,CAC/EgC,YAAai2C,EACbr3C,WACA6H,YAA8B,QAAnBkvC,EAAM,OAAJ5W,QAAI,IAAJA,OAAI,EAAJA,EAAMt4B,mBAAW,IAAAkvC,EAAAA,EAAkB,SAAb/2C,EAAsB7C,OAA0BoC,GAChFkL,GACJ7E,EAA0B,CACzBzB,OACAwS,OAAY,OAAJwpB,QAAI,IAAJA,OAAI,EAAJA,EAAMxpB,SAIlB,IAAI2gC,EAAiB7sC,EACrB,MAAM8sC,EAAY37B,EAAQ7E,KAAKrQ,KAC/B,GAAyB,kBAAd6wC,EACP,IACID,EAAiB32C,KAAKmX,MAAMy/B,EAChC,CACA,MAAOlkC,GACHvL,EAAOlB,MAAM,+BAAgCyM,EACjD,CAIJ,MAAMmkC,EAAkB,OAAJrX,QAAI,IAAJA,GAAAA,EAAMt4B,aAAoB,OAAJs4B,QAAI,IAAJA,GAAAA,EAAMiX,cAU1CE,EATa,SAAbt3C,GAAmBZ,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAEVqL,GAAM,IACTnJ,MAAO,GAAFlE,OAAKkE,EAAMK,GAAE,KAAAvE,OAAI4C,MAAUZ,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAG7BqL,GAAM,IACTnJ,MAAO,GAAFlE,OAAKkE,EAAMK,MAItBrB,EAAS,CACXc,YAAai2C,EACbI,oBAAyC,QAAtBT,EAAEp7B,EAAQ7E,KAAK1X,eAAO,IAAA23C,OAAA,EAApBA,EAAsB13C,cAC3CW,QAAkB,mBAATkE,GAAkC,OAAJg8B,QAAI,IAAJA,GAAAA,EAAMt4B,aAAoB,OAAJs4B,QAAI,IAAJA,GAAAA,EAAMiX,eAgNzDpsB,EA9MSpP,EAAQ3V,IA8MZyxC,EA9MiB,oBA+MjC1sB,EAAI5b,SAASsoC,GAAU1sB,EAAIhU,MAAM,GAAI0gC,EAAOt3C,QAAU4qB,GAhN/C7tB,EAENw6C,QAAkB,mBAATxzC,GAAkC,OAAJg8B,QAAI,IAAJA,GAAAA,EAAMt4B,aAAoB,OAAJs4B,QAAI,IAAJA,GAAAA,EAAMiX,cAE7Dx7B,EAAQ3V,IADR9I,EAA0B,oBAEhCsN,OAAQ,CACJmtC,MAAOntC,EACPotC,aAAcC,GAAWrtC,EAAQ,QACjCstC,aAAcD,GAAWrtC,EAAQ,QACjCutC,eAAgBF,GAAWrtC,EAAQ,UACnCwtC,WAAYH,GAAWrtC,EAAQ,OAEnC6sC,eAAgB,CACZM,MAAON,EACPO,aAAcC,GAAWR,EAAgB,QACzCS,aAAcD,GAAWR,EAAgB,QACzCU,eAAgBF,GAAWR,EAAgB,UAC3CW,WAAYH,GAAWR,EAAgB,OAE3CE,WAAY,CACRI,MAAOJ,EACPK,aAAcC,GAAWN,EAAY,QACrCO,aAAcD,GAAWN,EAAY,QACrCQ,eAAgBF,GAAWN,EAAY,UACvCS,WAAYH,GAAWN,EAAY,OAEvCl2C,QACAtB,WACAi3C,gBAA0B,mBAAT9yC,GAAkC,OAAJg8B,QAAI,IAAJA,GAAAA,EAAMt4B,aAAoB,OAAJs4B,QAAI,IAAJA,GAAAA,EAAMiX,cAItD,OAAfH,QAAe,IAAfA,EAAAA,EAAmB31C,EAAMK,GAHZ,SAAb3B,EAAmB,GAAA5C,OACZkE,EAAMK,GAAE,KAAAvE,OAAI4C,GACfsB,EAAMK,GAEhBgV,OAAY,OAAJwpB,QAAI,IAAJA,OAAI,EAAJA,EAAMxpB,OACd9O,YAAiB,OAAJs4B,QAAI,IAAJA,OAAI,EAAJA,EAAMt4B,YACnB1D,OACAizC,gBAAqB,OAAJjX,QAAI,IAAJA,IAAAA,EAAMiX,gBA2KnC,IAAsBpsB,EAAK0sB,EAxKnB,MAAMQ,EAAuB,SAAbl4C,GAAgC,mBAATmE,EAA4B8xC,GAAyCJ,GAC5G,OAAOF,GACFhyC,IAAKwyC,IAAa,IAAAgC,EAEnB,OADqC,QAApBA,EAAGD,EAAQ/B,UAAS,IAAAgC,EAAAA,EAAI,IAEpCx0C,IAAKyyC,IACN,IAnLIgC,EAACjC,EAAUC,EAAQC,KAAY,IAAAgC,EAAA,YAAuD94C,KAA/B,QAAnB84C,EAAAzC,GAAUO,UAAS,IAAAkC,GAAU,QAAVA,EAAnBA,EAAsBjC,UAAO,IAAAiC,OAAA,EAA7BA,EAAgChC,KAmLnE+B,CAAYjC,EAAUC,EAAQC,GAC/B,OAEJ,MAAMre,EAAWke,GAAaC,EAAUC,EAAQC,GAChD,GAAe,oBAAXD,GAAgCC,EAAajzC,SAAS,SAAU,CAChE,IAAM9B,EAAM08B,gBAAgB18B,EAAM08B,gBAAgByY,IAC9C,OAEJn2C,EAAmB,WAAIm2C,GAAkBn1C,EAAM08B,aACnD,CACA,GAAe,mBAAXoY,GAA+BC,EAAajzC,SAAS,SAAU,CAC/D,IAAM9B,EAAM08B,gBAAgB18B,EAAM08B,gBAAgB0Y,IAC9C,OAEJp2C,EAAmB,WAAIo2C,GAAcp1C,EAAM08B,aAC/C,CAEA,IAAIyG,EAAUzM,EAAS13B,GAAQ6O,OAC/B,GAAKs1B,EAAL,CAIA,GAAe,oBAAX2R,EAA8B,CAC9B,MAAMkC,EAAgB/B,IAAkCn3C,EAAAA,EAAAA,GAAC,CAAC,EAAIkB,IAC9DmkC,EAAU,GAAHrnC,OAAMk7C,EAAa,QAAAl7C,OAAOqnC,EACrC,MACK,GAAe,aAAX2R,EAAuB,CAC5B,MAAMkC,EAAgB9B,IAAqBp3C,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAC,CAAC,EACtCkB,GAAM,IACTi4C,aAAc9T,EAAQrhC,SAAS,UAC/Bo1C,WAAY/T,EAAQrhC,SAAS,YAEjCqhC,EAAU,GAAHrnC,OAAMk7C,EAAa,QAAAl7C,OAAOqnC,EACrC,CAMA,OAJIA,EAAQrhC,SAASw5B,KACjB6H,EAiIpB,SAAuC2S,EAAexa,EAAa6H,EAAS0R,EAAUn2C,EAAU6H,GAI5F,MAAM4wC,GAAc5wC,IACH,gBAAZ7H,IACKo3C,IACG3S,EAAQrhC,SAAS,oBACdqhC,EAAQrhC,SAAS,mCAC3Bs1C,EAAoBD,EACpB,WACA5wC,EACI,YACA7H,EAAS2pB,cAAc1oB,QAAQ,IAAK,KAAO,WAEpC,OAAbk1C,EACA1R,EAAUA,EAAQxjC,QAAQ,0BAAD7D,OAA2Bw/B,EAAW,gCAAAx/B,OAAgCs7C,EAAiB,MAG9F,WAAbvC,EAQL1R,GAFAA,GAFAA,GAFAA,GADAA,EAAU,cAAgBA,GACRxjC,QAAQ,IAAD7D,OAAKw/B,EAAW,oBAAAx/B,OAAoBs7C,EAAiB,QAE5Dz3C,QAAQ,WAAD7D,OAAYw/B,EAAW,+BAAAx/B,OAA8Bs7C,EAAiB,WAE7Ez3C,QAAQ,QAAD7D,OAASw/B,EAAW,4BAAAx/B,OAA2Bs7C,EAAiB,WAEvEz3C,QAAQ,UAAD7D,OAAWw/B,EAAW,8BAAAx/B,OAA6Bs7C,EAAiB,UAG3E,OAAbvC,IAOL1R,GAFAA,GAFAA,GAFAA,EAAUA,EAAQxjC,QAAQ,IAAD7D,OAAKw/B,EAAW,oBAAAx/B,OAAoBs7C,KAE3Cz3C,QAAQ,0BAAD7D,OAA2Bw/B,EAAW,8CAAAx/B,OAAgDs7C,EAAiB,SAE9Gz3C,QAAQ,uBAAD7D,OAAwBw/B,EAAW,2CAAAx/B,OAA6Cs7C,EAAiB,SAExGz3C,QAAQ,yBAAD7D,OAA0Bw/B,EAAW,6CAAAx/B,OAA+Cs7C,EAAiB,SAGlI,OAAOjU,CACX,CA1K8BkU,CAAkC,OAAJxY,QAAI,IAAJA,OAAI,EAAJA,EAAMiX,cAAexa,EAAa6H,EAAS0R,EAAUn2C,EAAc,OAAJmgC,QAAI,IAAJA,OAAI,EAAJA,EAAMt4B,cAG1G,CAAEsuC,WAAUC,OAAQA,EAAQ1lC,QAAS+zB,EAnB5C,IAqBC1gC,OAAQ0gC,QAAwBllC,IAAZklC,KAExBmU,QAMPC,GAA4Bv3C,IAC9B,MAAMZ,EAAOC,KAAKmX,MAAMgoB,GAAqBx+B,IAC7C,MAAO,CAAEmJ,OAAQ/J,EAAKqM,MAAOxC,WAAY,CAAEC,OAAQ9J,EAAK8J,UAEtD2sC,GAA6BA,CAAC71C,EAAO6+B,KAAS,IAAA2Y,EAChD,OAAA15C,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,CACIqR,SAAwB,QAAhBqoC,EAAM,OAAJ3Y,QAAI,IAAJA,OAAI,EAAJA,EAAM1vB,gBAAQ,IAAAqoC,EAAAA,EAAIhZ,GAAqBx+B,IACzC,OAAJ6+B,QAAI,IAAJA,GAAAA,EAAM4Y,YAAc,CAAEA,YAAiB,OAAJ5Y,QAAI,IAAJA,OAAI,EAAJA,EAAM4Y,kBAAgBx5C,GACrD,OAAJ4gC,QAAI,IAAJA,GAAAA,EAAMzxB,WAAa,CAAEA,WAAgB,OAAJyxB,QAAI,IAAJA,OAAI,EAAJA,EAAMzxB,iBAAenP,GAClD,OAAJ4gC,QAAI,IAAJA,GAAAA,EAAM6Y,MAAQ,CAAEA,MAAW,OAAJ7Y,QAAI,IAAJA,OAAI,EAAJA,EAAM6Y,YAAUz5C,IAYvBo3C,GAAiB,cACvBA,GAAiB,cACHA,GAAiB,cAClBA,GAAiB,4BA3BLr1C,GACpCX,KAAKmX,MAAMgoB,GAAqBx+B,KA2BjBq1C,GAAiB,SAC1BA,GAAiB,SACNA,GAAiB,cACnBA,GAAiB,cAChBA,GAAiB,eAAgBkC,IAClClC,GAAiB,kBAChBA,GAAiB,eAAgBkC,IACtClC,GAAiB,eAAgBkC,IAClClC,GAAiB,cAChBA,GAAiB,eAAgBkC,IAC/BlC,GAAiB,cACfA,GAAiB,oBAxBJr1C,IACnC,MAAMZ,EAAOC,KAAKmX,MAAMgoB,GAAqBx+B,IAC7C,MAAO,CAAEuc,SAAUnd,EAAKmd,SAAUsc,QAASz5B,EAAKy5B,WAuBzBwc,GAAiB,SACzBA,GAAiB,SACNA,GAAiB,WACrBA,GAAiB,WACXA,GAAiB,yBAzBLr1C,IACxC,MAAMZ,EAAOC,KAAKmX,MAAMgoB,GAAqBx+B,IAC7C,MAAO,CAAE23C,MAAOv4C,EAAKu4C,MAAOlf,MAAOp5B,KAAKC,UAAUF,EAAKq5B,UAwBhC4c,GAAiB,SACrBA,GAAiB,SACnBA,GAAiB,eACjBA,GAAiB,eAChBA,GAAiB,gBAClBA,GAAiB,eACVA,GAAiB,SAC5BA,GAAiB,SACFA,GAAiB,0BACXA,GAAiB,+BAQvD,SAASmB,GAAWl4C,EAAKgpB,GACrB,OAAQA,GACJ,IAAK,OACD,OAAOswB,GAAapB,GAAWl4C,EAAK,SACxC,IAAK,OAED,OAAOe,KAAKC,UAAUhB,EAAK,KAAM,GAAG+K,MAAM,MAAMqM,MAAM,GAAI,GAAG/T,KAAK,MACtE,IAAK,SACD,OAAOi2C,GAAaz1C,OAAO0D,QAAQvH,GAC9B+D,IAAIyD,IAAkB,IAAhBgN,EAAK7I,GAAMnE,EAClB,MAAM+xC,EAAiBx4C,KAAKC,UAAU2K,EAAO,KAAM,GAAGtK,QAAQ,KAAM,KACpE,MAAO,GAAP7D,OAAUgX,EAAG,KAAAhX,OAAI+7C,EAAc,OAE9Bl2C,KAAK,OACd,IAAK,KAED,OAAOm2C,GAAex5C,GAAK+K,MAAM,MAAMqM,MAAM,GAAI,GAAG/T,KAAK,MAC7D,QACI,MAAM,IAAIzE,MAAM,uBAADpB,OAAwBwrB,IAEnD,CACA,SAASwwB,GAAex5C,EAAK6rB,GAGzB,GAFAA,EAAa,OAALA,QAAK,IAALA,EAAAA,EAAS,EAEE,kBAAR7rB,GAA4B,OAARA,EAC3B,OAAOe,KAAKC,UAAUhB,GAG1B,GAAIC,MAAMC,QAAQF,GAAM,CACpB,MAAM0sB,EAAQ1sB,EACT+D,IAAKuN,IACN,MAAMmoC,EAAYD,GAAeloC,EAAMua,EAAQ,GAC/C,MAAO,GAAPruB,OAAU,IAAIyuB,OAAO,GAAKJ,EAAQ,KAAGruB,OAAGi8C,EAAS,OAEhDp2C,KAAK,MACV,MAAO,MAAP7F,OAAakvB,EAAK,MAAAlvB,OAAK,IAAIyuB,OAAO,EAAIJ,GAAM,IAChD,CAEA,MACMkH,EADUlvB,OAAO0D,QAAQvH,GAE1B+D,IAAIuoB,IAAkB,IAAhB9X,EAAK7I,GAAM2gB,EAClB,MAAMitB,EAAiBC,GAAe7tC,EAAOkgB,EAAQ,GAC/C6tB,EAAS,6BAA6B9wC,KAAK4L,GAAOA,EAAM,IAAHhX,OAAOgX,EAAG,KACrE,MAAO,GAAPhX,OAAU,IAAIyuB,OAAO,GAAKJ,EAAQ,KAAGruB,OAAGk8C,EAAM,MAAAl8C,OAAK+7C,EAAc,OAEhEl2C,KAAK,MACV,MAAO,MAAP7F,OAAau1B,EAAK,MAAAv1B,OAAK,IAAIyuB,OAAO,EAAIJ,GAAM,IAChD,CACA,SAASytB,GAAaluB,GAClB,OAAOA,EACFrgB,MAAM,MACNhH,IAAKqX,GAAS,IAAI6Q,OAAO,GAAK7Q,GAC9B/X,KAAK,KACd,C,6BC7VM,MAAAs2C,GAAOC,E,OAAAA,GAAiB,OAAQ,CACpC,CAAC,WAAY,CAAEC,OAAQ,oBAAqBrlC,IAAK,WACjD,CAAC,OAAQ,CAAEslC,GAAI,IAAKC,GAAI,KAAMC,GAAI,KAAMC,GAAI,KAAMzlC,IAAK,WACvD,CAAC,OAAQ,CAAEslC,GAAI,KAAMC,GAAI,KAAMC,GAAI,IAAKC,GAAI,KAAMzlC,IAAK,Y,8BCHnD,MAAA0lC,GAASN,E,OAAAA,GAAiB,SAAU,CACxC,CAAC,UAAW,CAAEC,OAAQ,2BAA4BrlC,IAAK,WACvD,CAAC,WAAY,CAAEqlC,OAAQ,mBAAoBrlC,IAAK,WAChD,CAAC,WAAY,CAAEqlC,OAAQ,mBAAoBrlC,IAAK,Y,8BCH5C,MAAA2lC,GAAQP,E,OAAAA,GAAiB,QAAS,CACtC,CACE,OACA,CACEhnB,MAAO,KACPwnB,OAAQ,KACR/3C,EAAG,IACHg4C,EAAG,IACHC,GAAI,IACJC,GAAI,IACJ/lC,IAAK,WAGT,CAAC,SAAU,CAAEgmC,GAAI,IAAKC,GAAI,IAAK7nC,EAAG,IAAK4B,IAAK,WAC5C,CAAC,OAAQ,CAAEd,EAAG,4CAA6Cc,IAAK,Y,8BCd5D,MAAAkmC,GAASd,E,OAAAA,GAAiB,SAAU,CACxC,CAAC,OAAQ,CAAElmC,EAAG,UAAWc,IAAK,WAC9B,CAAC,OAAQ,CAAEd,EAAG,wCAAyCc,IAAK,WAC5D,CAAC,OAAQ,CAAEd,EAAG,qCAAsCc,IAAK,WACzD,CAAC,OAAQ,CAAEslC,GAAI,KAAMC,GAAI,KAAMC,GAAI,KAAMC,GAAI,KAAMzlC,IAAK,WACxD,CAAC,OAAQ,CAAEslC,GAAI,KAAMC,GAAI,KAAMC,GAAI,KAAMC,GAAI,KAAMzlC,IAAK,W,8BCLpD,MAAAmmC,GAAQf,E,OAAAA,GAAiB,QAAS,CACtC,CACE,OACA,CACElmC,EAAG,iJACHc,IAAK,WAGT,CAAC,OAAQ,CAAEd,EAAG,YAAac,IAAK,WAChC,CAAC,OAAQ,CAAEd,EAAG,SAAUc,IAAK,WAC7B,CAAC,OAAQ,CAAEd,EAAG,WAAYc,IAAK,WAC/B,CAAC,OAAQ,CAAEd,EAAG,UAAWc,IAAK,WAC9B,CAAC,OAAQ,CAAEd,EAAG,SAAUc,IAAK,WAC7B,CAAC,OAAQ,CAAEd,EAAG,YAAac,IAAK,WAChC,CAAC,OAAQ,CAAEd,EAAG,UAAWc,IAAK,Y,8BCd1B,MAAAomC,GAAOhB,E,OAAAA,GAAiB,OAAQ,CACpC,CACE,OACA,CACEhnB,MAAO,KACPwnB,OAAQ,KACR/3C,EAAG,IACHg4C,EAAG,IACHC,GAAI,IACJC,GAAI,IACJ/lC,IAAK,WAGT,CAAC,OAAQ,CAAEslC,GAAI,IAAKC,GAAI,KAAMC,GAAI,IAAKC,GAAI,IAAKzlC,IAAK,WACrD,CAAC,OAAQ,CAAEslC,GAAI,IAAKC,GAAI,KAAMC,GAAI,KAAMC,GAAI,KAAMzlC,IAAK,WACvD,CAAC,OAAQ,CAAEslC,GAAI,IAAKC,GAAI,IAAKC,GAAI,IAAKC,GAAI,KAAMzlC,IAAK,WACrD,CAAC,OAAQ,CAAEslC,GAAI,KAAMC,GAAI,KAAMC,GAAI,IAAKC,GAAI,KAAMzlC,IAAK,Y,8BChBnD,MAAAqmC,GAAYjB,E,OAAAA,GAAiB,YAAa,CAC9C,CAAC,OAAQ,CAAElmC,EAAG,iBAAkBc,IAAK,WACrC,CAAC,OAAQ,CAAEd,EAAG,WAAYc,IAAK,Y,8BCF3B,MAAAsmC,GAAOlB,E,OAAAA,GAAiB,OAAQ,CACpC,CACE,OACA,CACElmC,EAAG,kEACHc,IAAK,WAGT,CAAC,WAAY,CAAEqlC,OAAQ,wBAAyBrlC,IAAK,WACrD,CAAC,WAAY,CAAEqlC,OAAQ,eAAgBrlC,IAAK,Y,8BCTxC,MAAAumC,GAAUnB,E,OAAAA,GAAiB,UAAW,CAC1C,CAAC,SAAU,CAAEY,GAAI,KAAMC,GAAI,KAAM7nC,EAAG,IAAK4B,IAAK,WAC9C,CAAC,OAAQ,CAAEslC,GAAI,KAAMC,GAAI,QAASC,GAAI,KAAMC,GAAI,QAASzlC,IAAK,WAC9D,CAAC,OAAQ,CAAEslC,GAAI,IAAKC,GAAI,KAAMC,GAAI,KAAMC,GAAI,KAAMzlC,IAAK,Y,8BCHnD,MAAAwmC,GAASpB,E,OAAAA,GAAiB,SAAU,CACxC,CAAC,SAAU,CAAEY,GAAI,KAAMC,GAAI,KAAM7nC,EAAG,IAAK4B,IAAK,WAC9C,CAAC,OAAQ,CAAEslC,GAAI,KAAMC,GAAI,QAASC,GAAI,KAAMC,GAAI,QAASzlC,IAAK,WAC9D,CAAC,OAAQ,CAAEslC,GAAI,KAAMC,GAAI,KAAMC,GAAI,IAAKC,GAAI,KAAMzlC,IAAK,WACvD,CAAC,OAAQ,CAAEslC,GAAI,IAAKC,GAAI,KAAMC,GAAI,KAAMC,GAAI,KAAMzlC,IAAK,Y,8BCJnD,MAAAymC,GAAWrB,E,OAAAA,GAAiB,WAAY,CAC5C,CACE,OACA,CACElmC,EAAG,wKACHc,IAAK,WAGT,CAAC,OAAQ,CAAEd,EAAG,SAAUc,IAAK,WAC7B,CAAC,OAAQ,CAAEd,EAAG,WAAYc,IAAK,WAC/B,CAAC,OAAQ,CAAEd,EAAG,SAAUc,IAAK,WAC7B,CAAC,OAAQ,CAAEd,EAAG,WAAYc,IAAK,Y,8BCX3B,MAAA0mC,GAAOtB,E,OAAAA,GAAiB,OAAQ,CACpC,CACE,OACA,CACEhnB,MAAO,KACPwnB,OAAQ,KACR/3C,EAAG,IACHg4C,EAAG,IACHC,GAAI,IACJC,GAAI,IACJ/lC,IAAK,WAGT,CACE,OACA,CACEd,EAAG,0DACHc,IAAK,Y,8BCjBL,MAAA2mC,GAAcvB,E,OAAAA,GAAiB,cAAe,CAClD,CAAC,SAAU,CAAEY,GAAI,KAAMC,GAAI,KAAM7nC,EAAG,KAAM4B,IAAK,WAC/C,CAAC,OAAQ,CAAEslC,GAAI,KAAMC,GAAI,KAAMC,GAAI,IAAKC,GAAI,KAAMzlC,IAAK,WACvD,CAAC,OAAQ,CAAEslC,GAAI,KAAMC,GAAI,QAASC,GAAI,KAAMC,GAAI,KAAMzlC,IAAK,Y","sources":["../node_modules/@huggingface/inference/dist/esm/config.js","../node_modules/@huggingface/inference/dist/esm/providers/consts.js","../node_modules/@huggingface/inference/dist/esm/errors.js","../node_modules/@huggingface/inference/dist/esm/utils/toArray.js","../node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js","../node_modules/@huggingface/inference/dist/esm/utils/base64FromBytes.js","../node_modules/@huggingface/inference/dist/esm/utils/typedInclude.js","../node_modules/@huggingface/inference/dist/esm/utils/omit.js","../node_modules/@huggingface/inference/dist/esm/utils/pick.js","../node_modules/@huggingface/inference/dist/esm/providers/hf-inference.js","../node_modules/@huggingface/inference/dist/esm/lib/logger.js","../node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js","../node_modules/@huggingface/inference/dist/esm/utils/delay.js","../node_modules/@huggingface/inference/dist/esm/lib/isUrl.js","../node_modules/@huggingface/inference/dist/esm/providers/fal-ai.js","../node_modules/@huggingface/inference/dist/esm/providers/featherless-ai.js","../node_modules/@huggingface/inference/dist/esm/providers/groq.js","../node_modules/@huggingface/inference/dist/esm/providers/hyperbolic.js","../node_modules/@huggingface/inference/dist/esm/providers/nebius.js","../node_modules/@huggingface/inference/dist/esm/providers/novita.js","../node_modules/@huggingface/inference/dist/esm/providers/nscale.js","../node_modules/@huggingface/inference/dist/esm/providers/ovhcloud.js","../node_modules/@huggingface/inference/dist/esm/providers/replicate.js","../node_modules/@huggingface/inference/dist/esm/providers/scaleway.js","../node_modules/@huggingface/inference/dist/esm/providers/together.js","../node_modules/@huggingface/inference/dist/esm/providers/wavespeed.js","../node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js","../node_modules/@huggingface/inference/dist/esm/providers/baseten.js","../node_modules/@huggingface/inference/dist/esm/providers/black-forest-labs.js","../node_modules/@huggingface/inference/dist/esm/providers/cerebras.js","../node_modules/@huggingface/inference/dist/esm/providers/clarifai.js","../node_modules/@huggingface/inference/dist/esm/providers/cohere.js","../node_modules/@huggingface/inference/dist/esm/providers/fireworks-ai.js","../node_modules/@huggingface/inference/dist/esm/providers/openai.js","../node_modules/@huggingface/inference/dist/esm/providers/publicai.js","../node_modules/@huggingface/inference/dist/esm/providers/sambanova.js","../node_modules/@huggingface/inference/dist/esm/providers/zai-org.js","../node_modules/@babel/runtime/helpers/esm/OverloadYield.js","../node_modules/@babel/runtime/helpers/esm/wrapAsyncGenerator.js","../node_modules/@babel/runtime/helpers/esm/awaitAsyncGenerator.js","../node_modules/@babel/runtime/helpers/esm/asyncGeneratorDelegate.js","../node_modules/@babel/runtime/helpers/esm/asyncIterator.js","../node_modules/@huggingface/inference/dist/esm/package.js","../node_modules/@huggingface/inference/dist/esm/lib/makeRequestOptions.js","../node_modules/@huggingface/inference/dist/esm/vendor/fetch-event-source/parse.js","../node_modules/@huggingface/inference/dist/esm/utils/request.js","../node_modules/@huggingface/inference/dist/esm/tasks/custom/request.js","../node_modules/@huggingface/inference/dist/esm/tasks/custom/streamingRequest.js","../node_modules/@huggingface/inference/dist/esm/tasks/audio/utils.js","../node_modules/@huggingface/inference/dist/esm/tasks/audio/audioClassification.js","../node_modules/@huggingface/inference/dist/esm/tasks/audio/audioToAudio.js","../node_modules/@huggingface/inference/dist/esm/tasks/audio/automaticSpeechRecognition.js","../node_modules/@huggingface/inference/dist/esm/tasks/audio/textToSpeech.js","../node_modules/@huggingface/inference/dist/esm/tasks/cv/utils.js","../node_modules/@huggingface/inference/dist/esm/tasks/cv/imageClassification.js","../node_modules/@huggingface/inference/dist/esm/tasks/cv/imageSegmentation.js","../node_modules/@huggingface/inference/dist/esm/tasks/cv/imageToImage.js","../node_modules/@huggingface/inference/dist/esm/tasks/cv/imageToText.js","../node_modules/@huggingface/inference/dist/esm/tasks/cv/imageToVideo.js","../node_modules/@huggingface/inference/dist/esm/tasks/cv/imageTextToImage.js","../node_modules/@huggingface/inference/dist/esm/tasks/cv/imageTextToVideo.js","../node_modules/@huggingface/inference/dist/esm/tasks/cv/objectDetection.js","../node_modules/@huggingface/inference/dist/esm/tasks/cv/textToImage.js","../node_modules/@huggingface/inference/dist/esm/tasks/cv/textToVideo.js","../node_modules/@huggingface/inference/dist/esm/tasks/cv/zeroShotImageClassification.js","../node_modules/@huggingface/inference/dist/esm/tasks/nlp/chatCompletion.js","../node_modules/@huggingface/inference/dist/esm/tasks/nlp/chatCompletionStream.js","../node_modules/@huggingface/inference/dist/esm/tasks/nlp/featureExtraction.js","../node_modules/@huggingface/inference/dist/esm/tasks/nlp/fillMask.js","../node_modules/@huggingface/inference/dist/esm/tasks/nlp/questionAnswering.js","../node_modules/@huggingface/inference/dist/esm/tasks/nlp/sentenceSimilarity.js","../node_modules/@huggingface/inference/dist/esm/tasks/nlp/summarization.js","../node_modules/@huggingface/inference/dist/esm/tasks/nlp/tableQuestionAnswering.js","../node_modules/@huggingface/inference/dist/esm/tasks/nlp/textClassification.js","../node_modules/@huggingface/inference/dist/esm/tasks/nlp/textGeneration.js","../node_modules/@huggingface/inference/dist/esm/tasks/nlp/textGenerationStream.js","../node_modules/@huggingface/inference/dist/esm/tasks/nlp/tokenClassification.js","../node_modules/@huggingface/inference/dist/esm/tasks/nlp/translation.js","../node_modules/@huggingface/inference/dist/esm/tasks/nlp/zeroShotClassification.js","../node_modules/@huggingface/inference/dist/esm/tasks/multimodal/documentQuestionAnswering.js","../node_modules/@huggingface/inference/dist/esm/tasks/multimodal/visualQuestionAnswering.js","../node_modules/@huggingface/inference/dist/esm/tasks/tabular/tabularClassification.js","../node_modules/@huggingface/inference/dist/esm/tasks/tabular/tabularRegression.js","../node_modules/@huggingface/inference/dist/esm/InferenceClient.js","../node_modules/@huggingface/inference/dist/esm/utils/typedEntries.js","../node_modules/@huggingface/jinja/dist/index.js","../node_modules/@huggingface/tasks/dist/esm/library-to-tasks.js","../node_modules/@huggingface/tasks/dist/esm/default-widget-inputs.js","../node_modules/@huggingface/tasks/dist/esm/pipelines.js","../node_modules/@huggingface/tasks/dist/esm/tasks/audio-classification/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/audio-text-to-text/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/audio-to-audio/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/automatic-speech-recognition/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/document-question-answering/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/feature-extraction/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/fill-mask/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/image-classification/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/image-feature-extraction/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/image-to-image/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/image-to-text/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/image-text-to-text/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/image-text-to-image/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/image-text-to-video/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/image-segmentation/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/image-to-video/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/mask-generation/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/object-detection/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/depth-estimation/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/placeholder/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/reinforcement-learning/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/question-answering/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/sentence-similarity/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/summarization/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/table-question-answering/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/tabular-classification/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/tabular-regression/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/text-to-image/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/text-to-speech/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/token-classification/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/translation/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/text-classification/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/text-generation/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/text-ranking/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/text-to-video/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/unconditional-image-generation/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/video-classification/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/visual-document-retrieval/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/visual-question-answering/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/zero-shot-classification/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/zero-shot-image-classification/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/zero-shot-object-detection/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/image-to-3d/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/text-to-3d/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/keypoint-detection/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/video-text-to-text/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/video-to-video/data.js","../node_modules/@huggingface/tasks/dist/esm/tasks/index.js","../node_modules/@huggingface/tasks/dist/esm/tasks/any-to-any/data.js","../node_modules/@huggingface/tasks/dist/esm/snippets/inputs.js","../node_modules/@huggingface/tasks/dist/esm/snippets/common.js","../node_modules/@huggingface/tasks/dist/esm/model-libraries-snippets.js","../node_modules/@huggingface/tasks/dist/esm/model-libraries.js","../node_modules/@huggingface/tasks/dist/esm/gguf.js","../node_modules/@huggingface/tasks/dist/esm/snippets/types.js","../node_modules/@huggingface/tasks/dist/esm/local-apps.js","../node_modules/@huggingface/inference/dist/esm/snippets/templates.exported.js","../node_modules/@huggingface/inference/dist/esm/snippets/getInferenceSnippets.js","../node_modules/lucide-react/src/icons/type.ts","../node_modules/lucide-react/src/icons/layers.ts","../node_modules/lucide-react/src/icons/image.ts","../node_modules/lucide-react/src/icons/trash-2.ts","../node_modules/lucide-react/src/icons/wand-2.ts","../node_modules/lucide-react/src/icons/grid.ts","../node_modules/lucide-react/src/icons/arrow-left.ts","../node_modules/lucide-react/src/icons/save.ts","../node_modules/lucide-react/src/icons/zoom-out.ts","../node_modules/lucide-react/src/icons/zoom-in.ts","../node_modules/lucide-react/src/icons/sparkles.ts","../node_modules/lucide-react/src/icons/copy.ts","../node_modules/lucide-react/src/icons/alert-circle.ts"],"sourcesContent":["export const HF_HUB_URL = \"https://huggingface.co\";\nexport const HF_ROUTER_URL = \"https://router.huggingface.co\";\nexport const HF_ROUTER_AUTO_ENDPOINT = `${HF_ROUTER_URL}/v1`;\nexport const HF_HEADER_X_BILL_TO = \"X-HF-Bill-To\";\n","/**\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co\n * for a given Inference Provider,\n * you can add it to the following dictionary, for dev purposes.\n *\n * We also inject into this dictionary from tests.\n */\nexport const HARDCODED_MODEL_INFERENCE_MAPPING = {\n    /**\n     * \"HF model ID\" => \"Model ID on Inference Provider's side\"\n     *\n     * Example:\n     * \"Qwen/Qwen2.5-Coder-32B-Instruct\": \"Qwen2.5-Coder-32B-Instruct\",\n     */\n    baseten: {},\n    \"black-forest-labs\": {},\n    cerebras: {},\n    clarifai: {},\n    cohere: {},\n    \"fal-ai\": {},\n    \"featherless-ai\": {},\n    \"fireworks-ai\": {},\n    groq: {},\n    \"hf-inference\": {},\n    hyperbolic: {},\n    nebius: {},\n    novita: {},\n    nscale: {},\n    openai: {},\n    publicai: {},\n    ovhcloud: {},\n    replicate: {},\n    sambanova: {},\n    scaleway: {},\n    together: {},\n    wavespeed: {},\n    \"zai-org\": {},\n};\n","/**\n * Base class for all inference-related errors.\n */\nexport class InferenceClientError extends Error {\n    constructor(message) {\n        super(message);\n        this.name = \"InferenceClientError\";\n    }\n}\nexport class InferenceClientInputError extends InferenceClientError {\n    constructor(message) {\n        super(message);\n        this.name = \"InputError\";\n    }\n}\nexport class InferenceClientRoutingError extends InferenceClientError {\n    constructor(message) {\n        super(message);\n        this.name = \"RoutingError\";\n    }\n}\nclass InferenceClientHttpRequestError extends InferenceClientError {\n    httpRequest;\n    httpResponse;\n    constructor(message, httpRequest, httpResponse) {\n        super(message);\n        this.httpRequest = {\n            ...httpRequest,\n            ...(httpRequest.headers\n                ? {\n                    headers: {\n                        ...httpRequest.headers,\n                        ...(\"Authorization\" in httpRequest.headers ? { Authorization: `Bearer [redacted]` } : undefined),\n                        /// redact authentication in the request headers\n                    },\n                }\n                : undefined),\n        };\n        this.httpResponse = httpResponse;\n    }\n}\n/**\n * Thrown when the HTTP request to the provider fails, e.g. due to API issues or server errors.\n */\nexport class InferenceClientProviderApiError extends InferenceClientHttpRequestError {\n    constructor(message, httpRequest, httpResponse) {\n        super(message, httpRequest, httpResponse);\n        this.name = \"ProviderApiError\";\n    }\n}\n/**\n * Thrown when the HTTP request to the hub fails, e.g. due to API issues or server errors.\n */\nexport class InferenceClientHubApiError extends InferenceClientHttpRequestError {\n    constructor(message, httpRequest, httpResponse) {\n        super(message, httpRequest, httpResponse);\n        this.name = \"HubApiError\";\n    }\n}\n/**\n * Thrown when the inference output returned by the provider is invalid / does not match the expectations\n */\nexport class InferenceClientProviderOutputError extends InferenceClientError {\n    constructor(message) {\n        super(message);\n        this.name = \"ProviderOutputError\";\n    }\n}\n","export function toArray(obj) {\n    if (Array.isArray(obj)) {\n        return obj;\n    }\n    return [obj];\n}\n","import { HF_ROUTER_URL } from \"../config.js\";\nimport { InferenceClientProviderOutputError, InferenceClientRoutingError } from \"../errors.js\";\nimport { toArray } from \"../utils/toArray.js\";\n/**\n * Base class for task-specific provider helpers\n */\nexport class TaskProviderHelper {\n    provider;\n    baseUrl;\n    clientSideRoutingOnly;\n    constructor(provider, baseUrl, clientSideRoutingOnly = false) {\n        this.provider = provider;\n        this.baseUrl = baseUrl;\n        this.clientSideRoutingOnly = clientSideRoutingOnly;\n    }\n    /**\n     * Prepare the base URL for the request\n     */\n    makeBaseUrl(params) {\n        return params.authMethod !== \"provider-key\" ? `${HF_ROUTER_URL}/${this.provider}` : this.baseUrl;\n    }\n    /**\n     * Prepare the body for the request\n     */\n    makeBody(params) {\n        if (\"data\" in params.args && !!params.args.data) {\n            return params.args.data;\n        }\n        return JSON.stringify(this.preparePayload(params));\n    }\n    /**\n     * Prepare the URL for the request\n     */\n    makeUrl(params) {\n        const baseUrl = this.makeBaseUrl(params);\n        const route = this.makeRoute(params).replace(/^\\/+/, \"\");\n        return `${baseUrl}/${route}`;\n    }\n    /**\n     * Prepare the headers for the request\n     */\n    prepareHeaders(params, isBinary) {\n        const headers = {};\n        if (params.authMethod !== \"none\") {\n            headers[\"Authorization\"] = `Bearer ${params.accessToken}`;\n        }\n        if (!isBinary) {\n            headers[\"Content-Type\"] = \"application/json\";\n        }\n        return headers;\n    }\n}\n// BASE IMPLEMENTATIONS FOR COMMON PATTERNS\nexport class BaseConversationalTask extends TaskProviderHelper {\n    constructor(provider, baseUrl, clientSideRoutingOnly = false) {\n        super(provider, baseUrl, clientSideRoutingOnly);\n    }\n    makeRoute() {\n        return \"v1/chat/completions\";\n    }\n    preparePayload(params) {\n        return {\n            ...params.args,\n            model: params.model,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            Array.isArray(response?.choices) &&\n            typeof response?.created === \"number\" &&\n            typeof response?.id === \"string\" &&\n            typeof response?.model === \"string\" &&\n            /// Together.ai and Nebius do not output a system_fingerprint\n            (response.system_fingerprint === undefined ||\n                response.system_fingerprint === null ||\n                typeof response.system_fingerprint === \"string\") &&\n            typeof response?.usage === \"object\") {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Expected ChatCompletionOutput\");\n    }\n}\nexport class BaseTextGenerationTask extends TaskProviderHelper {\n    constructor(provider, baseUrl, clientSideRoutingOnly = false) {\n        super(provider, baseUrl, clientSideRoutingOnly);\n    }\n    preparePayload(params) {\n        return {\n            ...params.args,\n            model: params.model,\n        };\n    }\n    makeRoute() {\n        return \"v1/completions\";\n    }\n    async getResponse(response) {\n        const res = toArray(response);\n        if (Array.isArray(res) &&\n            res.length > 0 &&\n            res.every((x) => typeof x === \"object\" && !!x && \"generated_text\" in x && typeof x.generated_text === \"string\")) {\n            return res[0];\n        }\n        throw new InferenceClientProviderOutputError(\"Expected Array<{generated_text: string}>\");\n    }\n}\nexport class AutoRouterConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"auto\", \"https://router.huggingface.co\");\n    }\n    makeBaseUrl(params) {\n        if (params.authMethod !== \"hf-token\") {\n            throw new InferenceClientRoutingError(\"Cannot select auto-router when using non-Hugging Face API key.\");\n        }\n        return this.baseUrl;\n    }\n}\n","export function base64FromBytes(arr) {\n    if (globalThis.Buffer) {\n        return globalThis.Buffer.from(arr).toString(\"base64\");\n    }\n    else {\n        const bin = [];\n        arr.forEach((byte) => {\n            bin.push(String.fromCharCode(byte));\n        });\n        return globalThis.btoa(bin.join(\"\"));\n    }\n}\n","export function typedInclude(arr, v) {\n    return arr.includes(v);\n}\n","import { pick } from \"./pick.js\";\nimport { typedInclude } from \"./typedInclude.js\";\n/**\n * Return copy of object, omitting blocklisted array of props\n */\nexport function omit(o, props) {\n    const propsArr = Array.isArray(props) ? props : [props];\n    const letsKeep = Object.keys(o).filter((prop) => !typedInclude(propsArr, prop));\n    return pick(o, letsKeep);\n}\n","/**\n * Return copy of object, only keeping allowlisted properties.\n */\nexport function pick(o, props) {\n    return Object.assign({}, ...props.map((prop) => {\n        if (o[prop] !== undefined) {\n            return { [prop]: o[prop] };\n        }\n    }));\n}\n","import { HF_ROUTER_URL } from \"../config.js\";\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nimport { toArray } from \"../utils/toArray.js\";\nimport { TaskProviderHelper } from \"./providerHelper.js\";\nimport { base64FromBytes } from \"../utils/base64FromBytes.js\";\nimport { omit } from \"../utils/omit.js\";\nexport const EQUIVALENT_SENTENCE_TRANSFORMERS_TASKS = [\"feature-extraction\", \"sentence-similarity\"];\nexport class HFInferenceTask extends TaskProviderHelper {\n    constructor() {\n        super(\"hf-inference\", `${HF_ROUTER_URL}/hf-inference`);\n    }\n    preparePayload(params) {\n        return params.args;\n    }\n    makeUrl(params) {\n        if (params.model.startsWith(\"http://\") || params.model.startsWith(\"https://\")) {\n            return params.model;\n        }\n        return super.makeUrl(params);\n    }\n    makeRoute(params) {\n        if (params.task && [\"feature-extraction\", \"sentence-similarity\"].includes(params.task)) {\n            // when deployed on hf-inference, those two tasks are automatically compatible with one another.\n            return `models/${params.model}/pipeline/${params.task}`;\n        }\n        return `models/${params.model}`;\n    }\n    async getResponse(response) {\n        return response;\n    }\n}\nexport class HFInferenceTextToImageTask extends HFInferenceTask {\n    async getResponse(response, url, headers, outputType) {\n        if (!response) {\n            throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference text-to-image API: response is undefined\");\n        }\n        if (typeof response == \"object\") {\n            if (outputType === \"json\") {\n                return { ...response };\n            }\n            if (\"data\" in response && Array.isArray(response.data) && response.data[0].b64_json) {\n                const base64Data = response.data[0].b64_json;\n                if (outputType === \"url\") {\n                    return `data:image/jpeg;base64,${base64Data}`;\n                }\n                const base64Response = await fetch(`data:image/jpeg;base64,${base64Data}`);\n                return await base64Response.blob();\n            }\n            if (\"output\" in response && Array.isArray(response.output)) {\n                if (outputType === \"url\") {\n                    return response.output[0];\n                }\n                const urlResponse = await fetch(response.output[0]);\n                const blob = await urlResponse.blob();\n                return blob;\n            }\n        }\n        if (response instanceof Blob) {\n            if (outputType === \"url\" || outputType === \"json\") {\n                const b64 = await response.arrayBuffer().then((buf) => Buffer.from(buf).toString(\"base64\"));\n                return outputType === \"url\" ? `data:image/jpeg;base64,${b64}` : { output: `data:image/jpeg;base64,${b64}` };\n            }\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference text-to-image API: expected a Blob\");\n    }\n}\nexport class HFInferenceConversationalTask extends HFInferenceTask {\n    makeUrl(params) {\n        let url;\n        if (params.model.startsWith(\"http://\") || params.model.startsWith(\"https://\")) {\n            url = params.model.trim();\n        }\n        else {\n            url = `${this.makeBaseUrl(params)}/models/${params.model}`;\n        }\n        url = url.replace(/\\/+$/, \"\");\n        if (url.endsWith(\"/v1\")) {\n            url += \"/chat/completions\";\n        }\n        else if (!url.endsWith(\"/chat/completions\")) {\n            url += \"/v1/chat/completions\";\n        }\n        return url;\n    }\n    preparePayload(params) {\n        return {\n            ...params.args,\n            model: params.model,\n        };\n    }\n    async getResponse(response) {\n        return response;\n    }\n}\nexport class HFInferenceTextGenerationTask extends HFInferenceTask {\n    async getResponse(response) {\n        const res = toArray(response);\n        if (Array.isArray(res) && res.every((x) => \"generated_text\" in x && typeof x?.generated_text === \"string\")) {\n            return res?.[0];\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference text generation API: expected Array<{generated_text: string}>\");\n    }\n}\nexport class HFInferenceAudioClassificationTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) &&\n            response.every((x) => typeof x === \"object\" && x !== null && typeof x.label === \"string\" && typeof x.score === \"number\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference audio-classification API: expected Array<{label: string, score: number}> but received different format\");\n    }\n}\nexport class HFInferenceAutomaticSpeechRecognitionTask extends HFInferenceTask {\n    async getResponse(response) {\n        return response;\n    }\n    async preparePayloadAsync(args) {\n        return \"data\" in args\n            ? args\n            : {\n                ...omit(args, \"inputs\"),\n                data: args.inputs,\n            };\n    }\n}\nexport class HFInferenceAudioToAudioTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (!Array.isArray(response)) {\n            throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference audio-to-audio API: expected Array\");\n        }\n        if (!response.every((elem) => {\n            return (typeof elem === \"object\" &&\n                elem &&\n                \"label\" in elem &&\n                typeof elem.label === \"string\" &&\n                \"content-type\" in elem &&\n                typeof elem[\"content-type\"] === \"string\" &&\n                \"blob\" in elem &&\n                typeof elem.blob === \"string\");\n        })) {\n            throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference audio-to-audio API: expected Array<{label: string, audio: Blob}>\");\n        }\n        return response;\n    }\n}\nexport class HFInferenceDocumentQuestionAnsweringTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) &&\n            response.every((elem) => typeof elem === \"object\" &&\n                !!elem &&\n                typeof elem?.answer === \"string\" &&\n                (typeof elem.end === \"number\" || typeof elem.end === \"undefined\") &&\n                (typeof elem.score === \"number\" || typeof elem.score === \"undefined\") &&\n                (typeof elem.start === \"number\" || typeof elem.start === \"undefined\"))) {\n            return response[0];\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference document-question-answering API: expected Array<{answer: string, end: number, score: number, start: number}>\");\n    }\n}\nexport class HFInferenceFeatureExtractionTask extends HFInferenceTask {\n    async getResponse(response) {\n        const isNumArrayRec = (arr, maxDepth, curDepth = 0) => {\n            if (curDepth > maxDepth)\n                return false;\n            if (arr.every((x) => Array.isArray(x))) {\n                return arr.every((x) => isNumArrayRec(x, maxDepth, curDepth + 1));\n            }\n            else {\n                return arr.every((x) => typeof x === \"number\");\n            }\n        };\n        if (Array.isArray(response) && isNumArrayRec(response, 3, 0)) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference feature-extraction API: expected Array<number[][][] | number[][] | number[] | number>\");\n    }\n}\nexport class HFInferenceImageClassificationTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) && response.every((x) => typeof x.label === \"string\" && typeof x.score === \"number\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference image-classification API: expected Array<{label: string, score: number}>\");\n    }\n}\nexport class HFInferenceImageSegmentationTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) &&\n            response.every((x) => typeof x.label === \"string\" &&\n                typeof x.mask === \"string\" &&\n                (x.score === undefined || typeof x.score === \"number\"))) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference image-segmentation API: expected Array<{label: string, mask: string, score: number}>\");\n    }\n    async preparePayloadAsync(args) {\n        return {\n            ...args,\n            inputs: base64FromBytes(new Uint8Array(args.inputs instanceof ArrayBuffer ? args.inputs : await args.inputs.arrayBuffer())),\n        };\n    }\n}\nexport class HFInferenceImageToTextTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (typeof response?.generated_text !== \"string\") {\n            throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference image-to-text API: expected {generated_text: string}\");\n        }\n        return response;\n    }\n}\nexport class HFInferenceImageToImageTask extends HFInferenceTask {\n    async preparePayloadAsync(args) {\n        if (!args.parameters) {\n            return {\n                ...args,\n                model: args.model,\n                data: args.inputs,\n            };\n        }\n        else {\n            return {\n                ...args,\n                inputs: base64FromBytes(new Uint8Array(args.inputs instanceof ArrayBuffer ? args.inputs : await args.inputs.arrayBuffer())),\n            };\n        }\n    }\n    async getResponse(response) {\n        if (response instanceof Blob) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference image-to-image API: expected Blob\");\n    }\n}\nexport class HFInferenceObjectDetectionTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) &&\n            response.every((x) => typeof x.label === \"string\" &&\n                typeof x.score === \"number\" &&\n                typeof x.box.xmin === \"number\" &&\n                typeof x.box.ymin === \"number\" &&\n                typeof x.box.xmax === \"number\" &&\n                typeof x.box.ymax === \"number\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference object-detection API: expected Array<{label: string, score: number, box: {xmin: number, ymin: number, xmax: number, ymax: number}}>\");\n    }\n}\nexport class HFInferenceZeroShotImageClassificationTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) && response.every((x) => typeof x.label === \"string\" && typeof x.score === \"number\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference zero-shot-image-classification API: expected Array<{label: string, score: number}>\");\n    }\n}\nexport class HFInferenceTextClassificationTask extends HFInferenceTask {\n    async getResponse(response) {\n        const output = response?.[0];\n        if (Array.isArray(output) && output.every((x) => typeof x?.label === \"string\" && typeof x.score === \"number\")) {\n            return output;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference text-classification API: expected Array<{label: string, score: number}>\");\n    }\n}\nexport class HFInferenceQuestionAnsweringTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response)\n            ? response.every((elem) => typeof elem === \"object\" &&\n                !!elem &&\n                typeof elem.answer === \"string\" &&\n                typeof elem.end === \"number\" &&\n                typeof elem.score === \"number\" &&\n                typeof elem.start === \"number\")\n            : typeof response === \"object\" &&\n                !!response &&\n                typeof response.answer === \"string\" &&\n                typeof response.end === \"number\" &&\n                typeof response.score === \"number\" &&\n                typeof response.start === \"number\") {\n            return Array.isArray(response) ? response[0] : response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference question-answering API: expected Array<{answer: string, end: number, score: number, start: number}>\");\n    }\n}\nexport class HFInferenceFillMaskTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) &&\n            response.every((x) => typeof x.score === \"number\" &&\n                typeof x.sequence === \"string\" &&\n                typeof x.token === \"number\" &&\n                typeof x.token_str === \"string\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference fill-mask API: expected Array<{score: number, sequence: string, token: number, token_str: string}>\");\n    }\n}\nexport class HFInferenceZeroShotClassificationTask extends HFInferenceTask {\n    async getResponse(response) {\n        /// Handle Legacy response format from Inference API\n        if (typeof response === \"object\" &&\n            response !== null &&\n            \"labels\" in response &&\n            \"scores\" in response &&\n            Array.isArray(response.labels) &&\n            Array.isArray(response.scores) &&\n            response.labels.length === response.scores.length &&\n            response.labels.every((label) => typeof label === \"string\") &&\n            response.scores.every((score) => typeof score === \"number\")) {\n            const scores = response.scores;\n            return response.labels.map((label, index) => ({\n                label,\n                score: scores[index],\n            }));\n        }\n        if (Array.isArray(response) && response.every(HFInferenceZeroShotClassificationTask.validateOutputElement)) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference zero-shot-classification API: expected Array<{label: string, score: number}>\");\n    }\n    static validateOutputElement(elem) {\n        return (typeof elem === \"object\" &&\n            !!elem &&\n            \"label\" in elem &&\n            \"score\" in elem &&\n            typeof elem.label === \"string\" &&\n            typeof elem.score === \"number\");\n    }\n}\nexport class HFInferenceSentenceSimilarityTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) && response.every((x) => typeof x === \"number\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference sentence-similarity API: expected Array<number>\");\n    }\n}\nexport class HFInferenceTableQuestionAnsweringTask extends HFInferenceTask {\n    static validate(elem) {\n        return (typeof elem === \"object\" &&\n            !!elem &&\n            \"aggregator\" in elem &&\n            typeof elem.aggregator === \"string\" &&\n            \"answer\" in elem &&\n            typeof elem.answer === \"string\" &&\n            \"cells\" in elem &&\n            Array.isArray(elem.cells) &&\n            elem.cells.every((x) => typeof x === \"string\") &&\n            \"coordinates\" in elem &&\n            Array.isArray(elem.coordinates) &&\n            elem.coordinates.every((coord) => Array.isArray(coord) && coord.every((x) => typeof x === \"number\")));\n    }\n    async getResponse(response) {\n        if (Array.isArray(response) && Array.isArray(response)\n            ? response.every((elem) => HFInferenceTableQuestionAnsweringTask.validate(elem))\n            : HFInferenceTableQuestionAnsweringTask.validate(response)) {\n            return Array.isArray(response) ? response[0] : response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference table-question-answering API: expected {aggregator: string, answer: string, cells: string[], coordinates: number[][]}\");\n    }\n}\nexport class HFInferenceTokenClassificationTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) &&\n            response.every((x) => typeof x.end === \"number\" &&\n                typeof x.entity_group === \"string\" &&\n                typeof x.score === \"number\" &&\n                typeof x.start === \"number\" &&\n                typeof x.word === \"string\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference token-classification API: expected Array<{end: number, entity_group: string, score: number, start: number, word: string}>\");\n    }\n}\nexport class HFInferenceTranslationTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) && response.every((x) => typeof x?.translation_text === \"string\")) {\n            return response?.length === 1 ? response?.[0] : response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference translation API: expected Array<{translation_text: string}>\");\n    }\n}\nexport class HFInferenceSummarizationTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) && response.every((x) => typeof x?.summary_text === \"string\")) {\n            return response?.[0];\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference summarization API: expected Array<{summary_text: string}>\");\n    }\n}\nexport class HFInferenceTextToSpeechTask extends HFInferenceTask {\n    async getResponse(response) {\n        return response;\n    }\n}\nexport class HFInferenceTabularClassificationTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) && response.every((x) => typeof x === \"number\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference tabular-classification API: expected Array<number>\");\n    }\n}\nexport class HFInferenceVisualQuestionAnsweringTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) &&\n            response.every((elem) => typeof elem === \"object\" && !!elem && typeof elem?.answer === \"string\" && typeof elem.score === \"number\")) {\n            return response[0];\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference visual-question-answering API: expected Array<{answer: string, score: number}>\");\n    }\n}\nexport class HFInferenceTabularRegressionTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) && response.every((x) => typeof x === \"number\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference tabular-regression API: expected Array<number>\");\n    }\n}\nexport class HFInferenceTextToAudioTask extends HFInferenceTask {\n    async getResponse(response) {\n        return response;\n    }\n}\n","let globalLogger = console;\nexport function setLogger(logger) {\n    globalLogger = logger;\n}\nexport function getLogger() {\n    return globalLogger;\n}\n","import { HF_HUB_URL } from \"../config.js\";\nimport { HARDCODED_MODEL_INFERENCE_MAPPING } from \"../providers/consts.js\";\nimport { EQUIVALENT_SENTENCE_TRANSFORMERS_TASKS } from \"../providers/hf-inference.js\";\nimport { typedInclude } from \"../utils/typedInclude.js\";\nimport { InferenceClientHubApiError, InferenceClientInputError } from \"../errors.js\";\nimport { getLogger } from \"./logger.js\";\nexport const inferenceProviderMappingCache = new Map();\n/**\n * Normalize inferenceProviderMapping to always return an array format.\n * This provides backward and forward compatibility for the API changes.\n *\n * Vendored from @huggingface/hub to avoid extra dependency.\n */\nfunction normalizeInferenceProviderMapping(modelId, inferenceProviderMapping) {\n    if (!inferenceProviderMapping) {\n        return [];\n    }\n    // If it's already an array, return it as is\n    if (Array.isArray(inferenceProviderMapping)) {\n        return inferenceProviderMapping;\n    }\n    // Convert mapping to array format\n    return Object.entries(inferenceProviderMapping).map(([provider, mapping]) => ({\n        provider,\n        hfModelId: modelId,\n        providerId: mapping.providerId,\n        status: mapping.status,\n        task: mapping.task,\n        adapter: mapping.adapter,\n        adapterWeightsPath: mapping.adapterWeightsPath,\n    }));\n}\nexport async function fetchInferenceProviderMappingForModel(modelId, accessToken, options) {\n    let inferenceProviderMapping;\n    if (inferenceProviderMappingCache.has(modelId)) {\n        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n        inferenceProviderMapping = inferenceProviderMappingCache.get(modelId);\n    }\n    else {\n        const url = `${HF_HUB_URL}/api/models/${modelId}?expand[]=inferenceProviderMapping`;\n        const resp = await (options?.fetch ?? fetch)(url, {\n            headers: accessToken?.startsWith(\"hf_\") ? { Authorization: `Bearer ${accessToken}` } : {},\n        });\n        if (!resp.ok) {\n            if (resp.headers.get(\"Content-Type\")?.startsWith(\"application/json\")) {\n                const error = await resp.json();\n                if (\"error\" in error && typeof error.error === \"string\") {\n                    throw new InferenceClientHubApiError(`Failed to fetch inference provider mapping for model ${modelId}: ${error.error}`, { url, method: \"GET\" }, { requestId: resp.headers.get(\"x-request-id\") ?? \"\", status: resp.status, body: error });\n                }\n            }\n            else {\n                throw new InferenceClientHubApiError(`Failed to fetch inference provider mapping for model ${modelId}`, { url, method: \"GET\" }, { requestId: resp.headers.get(\"x-request-id\") ?? \"\", status: resp.status, body: await resp.text() });\n            }\n        }\n        let payload = null;\n        try {\n            payload = await resp.json();\n        }\n        catch {\n            throw new InferenceClientHubApiError(`Failed to fetch inference provider mapping for model ${modelId}: malformed API response, invalid JSON`, { url, method: \"GET\" }, { requestId: resp.headers.get(\"x-request-id\") ?? \"\", status: resp.status, body: await resp.text() });\n        }\n        if (!payload?.inferenceProviderMapping) {\n            throw new InferenceClientHubApiError(`We have not been able to find inference provider information for model ${modelId}.`, { url, method: \"GET\" }, { requestId: resp.headers.get(\"x-request-id\") ?? \"\", status: resp.status, body: await resp.text() });\n        }\n        inferenceProviderMapping = normalizeInferenceProviderMapping(modelId, payload.inferenceProviderMapping);\n        inferenceProviderMappingCache.set(modelId, inferenceProviderMapping);\n    }\n    return inferenceProviderMapping;\n}\nexport async function getInferenceProviderMapping(params, options) {\n    const logger = getLogger();\n    if (params.provider === \"auto\" && params.task === \"conversational\") {\n        // Special case for auto + conversational to avoid extra API calls\n        // Call directly the server-side auto router\n        return {\n            hfModelId: params.modelId,\n            provider: \"auto\",\n            providerId: params.modelId,\n            status: \"live\",\n            task: \"conversational\",\n        };\n    }\n    if (HARDCODED_MODEL_INFERENCE_MAPPING[params.provider][params.modelId]) {\n        return HARDCODED_MODEL_INFERENCE_MAPPING[params.provider][params.modelId];\n    }\n    const mappings = await fetchInferenceProviderMappingForModel(params.modelId, params.accessToken, options);\n    const providerMapping = mappings.find((mapping) => mapping.provider === params.provider);\n    if (providerMapping) {\n        const equivalentTasks = params.provider === \"hf-inference\" && typedInclude(EQUIVALENT_SENTENCE_TRANSFORMERS_TASKS, params.task)\n            ? EQUIVALENT_SENTENCE_TRANSFORMERS_TASKS\n            : [params.task];\n        if (!typedInclude(equivalentTasks, providerMapping.task)) {\n            throw new InferenceClientInputError(`Model ${params.modelId} is not supported for task ${params.task} and provider ${params.provider}. Supported task: ${providerMapping.task}.`);\n        }\n        if (providerMapping.status === \"staging\") {\n            logger.warn(`Model ${params.modelId} is in staging mode for provider ${params.provider}. Meant for test purposes only.`);\n        }\n        return providerMapping;\n    }\n    return null;\n}\nexport async function resolveProvider(provider, modelId, endpointUrl) {\n    const logger = getLogger();\n    if (endpointUrl) {\n        if (provider) {\n            throw new InferenceClientInputError(\"Specifying both endpointUrl and provider is not supported.\");\n        }\n        /// Defaulting to hf-inference helpers / API\n        return \"hf-inference\";\n    }\n    if (!provider) {\n        logger.log(\"Defaulting to 'auto' which will select the first provider available for the model, sorted by the user's order in https://hf.co/settings/inference-providers.\");\n        provider = \"auto\";\n    }\n    if (provider === \"auto\") {\n        if (!modelId) {\n            throw new InferenceClientInputError(\"Specifying a model is required when provider is 'auto'\");\n        }\n        const mappings = await fetchInferenceProviderMappingForModel(modelId);\n        provider = mappings[0]?.provider;\n        logger.log(\"Auto selected provider:\", provider);\n    }\n    if (!provider) {\n        throw new InferenceClientInputError(`No Inference Provider available for model ${modelId}.`);\n    }\n    return provider;\n}\n","export function delay(ms) {\n    return new Promise((resolve) => {\n        setTimeout(() => resolve(), ms);\n    });\n}\n","export function isUrl(modelOrUrl) {\n    return /^http(s?):/.test(modelOrUrl) || modelOrUrl.startsWith(\"/\");\n}\n","/**\n * See the registered mapping of HF model ID => Fal model ID here:\n *\n * https://huggingface.co/api/partners/fal-ai/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Fal and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Fal, please open an issue on the present repo\n * and we will tag Fal team members.\n *\n * Thanks!\n */\nimport { base64FromBytes } from \"../utils/base64FromBytes.js\";\nimport { isUrl } from \"../lib/isUrl.js\";\nimport { delay } from \"../utils/delay.js\";\nimport { omit } from \"../utils/omit.js\";\nimport { TaskProviderHelper, } from \"./providerHelper.js\";\nimport { HF_HUB_URL } from \"../config.js\";\nimport { InferenceClientInputError, InferenceClientProviderApiError, InferenceClientProviderOutputError, } from \"../errors.js\";\nexport const FAL_AI_SUPPORTED_BLOB_TYPES = [\"audio/mpeg\", \"audio/mp4\", \"audio/wav\", \"audio/x-wav\"];\nclass FalAITask extends TaskProviderHelper {\n    constructor(url) {\n        super(\"fal-ai\", url || \"https://fal.run\");\n    }\n    preparePayload(params) {\n        return params.args;\n    }\n    makeRoute(params) {\n        return `/${params.model}`;\n    }\n    prepareHeaders(params, binary) {\n        const headers = {\n            Authorization: params.authMethod !== \"provider-key\" ? `Bearer ${params.accessToken}` : `Key ${params.accessToken}`,\n        };\n        if (!binary) {\n            headers[\"Content-Type\"] = \"application/json\";\n        }\n        return headers;\n    }\n}\nclass FalAiQueueTask extends FalAITask {\n    async getResponseFromQueueApi(response, url, headers) {\n        if (!url || !headers) {\n            throw new InferenceClientInputError(`URL and headers are required for ${this.task} task`);\n        }\n        const requestId = response.request_id;\n        if (!requestId) {\n            throw new InferenceClientProviderOutputError(`Received malformed response from Fal.ai ${this.task} API: no request ID found in the response`);\n        }\n        let status = response.status;\n        const parsedUrl = new URL(url);\n        const baseUrl = `${parsedUrl.protocol}//${parsedUrl.host}${parsedUrl.host === \"router.huggingface.co\" ? \"/fal-ai\" : \"\"}`;\n        // extracting the provider model id for status and result urls\n        // from the response as it might be different from the mapped model in `url`\n        const modelId = new URL(response.response_url).pathname;\n        const queryParams = parsedUrl.search;\n        const statusUrl = `${baseUrl}${modelId}/status${queryParams}`;\n        const resultUrl = `${baseUrl}${modelId}${queryParams}`;\n        while (status !== \"COMPLETED\") {\n            await delay(500);\n            const statusResponse = await fetch(statusUrl, { headers });\n            if (!statusResponse.ok) {\n                throw new InferenceClientProviderApiError(\"Failed to fetch response status from fal-ai API\", { url: statusUrl, method: \"GET\" }, {\n                    requestId: statusResponse.headers.get(\"x-request-id\") ?? \"\",\n                    status: statusResponse.status,\n                    body: await statusResponse.text(),\n                });\n            }\n            try {\n                status = (await statusResponse.json()).status;\n            }\n            catch (error) {\n                throw new InferenceClientProviderOutputError(\"Failed to parse status response from fal-ai API: received malformed response\");\n            }\n        }\n        const resultResponse = await fetch(resultUrl, { headers });\n        let result;\n        try {\n            result = await resultResponse.json();\n        }\n        catch (error) {\n            throw new InferenceClientProviderOutputError(\"Failed to parse result response from fal-ai API: received malformed response\");\n        }\n        return result;\n    }\n}\nfunction buildLoraPath(modelId, adapterWeightsPath) {\n    return `${HF_HUB_URL}/${modelId}/resolve/main/${adapterWeightsPath}`;\n}\nexport class FalAITextToImageTask extends FalAITask {\n    preparePayload(params) {\n        const payload = {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            sync_mode: true,\n            prompt: params.args.inputs,\n        };\n        if (params.mapping?.adapter === \"lora\" && params.mapping.adapterWeightsPath) {\n            payload.loras = [\n                {\n                    path: buildLoraPath(params.mapping.hfModelId, params.mapping.adapterWeightsPath),\n                    scale: 1,\n                },\n            ];\n            if (params.mapping.providerId === \"fal-ai/lora\") {\n                payload.model_name = \"stabilityai/stable-diffusion-xl-base-1.0\";\n            }\n        }\n        return payload;\n    }\n    async getResponse(response, url, headers, outputType) {\n        if (typeof response === \"object\" &&\n            \"images\" in response &&\n            Array.isArray(response.images) &&\n            response.images.length > 0 &&\n            \"url\" in response.images[0] &&\n            typeof response.images[0].url === \"string\") {\n            if (outputType === \"json\") {\n                return { ...response };\n            }\n            if (outputType === \"url\") {\n                return response.images[0].url;\n            }\n            const urlResponse = await fetch(response.images[0].url);\n            return await urlResponse.blob();\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Fal.ai text-to-image API\");\n    }\n}\nexport class FalAIImageToImageTask extends FalAiQueueTask {\n    task;\n    constructor() {\n        super(\"https://queue.fal.run\");\n        this.task = \"image-to-image\";\n    }\n    makeRoute(params) {\n        if (params.authMethod !== \"provider-key\") {\n            return `/${params.model}?_subdomain=queue`;\n        }\n        return `/${params.model}`;\n    }\n    preparePayload(params) {\n        const payload = params.args;\n        if (params.mapping?.adapter === \"lora\" && params.mapping.adapterWeightsPath) {\n            payload.loras = [\n                {\n                    path: buildLoraPath(params.mapping.hfModelId, params.mapping.adapterWeightsPath),\n                    scale: 1,\n                },\n            ];\n        }\n        return payload;\n    }\n    async preparePayloadAsync(args) {\n        const mimeType = args.inputs instanceof Blob ? args.inputs.type : \"image/png\";\n        const imageDataUrl = `data:${mimeType};base64,${base64FromBytes(new Uint8Array(args.inputs instanceof ArrayBuffer ? args.inputs : await args.inputs.arrayBuffer()))}`;\n        return {\n            ...omit(args, [\"inputs\", \"parameters\"]),\n            image_url: imageDataUrl,\n            ...args.parameters,\n            ...args,\n            // Some fal endpoints (e.g. FLUX.2-dev) expect `image_urls` (array) instead of `image_url`\n            image_urls: [imageDataUrl],\n        };\n    }\n    async getResponse(response, url, headers) {\n        const result = await this.getResponseFromQueueApi(response, url, headers);\n        if (typeof result === \"object\" &&\n            !!result &&\n            \"images\" in result &&\n            Array.isArray(result.images) &&\n            result.images.length > 0 &&\n            typeof result.images[0] === \"object\" &&\n            !!result.images[0] &&\n            \"url\" in result.images[0] &&\n            typeof result.images[0].url === \"string\" &&\n            isUrl(result.images[0].url)) {\n            const urlResponse = await fetch(result.images[0].url);\n            return await urlResponse.blob();\n        }\n        else {\n            throw new InferenceClientProviderOutputError(`Received malformed response from Fal.ai image-to-image API: expected { images: Array<{ url: string }> } result format, got instead: ${JSON.stringify(result)}`);\n        }\n    }\n}\nexport class FalAITextToVideoTask extends FalAiQueueTask {\n    task;\n    constructor() {\n        super(\"https://queue.fal.run\");\n        this.task = \"text-to-video\";\n    }\n    makeRoute(params) {\n        if (params.authMethod !== \"provider-key\") {\n            return `/${params.model}?_subdomain=queue`;\n        }\n        return `/${params.model}`;\n    }\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            prompt: params.args.inputs,\n        };\n    }\n    async getResponse(response, url, headers) {\n        const result = await this.getResponseFromQueueApi(response, url, headers);\n        if (typeof result === \"object\" &&\n            !!result &&\n            \"video\" in result &&\n            typeof result.video === \"object\" &&\n            !!result.video &&\n            \"url\" in result.video &&\n            typeof result.video.url === \"string\" &&\n            isUrl(result.video.url)) {\n            const urlResponse = await fetch(result.video.url);\n            return await urlResponse.blob();\n        }\n        else {\n            throw new InferenceClientProviderOutputError(`Received malformed response from Fal.ai text-to-video API: expected { video: { url: string } } result format, got instead: ${JSON.stringify(result)}`);\n        }\n    }\n}\nexport class FalAIImageToVideoTask extends FalAiQueueTask {\n    task;\n    constructor() {\n        super(\"https://queue.fal.run\");\n        this.task = \"image-to-video\";\n    }\n    /** Same queue routing rule as the other Fal queue tasks */\n    makeRoute(params) {\n        return params.authMethod !== \"provider-key\" ? `/${params.model}?_subdomain=queue` : `/${params.model}`;\n    }\n    /** Synchronous case  caller already gave us base64 or a URL */\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            // args.inputs is expected to be a base64 data URI or an URL\n            image_url: params.args.image_url,\n        };\n    }\n    /** Asynchronous helper  caller gave us a Blob */\n    async preparePayloadAsync(args) {\n        const mimeType = args.inputs instanceof Blob ? args.inputs.type : \"image/png\";\n        return {\n            ...omit(args, [\"inputs\", \"parameters\"]),\n            image_url: `data:${mimeType};base64,${base64FromBytes(new Uint8Array(args.inputs instanceof ArrayBuffer ? args.inputs : await args.inputs.arrayBuffer()))}`,\n            ...args.parameters,\n            ...args,\n        };\n    }\n    /** Queue polling + final download  mirrors TexttoVideo */\n    async getResponse(response, url, headers) {\n        const result = await this.getResponseFromQueueApi(response, url, headers);\n        if (typeof result === \"object\" &&\n            result !== null &&\n            \"video\" in result &&\n            typeof result.video === \"object\" &&\n            result.video !== null &&\n            \"url\" in result.video &&\n            typeof result.video.url === \"string\" &&\n            \"url\" in result.video &&\n            isUrl(result.video.url)) {\n            const urlResponse = await fetch(result.video.url);\n            return await urlResponse.blob();\n        }\n        throw new InferenceClientProviderOutputError(`Received malformed response from Fal.ai imagetovideo API: expected { video: { url: string } }, got: ${JSON.stringify(result)}`);\n    }\n}\nexport class FalAIAutomaticSpeechRecognitionTask extends FalAITask {\n    prepareHeaders(params, binary) {\n        const headers = super.prepareHeaders(params, binary);\n        headers[\"Content-Type\"] = \"application/json\";\n        return headers;\n    }\n    async getResponse(response) {\n        const res = response;\n        if (typeof res?.text !== \"string\") {\n            throw new InferenceClientProviderOutputError(`Received malformed response from Fal.ai Automatic Speech Recognition API: expected { text: string } format, got instead: ${JSON.stringify(response)}`);\n        }\n        return { text: res.text };\n    }\n    async preparePayloadAsync(args) {\n        const blob = \"data\" in args && args.data instanceof Blob ? args.data : \"inputs\" in args ? args.inputs : undefined;\n        const contentType = blob?.type;\n        if (!contentType) {\n            throw new InferenceClientInputError(`Unable to determine the input's content-type. Make sure your are passing a Blob when using provider fal-ai.`);\n        }\n        if (!FAL_AI_SUPPORTED_BLOB_TYPES.includes(contentType)) {\n            throw new InferenceClientInputError(`Provider fal-ai does not support blob type ${contentType} - supported content types are: ${FAL_AI_SUPPORTED_BLOB_TYPES.join(\", \")}`);\n        }\n        const base64audio = base64FromBytes(new Uint8Array(await blob.arrayBuffer()));\n        return {\n            ...(\"data\" in args ? omit(args, \"data\") : omit(args, \"inputs\")),\n            audio_url: `data:${contentType};base64,${base64audio}`,\n        };\n    }\n}\nexport class FalAITextToSpeechTask extends FalAITask {\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            text: params.args.inputs,\n        };\n    }\n    async getResponse(response) {\n        const res = response;\n        if (typeof res?.audio?.url !== \"string\") {\n            throw new InferenceClientProviderOutputError(`Received malformed response from Fal.ai Text-to-Speech API: expected { audio: { url: string } } format, got instead: ${JSON.stringify(response)}`);\n        }\n        const urlResponse = await fetch(res.audio.url);\n        if (!urlResponse.ok) {\n            throw new InferenceClientProviderApiError(`Failed to fetch audio from ${res.audio.url}: ${urlResponse.statusText}`, { url: res.audio.url, method: \"GET\", headers: { \"Content-Type\": \"application/json\" } }, {\n                requestId: urlResponse.headers.get(\"x-request-id\") ?? \"\",\n                status: urlResponse.status,\n                body: await urlResponse.text(),\n            });\n        }\n        try {\n            return await urlResponse.blob();\n        }\n        catch (error) {\n            throw new InferenceClientProviderApiError(`Failed to fetch audio from ${res.audio.url}: ${error instanceof Error ? error.message : String(error)}`, { url: res.audio.url, method: \"GET\", headers: { \"Content-Type\": \"application/json\" } }, {\n                requestId: urlResponse.headers.get(\"x-request-id\") ?? \"\",\n                status: urlResponse.status,\n                body: await urlResponse.text(),\n            });\n        }\n    }\n}\nexport class FalAIImageSegmentationTask extends FalAiQueueTask {\n    task;\n    constructor() {\n        super(\"https://queue.fal.run\");\n        this.task = \"image-segmentation\";\n    }\n    makeRoute(params) {\n        if (params.authMethod !== \"provider-key\") {\n            return `/${params.model}?_subdomain=queue`;\n        }\n        return `/${params.model}`;\n    }\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            sync_mode: true,\n        };\n    }\n    async preparePayloadAsync(args) {\n        const blob = \"data\" in args && args.data instanceof Blob ? args.data : \"inputs\" in args ? args.inputs : undefined;\n        const mimeType = blob instanceof Blob ? blob.type : \"image/png\";\n        const base64Image = base64FromBytes(new Uint8Array(blob instanceof ArrayBuffer ? blob : await blob.arrayBuffer()));\n        return {\n            ...omit(args, [\"inputs\", \"parameters\", \"data\"]),\n            ...args.parameters,\n            ...args,\n            image_url: `data:${mimeType};base64,${base64Image}`,\n            sync_mode: true,\n        };\n    }\n    async getResponse(response, url, headers) {\n        const result = await this.getResponseFromQueueApi(response, url, headers);\n        if (typeof result === \"object\" &&\n            result !== null &&\n            \"image\" in result &&\n            typeof result.image === \"object\" &&\n            result.image !== null &&\n            \"url\" in result.image &&\n            typeof result.image.url === \"string\") {\n            const maskResponse = await fetch(result.image.url);\n            if (!maskResponse.ok) {\n                throw new InferenceClientProviderApiError(`Failed to fetch segmentation mask from ${result.image.url}`, { url: result.image.url, method: \"GET\" }, {\n                    requestId: maskResponse.headers.get(\"x-request-id\") ?? \"\",\n                    status: maskResponse.status,\n                    body: await maskResponse.text(),\n                });\n            }\n            const maskBlob = await maskResponse.blob();\n            const maskArrayBuffer = await maskBlob.arrayBuffer();\n            const maskBase64 = base64FromBytes(new Uint8Array(maskArrayBuffer));\n            return [\n                {\n                    label: \"mask\", // placeholder label, as Fal does not provide labels in the response(?)\n                    score: 1.0, // placeholder score, as Fal does not provide scores in the response(?)\n                    mask: maskBase64,\n                },\n            ];\n        }\n        throw new InferenceClientProviderOutputError(`Received malformed response from Fal.ai image-segmentation API: expected { image: { url: string } } format, got instead: ${JSON.stringify(response)}`);\n    }\n}\n","import { BaseConversationalTask, BaseTextGenerationTask } from \"./providerHelper.js\";\nimport { omit } from \"../utils/omit.js\";\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nconst FEATHERLESS_API_BASE_URL = \"https://api.featherless.ai\";\nexport class FeatherlessAIConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"featherless-ai\", FEATHERLESS_API_BASE_URL);\n    }\n}\nexport class FeatherlessAITextGenerationTask extends BaseTextGenerationTask {\n    constructor() {\n        super(\"featherless-ai\", FEATHERLESS_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            model: params.model,\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...(params.args.parameters\n                ? {\n                    max_tokens: params.args.parameters.max_new_tokens,\n                    ...omit(params.args.parameters, \"max_new_tokens\"),\n                }\n                : undefined),\n            prompt: params.args.inputs,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            \"choices\" in response &&\n            Array.isArray(response?.choices) &&\n            typeof response?.model === \"string\") {\n            const completion = response.choices[0];\n            return {\n                generated_text: completion.text,\n            };\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Featherless AI text generation API\");\n    }\n}\n","import { BaseConversationalTask, BaseTextGenerationTask } from \"./providerHelper.js\";\n/**\n * See the registered mapping of HF model ID => Groq model ID here:\n *\n * https://huggingface.co/api/partners/groq/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Groq and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Groq, please open an issue on the present repo\n * and we will tag Groq team members.\n *\n * Thanks!\n */\nconst GROQ_API_BASE_URL = \"https://api.groq.com\";\nexport class GroqTextGenerationTask extends BaseTextGenerationTask {\n    constructor() {\n        super(\"groq\", GROQ_API_BASE_URL);\n    }\n    makeRoute() {\n        return \"/openai/v1/chat/completions\";\n    }\n}\nexport class GroqConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"groq\", GROQ_API_BASE_URL);\n    }\n    makeRoute() {\n        return \"/openai/v1/chat/completions\";\n    }\n}\n","import { omit } from \"../utils/omit.js\";\nimport { BaseConversationalTask, BaseTextGenerationTask, TaskProviderHelper, } from \"./providerHelper.js\";\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nconst HYPERBOLIC_API_BASE_URL = \"https://api.hyperbolic.xyz\";\nexport class HyperbolicConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"hyperbolic\", HYPERBOLIC_API_BASE_URL);\n    }\n}\nexport class HyperbolicTextGenerationTask extends BaseTextGenerationTask {\n    constructor() {\n        super(\"hyperbolic\", HYPERBOLIC_API_BASE_URL);\n    }\n    makeRoute() {\n        return \"v1/chat/completions\";\n    }\n    preparePayload(params) {\n        return {\n            messages: [{ content: params.args.inputs, role: \"user\" }],\n            ...(params.args.parameters\n                ? {\n                    max_tokens: params.args.parameters.max_new_tokens,\n                    ...omit(params.args.parameters, \"max_new_tokens\"),\n                }\n                : undefined),\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            model: params.model,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            \"choices\" in response &&\n            Array.isArray(response?.choices) &&\n            typeof response?.model === \"string\") {\n            const completion = response.choices[0];\n            return {\n                generated_text: completion.message.content,\n            };\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Hyperbolic text generation API\");\n    }\n}\nexport class HyperbolicTextToImageTask extends TaskProviderHelper {\n    constructor() {\n        super(\"hyperbolic\", HYPERBOLIC_API_BASE_URL);\n    }\n    makeRoute(params) {\n        void params;\n        return `/v1/images/generations`;\n    }\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            prompt: params.args.inputs,\n            model_name: params.model,\n        };\n    }\n    async getResponse(response, url, headers, outputType) {\n        if (typeof response === \"object\" &&\n            \"images\" in response &&\n            Array.isArray(response.images) &&\n            response.images[0] &&\n            typeof response.images[0].image === \"string\") {\n            if (outputType === \"json\") {\n                return { ...response };\n            }\n            if (outputType === \"url\") {\n                return `data:image/jpeg;base64,${response.images[0].image}`;\n            }\n            return fetch(`data:image/jpeg;base64,${response.images[0].image}`).then((res) => res.blob());\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Hyperbolic text-to-image API\");\n    }\n}\n","import { omit } from \"../utils/omit.js\";\nimport { BaseConversationalTask, BaseTextGenerationTask, TaskProviderHelper, } from \"./providerHelper.js\";\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nconst NEBIUS_API_BASE_URL = \"https://api.studio.nebius.ai\";\nexport class NebiusConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"nebius\", NEBIUS_API_BASE_URL);\n    }\n    preparePayload(params) {\n        const payload = super.preparePayload(params);\n        const responseFormat = params.args.response_format;\n        if (responseFormat?.type === \"json_schema\" && responseFormat.json_schema?.schema) {\n            payload[\"guided_json\"] = responseFormat.json_schema.schema;\n        }\n        return payload;\n    }\n}\nexport class NebiusTextGenerationTask extends BaseTextGenerationTask {\n    constructor() {\n        super(\"nebius\", NEBIUS_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            ...params.args,\n            model: params.model,\n            prompt: params.args.inputs,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            \"choices\" in response &&\n            Array.isArray(response?.choices) &&\n            response.choices.length > 0 &&\n            typeof response.choices[0]?.text === \"string\") {\n            return {\n                generated_text: response.choices[0].text,\n            };\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Nebius text generation API\");\n    }\n}\nexport class NebiusTextToImageTask extends TaskProviderHelper {\n    constructor() {\n        super(\"nebius\", NEBIUS_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            response_format: \"b64_json\",\n            prompt: params.args.inputs,\n            model: params.model,\n        };\n    }\n    makeRoute() {\n        return \"v1/images/generations\";\n    }\n    async getResponse(response, url, headers, outputType) {\n        if (typeof response === \"object\" &&\n            \"data\" in response &&\n            Array.isArray(response.data) &&\n            response.data.length > 0 &&\n            \"b64_json\" in response.data[0] &&\n            typeof response.data[0].b64_json === \"string\") {\n            if (outputType === \"json\") {\n                return { ...response };\n            }\n            const base64Data = response.data[0].b64_json;\n            if (outputType === \"url\") {\n                return `data:image/jpeg;base64,${base64Data}`;\n            }\n            return fetch(`data:image/jpeg;base64,${base64Data}`).then((res) => res.blob());\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Nebius text-to-image API\");\n    }\n}\nexport class NebiusFeatureExtractionTask extends TaskProviderHelper {\n    constructor() {\n        super(\"nebius\", NEBIUS_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            input: params.args.inputs,\n            model: params.model,\n        };\n    }\n    makeRoute() {\n        return \"v1/embeddings\";\n    }\n    async getResponse(response) {\n        return response.data.map((item) => item.embedding);\n    }\n}\n","/**\n * See the registered mapping of HF model ID => Novita model ID here:\n *\n * https://huggingface.co/api/partners/novita/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Novita and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Novita, please open an issue on the present repo\n * and we will tag Novita team members.\n *\n * Thanks!\n */\nimport { isUrl } from \"../lib/isUrl.js\";\nimport { delay } from \"../utils/delay.js\";\nimport { omit } from \"../utils/omit.js\";\nimport { BaseConversationalTask, BaseTextGenerationTask, TaskProviderHelper, } from \"./providerHelper.js\";\nimport { InferenceClientInputError, InferenceClientProviderApiError, InferenceClientProviderOutputError, } from \"../errors.js\";\nconst NOVITA_API_BASE_URL = \"https://api.novita.ai\";\nexport class NovitaTextGenerationTask extends BaseTextGenerationTask {\n    constructor() {\n        super(\"novita\", NOVITA_API_BASE_URL);\n    }\n    makeRoute() {\n        return \"/v3/openai/chat/completions\";\n    }\n}\nexport class NovitaConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"novita\", NOVITA_API_BASE_URL);\n    }\n    makeRoute() {\n        return \"/v3/openai/chat/completions\";\n    }\n}\nexport class NovitaTextToVideoTask extends TaskProviderHelper {\n    constructor() {\n        super(\"novita\", NOVITA_API_BASE_URL);\n    }\n    makeRoute(params) {\n        return `/v3/async/${params.model}`;\n    }\n    preparePayload(params) {\n        const { num_inference_steps, ...restParameters } = params.args.parameters ?? {};\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...restParameters,\n            steps: num_inference_steps,\n            prompt: params.args.inputs,\n        };\n    }\n    async getResponse(response, url, headers) {\n        if (!url || !headers) {\n            throw new InferenceClientInputError(\"URL and headers are required for text-to-video task\");\n        }\n        const taskId = response.task_id;\n        if (!taskId) {\n            throw new InferenceClientProviderOutputError(\"Received malformed response from Novita text-to-video API: no task ID found in the response\");\n        }\n        const parsedUrl = new URL(url);\n        const baseUrl = `${parsedUrl.protocol}//${parsedUrl.host}${parsedUrl.host === \"router.huggingface.co\" ? \"/novita\" : \"\"}`;\n        const resultUrl = `${baseUrl}/v3/async/task-result?task_id=${taskId}`;\n        let status = \"\";\n        let taskResult;\n        while (status !== \"TASK_STATUS_SUCCEED\" && status !== \"TASK_STATUS_FAILED\") {\n            await delay(500);\n            const resultResponse = await fetch(resultUrl, { headers });\n            if (!resultResponse.ok) {\n                throw new InferenceClientProviderApiError(\"Failed to fetch task result\", { url: resultUrl, method: \"GET\", headers }, {\n                    requestId: resultResponse.headers.get(\"x-request-id\") ?? \"\",\n                    status: resultResponse.status,\n                    body: await resultResponse.text(),\n                });\n            }\n            try {\n                taskResult = await resultResponse.json();\n                if (taskResult &&\n                    typeof taskResult === \"object\" &&\n                    \"task\" in taskResult &&\n                    taskResult.task &&\n                    typeof taskResult.task === \"object\" &&\n                    \"status\" in taskResult.task &&\n                    typeof taskResult.task.status === \"string\") {\n                    status = taskResult.task.status;\n                }\n                else {\n                    throw new InferenceClientProviderOutputError(\"Received malformed response from Novita text-to-video API: failed to get task status\");\n                }\n            }\n            catch (error) {\n                throw new InferenceClientProviderOutputError(\"Received malformed response from Novita text-to-video API: failed to parse task result\");\n            }\n        }\n        if (status === \"TASK_STATUS_FAILED\") {\n            throw new InferenceClientProviderOutputError(\"Novita text-to-video task failed\");\n        }\n        if (typeof taskResult === \"object\" &&\n            !!taskResult &&\n            \"videos\" in taskResult &&\n            typeof taskResult.videos === \"object\" &&\n            !!taskResult.videos &&\n            Array.isArray(taskResult.videos) &&\n            taskResult.videos.length > 0 &&\n            \"video_url\" in taskResult.videos[0] &&\n            typeof taskResult.videos[0].video_url === \"string\" &&\n            isUrl(taskResult.videos[0].video_url)) {\n            const urlResponse = await fetch(taskResult.videos[0].video_url);\n            return await urlResponse.blob();\n        }\n        else {\n            throw new InferenceClientProviderOutputError(`Received malformed response from Novita text-to-video API: expected { videos: [{ video_url: string }] } format, got instead: ${JSON.stringify(taskResult)}`);\n        }\n    }\n}\n","import { omit } from \"../utils/omit.js\";\nimport { BaseConversationalTask, TaskProviderHelper } from \"./providerHelper.js\";\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nconst NSCALE_API_BASE_URL = \"https://inference.api.nscale.com\";\nexport class NscaleConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"nscale\", NSCALE_API_BASE_URL);\n    }\n}\nexport class NscaleTextToImageTask extends TaskProviderHelper {\n    constructor() {\n        super(\"nscale\", NSCALE_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            response_format: \"b64_json\",\n            prompt: params.args.inputs,\n            model: params.model,\n        };\n    }\n    makeRoute() {\n        return \"v1/images/generations\";\n    }\n    async getResponse(response, url, headers, outputType) {\n        if (typeof response === \"object\" &&\n            \"data\" in response &&\n            Array.isArray(response.data) &&\n            response.data.length > 0 &&\n            \"b64_json\" in response.data[0] &&\n            typeof response.data[0].b64_json === \"string\") {\n            if (outputType === \"json\") {\n                return { ...response };\n            }\n            const base64Data = response.data[0].b64_json;\n            if (outputType === \"url\") {\n                return `data:image/jpeg;base64,${base64Data}`;\n            }\n            return fetch(`data:image/jpeg;base64,${base64Data}`).then((res) => res.blob());\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Nscale text-to-image API\");\n    }\n}\n","/**\n * See the registered mapping of HF model ID => OVHcloud model ID here:\n *\n * https://huggingface.co/api/partners/ovhcloud/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at OVHcloud and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to OVHcloud, please open an issue on the present repo\n * and we will tag OVHcloud team members.\n *\n * Thanks!\n */\nimport { BaseConversationalTask, BaseTextGenerationTask } from \"./providerHelper.js\";\nimport { omit } from \"../utils/omit.js\";\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nconst OVHCLOUD_API_BASE_URL = \"https://oai.endpoints.kepler.ai.cloud.ovh.net\";\nexport class OvhCloudConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"ovhcloud\", OVHCLOUD_API_BASE_URL);\n    }\n}\nexport class OvhCloudTextGenerationTask extends BaseTextGenerationTask {\n    constructor() {\n        super(\"ovhcloud\", OVHCLOUD_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            model: params.model,\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...(params.args.parameters\n                ? {\n                    max_tokens: params.args.parameters.max_new_tokens,\n                    ...omit(params.args.parameters, \"max_new_tokens\"),\n                }\n                : undefined),\n            prompt: params.args.inputs,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            \"choices\" in response &&\n            Array.isArray(response?.choices) &&\n            typeof response?.model === \"string\") {\n            const completion = response.choices[0];\n            return {\n                generated_text: completion.text,\n            };\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from OVHcloud text generation API\");\n    }\n}\n","/**\n * See the registered mapping of HF model ID => Replicate model ID here:\n *\n * https://huggingface.co/api/partners/replicate/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Replicate and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Replicate, please open an issue on the present repo\n * and we will tag Replicate team members.\n *\n * Thanks!\n */\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nimport { isUrl } from \"../lib/isUrl.js\";\nimport { omit } from \"../utils/omit.js\";\nimport { TaskProviderHelper, } from \"./providerHelper.js\";\nimport { base64FromBytes } from \"../utils/base64FromBytes.js\";\nclass ReplicateTask extends TaskProviderHelper {\n    constructor(url) {\n        super(\"replicate\", url || \"https://api.replicate.com\");\n    }\n    makeRoute(params) {\n        if (params.model.includes(\":\")) {\n            return \"v1/predictions\";\n        }\n        return `v1/models/${params.model}/predictions`;\n    }\n    preparePayload(params) {\n        return {\n            input: {\n                ...omit(params.args, [\"inputs\", \"parameters\"]),\n                ...params.args.parameters,\n                prompt: params.args.inputs,\n            },\n            version: params.model.includes(\":\") ? params.model.split(\":\")[1] : undefined,\n        };\n    }\n    prepareHeaders(params, binary) {\n        const headers = { Authorization: `Bearer ${params.accessToken}`, Prefer: \"wait\" };\n        if (!binary) {\n            headers[\"Content-Type\"] = \"application/json\";\n        }\n        return headers;\n    }\n    makeUrl(params) {\n        const baseUrl = this.makeBaseUrl(params);\n        if (params.model.includes(\":\")) {\n            return `${baseUrl}/v1/predictions`;\n        }\n        return `${baseUrl}/v1/models/${params.model}/predictions`;\n    }\n}\nexport class ReplicateTextToImageTask extends ReplicateTask {\n    preparePayload(params) {\n        return {\n            input: {\n                ...omit(params.args, [\"inputs\", \"parameters\"]),\n                ...params.args.parameters,\n                prompt: params.args.inputs,\n                lora_weights: params.mapping?.adapter === \"lora\" && params.mapping.adapterWeightsPath\n                    ? `https://huggingface.co/${params.mapping.hfModelId}`\n                    : undefined,\n            },\n            version: params.model.includes(\":\") ? params.model.split(\":\")[1] : undefined,\n        };\n    }\n    async getResponse(res, url, headers, outputType) {\n        void url;\n        void headers;\n        // Handle string output\n        if (typeof res === \"object\" && \"output\" in res && typeof res.output === \"string\" && isUrl(res.output)) {\n            if (outputType === \"json\") {\n                return { ...res };\n            }\n            if (outputType === \"url\") {\n                return res.output;\n            }\n            const urlResponse = await fetch(res.output);\n            return await urlResponse.blob();\n        }\n        // Handle array output\n        if (typeof res === \"object\" &&\n            \"output\" in res &&\n            Array.isArray(res.output) &&\n            res.output.length > 0 &&\n            typeof res.output[0] === \"string\") {\n            if (outputType === \"json\") {\n                return { ...res };\n            }\n            if (outputType === \"url\") {\n                return res.output[0];\n            }\n            const urlResponse = await fetch(res.output[0]);\n            return await urlResponse.blob();\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Replicate text-to-image API\");\n    }\n}\nexport class ReplicateTextToSpeechTask extends ReplicateTask {\n    preparePayload(params) {\n        const payload = super.preparePayload(params);\n        const input = payload[\"input\"];\n        if (typeof input === \"object\" && input !== null && \"prompt\" in input) {\n            const inputObj = input;\n            inputObj[\"text\"] = inputObj[\"prompt\"];\n            delete inputObj[\"prompt\"];\n        }\n        return payload;\n    }\n    async getResponse(response) {\n        if (response instanceof Blob) {\n            return response;\n        }\n        if (response && typeof response === \"object\") {\n            if (\"output\" in response) {\n                if (typeof response.output === \"string\") {\n                    const urlResponse = await fetch(response.output);\n                    return await urlResponse.blob();\n                }\n                else if (Array.isArray(response.output)) {\n                    const urlResponse = await fetch(response.output[0]);\n                    return await urlResponse.blob();\n                }\n            }\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Replicate text-to-speech API\");\n    }\n}\nexport class ReplicateTextToVideoTask extends ReplicateTask {\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            !!response &&\n            \"output\" in response &&\n            typeof response.output === \"string\" &&\n            isUrl(response.output)) {\n            const urlResponse = await fetch(response.output);\n            return await urlResponse.blob();\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Replicate text-to-video API\");\n    }\n}\nexport class ReplicateAutomaticSpeechRecognitionTask extends ReplicateTask {\n    preparePayload(params) {\n        return {\n            input: {\n                ...omit(params.args, [\"inputs\", \"parameters\"]),\n                ...params.args.parameters,\n                audio: params.args.inputs, // This will be processed in preparePayloadAsync\n            },\n            version: params.model.includes(\":\") ? params.model.split(\":\")[1] : undefined,\n        };\n    }\n    async preparePayloadAsync(args) {\n        const blob = \"data\" in args && args.data instanceof Blob ? args.data : \"inputs\" in args ? args.inputs : undefined;\n        if (!blob || !(blob instanceof Blob)) {\n            throw new Error(\"Audio input must be a Blob\");\n        }\n        // Convert Blob to base64 data URL\n        const bytes = new Uint8Array(await blob.arrayBuffer());\n        const base64 = base64FromBytes(bytes);\n        const audioInput = `data:${blob.type || \"audio/wav\"};base64,${base64}`;\n        return {\n            ...(\"data\" in args ? omit(args, \"data\") : omit(args, \"inputs\")),\n            inputs: audioInput,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response?.output === \"string\")\n            return { text: response.output };\n        if (Array.isArray(response?.output) && typeof response.output[0] === \"string\")\n            return { text: response.output[0] };\n        const out = response?.output;\n        if (out && typeof out === \"object\") {\n            if (typeof out.transcription === \"string\")\n                return { text: out.transcription };\n            if (typeof out.translation === \"string\")\n                return { text: out.translation };\n            if (typeof out.txt_file === \"string\") {\n                const r = await fetch(out.txt_file);\n                return { text: await r.text() };\n            }\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Replicate automatic-speech-recognition API\");\n    }\n}\nexport class ReplicateImageToImageTask extends ReplicateTask {\n    preparePayload(params) {\n        return {\n            input: {\n                ...omit(params.args, [\"inputs\", \"parameters\"]),\n                ...params.args.parameters,\n                input_image: params.args.inputs, // This will be processed in preparePayloadAsync\n                lora_weights: params.mapping?.adapter === \"lora\" && params.mapping.adapterWeightsPath\n                    ? `https://huggingface.co/${params.mapping.hfModelId}`\n                    : undefined,\n            },\n            version: params.model.includes(\":\") ? params.model.split(\":\")[1] : undefined,\n        };\n    }\n    async preparePayloadAsync(args) {\n        const { inputs, ...restArgs } = args;\n        // Convert Blob to base64 data URL\n        const bytes = new Uint8Array(await inputs.arrayBuffer());\n        const base64 = base64FromBytes(bytes);\n        const imageInput = `data:${inputs.type || \"image/jpeg\"};base64,${base64}`;\n        return {\n            ...restArgs,\n            inputs: imageInput,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            !!response &&\n            \"output\" in response &&\n            Array.isArray(response.output) &&\n            response.output.length > 0 &&\n            typeof response.output[0] === \"string\") {\n            const urlResponse = await fetch(response.output[0]);\n            return await urlResponse.blob();\n        }\n        if (typeof response === \"object\" &&\n            !!response &&\n            \"output\" in response &&\n            typeof response.output === \"string\" &&\n            isUrl(response.output)) {\n            const urlResponse = await fetch(response.output);\n            return await urlResponse.blob();\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Replicate image-to-image API\");\n    }\n}\n","import { InferenceClientProviderOutputError } from \"../errors.js\";\nimport { BaseConversationalTask, TaskProviderHelper, BaseTextGenerationTask } from \"./providerHelper.js\";\nconst SCALEWAY_API_BASE_URL = \"https://api.scaleway.ai\";\nexport class ScalewayConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"scaleway\", SCALEWAY_API_BASE_URL);\n    }\n}\nexport class ScalewayTextGenerationTask extends BaseTextGenerationTask {\n    constructor() {\n        super(\"scaleway\", SCALEWAY_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            model: params.model,\n            ...params.args,\n            prompt: params.args.inputs,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            response !== null &&\n            \"choices\" in response &&\n            Array.isArray(response.choices) &&\n            response.choices.length > 0) {\n            const completion = response.choices[0];\n            if (typeof completion === \"object\" &&\n                !!completion &&\n                \"text\" in completion &&\n                completion.text &&\n                typeof completion.text === \"string\") {\n                return {\n                    generated_text: completion.text,\n                };\n            }\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Scaleway text generation API\");\n    }\n}\nexport class ScalewayFeatureExtractionTask extends TaskProviderHelper {\n    constructor() {\n        super(\"scaleway\", SCALEWAY_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            input: params.args.inputs,\n            model: params.model,\n        };\n    }\n    makeRoute() {\n        return \"v1/embeddings\";\n    }\n    async getResponse(response) {\n        return response.data.map((item) => item.embedding);\n    }\n}\n","import { omit } from \"../utils/omit.js\";\nimport { BaseConversationalTask, BaseTextGenerationTask, TaskProviderHelper, } from \"./providerHelper.js\";\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nconst TOGETHER_API_BASE_URL = \"https://api.together.xyz\";\nexport class TogetherConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"together\", TOGETHER_API_BASE_URL);\n    }\n    preparePayload(params) {\n        const payload = super.preparePayload(params);\n        const response_format = payload.response_format;\n        if (response_format?.type === \"json_schema\" && response_format?.json_schema?.schema) {\n            payload.response_format = {\n                type: \"json_schema\",\n                schema: response_format.json_schema.schema,\n            };\n        }\n        return payload;\n    }\n}\nexport class TogetherTextGenerationTask extends BaseTextGenerationTask {\n    constructor() {\n        super(\"together\", TOGETHER_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            model: params.model,\n            ...params.args,\n            prompt: params.args.inputs,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            \"choices\" in response &&\n            Array.isArray(response?.choices) &&\n            typeof response?.model === \"string\") {\n            const completion = response.choices[0];\n            return {\n                generated_text: completion.text,\n            };\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Together text generation API\");\n    }\n}\nexport class TogetherTextToImageTask extends TaskProviderHelper {\n    constructor() {\n        super(\"together\", TOGETHER_API_BASE_URL);\n    }\n    makeRoute() {\n        return \"v1/images/generations\";\n    }\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            prompt: params.args.inputs,\n            response_format: \"base64\",\n            model: params.model,\n        };\n    }\n    async getResponse(response, url, headers, outputType) {\n        if (typeof response === \"object\" &&\n            \"data\" in response &&\n            Array.isArray(response.data) &&\n            response.data.length > 0 &&\n            \"b64_json\" in response.data[0] &&\n            typeof response.data[0].b64_json === \"string\") {\n            if (outputType === \"json\") {\n                return { ...response };\n            }\n            const base64Data = response.data[0].b64_json;\n            if (outputType === \"url\") {\n                return `data:image/jpeg;base64,${base64Data}`;\n            }\n            return fetch(`data:image/jpeg;base64,${base64Data}`).then((res) => res.blob());\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Together text-to-image API\");\n    }\n}\n","import { delay } from \"../utils/delay.js\";\nimport { omit } from \"../utils/omit.js\";\nimport { base64FromBytes } from \"../utils/base64FromBytes.js\";\nimport { TaskProviderHelper } from \"./providerHelper.js\";\nimport { InferenceClientInputError, InferenceClientProviderApiError, InferenceClientProviderOutputError, } from \"../errors.js\";\nconst WAVESPEEDAI_API_BASE_URL = \"https://api.wavespeed.ai\";\nasync function buildImagesField(inputs, hasImages) {\n    const base = base64FromBytes(new Uint8Array(inputs instanceof ArrayBuffer ? inputs : await inputs.arrayBuffer()));\n    const images = Array.isArray(hasImages) && hasImages.every((value) => typeof value === \"string\")\n        ? hasImages\n        : [base];\n    return { base, images };\n}\nclass WavespeedAITask extends TaskProviderHelper {\n    constructor(url) {\n        super(\"wavespeed\", url || WAVESPEEDAI_API_BASE_URL);\n    }\n    makeRoute(params) {\n        return `/api/v3/${params.model}`;\n    }\n    preparePayload(params) {\n        const payload = {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...(params.args.parameters ? omit(params.args.parameters, [\"images\"]) : undefined),\n            prompt: params.args.inputs,\n        };\n        // Add LoRA support if adapter is specified in the mapping\n        if (params.mapping?.adapter === \"lora\") {\n            payload.loras = [\n                {\n                    path: params.mapping.hfModelId,\n                    scale: 1, // Default scale value\n                },\n            ];\n        }\n        return payload;\n    }\n    async getResponse(response, url, headers) {\n        if (!url || !headers) {\n            throw new InferenceClientInputError(\"Headers are required for WaveSpeed AI API calls\");\n        }\n        const parsedUrl = new URL(url);\n        const resultPath = new URL(response.data.urls.get).pathname;\n        /// override the base url to use the router.huggingface.co if going through huggingface router\n        const baseUrl = `${parsedUrl.protocol}//${parsedUrl.host}${parsedUrl.host === \"router.huggingface.co\" ? \"/wavespeed\" : \"\"}`;\n        const resultUrl = `${baseUrl}${resultPath}`;\n        // Poll for results until completion\n        while (true) {\n            const resultResponse = await fetch(resultUrl, { headers });\n            if (!resultResponse.ok) {\n                throw new InferenceClientProviderApiError(\"Failed to fetch response status from WaveSpeed AI API\", { url: resultUrl, method: \"GET\" }, {\n                    requestId: resultResponse.headers.get(\"x-request-id\") ?? \"\",\n                    status: resultResponse.status,\n                    body: await resultResponse.text(),\n                });\n            }\n            const result = await resultResponse.json();\n            const taskResult = result.data;\n            switch (taskResult.status) {\n                case \"completed\": {\n                    // Get the media data from the first output URL\n                    if (!taskResult.outputs?.[0]) {\n                        throw new InferenceClientProviderOutputError(\"Received malformed response from WaveSpeed AI API: No output URL in completed response\");\n                    }\n                    const mediaResponse = await fetch(taskResult.outputs[0]);\n                    if (!mediaResponse.ok) {\n                        throw new InferenceClientProviderApiError(\"Failed to fetch generation output from WaveSpeed AI API\", { url: taskResult.outputs[0], method: \"GET\" }, {\n                            requestId: mediaResponse.headers.get(\"x-request-id\") ?? \"\",\n                            status: mediaResponse.status,\n                            body: await mediaResponse.text(),\n                        });\n                    }\n                    return await mediaResponse.blob();\n                }\n                case \"failed\": {\n                    throw new InferenceClientProviderOutputError(taskResult.error || \"Task failed\");\n                }\n                default: {\n                    // Wait before polling again\n                    await delay(500);\n                    continue;\n                }\n            }\n        }\n    }\n}\nexport class WavespeedAITextToImageTask extends WavespeedAITask {\n    constructor() {\n        super(WAVESPEEDAI_API_BASE_URL);\n    }\n}\nexport class WavespeedAITextToVideoTask extends WavespeedAITask {\n    constructor() {\n        super(WAVESPEEDAI_API_BASE_URL);\n    }\n}\nexport class WavespeedAIImageToImageTask extends WavespeedAITask {\n    constructor() {\n        super(WAVESPEEDAI_API_BASE_URL);\n    }\n    async preparePayloadAsync(args) {\n        const hasImages = args.images ?? args.parameters?.images;\n        const { base, images } = await buildImagesField(args.inputs, hasImages);\n        return { ...args, inputs: args.parameters?.prompt, image: base, images };\n    }\n}\nexport class WavespeedAIImageToVideoTask extends WavespeedAITask {\n    constructor() {\n        super(WAVESPEEDAI_API_BASE_URL);\n    }\n    async preparePayloadAsync(args) {\n        const hasImages = args.images ?? args.parameters?.images;\n        const { base, images } = await buildImagesField(args.inputs, hasImages);\n        return { ...args, inputs: args.parameters?.prompt, image: base, images };\n    }\n}\n","import * as Baseten from \"../providers/baseten.js\";\nimport * as Clarifai from \"../providers/clarifai.js\";\nimport * as BlackForestLabs from \"../providers/black-forest-labs.js\";\nimport * as Cerebras from \"../providers/cerebras.js\";\nimport * as Cohere from \"../providers/cohere.js\";\nimport * as FalAI from \"../providers/fal-ai.js\";\nimport * as FeatherlessAI from \"../providers/featherless-ai.js\";\nimport * as Fireworks from \"../providers/fireworks-ai.js\";\nimport * as Groq from \"../providers/groq.js\";\nimport * as HFInference from \"../providers/hf-inference.js\";\nimport * as Hyperbolic from \"../providers/hyperbolic.js\";\nimport * as Nebius from \"../providers/nebius.js\";\nimport * as Novita from \"../providers/novita.js\";\nimport * as Nscale from \"../providers/nscale.js\";\nimport * as OpenAI from \"../providers/openai.js\";\nimport * as OvhCloud from \"../providers/ovhcloud.js\";\nimport * as PublicAI from \"../providers/publicai.js\";\nimport * as Replicate from \"../providers/replicate.js\";\nimport * as Sambanova from \"../providers/sambanova.js\";\nimport * as Scaleway from \"../providers/scaleway.js\";\nimport * as Together from \"../providers/together.js\";\nimport * as Wavespeed from \"../providers/wavespeed.js\";\nimport * as Zai from \"../providers/zai-org.js\";\nimport { InferenceClientInputError } from \"../errors.js\";\nexport const PROVIDERS = {\n    baseten: {\n        conversational: new Baseten.BasetenConversationalTask(),\n    },\n    \"black-forest-labs\": {\n        \"text-to-image\": new BlackForestLabs.BlackForestLabsTextToImageTask(),\n    },\n    cerebras: {\n        conversational: new Cerebras.CerebrasConversationalTask(),\n    },\n    clarifai: {\n        conversational: new Clarifai.ClarifaiConversationalTask(),\n    },\n    cohere: {\n        conversational: new Cohere.CohereConversationalTask(),\n    },\n    \"fal-ai\": {\n        \"text-to-image\": new FalAI.FalAITextToImageTask(),\n        \"text-to-speech\": new FalAI.FalAITextToSpeechTask(),\n        \"text-to-video\": new FalAI.FalAITextToVideoTask(),\n        \"image-to-image\": new FalAI.FalAIImageToImageTask(),\n        \"automatic-speech-recognition\": new FalAI.FalAIAutomaticSpeechRecognitionTask(),\n        \"image-segmentation\": new FalAI.FalAIImageSegmentationTask(),\n        \"image-to-video\": new FalAI.FalAIImageToVideoTask(),\n    },\n    \"featherless-ai\": {\n        conversational: new FeatherlessAI.FeatherlessAIConversationalTask(),\n        \"text-generation\": new FeatherlessAI.FeatherlessAITextGenerationTask(),\n    },\n    \"hf-inference\": {\n        \"text-to-image\": new HFInference.HFInferenceTextToImageTask(),\n        conversational: new HFInference.HFInferenceConversationalTask(),\n        \"text-generation\": new HFInference.HFInferenceTextGenerationTask(),\n        \"text-classification\": new HFInference.HFInferenceTextClassificationTask(),\n        \"question-answering\": new HFInference.HFInferenceQuestionAnsweringTask(),\n        \"audio-classification\": new HFInference.HFInferenceAudioClassificationTask(),\n        \"automatic-speech-recognition\": new HFInference.HFInferenceAutomaticSpeechRecognitionTask(),\n        \"fill-mask\": new HFInference.HFInferenceFillMaskTask(),\n        \"feature-extraction\": new HFInference.HFInferenceFeatureExtractionTask(),\n        \"image-classification\": new HFInference.HFInferenceImageClassificationTask(),\n        \"image-segmentation\": new HFInference.HFInferenceImageSegmentationTask(),\n        \"document-question-answering\": new HFInference.HFInferenceDocumentQuestionAnsweringTask(),\n        \"image-to-text\": new HFInference.HFInferenceImageToTextTask(),\n        \"object-detection\": new HFInference.HFInferenceObjectDetectionTask(),\n        \"audio-to-audio\": new HFInference.HFInferenceAudioToAudioTask(),\n        \"zero-shot-image-classification\": new HFInference.HFInferenceZeroShotImageClassificationTask(),\n        \"zero-shot-classification\": new HFInference.HFInferenceZeroShotClassificationTask(),\n        \"image-to-image\": new HFInference.HFInferenceImageToImageTask(),\n        \"sentence-similarity\": new HFInference.HFInferenceSentenceSimilarityTask(),\n        \"table-question-answering\": new HFInference.HFInferenceTableQuestionAnsweringTask(),\n        \"tabular-classification\": new HFInference.HFInferenceTabularClassificationTask(),\n        \"text-to-speech\": new HFInference.HFInferenceTextToSpeechTask(),\n        \"token-classification\": new HFInference.HFInferenceTokenClassificationTask(),\n        translation: new HFInference.HFInferenceTranslationTask(),\n        summarization: new HFInference.HFInferenceSummarizationTask(),\n        \"visual-question-answering\": new HFInference.HFInferenceVisualQuestionAnsweringTask(),\n        \"tabular-regression\": new HFInference.HFInferenceTabularRegressionTask(),\n        \"text-to-audio\": new HFInference.HFInferenceTextToAudioTask(),\n    },\n    \"fireworks-ai\": {\n        conversational: new Fireworks.FireworksConversationalTask(),\n    },\n    groq: {\n        conversational: new Groq.GroqConversationalTask(),\n        \"text-generation\": new Groq.GroqTextGenerationTask(),\n    },\n    hyperbolic: {\n        \"text-to-image\": new Hyperbolic.HyperbolicTextToImageTask(),\n        conversational: new Hyperbolic.HyperbolicConversationalTask(),\n        \"text-generation\": new Hyperbolic.HyperbolicTextGenerationTask(),\n    },\n    nebius: {\n        \"text-to-image\": new Nebius.NebiusTextToImageTask(),\n        conversational: new Nebius.NebiusConversationalTask(),\n        \"text-generation\": new Nebius.NebiusTextGenerationTask(),\n        \"feature-extraction\": new Nebius.NebiusFeatureExtractionTask(),\n    },\n    novita: {\n        conversational: new Novita.NovitaConversationalTask(),\n        \"text-generation\": new Novita.NovitaTextGenerationTask(),\n        \"text-to-video\": new Novita.NovitaTextToVideoTask(),\n    },\n    nscale: {\n        \"text-to-image\": new Nscale.NscaleTextToImageTask(),\n        conversational: new Nscale.NscaleConversationalTask(),\n    },\n    openai: {\n        conversational: new OpenAI.OpenAIConversationalTask(),\n    },\n    ovhcloud: {\n        conversational: new OvhCloud.OvhCloudConversationalTask(),\n        \"text-generation\": new OvhCloud.OvhCloudTextGenerationTask(),\n    },\n    publicai: {\n        conversational: new PublicAI.PublicAIConversationalTask(),\n    },\n    replicate: {\n        \"text-to-image\": new Replicate.ReplicateTextToImageTask(),\n        \"text-to-speech\": new Replicate.ReplicateTextToSpeechTask(),\n        \"text-to-video\": new Replicate.ReplicateTextToVideoTask(),\n        \"image-to-image\": new Replicate.ReplicateImageToImageTask(),\n        \"automatic-speech-recognition\": new Replicate.ReplicateAutomaticSpeechRecognitionTask(),\n    },\n    sambanova: {\n        conversational: new Sambanova.SambanovaConversationalTask(),\n        \"feature-extraction\": new Sambanova.SambanovaFeatureExtractionTask(),\n    },\n    scaleway: {\n        conversational: new Scaleway.ScalewayConversationalTask(),\n        \"text-generation\": new Scaleway.ScalewayTextGenerationTask(),\n        \"feature-extraction\": new Scaleway.ScalewayFeatureExtractionTask(),\n    },\n    together: {\n        \"text-to-image\": new Together.TogetherTextToImageTask(),\n        conversational: new Together.TogetherConversationalTask(),\n        \"text-generation\": new Together.TogetherTextGenerationTask(),\n    },\n    wavespeed: {\n        \"text-to-image\": new Wavespeed.WavespeedAITextToImageTask(),\n        \"text-to-video\": new Wavespeed.WavespeedAITextToVideoTask(),\n        \"image-to-image\": new Wavespeed.WavespeedAIImageToImageTask(),\n        \"image-to-video\": new Wavespeed.WavespeedAIImageToVideoTask(),\n    },\n    \"zai-org\": {\n        conversational: new Zai.ZaiConversationalTask(),\n    },\n};\nexport function getProviderHelper(provider, task) {\n    if ((provider === \"hf-inference\" && !task) || provider === \"auto\") {\n        return new HFInference.HFInferenceTask();\n    }\n    if (!task) {\n        throw new InferenceClientInputError(\"you need to provide a task name when using an external provider, e.g. 'text-to-image'\");\n    }\n    if (!(provider in PROVIDERS)) {\n        throw new InferenceClientInputError(`Provider '${provider}' not supported. Available providers: ${Object.keys(PROVIDERS)}`);\n    }\n    const providerTasks = PROVIDERS[provider];\n    if (!providerTasks || !(task in providerTasks)) {\n        throw new InferenceClientInputError(`Task '${task}' not supported for provider '${provider}'. Available tasks: ${Object.keys(providerTasks ?? {})}`);\n    }\n    return providerTasks[task];\n}\n","/**\n * See the registered mapping of HF model ID => Baseten model ID here:\n *\n * https://huggingface.co/api/partners/baseten/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Baseten and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Baseten, please open an issue on the present repo\n * and we will tag Baseten team members.\n *\n * Thanks!\n */\nimport { BaseConversationalTask } from \"./providerHelper.js\";\nconst BASETEN_API_BASE_URL = \"https://inference.baseten.co\";\nexport class BasetenConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"baseten\", BASETEN_API_BASE_URL);\n    }\n}\n","/**\n * See the registered mapping of HF model ID => Black Forest Labs model ID here:\n *\n * https://huggingface.co/api/partners/blackforestlabs/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Black Forest Labs and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Black Forest Labs, please open an issue on the present repo\n * and we will tag Black Forest Labs team members.\n *\n * Thanks!\n */\nimport { InferenceClientInputError, InferenceClientProviderApiError, InferenceClientProviderOutputError, } from \"../errors.js\";\nimport { getLogger } from \"../lib/logger.js\";\nimport { delay } from \"../utils/delay.js\";\nimport { omit } from \"../utils/omit.js\";\nimport { TaskProviderHelper } from \"./providerHelper.js\";\nconst BLACK_FOREST_LABS_AI_API_BASE_URL = \"https://api.us1.bfl.ai\";\nexport class BlackForestLabsTextToImageTask extends TaskProviderHelper {\n    constructor() {\n        super(\"black-forest-labs\", BLACK_FOREST_LABS_AI_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            prompt: params.args.inputs,\n        };\n    }\n    prepareHeaders(params, binary) {\n        const headers = {\n            Authorization: params.authMethod !== \"provider-key\" ? `Bearer ${params.accessToken}` : `X-Key ${params.accessToken}`,\n        };\n        if (!binary) {\n            headers[\"Content-Type\"] = \"application/json\";\n        }\n        return headers;\n    }\n    makeRoute(params) {\n        if (!params) {\n            throw new InferenceClientInputError(\"Params are required\");\n        }\n        return `/v1/${params.model}`;\n    }\n    async getResponse(response, url, headers, outputType) {\n        const logger = getLogger();\n        const urlObj = new URL(response.polling_url);\n        for (let step = 0; step < 5; step++) {\n            await delay(1000);\n            logger.debug(`Polling Black Forest Labs API for the result... ${step + 1}/5`);\n            urlObj.searchParams.set(\"attempt\", step.toString(10));\n            const resp = await fetch(urlObj, { headers: { \"Content-Type\": \"application/json\" } });\n            if (!resp.ok) {\n                throw new InferenceClientProviderApiError(\"Failed to fetch result from black forest labs API\", { url: urlObj.toString(), method: \"GET\", headers: { \"Content-Type\": \"application/json\" } }, { requestId: resp.headers.get(\"x-request-id\") ?? \"\", status: resp.status, body: await resp.text() });\n            }\n            const payload = await resp.json();\n            if (typeof payload === \"object\" &&\n                payload &&\n                \"status\" in payload &&\n                typeof payload.status === \"string\" &&\n                payload.status === \"Ready\" &&\n                \"result\" in payload &&\n                typeof payload.result === \"object\" &&\n                payload.result &&\n                \"sample\" in payload.result &&\n                typeof payload.result.sample === \"string\") {\n                if (outputType === \"json\") {\n                    return payload.result;\n                }\n                if (outputType === \"url\") {\n                    return payload.result.sample;\n                }\n                const image = await fetch(payload.result.sample);\n                return await image.blob();\n            }\n        }\n        throw new InferenceClientProviderOutputError(`Timed out while waiting for the result from black forest labs API - aborting after 5 attempts`);\n    }\n}\n","/**\n * See the registered mapping of HF model ID => Cerebras model ID here:\n *\n * https://huggingface.co/api/partners/cerebras/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Cerebras and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Cerebras, please open an issue on the present repo\n * and we will tag Cerebras team members.\n *\n * Thanks!\n */\nimport { BaseConversationalTask } from \"./providerHelper.js\";\nexport class CerebrasConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"cerebras\", \"https://api.cerebras.ai\");\n    }\n}\n","/**\n * See the registered mapping of HF model ID => Clarifai model ID here:\n *\n * https://huggingface.co/api/partners/clarifai/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Clarifai and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Clarifai, please open an issue on the present repo\n * and we will tag Clarifai team members.\n *\n * Thanks!\n */\nimport { BaseConversationalTask } from \"./providerHelper.js\";\nconst CLARIFAI_API_BASE_URL = \"https://api.clarifai.com\";\nexport class ClarifaiConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"clarifai\", CLARIFAI_API_BASE_URL);\n    }\n    makeRoute() {\n        return \"/v2/ext/openai/v1/chat/completions\";\n    }\n    prepareHeaders(params, isBinary) {\n        const headers = {\n            Authorization: params.authMethod !== \"provider-key\" ? `Bearer ${params.accessToken}` : `Key ${params.accessToken}`,\n        };\n        if (!isBinary) {\n            headers[\"Content-Type\"] = \"application/json\";\n        }\n        return headers;\n    }\n}\n","/**\n * See the registered mapping of HF model ID => Cohere model ID here:\n *\n * https://huggingface.co/api/partners/cohere/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Cohere and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Cohere, please open an issue on the present repo\n * and we will tag Cohere team members.\n *\n * Thanks!\n */\nimport { BaseConversationalTask } from \"./providerHelper.js\";\nexport class CohereConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"cohere\", \"https://api.cohere.com\");\n    }\n    makeRoute() {\n        return \"/compatibility/v1/chat/completions\";\n    }\n}\n","/**\n * See the registered mapping of HF model ID => Fireworks model ID here:\n *\n * https://huggingface.co/api/partners/fireworks/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Fireworks and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Fireworks, please open an issue on the present repo\n * and we will tag Fireworks team members.\n *\n * Thanks!\n */\nimport { BaseConversationalTask } from \"./providerHelper.js\";\nexport class FireworksConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"fireworks-ai\", \"https://api.fireworks.ai\");\n    }\n    makeRoute() {\n        return \"/inference/v1/chat/completions\";\n    }\n}\n","/**\n * Special case: provider configuration for a private models provider (OpenAI in this case).\n */\nimport { BaseConversationalTask } from \"./providerHelper.js\";\nconst OPENAI_API_BASE_URL = \"https://api.openai.com\";\nexport class OpenAIConversationalTask extends BaseConversationalTask {\n    constructor() {\n        // Pass clientSideRoutingOnly: true to the constructor\n        super(\"openai\", OPENAI_API_BASE_URL, true);\n    }\n}\n","import { BaseConversationalTask } from \"./providerHelper.js\";\nexport class PublicAIConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"publicai\", \"https://api.publicai.co\");\n    }\n}\n","import { BaseConversationalTask, TaskProviderHelper } from \"./providerHelper.js\";\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nexport class SambanovaConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"sambanova\", \"https://api.sambanova.ai\");\n    }\n    preparePayload(params) {\n        const responseFormat = params.args.response_format;\n        if (responseFormat?.type === \"json_schema\" && responseFormat.json_schema) {\n            if (responseFormat.json_schema.strict ?? true) {\n                responseFormat.json_schema.strict = false;\n            }\n        }\n        const payload = super.preparePayload(params);\n        return payload;\n    }\n}\nexport class SambanovaFeatureExtractionTask extends TaskProviderHelper {\n    constructor() {\n        super(\"sambanova\", \"https://api.sambanova.ai\");\n    }\n    makeRoute() {\n        return `/v1/embeddings`;\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" && \"data\" in response && Array.isArray(response.data)) {\n            return response.data.map((item) => item.embedding);\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Sambanova feature-extraction (embeddings) API\");\n    }\n    preparePayload(params) {\n        return {\n            model: params.model,\n            input: params.args.inputs,\n            ...params.args,\n        };\n    }\n}\n","/**\n * See the registered mapping of HF model ID => ZAI model ID here:\n *\n * https://huggingface.co/api/partners/zai-org/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at zai and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to zai, please open an issue on the present repo\n * and we will tag zai team members.\n *\n * Thanks!\n */\nimport { BaseConversationalTask } from \"./providerHelper.js\";\nconst ZAI_API_BASE_URL = \"https://api.z.ai\";\nexport class ZaiConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"zai-org\", ZAI_API_BASE_URL);\n    }\n    prepareHeaders(params, binary) {\n        const headers = super.prepareHeaders(params, binary);\n        headers[\"x-source-channel\"] = \"hugging_face\";\n        headers[\"accept-language\"] = \"en-US,en\";\n        return headers;\n    }\n    makeRoute() {\n        return \"/api/paas/v4/chat/completions\";\n    }\n}\n","function _OverloadYield(e, d) {\n  this.v = e, this.k = d;\n}\nexport { _OverloadYield as default };","import OverloadYield from \"./OverloadYield.js\";\nfunction _wrapAsyncGenerator(e) {\n  return function () {\n    return new AsyncGenerator(e.apply(this, arguments));\n  };\n}\nfunction AsyncGenerator(e) {\n  var r, t;\n  function resume(r, t) {\n    try {\n      var n = e[r](t),\n        o = n.value,\n        u = o instanceof OverloadYield;\n      Promise.resolve(u ? o.v : o).then(function (t) {\n        if (u) {\n          var i = \"return\" === r ? \"return\" : \"next\";\n          if (!o.k || t.done) return resume(i, t);\n          t = e[i](t).value;\n        }\n        settle(n.done ? \"return\" : \"normal\", t);\n      }, function (e) {\n        resume(\"throw\", e);\n      });\n    } catch (e) {\n      settle(\"throw\", e);\n    }\n  }\n  function settle(e, n) {\n    switch (e) {\n      case \"return\":\n        r.resolve({\n          value: n,\n          done: !0\n        });\n        break;\n      case \"throw\":\n        r.reject(n);\n        break;\n      default:\n        r.resolve({\n          value: n,\n          done: !1\n        });\n    }\n    (r = r.next) ? resume(r.key, r.arg) : t = null;\n  }\n  this._invoke = function (e, n) {\n    return new Promise(function (o, u) {\n      var i = {\n        key: e,\n        arg: n,\n        resolve: o,\n        reject: u,\n        next: null\n      };\n      t ? t = t.next = i : (r = t = i, resume(e, n));\n    });\n  }, \"function\" != typeof e[\"return\"] && (this[\"return\"] = void 0);\n}\nAsyncGenerator.prototype[\"function\" == typeof Symbol && Symbol.asyncIterator || \"@@asyncIterator\"] = function () {\n  return this;\n}, AsyncGenerator.prototype.next = function (e) {\n  return this._invoke(\"next\", e);\n}, AsyncGenerator.prototype[\"throw\"] = function (e) {\n  return this._invoke(\"throw\", e);\n}, AsyncGenerator.prototype[\"return\"] = function (e) {\n  return this._invoke(\"return\", e);\n};\nexport { _wrapAsyncGenerator as default };","import OverloadYield from \"./OverloadYield.js\";\nfunction _awaitAsyncGenerator(e) {\n  return new OverloadYield(e, 0);\n}\nexport { _awaitAsyncGenerator as default };","import OverloadYield from \"./OverloadYield.js\";\nfunction _asyncGeneratorDelegate(t) {\n  var e = {},\n    n = !1;\n  function pump(e, r) {\n    return n = !0, r = new Promise(function (n) {\n      n(t[e](r));\n    }), {\n      done: !1,\n      value: new OverloadYield(r, 1)\n    };\n  }\n  return e[\"undefined\" != typeof Symbol && Symbol.iterator || \"@@iterator\"] = function () {\n    return this;\n  }, e.next = function (t) {\n    return n ? (n = !1, t) : pump(\"next\", t);\n  }, \"function\" == typeof t[\"throw\"] && (e[\"throw\"] = function (t) {\n    if (n) throw n = !1, t;\n    return pump(\"throw\", t);\n  }), \"function\" == typeof t[\"return\"] && (e[\"return\"] = function (t) {\n    return n ? (n = !1, t) : pump(\"return\", t);\n  }), e;\n}\nexport { _asyncGeneratorDelegate as default };","function _asyncIterator(r) {\n  var n,\n    t,\n    o,\n    e = 2;\n  for (\"undefined\" != typeof Symbol && (t = Symbol.asyncIterator, o = Symbol.iterator); e--;) {\n    if (t && null != (n = r[t])) return n.call(r);\n    if (o && null != (n = r[o])) return new AsyncFromSyncIterator(n.call(r));\n    t = \"@@asyncIterator\", o = \"@@iterator\";\n  }\n  throw new TypeError(\"Object is not async iterable\");\n}\nfunction AsyncFromSyncIterator(r) {\n  function AsyncFromSyncIteratorContinuation(r) {\n    if (Object(r) !== r) return Promise.reject(new TypeError(r + \" is not an object.\"));\n    var n = r.done;\n    return Promise.resolve(r.value).then(function (r) {\n      return {\n        value: r,\n        done: n\n      };\n    });\n  }\n  return AsyncFromSyncIterator = function AsyncFromSyncIterator(r) {\n    this.s = r, this.n = r.next;\n  }, AsyncFromSyncIterator.prototype = {\n    s: null,\n    n: null,\n    next: function next() {\n      return AsyncFromSyncIteratorContinuation(this.n.apply(this.s, arguments));\n    },\n    \"return\": function _return(r) {\n      var n = this.s[\"return\"];\n      return void 0 === n ? Promise.resolve({\n        value: r,\n        done: !0\n      }) : AsyncFromSyncIteratorContinuation(n.apply(this.s, arguments));\n    },\n    \"throw\": function _throw(r) {\n      var n = this.s[\"return\"];\n      return void 0 === n ? Promise.reject(r) : AsyncFromSyncIteratorContinuation(n.apply(this.s, arguments));\n    }\n  }, new AsyncFromSyncIterator(r);\n}\nexport { _asyncIterator as default };","// Generated file from package.json. Issues importing JSON directly when publishing on commonjs/ESM - see https://github.com/microsoft/TypeScript/issues/51783\nexport const PACKAGE_VERSION = \"4.13.5\";\nexport const PACKAGE_NAME = \"@huggingface/inference\";\n","import { HF_HEADER_X_BILL_TO, HF_HUB_URL } from \"../config.js\";\nimport { PACKAGE_NAME, PACKAGE_VERSION } from \"../package.js\";\nimport { getInferenceProviderMapping } from \"./getInferenceProviderMapping.js\";\nimport { isUrl } from \"./isUrl.js\";\nimport { InferenceClientHubApiError, InferenceClientInputError } from \"../errors.js\";\n/**\n * Lazy-loaded from huggingface.co/api/tasks when needed\n * Used to determine the default model to use when it's not user defined\n */\nlet tasks = null;\n/**\n * Helper that prepares request arguments.\n * This async version handle the model ID resolution step.\n */\nexport async function makeRequestOptions(args, providerHelper, options) {\n    const { model: maybeModel } = args;\n    const provider = providerHelper.provider;\n    const { task } = options ?? {};\n    // Validate inputs\n    if (args.endpointUrl && provider !== \"hf-inference\") {\n        throw new InferenceClientInputError(`Cannot use endpointUrl with a third-party provider.`);\n    }\n    if (maybeModel && isUrl(maybeModel)) {\n        throw new InferenceClientInputError(`Model URLs are no longer supported. Use endpointUrl instead.`);\n    }\n    if (args.endpointUrl) {\n        // No need to have maybeModel, or to load default model for a task\n        return makeRequestOptionsFromResolvedModel(maybeModel ?? args.endpointUrl, providerHelper, args, undefined, options);\n    }\n    if (!maybeModel && !task) {\n        throw new InferenceClientInputError(\"No model provided, and no task has been specified.\");\n    }\n    // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n    const hfModel = maybeModel ?? (await loadDefaultModel(task));\n    if (providerHelper.clientSideRoutingOnly && !maybeModel) {\n        throw new InferenceClientInputError(`Provider ${provider} requires a model ID to be passed directly.`);\n    }\n    const inferenceProviderMapping = providerHelper.clientSideRoutingOnly\n        ? {\n            provider: provider,\n            // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n            providerId: removeProviderPrefix(maybeModel, provider),\n            // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n            hfModelId: maybeModel,\n            status: \"live\",\n            // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n            task: task,\n        }\n        : await getInferenceProviderMapping({\n            modelId: hfModel,\n            // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n            task: task,\n            provider,\n            accessToken: args.accessToken,\n        }, { fetch: options?.fetch });\n    if (!inferenceProviderMapping) {\n        throw new InferenceClientInputError(`We have not been able to find inference provider information for model ${hfModel}.`);\n    }\n    // Use the sync version with the resolved model\n    return makeRequestOptionsFromResolvedModel(inferenceProviderMapping.providerId, providerHelper, args, inferenceProviderMapping, options);\n}\n/**\n * Helper that prepares request arguments. - for internal use only\n * This sync version skips the model ID resolution step\n */\nexport function makeRequestOptionsFromResolvedModel(resolvedModel, providerHelper, args, mapping, options) {\n    const { accessToken, endpointUrl, provider: maybeProvider, model, ...remainingArgs } = args;\n    void model;\n    void maybeProvider;\n    const provider = providerHelper.provider;\n    const { includeCredentials, task, signal, billTo } = options ?? {};\n    const authMethod = (() => {\n        if (providerHelper.clientSideRoutingOnly) {\n            // Closed-source providers require an accessToken (cannot be routed).\n            if (accessToken && accessToken.startsWith(\"hf_\")) {\n                throw new InferenceClientInputError(`Provider ${provider} is closed-source and does not support HF tokens.`);\n            }\n        }\n        if (accessToken) {\n            return accessToken.startsWith(\"hf_\") ? \"hf-token\" : \"provider-key\";\n        }\n        if (includeCredentials === \"include\") {\n            // If accessToken is passed, it should take precedence over includeCredentials\n            return \"credentials-include\";\n        }\n        return \"none\";\n    })();\n    // Make URL\n    const modelId = endpointUrl ?? resolvedModel;\n    const url = providerHelper.makeUrl({\n        authMethod,\n        model: modelId,\n        task,\n    });\n    // Make headers\n    const headers = providerHelper.prepareHeaders({\n        accessToken,\n        authMethod,\n    }, \"data\" in args && !!args.data);\n    if (billTo) {\n        headers[HF_HEADER_X_BILL_TO] = billTo;\n    }\n    // Add user-agent to headers\n    // e.g. @huggingface/inference/3.1.3\n    const ownUserAgent = `${PACKAGE_NAME}/${PACKAGE_VERSION}`;\n    const userAgent = [ownUserAgent, typeof navigator !== \"undefined\" ? navigator.userAgent : undefined]\n        .filter((x) => x !== undefined)\n        .join(\" \");\n    headers[\"User-Agent\"] = userAgent;\n    // Make body\n    const body = providerHelper.makeBody({\n        args: remainingArgs,\n        model: resolvedModel,\n        task,\n        mapping,\n    });\n    /**\n     * For edge runtimes, leave 'credentials' undefined, otherwise cloudflare workers will error\n     */\n    let credentials;\n    if (typeof includeCredentials === \"string\") {\n        credentials = includeCredentials;\n    }\n    else if (includeCredentials === true) {\n        credentials = \"include\";\n    }\n    const info = {\n        headers,\n        method: \"POST\",\n        body: body,\n        ...(credentials ? { credentials } : undefined),\n        signal,\n    };\n    return { url, info };\n}\nasync function loadDefaultModel(task) {\n    if (!tasks) {\n        tasks = await loadTaskInfo();\n    }\n    const taskInfo = tasks[task];\n    if ((taskInfo?.models.length ?? 0) <= 0) {\n        throw new InferenceClientInputError(`No default model defined for task ${task}, please define the model explicitly.`);\n    }\n    return taskInfo.models[0].id;\n}\nasync function loadTaskInfo() {\n    const url = `${HF_HUB_URL}/api/tasks`;\n    const res = await fetch(url);\n    if (!res.ok) {\n        throw new InferenceClientHubApiError(\"Failed to load tasks definitions from Hugging Face Hub.\", { url, method: \"GET\" }, { requestId: res.headers.get(\"x-request-id\") ?? \"\", status: res.status, body: await res.text() });\n    }\n    return await res.json();\n}\nfunction removeProviderPrefix(model, provider) {\n    if (!model.startsWith(`${provider}/`)) {\n        throw new InferenceClientInputError(`Models from ${provider} must be prefixed by \"${provider}/\". Got \"${model}\".`);\n    }\n    return model.slice(provider.length + 1);\n}\n","/**\n This file is a part of fetch-event-source package (as of v2.0.1)\n https://github.com/Azure/fetch-event-source/blob/v2.0.1/src/parse.ts\n\n Full package can be used after it is made compatible with nodejs:\n https://github.com/Azure/fetch-event-source/issues/20\n\n Below is the fetch-event-source package license:\n\n MIT License\n\n Copyright (c) Microsoft Corporation.\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in all\n copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n SOFTWARE\n\n */\n/**\n * Converts a ReadableStream into a callback pattern.\n * @param stream The input ReadableStream.\n * @param onChunk A function that will be called on each new byte chunk in the stream.\n * @returns {Promise<void>} A promise that will be resolved when the stream closes.\n */\nexport async function getBytes(stream, onChunk) {\n    const reader = stream.getReader();\n    let result;\n    while (!(result = await reader.read()).done) {\n        onChunk(result.value);\n    }\n}\n/**\n * Parses arbitary byte chunks into EventSource line buffers.\n * Each line should be of the format \"field: value\" and ends with \\r, \\n, or \\r\\n.\n * @param onLine A function that will be called on each new EventSource line.\n * @returns A function that should be called for each incoming byte chunk.\n */\nexport function getLines(onLine) {\n    let buffer;\n    let position; // current read position\n    let fieldLength; // length of the `field` portion of the line\n    let discardTrailingNewline = false;\n    // return a function that can process each incoming byte chunk:\n    return function onChunk(arr) {\n        if (buffer === undefined) {\n            buffer = arr;\n            position = 0;\n            fieldLength = -1;\n        }\n        else {\n            // we're still parsing the old line. Append the new bytes into buffer:\n            buffer = concat(buffer, arr);\n        }\n        const bufLength = buffer.length;\n        let lineStart = 0; // index where the current line starts\n        while (position < bufLength) {\n            if (discardTrailingNewline) {\n                if (buffer[position] === 10 /* ControlChars.NewLine */) {\n                    lineStart = ++position; // skip to next char\n                }\n                discardTrailingNewline = false;\n            }\n            // start looking forward till the end of line:\n            let lineEnd = -1; // index of the \\r or \\n char\n            for (; position < bufLength && lineEnd === -1; ++position) {\n                switch (buffer[position]) {\n                    case 58 /* ControlChars.Colon */:\n                        if (fieldLength === -1) { // first colon in line\n                            fieldLength = position - lineStart;\n                        }\n                        break;\n                    case 13 /* ControlChars.CarriageReturn */:\n                        discardTrailingNewline = true;\n                    // eslint-disable-next-line no-fallthrough\n                    case 10 /* ControlChars.NewLine */:\n                        lineEnd = position;\n                        break;\n                }\n            }\n            if (lineEnd === -1) {\n                // We reached the end of the buffer but the line hasn't ended.\n                // Wait for the next arr and then continue parsing:\n                break;\n            }\n            // we've reached the line end, send it out:\n            onLine(buffer.subarray(lineStart, lineEnd), fieldLength);\n            lineStart = position; // we're now on the next line\n            fieldLength = -1;\n        }\n        if (lineStart === bufLength) {\n            buffer = undefined; // we've finished reading it\n        }\n        else if (lineStart !== 0) {\n            // Create a new view into buffer beginning at lineStart so we don't\n            // need to copy over the previous lines when we get the new arr:\n            buffer = buffer.subarray(lineStart);\n            position -= lineStart;\n        }\n    };\n}\n/**\n * Parses line buffers into EventSourceMessages.\n * @param onId A function that will be called on each `id` field.\n * @param onRetry A function that will be called on each `retry` field.\n * @param onMessage A function that will be called on each message.\n * @returns A function that should be called for each incoming line buffer.\n */\nexport function getMessages(onId, onRetry, onMessage) {\n    let message = newMessage();\n    const decoder = new TextDecoder();\n    // return a function that can process each incoming line buffer:\n    return function onLine(line, fieldLength) {\n        if (line.length === 0) {\n            // empty line denotes end of message. Trigger the callback and start a new message:\n            onMessage?.(message);\n            message = newMessage();\n        }\n        else if (fieldLength > 0) { // exclude comments and lines with no values\n            // line is of format \"<field>:<value>\" or \"<field>: <value>\"\n            // https://html.spec.whatwg.org/multipage/server-sent-events.html#event-stream-interpretation\n            const field = decoder.decode(line.subarray(0, fieldLength));\n            const valueOffset = fieldLength + (line[fieldLength + 1] === 32 /* ControlChars.Space */ ? 2 : 1);\n            const value = decoder.decode(line.subarray(valueOffset));\n            switch (field) {\n                case 'data':\n                    // if this message already has data, append the new value to the old.\n                    // otherwise, just set to the new value:\n                    message.data = message.data\n                        ? message.data + '\\n' + value\n                        : value; // otherwise, \n                    break;\n                case 'event':\n                    message.event = value;\n                    break;\n                case 'id':\n                    onId(message.id = value);\n                    break;\n                case 'retry': {\n                    const retry = parseInt(value, 10);\n                    if (!isNaN(retry)) { // per spec, ignore non-integers\n                        onRetry(message.retry = retry);\n                    }\n                    break;\n                }\n            }\n        }\n    };\n}\nfunction concat(a, b) {\n    const res = new Uint8Array(a.length + b.length);\n    res.set(a);\n    res.set(b, a.length);\n    return res;\n}\nfunction newMessage() {\n    // data, event, and id must be initialized to empty strings:\n    // https://html.spec.whatwg.org/multipage/server-sent-events.html#event-stream-interpretation\n    // retry should be initialized to undefined so we return a consistent shape\n    // to the js engine all the time: https://mathiasbynens.be/notes/shapes-ics#takeaways\n    return {\n        data: '',\n        event: '',\n        id: '',\n        retry: undefined,\n    };\n}\n","import { makeRequestOptions } from \"../lib/makeRequestOptions.js\";\nimport { getLines, getMessages } from \"../vendor/fetch-event-source/parse.js\";\nimport { InferenceClientProviderApiError } from \"../errors.js\";\nfunction bodyToJson(body) {\n    let data = null;\n    if (body instanceof Blob || body instanceof ArrayBuffer) {\n        data = \"[Blob or ArrayBuffer]\";\n    }\n    else if (typeof body === \"string\") {\n        try {\n            data = JSON.parse(body);\n        }\n        catch {\n            data = body;\n        }\n    }\n    if (data.accessToken) {\n        data.accessToken = \"[REDACTED]\";\n    }\n    return data;\n}\n/**\n * Primitive to make custom calls to the inference provider\n */\nexport async function innerRequest(args, providerHelper, options) {\n    const { url, info } = await makeRequestOptions(args, providerHelper, options);\n    const response = await (options?.fetch ?? fetch)(url, info);\n    const requestContext = { url, info };\n    if (options?.retry_on_error !== false && response.status === 503) {\n        return innerRequest(args, providerHelper, options);\n    }\n    if (!response.ok) {\n        const contentType = response.headers.get(\"Content-Type\");\n        if ([\"application/json\", \"application/problem+json\"].some((ct) => contentType?.startsWith(ct))) {\n            const output = await response.json();\n            if ([400, 422, 404, 500].includes(response.status) && options?.chatCompletion) {\n                throw new InferenceClientProviderApiError(`Provider ${args.provider} does not seem to support chat completion for model ${args.model} . Error: ${JSON.stringify(output.error)}`, {\n                    url,\n                    method: info.method ?? \"GET\",\n                    headers: info.headers,\n                    body: bodyToJson(info.body),\n                }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: output });\n            }\n            if (typeof output.error === \"string\" || typeof output.detail === \"string\" || typeof output.message === \"string\") {\n                throw new InferenceClientProviderApiError(`Failed to perform inference: ${output.error ?? output.detail ?? output.message}`, {\n                    url,\n                    method: info.method ?? \"GET\",\n                    headers: info.headers,\n                    body: bodyToJson(info.body),\n                }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: output });\n            }\n            else {\n                throw new InferenceClientProviderApiError(`Failed to perform inference: an HTTP error occurred when requesting the provider.`, {\n                    url,\n                    method: info.method ?? \"GET\",\n                    headers: info.headers,\n                    body: bodyToJson(info.body),\n                }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: output });\n            }\n        }\n        const message = contentType?.startsWith(\"text/plain;\") ? await response.text() : undefined;\n        throw new InferenceClientProviderApiError(`Failed to perform inference: ${message ?? \"an HTTP error occurred when requesting the provider\"}`, {\n            url,\n            method: info.method ?? \"GET\",\n            headers: info.headers,\n            body: bodyToJson(info.body),\n        }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: message ?? \"\" });\n    }\n    if (response.headers.get(\"Content-Type\")?.startsWith(\"application/json\")) {\n        const data = (await response.json());\n        return { data, requestContext };\n    }\n    const blob = (await response.blob());\n    return { data: blob, requestContext };\n}\n/**\n * Primitive to make custom inference calls that expect server-sent events, and returns the response through a generator\n */\nexport async function* innerStreamingRequest(args, providerHelper, options) {\n    const { url, info } = await makeRequestOptions({ ...args, stream: true }, providerHelper, options);\n    const response = await (options?.fetch ?? fetch)(url, info);\n    if (options?.retry_on_error !== false && response.status === 503) {\n        return yield* innerStreamingRequest(args, providerHelper, options);\n    }\n    if (!response.ok) {\n        if (response.headers.get(\"Content-Type\")?.startsWith(\"application/json\")) {\n            const output = await response.json();\n            if ([400, 422, 404, 500].includes(response.status) && options?.chatCompletion) {\n                throw new InferenceClientProviderApiError(`Provider ${args.provider} does not seem to support chat completion for model ${args.model} . Error: ${JSON.stringify(output.error)}`, {\n                    url,\n                    method: info.method ?? \"GET\",\n                    headers: info.headers,\n                    body: bodyToJson(info.body),\n                }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: output });\n            }\n            if (typeof output.error === \"string\") {\n                throw new InferenceClientProviderApiError(`Failed to perform inference: ${output.error}`, {\n                    url,\n                    method: info.method ?? \"GET\",\n                    headers: info.headers,\n                    body: bodyToJson(info.body),\n                }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: output });\n            }\n            if (output.error && \"message\" in output.error && typeof output.error.message === \"string\") {\n                /// OpenAI errors\n                throw new InferenceClientProviderApiError(`Failed to perform inference: ${output.error.message}`, {\n                    url,\n                    method: info.method ?? \"GET\",\n                    headers: info.headers,\n                    body: bodyToJson(info.body),\n                }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: output });\n            }\n            // Sambanova errors\n            if (typeof output.message === \"string\") {\n                throw new InferenceClientProviderApiError(`Failed to perform inference: ${output.message}`, {\n                    url,\n                    method: info.method ?? \"GET\",\n                    headers: info.headers,\n                    body: bodyToJson(info.body),\n                }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: output });\n            }\n        }\n        throw new InferenceClientProviderApiError(`Failed to perform inference: an HTTP error occurred when requesting the provider.`, {\n            url,\n            method: info.method ?? \"GET\",\n            headers: info.headers,\n            body: bodyToJson(info.body),\n        }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: \"\" });\n    }\n    if (!response.headers.get(\"content-type\")?.startsWith(\"text/event-stream\")) {\n        throw new InferenceClientProviderApiError(`Failed to perform inference: server does not support event stream content type, it returned ` +\n            response.headers.get(\"content-type\"), {\n            url,\n            method: info.method ?? \"GET\",\n            headers: info.headers,\n            body: bodyToJson(info.body),\n        }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: \"\" });\n    }\n    if (!response.body) {\n        return;\n    }\n    const reader = response.body.getReader();\n    let events = [];\n    const onEvent = (event) => {\n        // accumulate events in array\n        events.push(event);\n    };\n    const onChunk = getLines(getMessages(() => { }, () => { }, onEvent));\n    try {\n        while (true) {\n            const { done, value } = await reader.read();\n            if (done) {\n                return;\n            }\n            onChunk(value);\n            for (const event of events) {\n                if (event.data.length > 0) {\n                    if (event.data === \"[DONE]\") {\n                        return;\n                    }\n                    const data = JSON.parse(event.data);\n                    if (typeof data === \"object\" && data !== null && \"error\" in data) {\n                        const errorStr = typeof data.error === \"string\"\n                            ? data.error\n                            : typeof data.error === \"object\" &&\n                                data.error &&\n                                \"message\" in data.error &&\n                                typeof data.error.message === \"string\"\n                                ? data.error.message\n                                : JSON.stringify(data.error);\n                        throw new InferenceClientProviderApiError(`Failed to perform inference: an occurred while streaming the response: ${errorStr}`, {\n                            url,\n                            method: info.method ?? \"GET\",\n                            headers: info.headers,\n                            body: bodyToJson(info.body),\n                        }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: data });\n                    }\n                    yield data;\n                }\n            }\n            events = [];\n        }\n    }\n    finally {\n        reader.releaseLock();\n    }\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { getLogger } from \"../../lib/logger.js\";\n/**\n * Primitive to make custom calls to the inference provider\n * @deprecated Use specific task functions instead. This function will be removed in a future version.\n */\nexport async function request(args, options) {\n    const logger = getLogger();\n    logger.warn(\"The request method is deprecated and will be removed in a future version of huggingface.js. Use specific task functions instead.\");\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, options?.task);\n    const result = await innerRequest(args, providerHelper, options);\n    return result.data;\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerStreamingRequest } from \"../../utils/request.js\";\nimport { getLogger } from \"../../lib/logger.js\";\n/**\n * Primitive to make custom inference calls that expect server-sent events, and returns the response through a generator\n * @deprecated Use specific task functions instead. This function will be removed in a future version.\n */\nexport async function* streamingRequest(args, options) {\n    const logger = getLogger();\n    logger.warn(\"The streamingRequest method is deprecated and will be removed in a future version of huggingface.js. Use specific task functions instead.\");\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, options?.task);\n    yield* innerStreamingRequest(args, providerHelper, options);\n}\n","import { omit } from \"../../utils/omit.js\";\nexport function preparePayload(args) {\n    return \"data\" in args\n        ? args\n        : {\n            ...omit(args, \"inputs\"),\n            data: args.inputs,\n        };\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { preparePayload } from \"./utils.js\";\n/**\n * This task reads some audio input and outputs the likelihood of classes.\n * Recommended model:  superb/hubert-large-superb-er\n */\nexport async function audioClassification(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"audio-classification\");\n    const payload = preparePayload(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"audio-classification\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { preparePayload } from \"./utils.js\";\n/**\n * This task reads some audio input and outputs one or multiple audio files.\n * Example model: speechbrain/sepformer-wham does audio source separation.\n */\nexport async function audioToAudio(args, options) {\n    const model = \"inputs\" in args ? args.model : undefined;\n    const provider = await resolveProvider(args.provider, model);\n    const providerHelper = getProviderHelper(provider, \"audio-to-audio\");\n    const payload = preparePayload(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"audio-to-audio\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * This task reads some audio input and outputs the said words within the audio files.\n * Recommended model (english language): facebook/wav2vec2-large-960h-lv60-self\n */\nexport async function automaticSpeechRecognition(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"automatic-speech-recognition\");\n    const payload = await providerHelper.preparePayloadAsync(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"automatic-speech-recognition\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * This task synthesize an audio of a voice pronouncing a given text.\n * Recommended model: espnet/kan-bayashi_ljspeech_vits\n */\nexport async function textToSpeech(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"text-to-speech\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"text-to-speech\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { omit } from \"../../utils/omit.js\";\nexport function preparePayload(args) {\n    return \"data\" in args ? args : { ...omit(args, \"inputs\"), data: args.inputs };\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { preparePayload } from \"./utils.js\";\n/**\n * This task reads some image input and outputs the likelihood of classes.\n * Recommended model: google/vit-base-patch16-224\n */\nexport async function imageClassification(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"image-classification\");\n    const payload = preparePayload(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"image-classification\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { makeRequestOptions } from \"../../lib/makeRequestOptions.js\";\n/**\n * This task reads some image input and outputs the likelihood of classes & bounding boxes of detected objects.\n * Recommended model: facebook/detr-resnet-50-panoptic\n */\nexport async function imageSegmentation(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"image-segmentation\");\n    const payload = await providerHelper.preparePayloadAsync(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"image-segmentation\",\n    });\n    const { url, info } = await makeRequestOptions(args, providerHelper, { ...options, task: \"image-segmentation\" });\n    return providerHelper.getResponse(res, url, info.headers);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { makeRequestOptions } from \"../../lib/makeRequestOptions.js\";\n/**\n * This task reads some text input and outputs an image.\n * Recommended model: lllyasviel/sd-controlnet-depth\n */\nexport async function imageToImage(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"image-to-image\");\n    const payload = await providerHelper.preparePayloadAsync(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"image-to-image\",\n    });\n    const { url, info } = await makeRequestOptions(args, providerHelper, { ...options, task: \"image-to-image\" });\n    return providerHelper.getResponse(res, url, info.headers);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { preparePayload } from \"./utils.js\";\n/**\n * This task reads some image input and outputs the text caption.\n */\nexport async function imageToText(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"image-to-text\");\n    const payload = preparePayload(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"image-to-text\",\n    });\n    return providerHelper.getResponse(res[0]);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { makeRequestOptions } from \"../../lib/makeRequestOptions.js\";\n/**\n * This task reads some text input and outputs an image.\n * Recommended model: Wan-AI/Wan2.1-I2V-14B-720P\n */\nexport async function imageToVideo(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"image-to-video\");\n    const payload = await providerHelper.preparePayloadAsync(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"image-to-video\",\n    });\n    const { url, info } = await makeRequestOptions(args, providerHelper, { ...options, task: \"image-to-video\" });\n    return providerHelper.getResponse(res, url, info.headers);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * This task takes an image and text input and outputs a new generated image.\n * Recommended model: black-forest-labs/FLUX.2-dev\n */\nexport async function imageTextToImage(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"image-text-to-image\");\n    const payload = await providerHelper.preparePayloadAsync(args);\n    const { data: res, requestContext } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"image-text-to-image\",\n    });\n    return providerHelper.getResponse(res, requestContext.url, requestContext.info.headers);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * This task takes an image and text input and outputs a generated video.\n * Recommended model: Lightricks/LTX-Video\n */\nexport async function imageTextToVideo(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"image-text-to-video\");\n    const payload = await providerHelper.preparePayloadAsync(args);\n    const { data: res, requestContext } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"image-text-to-video\",\n    });\n    return providerHelper.getResponse(res, requestContext.url, requestContext.info.headers);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { preparePayload } from \"./utils.js\";\n/**\n * This task reads some image input and outputs the likelihood of classes & bounding boxes of detected objects.\n * Recommended model: facebook/detr-resnet-50\n */\nexport async function objectDetection(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"object-detection\");\n    const payload = preparePayload(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"object-detection\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { makeRequestOptions } from \"../../lib/makeRequestOptions.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nexport async function textToImage(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"text-to-image\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"text-to-image\",\n    });\n    const { url, info } = await makeRequestOptions(args, providerHelper, { ...options, task: \"text-to-image\" });\n    return providerHelper.getResponse(res, url, info.headers, options?.outputType);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { makeRequestOptions } from \"../../lib/makeRequestOptions.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nexport async function textToVideo(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"text-to-video\");\n    const { data: response } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"text-to-video\",\n    });\n    const { url, info } = await makeRequestOptions(args, providerHelper, { ...options, task: \"text-to-video\" });\n    return providerHelper.getResponse(response, url, info.headers);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { base64FromBytes } from \"../../utils/base64FromBytes.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nasync function preparePayload(args) {\n    if (args.inputs instanceof Blob) {\n        return {\n            ...args,\n            inputs: {\n                image: base64FromBytes(new Uint8Array(await args.inputs.arrayBuffer())),\n            },\n        };\n    }\n    else {\n        return {\n            ...args,\n            inputs: {\n                image: base64FromBytes(new Uint8Array(args.inputs.image instanceof ArrayBuffer ? args.inputs.image : await args.inputs.image.arrayBuffer())),\n            },\n        };\n    }\n}\n/**\n * Classify an image to specified classes.\n * Recommended model: openai/clip-vit-large-patch14-336\n */\nexport async function zeroShotImageClassification(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"zero-shot-image-classification\");\n    const payload = await preparePayload(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"zero-shot-image-classification\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { AutoRouterConversationalTask } from \"../../providers/providerHelper.js\";\n/**\n * Use the chat completion endpoint to generate a response to a prompt, using OpenAI message completion API no stream\n */\nexport async function chatCompletion(args, options) {\n    let providerHelper;\n    if (!args.provider || args.provider === \"auto\") {\n        // Special case: we have a dedicated auto-router for conversational models. No need to fetch provider mapping.\n        providerHelper = new AutoRouterConversationalTask();\n    }\n    else {\n        const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n        providerHelper = getProviderHelper(provider, \"conversational\");\n    }\n    const { data: response } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"conversational\",\n    });\n    return providerHelper.getResponse(response);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerStreamingRequest } from \"../../utils/request.js\";\nimport { AutoRouterConversationalTask } from \"../../providers/providerHelper.js\";\n/**\n * Use to continue text from a prompt. Same as `textGeneration` but returns generator that can be read one token at a time\n */\nexport async function* chatCompletionStream(args, options) {\n    let providerHelper;\n    if (!args.provider || args.provider === \"auto\") {\n        // Special case: we have a dedicated auto-router for conversational models. No need to fetch provider mapping.\n        providerHelper = new AutoRouterConversationalTask();\n    }\n    else {\n        const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n        providerHelper = getProviderHelper(provider, \"conversational\");\n    }\n    yield* innerStreamingRequest(args, providerHelper, {\n        ...options,\n        task: \"conversational\",\n    });\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * This task reads some text and outputs raw float values, that are usually consumed as part of a semantic database/semantic search.\n */\nexport async function featureExtraction(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"feature-extraction\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"feature-extraction\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Tries to fill in a hole with a missing word (token to be precise). Thats the base task for BERT models.\n */\nexport async function fillMask(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"fill-mask\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"fill-mask\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Want to have a nice know-it-all bot that can answer any question?. Recommended model: deepset/roberta-base-squad2\n */\nexport async function questionAnswering(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"question-answering\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"question-answering\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Calculate the semantic similarity between one text and a list of other sentences by comparing their embeddings.\n */\nexport async function sentenceSimilarity(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"sentence-similarity\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"sentence-similarity\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * This task is well known to summarize longer text into shorter text. Be careful, some models have a maximum length of input. That means that the summary cannot handle full books for instance. Be careful when choosing your model.\n */\nexport async function summarization(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"summarization\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"summarization\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Dont know SQL? Dont want to dive into a large spreadsheet? Ask questions in plain english! Recommended model: google/tapas-base-finetuned-wtq.\n */\nexport async function tableQuestionAnswering(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"table-question-answering\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"table-question-answering\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Usually used for sentiment-analysis this will output the likelihood of classes of an input. Recommended model: distilbert-base-uncased-finetuned-sst-2-english\n */\nexport async function textClassification(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"text-classification\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"text-classification\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Use to continue text from a prompt. This is a very generic task. Recommended model: gpt2 (its a simple model, but fun to play with).\n */\nexport async function textGeneration(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"text-generation\");\n    const { data: response } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"text-generation\",\n    });\n    return providerHelper.getResponse(response);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerStreamingRequest } from \"../../utils/request.js\";\n/**\n * Use to continue text from a prompt. Same as `textGeneration` but returns generator that can be read one token at a time\n */\nexport async function* textGenerationStream(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"text-generation\");\n    yield* innerStreamingRequest(args, providerHelper, {\n        ...options,\n        task: \"text-generation\",\n    });\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Usually used for sentence parsing, either grammatical, or Named Entity Recognition (NER) to understand keywords contained within text. Recommended model: dbmdz/bert-large-cased-finetuned-conll03-english\n */\nexport async function tokenClassification(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"token-classification\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"token-classification\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * This task is well known to translate text from one language to another. Recommended model: Helsinki-NLP/opus-mt-ru-en.\n */\nexport async function translation(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"translation\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"translation\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * This task is super useful to try out classification with zero code, you simply pass a sentence/paragraph and the possible labels for that sentence, and you get a result. Recommended model: facebook/bart-large-mnli.\n */\nexport async function zeroShotClassification(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"zero-shot-classification\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"zero-shot-classification\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { base64FromBytes } from \"../../utils/base64FromBytes.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Answers a question on a document image. Recommended model: impira/layoutlm-document-qa.\n */\nexport async function documentQuestionAnswering(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"document-question-answering\");\n    const reqArgs = {\n        ...args,\n        inputs: {\n            question: args.inputs.question,\n            // convert Blob or ArrayBuffer to base64\n            image: base64FromBytes(new Uint8Array(await args.inputs.image.arrayBuffer())),\n        },\n    };\n    const { data: res } = await innerRequest(reqArgs, providerHelper, {\n        ...options,\n        task: \"document-question-answering\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { base64FromBytes } from \"../../utils/base64FromBytes.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Answers a question on an image. Recommended model: dandelin/vilt-b32-finetuned-vqa.\n */\nexport async function visualQuestionAnswering(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"visual-question-answering\");\n    const reqArgs = {\n        ...args,\n        inputs: {\n            question: args.inputs.question,\n            // convert Blob or ArrayBuffer to base64\n            image: base64FromBytes(new Uint8Array(await args.inputs.image.arrayBuffer())),\n        },\n    };\n    const { data: res } = await innerRequest(reqArgs, providerHelper, {\n        ...options,\n        task: \"visual-question-answering\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Predicts target label for a given set of features in tabular form.\n * Typically, you will want to train a classification model on your training data and use it with your new data of the same format.\n * Example model: vvmnnnkv/wine-quality\n */\nexport async function tabularClassification(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"tabular-classification\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"tabular-classification\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Predicts target value for a given set of features in tabular form.\n * Typically, you will want to train a regression model on your training data and use it with your new data of the same format.\n * Example model: scikit-learn/Fish-Weight\n */\nexport async function tabularRegression(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"tabular-regression\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"tabular-regression\",\n    });\n    return providerHelper.getResponse(res);\n}\n","import * as tasks from \"./tasks/index.js\";\nimport { omit } from \"./utils/omit.js\";\nimport { typedEntries } from \"./utils/typedEntries.js\";\nexport class InferenceClient {\n    accessToken;\n    defaultOptions;\n    constructor(accessToken = \"\", defaultOptions = {}) {\n        this.accessToken = accessToken;\n        this.defaultOptions = defaultOptions;\n        for (const [name, fn] of typedEntries(tasks)) {\n            Object.defineProperty(this, name, {\n                enumerable: false,\n                value: (params, options) => \n                // eslint-disable-next-line @typescript-eslint/no-explicit-any\n                fn(\n                /// ^ The cast of fn to any is necessary, otherwise TS can't compile because the generated union type is too complex\n                { endpointUrl: defaultOptions.endpointUrl, accessToken, ...params }, {\n                    ...omit(defaultOptions, [\"endpointUrl\"]),\n                    ...options,\n                }),\n            });\n        }\n    }\n    /**\n     * Returns a new instance of InferenceClient tied to a specified endpoint.\n     *\n     * For backward compatibility mostly.\n     */\n    endpoint(endpointUrl) {\n        return new InferenceClient(this.accessToken, { ...this.defaultOptions, endpointUrl });\n    }\n}\n/**\n * For backward compatibility only, will remove soon.\n * @deprecated replace with InferenceClient\n */\nexport class HfInference extends InferenceClient {\n}\n/**\n * For backward compatibility only, will remove soon.\n * @deprecated replace with InferenceClient\n */\nexport class InferenceClientEndpoint extends InferenceClient {\n}\n","export function typedEntries(obj) {\n    return Object.entries(obj);\n}\n","// src/lexer.ts\nvar TOKEN_TYPES = Object.freeze({\n  Text: \"Text\",\n  // The text between Jinja statements or expressions\n  NumericLiteral: \"NumericLiteral\",\n  // e.g., 123, 1.0\n  StringLiteral: \"StringLiteral\",\n  // 'string'\n  Identifier: \"Identifier\",\n  // Variables, functions, statements, booleans, etc.\n  Equals: \"Equals\",\n  // =\n  OpenParen: \"OpenParen\",\n  // (\n  CloseParen: \"CloseParen\",\n  // )\n  OpenStatement: \"OpenStatement\",\n  // {%\n  CloseStatement: \"CloseStatement\",\n  // %}\n  OpenExpression: \"OpenExpression\",\n  // {{\n  CloseExpression: \"CloseExpression\",\n  // }}\n  OpenSquareBracket: \"OpenSquareBracket\",\n  // [\n  CloseSquareBracket: \"CloseSquareBracket\",\n  // ]\n  OpenCurlyBracket: \"OpenCurlyBracket\",\n  // {\n  CloseCurlyBracket: \"CloseCurlyBracket\",\n  // }\n  Comma: \"Comma\",\n  // ,\n  Dot: \"Dot\",\n  // .\n  Colon: \"Colon\",\n  // :\n  Pipe: \"Pipe\",\n  // |\n  CallOperator: \"CallOperator\",\n  // ()\n  AdditiveBinaryOperator: \"AdditiveBinaryOperator\",\n  // + - ~\n  MultiplicativeBinaryOperator: \"MultiplicativeBinaryOperator\",\n  // * / %\n  ComparisonBinaryOperator: \"ComparisonBinaryOperator\",\n  // < > <= >= == !=\n  UnaryOperator: \"UnaryOperator\",\n  // ! - +\n  Comment: \"Comment\"\n  // {# ... #}\n});\nvar Token = class {\n  /**\n   * Constructs a new Token.\n   * @param {string} value The raw value as seen inside the source code.\n   * @param {TokenType} type The type of token.\n   */\n  constructor(value, type) {\n    this.value = value;\n    this.type = type;\n  }\n};\nfunction isWord(char) {\n  return /\\w/.test(char);\n}\nfunction isInteger(char) {\n  return /[0-9]/.test(char);\n}\nfunction isWhitespace(char) {\n  return /\\s/.test(char);\n}\nvar ORDERED_MAPPING_TABLE = [\n  // Control sequences\n  [\"{%\", TOKEN_TYPES.OpenStatement],\n  [\"%}\", TOKEN_TYPES.CloseStatement],\n  [\"{{\", TOKEN_TYPES.OpenExpression],\n  [\"}}\", TOKEN_TYPES.CloseExpression],\n  // Single character tokens\n  [\"(\", TOKEN_TYPES.OpenParen],\n  [\")\", TOKEN_TYPES.CloseParen],\n  [\"{\", TOKEN_TYPES.OpenCurlyBracket],\n  [\"}\", TOKEN_TYPES.CloseCurlyBracket],\n  [\"[\", TOKEN_TYPES.OpenSquareBracket],\n  [\"]\", TOKEN_TYPES.CloseSquareBracket],\n  [\",\", TOKEN_TYPES.Comma],\n  [\".\", TOKEN_TYPES.Dot],\n  [\":\", TOKEN_TYPES.Colon],\n  [\"|\", TOKEN_TYPES.Pipe],\n  // Comparison operators\n  [\"<=\", TOKEN_TYPES.ComparisonBinaryOperator],\n  [\">=\", TOKEN_TYPES.ComparisonBinaryOperator],\n  [\"==\", TOKEN_TYPES.ComparisonBinaryOperator],\n  [\"!=\", TOKEN_TYPES.ComparisonBinaryOperator],\n  [\"<\", TOKEN_TYPES.ComparisonBinaryOperator],\n  [\">\", TOKEN_TYPES.ComparisonBinaryOperator],\n  // Arithmetic operators\n  [\"+\", TOKEN_TYPES.AdditiveBinaryOperator],\n  [\"-\", TOKEN_TYPES.AdditiveBinaryOperator],\n  [\"~\", TOKEN_TYPES.AdditiveBinaryOperator],\n  [\"*\", TOKEN_TYPES.MultiplicativeBinaryOperator],\n  [\"/\", TOKEN_TYPES.MultiplicativeBinaryOperator],\n  [\"%\", TOKEN_TYPES.MultiplicativeBinaryOperator],\n  // Assignment operator\n  [\"=\", TOKEN_TYPES.Equals]\n];\nvar ESCAPE_CHARACTERS = /* @__PURE__ */ new Map([\n  [\"n\", \"\\n\"],\n  // New line\n  [\"t\", \"\t\"],\n  // Horizontal tab\n  [\"r\", \"\\r\"],\n  // Carriage return\n  [\"b\", \"\\b\"],\n  // Backspace\n  [\"f\", \"\\f\"],\n  // Form feed\n  [\"v\", \"\\v\"],\n  // Vertical tab\n  [\"'\", \"'\"],\n  // Single quote\n  ['\"', '\"'],\n  // Double quote\n  [\"\\\\\", \"\\\\\"]\n  // Backslash\n]);\nfunction preprocess(template, options = {}) {\n  if (template.endsWith(\"\\n\")) {\n    template = template.slice(0, -1);\n  }\n  if (options.lstrip_blocks) {\n    template = template.replace(/^[ \\t]*({[#%-])/gm, \"$1\");\n  }\n  if (options.trim_blocks) {\n    template = template.replace(/([#%-]})\\n/g, \"$1\");\n  }\n  return template.replace(/{%\\s*(end)?generation\\s*%}/gs, \"\");\n}\nfunction tokenize(source, options = {}) {\n  const tokens = [];\n  const src = preprocess(source, options);\n  let cursorPosition = 0;\n  let curlyBracketDepth = 0;\n  const consumeWhile = (predicate) => {\n    let str = \"\";\n    while (predicate(src[cursorPosition])) {\n      if (src[cursorPosition] === \"\\\\\") {\n        ++cursorPosition;\n        if (cursorPosition >= src.length)\n          throw new SyntaxError(\"Unexpected end of input\");\n        const escaped = src[cursorPosition++];\n        const unescaped = ESCAPE_CHARACTERS.get(escaped);\n        if (unescaped === void 0) {\n          throw new SyntaxError(`Unexpected escaped character: ${escaped}`);\n        }\n        str += unescaped;\n        continue;\n      }\n      str += src[cursorPosition++];\n      if (cursorPosition >= src.length)\n        throw new SyntaxError(\"Unexpected end of input\");\n    }\n    return str;\n  };\n  const stripTrailingWhitespace = () => {\n    const lastToken = tokens.at(-1);\n    if (lastToken && lastToken.type === TOKEN_TYPES.Text) {\n      lastToken.value = lastToken.value.trimEnd();\n      if (lastToken.value === \"\") {\n        tokens.pop();\n      }\n    }\n  };\n  const skipLeadingWhitespace = () => {\n    while (cursorPosition < src.length && isWhitespace(src[cursorPosition])) {\n      ++cursorPosition;\n    }\n  };\n  main:\n    while (cursorPosition < src.length) {\n      const lastTokenType = tokens.at(-1)?.type;\n      if (lastTokenType === void 0 || lastTokenType === TOKEN_TYPES.CloseStatement || lastTokenType === TOKEN_TYPES.CloseExpression || lastTokenType === TOKEN_TYPES.Comment) {\n        let text = \"\";\n        while (cursorPosition < src.length && // Keep going until we hit the next Jinja statement or expression\n        !(src[cursorPosition] === \"{\" && (src[cursorPosition + 1] === \"%\" || src[cursorPosition + 1] === \"{\" || src[cursorPosition + 1] === \"#\"))) {\n          text += src[cursorPosition++];\n        }\n        if (text.length > 0) {\n          tokens.push(new Token(text, TOKEN_TYPES.Text));\n          continue;\n        }\n      }\n      if (src[cursorPosition] === \"{\" && src[cursorPosition + 1] === \"#\") {\n        cursorPosition += 2;\n        const stripBefore = src[cursorPosition] === \"-\";\n        if (stripBefore) {\n          ++cursorPosition;\n        }\n        let comment = \"\";\n        while (src[cursorPosition] !== \"#\" || src[cursorPosition + 1] !== \"}\") {\n          if (cursorPosition + 2 >= src.length) {\n            throw new SyntaxError(\"Missing end of comment tag\");\n          }\n          comment += src[cursorPosition++];\n        }\n        const stripAfter = comment.endsWith(\"-\");\n        if (stripAfter) {\n          comment = comment.slice(0, -1);\n        }\n        if (stripBefore) {\n          stripTrailingWhitespace();\n        }\n        tokens.push(new Token(comment, TOKEN_TYPES.Comment));\n        cursorPosition += 2;\n        if (stripAfter) {\n          skipLeadingWhitespace();\n        }\n        continue;\n      }\n      if (src.slice(cursorPosition, cursorPosition + 3) === \"{%-\") {\n        stripTrailingWhitespace();\n        tokens.push(new Token(\"{%\", TOKEN_TYPES.OpenStatement));\n        cursorPosition += 3;\n        continue;\n      }\n      if (src.slice(cursorPosition, cursorPosition + 3) === \"{{-\") {\n        stripTrailingWhitespace();\n        tokens.push(new Token(\"{{\", TOKEN_TYPES.OpenExpression));\n        curlyBracketDepth = 0;\n        cursorPosition += 3;\n        continue;\n      }\n      consumeWhile(isWhitespace);\n      if (src.slice(cursorPosition, cursorPosition + 3) === \"-%}\") {\n        tokens.push(new Token(\"%}\", TOKEN_TYPES.CloseStatement));\n        cursorPosition += 3;\n        skipLeadingWhitespace();\n        continue;\n      }\n      if (src.slice(cursorPosition, cursorPosition + 3) === \"-}}\") {\n        tokens.push(new Token(\"}}\", TOKEN_TYPES.CloseExpression));\n        cursorPosition += 3;\n        skipLeadingWhitespace();\n        continue;\n      }\n      const char = src[cursorPosition];\n      if (char === \"-\" || char === \"+\") {\n        const lastTokenType2 = tokens.at(-1)?.type;\n        if (lastTokenType2 === TOKEN_TYPES.Text || lastTokenType2 === void 0) {\n          throw new SyntaxError(`Unexpected character: ${char}`);\n        }\n        switch (lastTokenType2) {\n          case TOKEN_TYPES.Identifier:\n          case TOKEN_TYPES.NumericLiteral:\n          case TOKEN_TYPES.StringLiteral:\n          case TOKEN_TYPES.CloseParen:\n          case TOKEN_TYPES.CloseSquareBracket:\n            break;\n          default: {\n            ++cursorPosition;\n            const num = consumeWhile(isInteger);\n            tokens.push(\n              new Token(`${char}${num}`, num.length > 0 ? TOKEN_TYPES.NumericLiteral : TOKEN_TYPES.UnaryOperator)\n            );\n            continue;\n          }\n        }\n      }\n      for (const [seq, type] of ORDERED_MAPPING_TABLE) {\n        if (seq === \"}}\" && curlyBracketDepth > 0) {\n          continue;\n        }\n        const slice2 = src.slice(cursorPosition, cursorPosition + seq.length);\n        if (slice2 === seq) {\n          tokens.push(new Token(seq, type));\n          if (type === TOKEN_TYPES.OpenExpression) {\n            curlyBracketDepth = 0;\n          } else if (type === TOKEN_TYPES.OpenCurlyBracket) {\n            ++curlyBracketDepth;\n          } else if (type === TOKEN_TYPES.CloseCurlyBracket) {\n            --curlyBracketDepth;\n          }\n          cursorPosition += seq.length;\n          continue main;\n        }\n      }\n      if (char === \"'\" || char === '\"') {\n        ++cursorPosition;\n        const str = consumeWhile((c) => c !== char);\n        tokens.push(new Token(str, TOKEN_TYPES.StringLiteral));\n        ++cursorPosition;\n        continue;\n      }\n      if (isInteger(char)) {\n        let num = consumeWhile(isInteger);\n        if (src[cursorPosition] === \".\" && isInteger(src[cursorPosition + 1])) {\n          ++cursorPosition;\n          const frac = consumeWhile(isInteger);\n          num = `${num}.${frac}`;\n        }\n        tokens.push(new Token(num, TOKEN_TYPES.NumericLiteral));\n        continue;\n      }\n      if (isWord(char)) {\n        const word = consumeWhile(isWord);\n        tokens.push(new Token(word, TOKEN_TYPES.Identifier));\n        continue;\n      }\n      throw new SyntaxError(`Unexpected character: ${char}`);\n    }\n  return tokens;\n}\n\n// src/ast.ts\nvar Statement = class {\n  type = \"Statement\";\n};\nvar Program = class extends Statement {\n  constructor(body) {\n    super();\n    this.body = body;\n  }\n  type = \"Program\";\n};\nvar If = class extends Statement {\n  constructor(test, body, alternate) {\n    super();\n    this.test = test;\n    this.body = body;\n    this.alternate = alternate;\n  }\n  type = \"If\";\n};\nvar For = class extends Statement {\n  constructor(loopvar, iterable, body, defaultBlock) {\n    super();\n    this.loopvar = loopvar;\n    this.iterable = iterable;\n    this.body = body;\n    this.defaultBlock = defaultBlock;\n  }\n  type = \"For\";\n};\nvar Break = class extends Statement {\n  type = \"Break\";\n};\nvar Continue = class extends Statement {\n  type = \"Continue\";\n};\nvar SetStatement = class extends Statement {\n  constructor(assignee, value, body) {\n    super();\n    this.assignee = assignee;\n    this.value = value;\n    this.body = body;\n  }\n  type = \"Set\";\n};\nvar Macro = class extends Statement {\n  constructor(name, args, body) {\n    super();\n    this.name = name;\n    this.args = args;\n    this.body = body;\n  }\n  type = \"Macro\";\n};\nvar Comment = class extends Statement {\n  constructor(value) {\n    super();\n    this.value = value;\n  }\n  type = \"Comment\";\n};\nvar Expression = class extends Statement {\n  type = \"Expression\";\n};\nvar MemberExpression = class extends Expression {\n  constructor(object, property, computed) {\n    super();\n    this.object = object;\n    this.property = property;\n    this.computed = computed;\n  }\n  type = \"MemberExpression\";\n};\nvar CallExpression = class extends Expression {\n  constructor(callee, args) {\n    super();\n    this.callee = callee;\n    this.args = args;\n  }\n  type = \"CallExpression\";\n};\nvar Identifier = class extends Expression {\n  /**\n   * @param {string} value The name of the identifier\n   */\n  constructor(value) {\n    super();\n    this.value = value;\n  }\n  type = \"Identifier\";\n};\nvar Literal = class extends Expression {\n  constructor(value) {\n    super();\n    this.value = value;\n  }\n  type = \"Literal\";\n};\nvar IntegerLiteral = class extends Literal {\n  type = \"IntegerLiteral\";\n};\nvar FloatLiteral = class extends Literal {\n  type = \"FloatLiteral\";\n};\nvar StringLiteral = class extends Literal {\n  type = \"StringLiteral\";\n};\nvar ArrayLiteral = class extends Literal {\n  type = \"ArrayLiteral\";\n};\nvar TupleLiteral = class extends Literal {\n  type = \"TupleLiteral\";\n};\nvar ObjectLiteral = class extends Literal {\n  type = \"ObjectLiteral\";\n};\nvar BinaryExpression = class extends Expression {\n  constructor(operator, left, right) {\n    super();\n    this.operator = operator;\n    this.left = left;\n    this.right = right;\n  }\n  type = \"BinaryExpression\";\n};\nvar FilterExpression = class extends Expression {\n  constructor(operand, filter) {\n    super();\n    this.operand = operand;\n    this.filter = filter;\n  }\n  type = \"FilterExpression\";\n};\nvar FilterStatement = class extends Statement {\n  constructor(filter, body) {\n    super();\n    this.filter = filter;\n    this.body = body;\n  }\n  type = \"FilterStatement\";\n};\nvar SelectExpression = class extends Expression {\n  constructor(lhs, test) {\n    super();\n    this.lhs = lhs;\n    this.test = test;\n  }\n  type = \"SelectExpression\";\n};\nvar TestExpression = class extends Expression {\n  constructor(operand, negate, test) {\n    super();\n    this.operand = operand;\n    this.negate = negate;\n    this.test = test;\n  }\n  type = \"TestExpression\";\n};\nvar UnaryExpression = class extends Expression {\n  constructor(operator, argument) {\n    super();\n    this.operator = operator;\n    this.argument = argument;\n  }\n  type = \"UnaryExpression\";\n};\nvar SliceExpression = class extends Expression {\n  constructor(start = void 0, stop = void 0, step = void 0) {\n    super();\n    this.start = start;\n    this.stop = stop;\n    this.step = step;\n  }\n  type = \"SliceExpression\";\n};\nvar KeywordArgumentExpression = class extends Expression {\n  constructor(key, value) {\n    super();\n    this.key = key;\n    this.value = value;\n  }\n  type = \"KeywordArgumentExpression\";\n};\nvar SpreadExpression = class extends Expression {\n  constructor(argument) {\n    super();\n    this.argument = argument;\n  }\n  type = \"SpreadExpression\";\n};\nvar CallStatement = class extends Statement {\n  constructor(call, callerArgs, body) {\n    super();\n    this.call = call;\n    this.callerArgs = callerArgs;\n    this.body = body;\n  }\n  type = \"CallStatement\";\n};\nvar Ternary = class extends Expression {\n  constructor(condition, trueExpr, falseExpr) {\n    super();\n    this.condition = condition;\n    this.trueExpr = trueExpr;\n    this.falseExpr = falseExpr;\n  }\n  type = \"Ternary\";\n};\n\n// src/parser.ts\nfunction parse(tokens) {\n  const program = new Program([]);\n  let current = 0;\n  function expect(type, error) {\n    const prev = tokens[current++];\n    if (!prev || prev.type !== type) {\n      throw new Error(`Parser Error: ${error}. ${prev.type} !== ${type}.`);\n    }\n    return prev;\n  }\n  function expectIdentifier(name) {\n    if (!isIdentifier(name)) {\n      throw new SyntaxError(`Expected ${name}`);\n    }\n    ++current;\n  }\n  function parseAny() {\n    switch (tokens[current].type) {\n      case TOKEN_TYPES.Comment:\n        return new Comment(tokens[current++].value);\n      case TOKEN_TYPES.Text:\n        return parseText();\n      case TOKEN_TYPES.OpenStatement:\n        return parseJinjaStatement();\n      case TOKEN_TYPES.OpenExpression:\n        return parseJinjaExpression();\n      default:\n        throw new SyntaxError(`Unexpected token type: ${tokens[current].type}`);\n    }\n  }\n  function is(...types) {\n    return current + types.length <= tokens.length && types.every((type, i) => type === tokens[current + i].type);\n  }\n  function isStatement(...names) {\n    return tokens[current]?.type === TOKEN_TYPES.OpenStatement && tokens[current + 1]?.type === TOKEN_TYPES.Identifier && names.includes(tokens[current + 1]?.value);\n  }\n  function isIdentifier(...names) {\n    return current + names.length <= tokens.length && names.every((name, i) => tokens[current + i].type === \"Identifier\" && name === tokens[current + i].value);\n  }\n  function parseText() {\n    return new StringLiteral(expect(TOKEN_TYPES.Text, \"Expected text token\").value);\n  }\n  function parseJinjaStatement() {\n    expect(TOKEN_TYPES.OpenStatement, \"Expected opening statement token\");\n    if (tokens[current].type !== TOKEN_TYPES.Identifier) {\n      throw new SyntaxError(`Unknown statement, got ${tokens[current].type}`);\n    }\n    const name = tokens[current].value;\n    let result;\n    switch (name) {\n      case \"set\":\n        ++current;\n        result = parseSetStatement();\n        break;\n      case \"if\":\n        ++current;\n        result = parseIfStatement();\n        expect(TOKEN_TYPES.OpenStatement, \"Expected {% token\");\n        expectIdentifier(\"endif\");\n        expect(TOKEN_TYPES.CloseStatement, \"Expected %} token\");\n        break;\n      case \"macro\":\n        ++current;\n        result = parseMacroStatement();\n        expect(TOKEN_TYPES.OpenStatement, \"Expected {% token\");\n        expectIdentifier(\"endmacro\");\n        expect(TOKEN_TYPES.CloseStatement, \"Expected %} token\");\n        break;\n      case \"for\":\n        ++current;\n        result = parseForStatement();\n        expect(TOKEN_TYPES.OpenStatement, \"Expected {% token\");\n        expectIdentifier(\"endfor\");\n        expect(TOKEN_TYPES.CloseStatement, \"Expected %} token\");\n        break;\n      case \"call\": {\n        ++current;\n        let callerArgs = null;\n        if (is(TOKEN_TYPES.OpenParen)) {\n          callerArgs = parseArgs();\n        }\n        const callee = parsePrimaryExpression();\n        if (callee.type !== \"Identifier\") {\n          throw new SyntaxError(`Expected identifier following call statement`);\n        }\n        const callArgs = parseArgs();\n        expect(TOKEN_TYPES.CloseStatement, \"Expected closing statement token\");\n        const body = [];\n        while (!isStatement(\"endcall\")) {\n          body.push(parseAny());\n        }\n        expect(TOKEN_TYPES.OpenStatement, \"Expected '{%'\");\n        expectIdentifier(\"endcall\");\n        expect(TOKEN_TYPES.CloseStatement, \"Expected closing statement token\");\n        const callExpr = new CallExpression(callee, callArgs);\n        result = new CallStatement(callExpr, callerArgs, body);\n        break;\n      }\n      case \"break\":\n        ++current;\n        expect(TOKEN_TYPES.CloseStatement, \"Expected closing statement token\");\n        result = new Break();\n        break;\n      case \"continue\":\n        ++current;\n        expect(TOKEN_TYPES.CloseStatement, \"Expected closing statement token\");\n        result = new Continue();\n        break;\n      case \"filter\": {\n        ++current;\n        let filterNode = parsePrimaryExpression();\n        if (filterNode instanceof Identifier && is(TOKEN_TYPES.OpenParen)) {\n          filterNode = parseCallExpression(filterNode);\n        }\n        expect(TOKEN_TYPES.CloseStatement, \"Expected closing statement token\");\n        const filterBody = [];\n        while (!isStatement(\"endfilter\")) {\n          filterBody.push(parseAny());\n        }\n        expect(TOKEN_TYPES.OpenStatement, \"Expected '{%'\");\n        expectIdentifier(\"endfilter\");\n        expect(TOKEN_TYPES.CloseStatement, \"Expected '%}'\");\n        result = new FilterStatement(filterNode, filterBody);\n        break;\n      }\n      default:\n        throw new SyntaxError(`Unknown statement type: ${name}`);\n    }\n    return result;\n  }\n  function parseJinjaExpression() {\n    expect(TOKEN_TYPES.OpenExpression, \"Expected opening expression token\");\n    const result = parseExpression();\n    expect(TOKEN_TYPES.CloseExpression, \"Expected closing expression token\");\n    return result;\n  }\n  function parseSetStatement() {\n    const left = parseExpressionSequence();\n    let value = null;\n    const body = [];\n    if (is(TOKEN_TYPES.Equals)) {\n      ++current;\n      value = parseExpressionSequence();\n    } else {\n      expect(TOKEN_TYPES.CloseStatement, \"Expected %} token\");\n      while (!isStatement(\"endset\")) {\n        body.push(parseAny());\n      }\n      expect(TOKEN_TYPES.OpenStatement, \"Expected {% token\");\n      expectIdentifier(\"endset\");\n    }\n    expect(TOKEN_TYPES.CloseStatement, \"Expected closing statement token\");\n    return new SetStatement(left, value, body);\n  }\n  function parseIfStatement() {\n    const test = parseExpression();\n    expect(TOKEN_TYPES.CloseStatement, \"Expected closing statement token\");\n    const body = [];\n    const alternate = [];\n    while (!isStatement(\"elif\", \"else\", \"endif\")) {\n      body.push(parseAny());\n    }\n    if (isStatement(\"elif\")) {\n      ++current;\n      ++current;\n      const result = parseIfStatement();\n      alternate.push(result);\n    } else if (isStatement(\"else\")) {\n      ++current;\n      ++current;\n      expect(TOKEN_TYPES.CloseStatement, \"Expected closing statement token\");\n      while (!isStatement(\"endif\")) {\n        alternate.push(parseAny());\n      }\n    }\n    return new If(test, body, alternate);\n  }\n  function parseMacroStatement() {\n    const name = parsePrimaryExpression();\n    if (name.type !== \"Identifier\") {\n      throw new SyntaxError(`Expected identifier following macro statement`);\n    }\n    const args = parseArgs();\n    expect(TOKEN_TYPES.CloseStatement, \"Expected closing statement token\");\n    const body = [];\n    while (!isStatement(\"endmacro\")) {\n      body.push(parseAny());\n    }\n    return new Macro(name, args, body);\n  }\n  function parseExpressionSequence(primary = false) {\n    const fn = primary ? parsePrimaryExpression : parseExpression;\n    const expressions = [fn()];\n    const isTuple = is(TOKEN_TYPES.Comma);\n    while (isTuple) {\n      ++current;\n      expressions.push(fn());\n      if (!is(TOKEN_TYPES.Comma)) {\n        break;\n      }\n    }\n    return isTuple ? new TupleLiteral(expressions) : expressions[0];\n  }\n  function parseForStatement() {\n    const loopVariable = parseExpressionSequence(true);\n    if (!(loopVariable instanceof Identifier || loopVariable instanceof TupleLiteral)) {\n      throw new SyntaxError(`Expected identifier/tuple for the loop variable, got ${loopVariable.type} instead`);\n    }\n    if (!isIdentifier(\"in\")) {\n      throw new SyntaxError(\"Expected `in` keyword following loop variable\");\n    }\n    ++current;\n    const iterable = parseExpression();\n    expect(TOKEN_TYPES.CloseStatement, \"Expected closing statement token\");\n    const body = [];\n    while (!isStatement(\"endfor\", \"else\")) {\n      body.push(parseAny());\n    }\n    const alternative = [];\n    if (isStatement(\"else\")) {\n      ++current;\n      ++current;\n      expect(TOKEN_TYPES.CloseStatement, \"Expected closing statement token\");\n      while (!isStatement(\"endfor\")) {\n        alternative.push(parseAny());\n      }\n    }\n    return new For(loopVariable, iterable, body, alternative);\n  }\n  function parseExpression() {\n    return parseIfExpression();\n  }\n  function parseIfExpression() {\n    const a = parseLogicalOrExpression();\n    if (isIdentifier(\"if\")) {\n      ++current;\n      const test = parseLogicalOrExpression();\n      if (isIdentifier(\"else\")) {\n        ++current;\n        const falseExpr = parseIfExpression();\n        return new Ternary(test, a, falseExpr);\n      } else {\n        return new SelectExpression(a, test);\n      }\n    }\n    return a;\n  }\n  function parseLogicalOrExpression() {\n    let left = parseLogicalAndExpression();\n    while (isIdentifier(\"or\")) {\n      const operator = tokens[current];\n      ++current;\n      const right = parseLogicalAndExpression();\n      left = new BinaryExpression(operator, left, right);\n    }\n    return left;\n  }\n  function parseLogicalAndExpression() {\n    let left = parseLogicalNegationExpression();\n    while (isIdentifier(\"and\")) {\n      const operator = tokens[current];\n      ++current;\n      const right = parseLogicalNegationExpression();\n      left = new BinaryExpression(operator, left, right);\n    }\n    return left;\n  }\n  function parseLogicalNegationExpression() {\n    let right;\n    while (isIdentifier(\"not\")) {\n      const operator = tokens[current];\n      ++current;\n      const arg = parseLogicalNegationExpression();\n      right = new UnaryExpression(operator, arg);\n    }\n    return right ?? parseComparisonExpression();\n  }\n  function parseComparisonExpression() {\n    let left = parseAdditiveExpression();\n    while (true) {\n      let operator;\n      if (isIdentifier(\"not\", \"in\")) {\n        operator = new Token(\"not in\", TOKEN_TYPES.Identifier);\n        current += 2;\n      } else if (isIdentifier(\"in\")) {\n        operator = tokens[current++];\n      } else if (is(TOKEN_TYPES.ComparisonBinaryOperator)) {\n        operator = tokens[current++];\n      } else {\n        break;\n      }\n      const right = parseAdditiveExpression();\n      left = new BinaryExpression(operator, left, right);\n    }\n    return left;\n  }\n  function parseAdditiveExpression() {\n    let left = parseMultiplicativeExpression();\n    while (is(TOKEN_TYPES.AdditiveBinaryOperator)) {\n      const operator = tokens[current];\n      ++current;\n      const right = parseMultiplicativeExpression();\n      left = new BinaryExpression(operator, left, right);\n    }\n    return left;\n  }\n  function parseCallMemberExpression() {\n    const member = parseMemberExpression(parsePrimaryExpression());\n    if (is(TOKEN_TYPES.OpenParen)) {\n      return parseCallExpression(member);\n    }\n    return member;\n  }\n  function parseCallExpression(callee) {\n    let expression = new CallExpression(callee, parseArgs());\n    expression = parseMemberExpression(expression);\n    if (is(TOKEN_TYPES.OpenParen)) {\n      expression = parseCallExpression(expression);\n    }\n    return expression;\n  }\n  function parseArgs() {\n    expect(TOKEN_TYPES.OpenParen, \"Expected opening parenthesis for arguments list\");\n    const args = parseArgumentsList();\n    expect(TOKEN_TYPES.CloseParen, \"Expected closing parenthesis for arguments list\");\n    return args;\n  }\n  function parseArgumentsList() {\n    const args = [];\n    while (!is(TOKEN_TYPES.CloseParen)) {\n      let argument;\n      if (tokens[current].type === TOKEN_TYPES.MultiplicativeBinaryOperator && tokens[current].value === \"*\") {\n        ++current;\n        const expr = parseExpression();\n        argument = new SpreadExpression(expr);\n      } else {\n        argument = parseExpression();\n        if (is(TOKEN_TYPES.Equals)) {\n          ++current;\n          if (!(argument instanceof Identifier)) {\n            throw new SyntaxError(`Expected identifier for keyword argument`);\n          }\n          const value = parseExpression();\n          argument = new KeywordArgumentExpression(argument, value);\n        }\n      }\n      args.push(argument);\n      if (is(TOKEN_TYPES.Comma)) {\n        ++current;\n      }\n    }\n    return args;\n  }\n  function parseMemberExpressionArgumentsList() {\n    const slices = [];\n    let isSlice = false;\n    while (!is(TOKEN_TYPES.CloseSquareBracket)) {\n      if (is(TOKEN_TYPES.Colon)) {\n        slices.push(void 0);\n        ++current;\n        isSlice = true;\n      } else {\n        slices.push(parseExpression());\n        if (is(TOKEN_TYPES.Colon)) {\n          ++current;\n          isSlice = true;\n        }\n      }\n    }\n    if (slices.length === 0) {\n      throw new SyntaxError(`Expected at least one argument for member/slice expression`);\n    }\n    if (isSlice) {\n      if (slices.length > 3) {\n        throw new SyntaxError(`Expected 0-3 arguments for slice expression`);\n      }\n      return new SliceExpression(...slices);\n    }\n    return slices[0];\n  }\n  function parseMemberExpression(object) {\n    while (is(TOKEN_TYPES.Dot) || is(TOKEN_TYPES.OpenSquareBracket)) {\n      const operator = tokens[current];\n      ++current;\n      let property;\n      const computed = operator.type === TOKEN_TYPES.OpenSquareBracket;\n      if (computed) {\n        property = parseMemberExpressionArgumentsList();\n        expect(TOKEN_TYPES.CloseSquareBracket, \"Expected closing square bracket\");\n      } else {\n        property = parsePrimaryExpression();\n        if (property.type !== \"Identifier\") {\n          throw new SyntaxError(`Expected identifier following dot operator`);\n        }\n      }\n      object = new MemberExpression(object, property, computed);\n    }\n    return object;\n  }\n  function parseMultiplicativeExpression() {\n    let left = parseTestExpression();\n    while (is(TOKEN_TYPES.MultiplicativeBinaryOperator)) {\n      const operator = tokens[current++];\n      const right = parseTestExpression();\n      left = new BinaryExpression(operator, left, right);\n    }\n    return left;\n  }\n  function parseTestExpression() {\n    let operand = parseFilterExpression();\n    while (isIdentifier(\"is\")) {\n      ++current;\n      const negate = isIdentifier(\"not\");\n      if (negate) {\n        ++current;\n      }\n      const filter = parsePrimaryExpression();\n      if (!(filter instanceof Identifier)) {\n        throw new SyntaxError(`Expected identifier for the test`);\n      }\n      operand = new TestExpression(operand, negate, filter);\n    }\n    return operand;\n  }\n  function parseFilterExpression() {\n    let operand = parseCallMemberExpression();\n    while (is(TOKEN_TYPES.Pipe)) {\n      ++current;\n      let filter = parsePrimaryExpression();\n      if (!(filter instanceof Identifier)) {\n        throw new SyntaxError(`Expected identifier for the filter`);\n      }\n      if (is(TOKEN_TYPES.OpenParen)) {\n        filter = parseCallExpression(filter);\n      }\n      operand = new FilterExpression(operand, filter);\n    }\n    return operand;\n  }\n  function parsePrimaryExpression() {\n    const token = tokens[current++];\n    switch (token.type) {\n      case TOKEN_TYPES.NumericLiteral: {\n        const num = token.value;\n        return num.includes(\".\") ? new FloatLiteral(Number(num)) : new IntegerLiteral(Number(num));\n      }\n      case TOKEN_TYPES.StringLiteral: {\n        let value = token.value;\n        while (is(TOKEN_TYPES.StringLiteral)) {\n          value += tokens[current++].value;\n        }\n        return new StringLiteral(value);\n      }\n      case TOKEN_TYPES.Identifier:\n        return new Identifier(token.value);\n      case TOKEN_TYPES.OpenParen: {\n        const expression = parseExpressionSequence();\n        expect(TOKEN_TYPES.CloseParen, \"Expected closing parenthesis, got ${tokens[current].type} instead.\");\n        return expression;\n      }\n      case TOKEN_TYPES.OpenSquareBracket: {\n        const values = [];\n        while (!is(TOKEN_TYPES.CloseSquareBracket)) {\n          values.push(parseExpression());\n          if (is(TOKEN_TYPES.Comma)) {\n            ++current;\n          }\n        }\n        ++current;\n        return new ArrayLiteral(values);\n      }\n      case TOKEN_TYPES.OpenCurlyBracket: {\n        const values = /* @__PURE__ */ new Map();\n        while (!is(TOKEN_TYPES.CloseCurlyBracket)) {\n          const key = parseExpression();\n          expect(TOKEN_TYPES.Colon, \"Expected colon between key and value in object literal\");\n          const value = parseExpression();\n          values.set(key, value);\n          if (is(TOKEN_TYPES.Comma)) {\n            ++current;\n          }\n        }\n        ++current;\n        return new ObjectLiteral(values);\n      }\n      default:\n        throw new SyntaxError(`Unexpected token: ${token.type}`);\n    }\n  }\n  while (current < tokens.length) {\n    program.body.push(parseAny());\n  }\n  return program;\n}\n\n// src/utils.ts\nfunction range(start, stop, step = 1) {\n  if (stop === void 0) {\n    stop = start;\n    start = 0;\n  }\n  const result = [];\n  for (let i = start; i < stop; i += step) {\n    result.push(i);\n  }\n  return result;\n}\nfunction slice(array, start, stop, step = 1) {\n  const direction = Math.sign(step);\n  if (direction >= 0) {\n    start = (start ??= 0) < 0 ? Math.max(array.length + start, 0) : Math.min(start, array.length);\n    stop = (stop ??= array.length) < 0 ? Math.max(array.length + stop, 0) : Math.min(stop, array.length);\n  } else {\n    start = (start ??= array.length - 1) < 0 ? Math.max(array.length + start, -1) : Math.min(start, array.length - 1);\n    stop = (stop ??= -1) < -1 ? Math.max(array.length + stop, -1) : Math.min(stop, array.length - 1);\n  }\n  const result = [];\n  for (let i = start; direction * i < direction * stop; i += step) {\n    result.push(array[i]);\n  }\n  return result;\n}\nfunction titleCase(value) {\n  return value.replace(/\\b\\w/g, (c) => c.toUpperCase());\n}\nfunction strftime_now(format2) {\n  return strftime(/* @__PURE__ */ new Date(), format2);\n}\nfunction strftime(date, format2) {\n  const monthFormatterLong = new Intl.DateTimeFormat(void 0, { month: \"long\" });\n  const monthFormatterShort = new Intl.DateTimeFormat(void 0, { month: \"short\" });\n  const pad2 = (n) => n < 10 ? \"0\" + n : n.toString();\n  return format2.replace(/%[YmdbBHM%]/g, (token) => {\n    switch (token) {\n      case \"%Y\":\n        return date.getFullYear().toString();\n      case \"%m\":\n        return pad2(date.getMonth() + 1);\n      case \"%d\":\n        return pad2(date.getDate());\n      case \"%b\":\n        return monthFormatterShort.format(date);\n      case \"%B\":\n        return monthFormatterLong.format(date);\n      case \"%H\":\n        return pad2(date.getHours());\n      case \"%M\":\n        return pad2(date.getMinutes());\n      case \"%%\":\n        return \"%\";\n      default:\n        return token;\n    }\n  });\n}\nfunction escapeRegExp(s) {\n  return s.replace(/[.*+?^${}()|[\\]\\\\]/g, \"\\\\$&\");\n}\nfunction replace(str, oldvalue, newvalue, count) {\n  if (count === 0)\n    return str;\n  let remaining = count == null || count < 0 ? Infinity : count;\n  const pattern = oldvalue.length === 0 ? new RegExp(\"(?=)\", \"gu\") : new RegExp(escapeRegExp(oldvalue), \"gu\");\n  return str.replaceAll(pattern, (match) => {\n    if (remaining > 0) {\n      --remaining;\n      return newvalue;\n    }\n    return match;\n  });\n}\n\n// src/runtime.ts\nvar BreakControl = class extends Error {\n};\nvar ContinueControl = class extends Error {\n};\nvar RuntimeValue = class {\n  type = \"RuntimeValue\";\n  value;\n  /**\n   * A collection of built-in functions for this type.\n   */\n  builtins = /* @__PURE__ */ new Map();\n  /**\n   * Creates a new RuntimeValue.\n   */\n  constructor(value = void 0) {\n    this.value = value;\n  }\n  /**\n   * Determines truthiness or falsiness of the runtime value.\n   * This function should be overridden by subclasses if it has custom truthiness criteria.\n   * @returns {BooleanValue} BooleanValue(true) if the value is truthy, BooleanValue(false) otherwise.\n   */\n  __bool__() {\n    return new BooleanValue(!!this.value);\n  }\n  toString() {\n    return String(this.value);\n  }\n};\nvar IntegerValue = class extends RuntimeValue {\n  type = \"IntegerValue\";\n};\nvar FloatValue = class extends RuntimeValue {\n  type = \"FloatValue\";\n  toString() {\n    return this.value % 1 === 0 ? this.value.toFixed(1) : this.value.toString();\n  }\n};\nvar StringValue = class extends RuntimeValue {\n  type = \"StringValue\";\n  builtins = /* @__PURE__ */ new Map([\n    [\n      \"upper\",\n      new FunctionValue(() => {\n        return new StringValue(this.value.toUpperCase());\n      })\n    ],\n    [\n      \"lower\",\n      new FunctionValue(() => {\n        return new StringValue(this.value.toLowerCase());\n      })\n    ],\n    [\n      \"strip\",\n      new FunctionValue(() => {\n        return new StringValue(this.value.trim());\n      })\n    ],\n    [\n      \"title\",\n      new FunctionValue(() => {\n        return new StringValue(titleCase(this.value));\n      })\n    ],\n    [\n      \"capitalize\",\n      new FunctionValue(() => {\n        return new StringValue(this.value.charAt(0).toUpperCase() + this.value.slice(1));\n      })\n    ],\n    [\"length\", new IntegerValue(this.value.length)],\n    [\n      \"rstrip\",\n      new FunctionValue(() => {\n        return new StringValue(this.value.trimEnd());\n      })\n    ],\n    [\n      \"lstrip\",\n      new FunctionValue(() => {\n        return new StringValue(this.value.trimStart());\n      })\n    ],\n    [\n      \"startswith\",\n      new FunctionValue((args) => {\n        if (args.length === 0) {\n          throw new Error(\"startswith() requires at least one argument\");\n        }\n        const pattern = args[0];\n        if (pattern instanceof StringValue) {\n          return new BooleanValue(this.value.startsWith(pattern.value));\n        } else if (pattern instanceof ArrayValue) {\n          for (const item of pattern.value) {\n            if (!(item instanceof StringValue)) {\n              throw new Error(\"startswith() tuple elements must be strings\");\n            }\n            if (this.value.startsWith(item.value)) {\n              return new BooleanValue(true);\n            }\n          }\n          return new BooleanValue(false);\n        }\n        throw new Error(\"startswith() argument must be a string or tuple of strings\");\n      })\n    ],\n    [\n      \"endswith\",\n      new FunctionValue((args) => {\n        if (args.length === 0) {\n          throw new Error(\"endswith() requires at least one argument\");\n        }\n        const pattern = args[0];\n        if (pattern instanceof StringValue) {\n          return new BooleanValue(this.value.endsWith(pattern.value));\n        } else if (pattern instanceof ArrayValue) {\n          for (const item of pattern.value) {\n            if (!(item instanceof StringValue)) {\n              throw new Error(\"endswith() tuple elements must be strings\");\n            }\n            if (this.value.endsWith(item.value)) {\n              return new BooleanValue(true);\n            }\n          }\n          return new BooleanValue(false);\n        }\n        throw new Error(\"endswith() argument must be a string or tuple of strings\");\n      })\n    ],\n    [\n      \"split\",\n      // follows Python's `str.split(sep=None, maxsplit=-1)` function behavior\n      // https://docs.python.org/3.13/library/stdtypes.html#str.split\n      new FunctionValue((args) => {\n        const sep = args[0] ?? new NullValue();\n        if (!(sep instanceof StringValue || sep instanceof NullValue)) {\n          throw new Error(\"sep argument must be a string or null\");\n        }\n        const maxsplit = args[1] ?? new IntegerValue(-1);\n        if (!(maxsplit instanceof IntegerValue)) {\n          throw new Error(\"maxsplit argument must be a number\");\n        }\n        let result = [];\n        if (sep instanceof NullValue) {\n          const text = this.value.trimStart();\n          for (const { 0: match, index } of text.matchAll(/\\S+/g)) {\n            if (maxsplit.value !== -1 && result.length >= maxsplit.value && index !== void 0) {\n              result.push(match + text.slice(index + match.length));\n              break;\n            }\n            result.push(match);\n          }\n        } else {\n          if (sep.value === \"\") {\n            throw new Error(\"empty separator\");\n          }\n          result = this.value.split(sep.value);\n          if (maxsplit.value !== -1 && result.length > maxsplit.value) {\n            result.push(result.splice(maxsplit.value).join(sep.value));\n          }\n        }\n        return new ArrayValue(result.map((part) => new StringValue(part)));\n      })\n    ],\n    [\n      \"replace\",\n      new FunctionValue((args) => {\n        if (args.length < 2) {\n          throw new Error(\"replace() requires at least two arguments\");\n        }\n        const oldValue = args[0];\n        const newValue = args[1];\n        if (!(oldValue instanceof StringValue && newValue instanceof StringValue)) {\n          throw new Error(\"replace() arguments must be strings\");\n        }\n        let count;\n        if (args.length > 2) {\n          if (args[2].type === \"KeywordArgumentsValue\") {\n            count = args[2].value.get(\"count\") ?? new NullValue();\n          } else {\n            count = args[2];\n          }\n        } else {\n          count = new NullValue();\n        }\n        if (!(count instanceof IntegerValue || count instanceof NullValue)) {\n          throw new Error(\"replace() count argument must be a number or null\");\n        }\n        return new StringValue(replace(this.value, oldValue.value, newValue.value, count.value));\n      })\n    ]\n  ]);\n};\nvar BooleanValue = class extends RuntimeValue {\n  type = \"BooleanValue\";\n};\nfunction toJSON(input, indent, depth, convertUndefinedToNull = true) {\n  const currentDepth = depth ?? 0;\n  switch (input.type) {\n    case \"NullValue\":\n      return \"null\";\n    case \"UndefinedValue\":\n      return convertUndefinedToNull ? \"null\" : \"undefined\";\n    case \"IntegerValue\":\n    case \"FloatValue\":\n    case \"StringValue\":\n    case \"BooleanValue\":\n      return JSON.stringify(input.value);\n    case \"ArrayValue\":\n    case \"ObjectValue\": {\n      const indentValue = indent ? \" \".repeat(indent) : \"\";\n      const basePadding = \"\\n\" + indentValue.repeat(currentDepth);\n      const childrenPadding = basePadding + indentValue;\n      if (input.type === \"ArrayValue\") {\n        const core = input.value.map(\n          (x) => toJSON(x, indent, currentDepth + 1, convertUndefinedToNull)\n        );\n        return indent ? `[${childrenPadding}${core.join(`,${childrenPadding}`)}${basePadding}]` : `[${core.join(\", \")}]`;\n      } else {\n        const core = Array.from(input.value.entries()).map(([key, value]) => {\n          const v = `\"${key}\": ${toJSON(value, indent, currentDepth + 1, convertUndefinedToNull)}`;\n          return indent ? `${childrenPadding}${v}` : v;\n        });\n        return indent ? `{${core.join(\",\")}${basePadding}}` : `{${core.join(\", \")}}`;\n      }\n    }\n    default:\n      throw new Error(`Cannot convert to JSON: ${input.type}`);\n  }\n}\nvar ObjectValue = class extends RuntimeValue {\n  type = \"ObjectValue\";\n  /**\n   * NOTE: necessary to override since all JavaScript arrays are considered truthy,\n   * while only non-empty Python arrays are consider truthy.\n   *\n   * e.g.,\n   *  - JavaScript:  {} && 5 -> 5\n   *  - Python:      {} and 5 -> {}\n   */\n  __bool__() {\n    return new BooleanValue(this.value.size > 0);\n  }\n  builtins = /* @__PURE__ */ new Map([\n    [\n      \"get\",\n      new FunctionValue(([key, defaultValue]) => {\n        if (!(key instanceof StringValue)) {\n          throw new Error(`Object key must be a string: got ${key.type}`);\n        }\n        return this.value.get(key.value) ?? defaultValue ?? new NullValue();\n      })\n    ],\n    [\"items\", new FunctionValue(() => this.items())],\n    [\"keys\", new FunctionValue(() => this.keys())],\n    [\"values\", new FunctionValue(() => this.values())],\n    [\n      \"dictsort\",\n      new FunctionValue((args) => {\n        let kwargs = /* @__PURE__ */ new Map();\n        const positionalArgs = args.filter((arg) => {\n          if (arg instanceof KeywordArgumentsValue) {\n            kwargs = arg.value;\n            return false;\n          }\n          return true;\n        });\n        const caseSensitive = positionalArgs.at(0) ?? kwargs.get(\"case_sensitive\") ?? new BooleanValue(false);\n        if (!(caseSensitive instanceof BooleanValue)) {\n          throw new Error(\"case_sensitive must be a boolean\");\n        }\n        const by = positionalArgs.at(1) ?? kwargs.get(\"by\") ?? new StringValue(\"key\");\n        if (!(by instanceof StringValue)) {\n          throw new Error(\"by must be a string\");\n        }\n        if (![\"key\", \"value\"].includes(by.value)) {\n          throw new Error(\"by must be either 'key' or 'value'\");\n        }\n        const reverse = positionalArgs.at(2) ?? kwargs.get(\"reverse\") ?? new BooleanValue(false);\n        if (!(reverse instanceof BooleanValue)) {\n          throw new Error(\"reverse must be a boolean\");\n        }\n        const items = Array.from(this.value.entries()).map(([key, value]) => new ArrayValue([new StringValue(key), value])).sort((a, b) => {\n          const index = by.value === \"key\" ? 0 : 1;\n          const aVal = a.value[index];\n          const bVal = b.value[index];\n          const result = compareRuntimeValues(aVal, bVal, caseSensitive.value);\n          return reverse.value ? -result : result;\n        });\n        return new ArrayValue(items);\n      })\n    ]\n  ]);\n  items() {\n    return new ArrayValue(\n      Array.from(this.value.entries()).map(([key, value]) => new ArrayValue([new StringValue(key), value]))\n    );\n  }\n  keys() {\n    return new ArrayValue(Array.from(this.value.keys()).map((key) => new StringValue(key)));\n  }\n  values() {\n    return new ArrayValue(Array.from(this.value.values()));\n  }\n  toString() {\n    return toJSON(this, null, 0, false);\n  }\n};\nvar KeywordArgumentsValue = class extends ObjectValue {\n  type = \"KeywordArgumentsValue\";\n};\nvar ArrayValue = class extends RuntimeValue {\n  type = \"ArrayValue\";\n  builtins = /* @__PURE__ */ new Map([[\"length\", new IntegerValue(this.value.length)]]);\n  /**\n   * NOTE: necessary to override since all JavaScript arrays are considered truthy,\n   * while only non-empty Python arrays are consider truthy.\n   *\n   * e.g.,\n   *  - JavaScript:  [] && 5 -> 5\n   *  - Python:      [] and 5 -> []\n   */\n  __bool__() {\n    return new BooleanValue(this.value.length > 0);\n  }\n  toString() {\n    return toJSON(this, null, 0, false);\n  }\n};\nvar TupleValue = class extends ArrayValue {\n  type = \"TupleValue\";\n};\nvar FunctionValue = class extends RuntimeValue {\n  type = \"FunctionValue\";\n};\nvar NullValue = class extends RuntimeValue {\n  type = \"NullValue\";\n};\nvar UndefinedValue = class extends RuntimeValue {\n  type = \"UndefinedValue\";\n};\nvar Environment = class {\n  constructor(parent) {\n    this.parent = parent;\n  }\n  /**\n   * The variables declared in this environment.\n   */\n  variables = /* @__PURE__ */ new Map([\n    [\n      \"namespace\",\n      new FunctionValue((args) => {\n        if (args.length === 0) {\n          return new ObjectValue(/* @__PURE__ */ new Map());\n        }\n        if (args.length !== 1 || !(args[0] instanceof ObjectValue)) {\n          throw new Error(\"`namespace` expects either zero arguments or a single object argument\");\n        }\n        return args[0];\n      })\n    ]\n  ]);\n  /**\n   * The tests available in this environment.\n   */\n  tests = /* @__PURE__ */ new Map([\n    [\"boolean\", (operand) => operand.type === \"BooleanValue\"],\n    [\"callable\", (operand) => operand instanceof FunctionValue],\n    [\n      \"odd\",\n      (operand) => {\n        if (!(operand instanceof IntegerValue)) {\n          throw new Error(`cannot odd on ${operand.type}`);\n        }\n        return operand.value % 2 !== 0;\n      }\n    ],\n    [\n      \"even\",\n      (operand) => {\n        if (!(operand instanceof IntegerValue)) {\n          throw new Error(`cannot even on ${operand.type}`);\n        }\n        return operand.value % 2 === 0;\n      }\n    ],\n    [\"false\", (operand) => operand.type === \"BooleanValue\" && !operand.value],\n    [\"true\", (operand) => operand.type === \"BooleanValue\" && operand.value],\n    [\"none\", (operand) => operand.type === \"NullValue\"],\n    [\"string\", (operand) => operand.type === \"StringValue\"],\n    [\"number\", (operand) => operand instanceof IntegerValue || operand instanceof FloatValue],\n    [\"integer\", (operand) => operand instanceof IntegerValue],\n    [\"iterable\", (operand) => operand.type === \"ArrayValue\" || operand.type === \"StringValue\"],\n    [\"mapping\", (operand) => operand.type === \"ObjectValue\"],\n    [\n      \"lower\",\n      (operand) => {\n        const str = operand.value;\n        return operand.type === \"StringValue\" && str === str.toLowerCase();\n      }\n    ],\n    [\n      \"upper\",\n      (operand) => {\n        const str = operand.value;\n        return operand.type === \"StringValue\" && str === str.toUpperCase();\n      }\n    ],\n    [\"none\", (operand) => operand.type === \"NullValue\"],\n    [\"defined\", (operand) => operand.type !== \"UndefinedValue\"],\n    [\"undefined\", (operand) => operand.type === \"UndefinedValue\"],\n    [\"equalto\", (a, b) => a.value === b.value],\n    [\"eq\", (a, b) => a.value === b.value]\n  ]);\n  /**\n   * Set the value of a variable in the current environment.\n   */\n  set(name, value) {\n    return this.declareVariable(name, convertToRuntimeValues(value));\n  }\n  declareVariable(name, value) {\n    if (this.variables.has(name)) {\n      throw new SyntaxError(`Variable already declared: ${name}`);\n    }\n    this.variables.set(name, value);\n    return value;\n  }\n  // private assignVariable(name: string, value: AnyRuntimeValue): AnyRuntimeValue {\n  // \tconst env = this.resolve(name);\n  // \tenv.variables.set(name, value);\n  // \treturn value;\n  // }\n  /**\n   * Set variable in the current scope.\n   * See https://jinja.palletsprojects.com/en/3.0.x/templates/#assignments for more information.\n   */\n  setVariable(name, value) {\n    this.variables.set(name, value);\n    return value;\n  }\n  /**\n   * Resolve the environment in which the variable is declared.\n   * @param {string} name The name of the variable.\n   * @returns {Environment} The environment in which the variable is declared.\n   */\n  resolve(name) {\n    if (this.variables.has(name)) {\n      return this;\n    }\n    if (this.parent) {\n      return this.parent.resolve(name);\n    }\n    throw new Error(`Unknown variable: ${name}`);\n  }\n  lookupVariable(name) {\n    try {\n      return this.resolve(name).variables.get(name) ?? new UndefinedValue();\n    } catch {\n      return new UndefinedValue();\n    }\n  }\n};\nfunction setupGlobals(env) {\n  env.set(\"false\", false);\n  env.set(\"true\", true);\n  env.set(\"none\", null);\n  env.set(\"raise_exception\", (args) => {\n    throw new Error(args);\n  });\n  env.set(\"range\", range);\n  env.set(\"strftime_now\", strftime_now);\n  env.set(\"True\", true);\n  env.set(\"False\", false);\n  env.set(\"None\", null);\n}\nfunction getAttributeValue(item, attributePath) {\n  const parts = attributePath.split(\".\");\n  let value = item;\n  for (const part of parts) {\n    if (value instanceof ObjectValue) {\n      value = value.value.get(part) ?? new UndefinedValue();\n    } else if (value instanceof ArrayValue) {\n      const index = parseInt(part, 10);\n      if (!isNaN(index) && index >= 0 && index < value.value.length) {\n        value = value.value[index];\n      } else {\n        return new UndefinedValue();\n      }\n    } else {\n      return new UndefinedValue();\n    }\n  }\n  return value;\n}\nfunction compareRuntimeValues(a, b, caseSensitive = false) {\n  if (a instanceof NullValue && b instanceof NullValue) {\n    return 0;\n  }\n  if (a instanceof NullValue || b instanceof NullValue) {\n    throw new Error(`Cannot compare ${a.type} with ${b.type}`);\n  }\n  if (a instanceof UndefinedValue && b instanceof UndefinedValue) {\n    return 0;\n  }\n  if (a instanceof UndefinedValue || b instanceof UndefinedValue) {\n    throw new Error(`Cannot compare ${a.type} with ${b.type}`);\n  }\n  const isNumericLike = (v) => v instanceof IntegerValue || v instanceof FloatValue || v instanceof BooleanValue;\n  const getNumericValue = (v) => {\n    if (v instanceof BooleanValue) {\n      return v.value ? 1 : 0;\n    }\n    return v.value;\n  };\n  if (isNumericLike(a) && isNumericLike(b)) {\n    const aNum = getNumericValue(a);\n    const bNum = getNumericValue(b);\n    return aNum < bNum ? -1 : aNum > bNum ? 1 : 0;\n  }\n  if (a.type !== b.type) {\n    throw new Error(`Cannot compare different types: ${a.type} and ${b.type}`);\n  }\n  switch (a.type) {\n    case \"StringValue\": {\n      let aStr = a.value;\n      let bStr = b.value;\n      if (!caseSensitive) {\n        aStr = aStr.toLowerCase();\n        bStr = bStr.toLowerCase();\n      }\n      return aStr < bStr ? -1 : aStr > bStr ? 1 : 0;\n    }\n    default:\n      throw new Error(`Cannot compare type: ${a.type}`);\n  }\n}\nvar Interpreter = class {\n  global;\n  constructor(env) {\n    this.global = env ?? new Environment();\n  }\n  /**\n   * Run the program.\n   */\n  run(program) {\n    return this.evaluate(program, this.global);\n  }\n  /**\n   * Evaluates expressions following the binary operation type.\n   */\n  evaluateBinaryExpression(node, environment) {\n    const left = this.evaluate(node.left, environment);\n    switch (node.operator.value) {\n      case \"and\":\n        return left.__bool__().value ? this.evaluate(node.right, environment) : left;\n      case \"or\":\n        return left.__bool__().value ? left : this.evaluate(node.right, environment);\n    }\n    const right = this.evaluate(node.right, environment);\n    switch (node.operator.value) {\n      case \"==\":\n        return new BooleanValue(left.value == right.value);\n      case \"!=\":\n        return new BooleanValue(left.value != right.value);\n    }\n    if (left instanceof UndefinedValue || right instanceof UndefinedValue) {\n      if (right instanceof UndefinedValue && [\"in\", \"not in\"].includes(node.operator.value)) {\n        return new BooleanValue(node.operator.value === \"not in\");\n      }\n      throw new Error(`Cannot perform operation ${node.operator.value} on undefined values`);\n    } else if (left instanceof NullValue || right instanceof NullValue) {\n      throw new Error(\"Cannot perform operation on null values\");\n    } else if (node.operator.value === \"~\") {\n      return new StringValue(left.value.toString() + right.value.toString());\n    } else if ((left instanceof IntegerValue || left instanceof FloatValue) && (right instanceof IntegerValue || right instanceof FloatValue)) {\n      const a = left.value, b = right.value;\n      switch (node.operator.value) {\n        case \"+\":\n        case \"-\":\n        case \"*\": {\n          const res = node.operator.value === \"+\" ? a + b : node.operator.value === \"-\" ? a - b : a * b;\n          const isFloat = left instanceof FloatValue || right instanceof FloatValue;\n          return isFloat ? new FloatValue(res) : new IntegerValue(res);\n        }\n        case \"/\":\n          return new FloatValue(a / b);\n        case \"%\": {\n          const rem = a % b;\n          const isFloat = left instanceof FloatValue || right instanceof FloatValue;\n          return isFloat ? new FloatValue(rem) : new IntegerValue(rem);\n        }\n        case \"<\":\n          return new BooleanValue(a < b);\n        case \">\":\n          return new BooleanValue(a > b);\n        case \">=\":\n          return new BooleanValue(a >= b);\n        case \"<=\":\n          return new BooleanValue(a <= b);\n      }\n    } else if (left instanceof ArrayValue && right instanceof ArrayValue) {\n      switch (node.operator.value) {\n        case \"+\":\n          return new ArrayValue(left.value.concat(right.value));\n      }\n    } else if (right instanceof ArrayValue) {\n      const member = right.value.find((x) => x.value === left.value) !== void 0;\n      switch (node.operator.value) {\n        case \"in\":\n          return new BooleanValue(member);\n        case \"not in\":\n          return new BooleanValue(!member);\n      }\n    }\n    if (left instanceof StringValue || right instanceof StringValue) {\n      switch (node.operator.value) {\n        case \"+\":\n          return new StringValue(left.value.toString() + right.value.toString());\n      }\n    }\n    if (left instanceof StringValue && right instanceof StringValue) {\n      switch (node.operator.value) {\n        case \"in\":\n          return new BooleanValue(right.value.includes(left.value));\n        case \"not in\":\n          return new BooleanValue(!right.value.includes(left.value));\n      }\n    }\n    if (left instanceof StringValue && right instanceof ObjectValue) {\n      switch (node.operator.value) {\n        case \"in\":\n          return new BooleanValue(right.value.has(left.value));\n        case \"not in\":\n          return new BooleanValue(!right.value.has(left.value));\n      }\n    }\n    throw new SyntaxError(`Unknown operator \"${node.operator.value}\" between ${left.type} and ${right.type}`);\n  }\n  evaluateArguments(args, environment) {\n    const positionalArguments = [];\n    const keywordArguments = /* @__PURE__ */ new Map();\n    for (const argument of args) {\n      if (argument.type === \"SpreadExpression\") {\n        const spreadNode = argument;\n        const val = this.evaluate(spreadNode.argument, environment);\n        if (!(val instanceof ArrayValue)) {\n          throw new Error(`Cannot unpack non-iterable type: ${val.type}`);\n        }\n        for (const item of val.value) {\n          positionalArguments.push(item);\n        }\n      } else if (argument.type === \"KeywordArgumentExpression\") {\n        const kwarg = argument;\n        keywordArguments.set(kwarg.key.value, this.evaluate(kwarg.value, environment));\n      } else {\n        if (keywordArguments.size > 0) {\n          throw new Error(\"Positional arguments must come before keyword arguments\");\n        }\n        positionalArguments.push(this.evaluate(argument, environment));\n      }\n    }\n    return [positionalArguments, keywordArguments];\n  }\n  applyFilter(operand, filterNode, environment) {\n    if (filterNode.type === \"Identifier\") {\n      const filter = filterNode;\n      if (filter.value === \"tojson\") {\n        return new StringValue(toJSON(operand));\n      }\n      if (operand instanceof ArrayValue) {\n        switch (filter.value) {\n          case \"list\":\n            return operand;\n          case \"first\":\n            return operand.value[0];\n          case \"last\":\n            return operand.value[operand.value.length - 1];\n          case \"length\":\n            return new IntegerValue(operand.value.length);\n          case \"reverse\":\n            return new ArrayValue(operand.value.slice().reverse());\n          case \"sort\": {\n            return new ArrayValue(operand.value.slice().sort((a, b) => compareRuntimeValues(a, b, false)));\n          }\n          case \"join\":\n            return new StringValue(operand.value.map((x) => x.value).join(\"\"));\n          case \"string\":\n            return new StringValue(toJSON(operand, null, 0, false));\n          case \"unique\": {\n            const seen = /* @__PURE__ */ new Set();\n            const output = [];\n            for (const item of operand.value) {\n              if (!seen.has(item.value)) {\n                seen.add(item.value);\n                output.push(item);\n              }\n            }\n            return new ArrayValue(output);\n          }\n          default:\n            throw new Error(`Unknown ArrayValue filter: ${filter.value}`);\n        }\n      } else if (operand instanceof StringValue) {\n        switch (filter.value) {\n          case \"length\":\n          case \"upper\":\n          case \"lower\":\n          case \"title\":\n          case \"capitalize\": {\n            const builtin = operand.builtins.get(filter.value);\n            if (builtin instanceof FunctionValue) {\n              return builtin.value(\n                /* no arguments */\n                [],\n                environment\n              );\n            } else if (builtin instanceof IntegerValue) {\n              return builtin;\n            } else {\n              throw new Error(`Unknown StringValue filter: ${filter.value}`);\n            }\n          }\n          case \"trim\":\n            return new StringValue(operand.value.trim());\n          case \"indent\":\n            return new StringValue(\n              operand.value.split(\"\\n\").map(\n                (x, i) => (\n                  // By default, don't indent the first line or empty lines\n                  i === 0 || x.length === 0 ? x : \"    \" + x\n                )\n              ).join(\"\\n\")\n            );\n          case \"join\":\n          case \"string\":\n            return operand;\n          case \"int\": {\n            const val = parseInt(operand.value, 10);\n            return new IntegerValue(isNaN(val) ? 0 : val);\n          }\n          case \"float\": {\n            const val = parseFloat(operand.value);\n            return new FloatValue(isNaN(val) ? 0 : val);\n          }\n          default:\n            throw new Error(`Unknown StringValue filter: ${filter.value}`);\n        }\n      } else if (operand instanceof IntegerValue || operand instanceof FloatValue) {\n        switch (filter.value) {\n          case \"abs\":\n            return operand instanceof IntegerValue ? new IntegerValue(Math.abs(operand.value)) : new FloatValue(Math.abs(operand.value));\n          case \"int\":\n            return new IntegerValue(Math.floor(operand.value));\n          case \"float\":\n            return new FloatValue(operand.value);\n          default:\n            throw new Error(`Unknown NumericValue filter: ${filter.value}`);\n        }\n      } else if (operand instanceof ObjectValue) {\n        switch (filter.value) {\n          case \"items\":\n            return new ArrayValue(\n              Array.from(operand.value.entries()).map(([key, value]) => new ArrayValue([new StringValue(key), value]))\n            );\n          case \"length\":\n            return new IntegerValue(operand.value.size);\n          default: {\n            const builtin = operand.builtins.get(filter.value);\n            if (builtin) {\n              if (builtin instanceof FunctionValue) {\n                return builtin.value([], environment);\n              }\n              return builtin;\n            }\n            throw new Error(`Unknown ObjectValue filter: ${filter.value}`);\n          }\n        }\n      } else if (operand instanceof BooleanValue) {\n        switch (filter.value) {\n          case \"bool\":\n            return new BooleanValue(operand.value);\n          case \"int\":\n            return new IntegerValue(operand.value ? 1 : 0);\n          case \"float\":\n            return new FloatValue(operand.value ? 1 : 0);\n          case \"string\":\n            return new StringValue(operand.value ? \"true\" : \"false\");\n          default:\n            throw new Error(`Unknown BooleanValue filter: ${filter.value}`);\n        }\n      }\n      throw new Error(`Cannot apply filter \"${filter.value}\" to type: ${operand.type}`);\n    } else if (filterNode.type === \"CallExpression\") {\n      const filter = filterNode;\n      if (filter.callee.type !== \"Identifier\") {\n        throw new Error(`Unknown filter: ${filter.callee.type}`);\n      }\n      const filterName = filter.callee.value;\n      if (filterName === \"tojson\") {\n        const [, kwargs] = this.evaluateArguments(filter.args, environment);\n        const indent = kwargs.get(\"indent\") ?? new NullValue();\n        if (!(indent instanceof IntegerValue || indent instanceof NullValue)) {\n          throw new Error(\"If set, indent must be a number\");\n        }\n        return new StringValue(toJSON(operand, indent.value));\n      } else if (filterName === \"join\") {\n        let value;\n        if (operand instanceof StringValue) {\n          value = Array.from(operand.value);\n        } else if (operand instanceof ArrayValue) {\n          value = operand.value.map((x) => x.value);\n        } else {\n          throw new Error(`Cannot apply filter \"${filterName}\" to type: ${operand.type}`);\n        }\n        const [args, kwargs] = this.evaluateArguments(filter.args, environment);\n        const separator = args.at(0) ?? kwargs.get(\"separator\") ?? new StringValue(\"\");\n        if (!(separator instanceof StringValue)) {\n          throw new Error(\"separator must be a string\");\n        }\n        return new StringValue(value.join(separator.value));\n      } else if (filterName === \"int\" || filterName === \"float\") {\n        const [args, kwargs] = this.evaluateArguments(filter.args, environment);\n        const defaultValue = args.at(0) ?? kwargs.get(\"default\") ?? (filterName === \"int\" ? new IntegerValue(0) : new FloatValue(0));\n        if (operand instanceof StringValue) {\n          const val = filterName === \"int\" ? parseInt(operand.value, 10) : parseFloat(operand.value);\n          return isNaN(val) ? defaultValue : filterName === \"int\" ? new IntegerValue(val) : new FloatValue(val);\n        } else if (operand instanceof IntegerValue || operand instanceof FloatValue) {\n          return operand;\n        } else if (operand instanceof BooleanValue) {\n          return filterName === \"int\" ? new IntegerValue(operand.value ? 1 : 0) : new FloatValue(operand.value ? 1 : 0);\n        } else {\n          throw new Error(`Cannot apply filter \"${filterName}\" to type: ${operand.type}`);\n        }\n      } else if (filterName === \"default\") {\n        const [args, kwargs] = this.evaluateArguments(filter.args, environment);\n        const defaultValue = args[0] ?? new StringValue(\"\");\n        const booleanValue = args[1] ?? kwargs.get(\"boolean\") ?? new BooleanValue(false);\n        if (!(booleanValue instanceof BooleanValue)) {\n          throw new Error(\"`default` filter flag must be a boolean\");\n        }\n        if (operand instanceof UndefinedValue || booleanValue.value && !operand.__bool__().value) {\n          return defaultValue;\n        }\n        return operand;\n      }\n      if (operand instanceof ArrayValue) {\n        switch (filterName) {\n          case \"sort\": {\n            const [args, kwargs] = this.evaluateArguments(filter.args, environment);\n            const reverse = args.at(0) ?? kwargs.get(\"reverse\") ?? new BooleanValue(false);\n            if (!(reverse instanceof BooleanValue)) {\n              throw new Error(\"reverse must be a boolean\");\n            }\n            const caseSensitive = args.at(1) ?? kwargs.get(\"case_sensitive\") ?? new BooleanValue(false);\n            if (!(caseSensitive instanceof BooleanValue)) {\n              throw new Error(\"case_sensitive must be a boolean\");\n            }\n            const attribute = args.at(2) ?? kwargs.get(\"attribute\") ?? new NullValue();\n            if (!(attribute instanceof StringValue || attribute instanceof IntegerValue || attribute instanceof NullValue)) {\n              throw new Error(\"attribute must be a string, integer, or null\");\n            }\n            const getSortValue = (item) => {\n              if (attribute instanceof NullValue) {\n                return item;\n              }\n              const attrPath = attribute instanceof IntegerValue ? String(attribute.value) : attribute.value;\n              return getAttributeValue(item, attrPath);\n            };\n            return new ArrayValue(\n              operand.value.slice().sort((a, b) => {\n                const aVal = getSortValue(a);\n                const bVal = getSortValue(b);\n                const result = compareRuntimeValues(aVal, bVal, caseSensitive.value);\n                return reverse.value ? -result : result;\n              })\n            );\n          }\n          case \"selectattr\":\n          case \"rejectattr\": {\n            const select = filterName === \"selectattr\";\n            if (operand.value.some((x) => !(x instanceof ObjectValue))) {\n              throw new Error(`\\`${filterName}\\` can only be applied to array of objects`);\n            }\n            if (filter.args.some((x) => x.type !== \"StringLiteral\")) {\n              throw new Error(`arguments of \\`${filterName}\\` must be strings`);\n            }\n            const [attr, testName, value] = filter.args.map((x) => this.evaluate(x, environment));\n            let testFunction;\n            if (testName) {\n              const test = environment.tests.get(testName.value);\n              if (!test) {\n                throw new Error(`Unknown test: ${testName.value}`);\n              }\n              testFunction = test;\n            } else {\n              testFunction = (...x) => x[0].__bool__().value;\n            }\n            const filtered = operand.value.filter((item) => {\n              const a = item.value.get(attr.value);\n              const result = a ? testFunction(a, value) : false;\n              return select ? result : !result;\n            });\n            return new ArrayValue(filtered);\n          }\n          case \"map\": {\n            const [, kwargs] = this.evaluateArguments(filter.args, environment);\n            if (kwargs.has(\"attribute\")) {\n              const attr = kwargs.get(\"attribute\");\n              if (!(attr instanceof StringValue)) {\n                throw new Error(\"attribute must be a string\");\n              }\n              const defaultValue = kwargs.get(\"default\");\n              const mapped = operand.value.map((item) => {\n                if (!(item instanceof ObjectValue)) {\n                  throw new Error(\"items in map must be an object\");\n                }\n                const value = getAttributeValue(item, attr.value);\n                return value instanceof UndefinedValue ? defaultValue ?? new UndefinedValue() : value;\n              });\n              return new ArrayValue(mapped);\n            } else {\n              throw new Error(\"`map` expressions without `attribute` set are not currently supported.\");\n            }\n          }\n        }\n        throw new Error(`Unknown ArrayValue filter: ${filterName}`);\n      } else if (operand instanceof StringValue) {\n        switch (filterName) {\n          case \"indent\": {\n            const [args, kwargs] = this.evaluateArguments(filter.args, environment);\n            const width = args.at(0) ?? kwargs.get(\"width\") ?? new IntegerValue(4);\n            if (!(width instanceof IntegerValue)) {\n              throw new Error(\"width must be a number\");\n            }\n            const first = args.at(1) ?? kwargs.get(\"first\") ?? new BooleanValue(false);\n            const blank = args.at(2) ?? kwargs.get(\"blank\") ?? new BooleanValue(false);\n            const lines = operand.value.split(\"\\n\");\n            const indent = \" \".repeat(width.value);\n            const indented = lines.map(\n              (x, i) => !first.value && i === 0 || !blank.value && x.length === 0 ? x : indent + x\n            );\n            return new StringValue(indented.join(\"\\n\"));\n          }\n          case \"replace\": {\n            const replaceFn = operand.builtins.get(\"replace\");\n            if (!(replaceFn instanceof FunctionValue)) {\n              throw new Error(\"replace filter not available\");\n            }\n            const [args, kwargs] = this.evaluateArguments(filter.args, environment);\n            return replaceFn.value([...args, new KeywordArgumentsValue(kwargs)], environment);\n          }\n        }\n        throw new Error(`Unknown StringValue filter: ${filterName}`);\n      } else if (operand instanceof ObjectValue) {\n        const builtin = operand.builtins.get(filterName);\n        if (builtin && builtin instanceof FunctionValue) {\n          const [args, kwargs] = this.evaluateArguments(filter.args, environment);\n          if (kwargs.size > 0) {\n            args.push(new KeywordArgumentsValue(kwargs));\n          }\n          return builtin.value(args, environment);\n        }\n        throw new Error(`Unknown ObjectValue filter: ${filterName}`);\n      } else {\n        throw new Error(`Cannot apply filter \"${filterName}\" to type: ${operand.type}`);\n      }\n    }\n    throw new Error(`Unknown filter: ${filterNode.type}`);\n  }\n  /**\n   * Evaluates expressions following the filter operation type.\n   */\n  evaluateFilterExpression(node, environment) {\n    const operand = this.evaluate(node.operand, environment);\n    return this.applyFilter(operand, node.filter, environment);\n  }\n  /**\n   * Evaluates expressions following the test operation type.\n   */\n  evaluateTestExpression(node, environment) {\n    const operand = this.evaluate(node.operand, environment);\n    const test = environment.tests.get(node.test.value);\n    if (!test) {\n      throw new Error(`Unknown test: ${node.test.value}`);\n    }\n    const result = test(operand);\n    return new BooleanValue(node.negate ? !result : result);\n  }\n  /**\n   * Evaluates expressions following the select operation type.\n   */\n  evaluateSelectExpression(node, environment) {\n    const predicate = this.evaluate(node.test, environment);\n    if (!predicate.__bool__().value) {\n      return new UndefinedValue();\n    }\n    return this.evaluate(node.lhs, environment);\n  }\n  /**\n   * Evaluates expressions following the unary operation type.\n   */\n  evaluateUnaryExpression(node, environment) {\n    const argument = this.evaluate(node.argument, environment);\n    switch (node.operator.value) {\n      case \"not\":\n        return new BooleanValue(!argument.value);\n      default:\n        throw new SyntaxError(`Unknown operator: ${node.operator.value}`);\n    }\n  }\n  evaluateTernaryExpression(node, environment) {\n    const cond = this.evaluate(node.condition, environment);\n    return cond.__bool__().value ? this.evaluate(node.trueExpr, environment) : this.evaluate(node.falseExpr, environment);\n  }\n  evalProgram(program, environment) {\n    return this.evaluateBlock(program.body, environment);\n  }\n  evaluateBlock(statements, environment) {\n    let result = \"\";\n    for (const statement of statements) {\n      const lastEvaluated = this.evaluate(statement, environment);\n      if (lastEvaluated.type !== \"NullValue\" && lastEvaluated.type !== \"UndefinedValue\") {\n        result += lastEvaluated.toString();\n      }\n    }\n    return new StringValue(result);\n  }\n  evaluateIdentifier(node, environment) {\n    return environment.lookupVariable(node.value);\n  }\n  evaluateCallExpression(expr, environment) {\n    const [args, kwargs] = this.evaluateArguments(expr.args, environment);\n    if (kwargs.size > 0) {\n      args.push(new KeywordArgumentsValue(kwargs));\n    }\n    const fn = this.evaluate(expr.callee, environment);\n    if (fn.type !== \"FunctionValue\") {\n      throw new Error(`Cannot call something that is not a function: got ${fn.type}`);\n    }\n    return fn.value(args, environment);\n  }\n  evaluateSliceExpression(object, expr, environment) {\n    if (!(object instanceof ArrayValue || object instanceof StringValue)) {\n      throw new Error(\"Slice object must be an array or string\");\n    }\n    const start = this.evaluate(expr.start, environment);\n    const stop = this.evaluate(expr.stop, environment);\n    const step = this.evaluate(expr.step, environment);\n    if (!(start instanceof IntegerValue || start instanceof UndefinedValue)) {\n      throw new Error(\"Slice start must be numeric or undefined\");\n    }\n    if (!(stop instanceof IntegerValue || stop instanceof UndefinedValue)) {\n      throw new Error(\"Slice stop must be numeric or undefined\");\n    }\n    if (!(step instanceof IntegerValue || step instanceof UndefinedValue)) {\n      throw new Error(\"Slice step must be numeric or undefined\");\n    }\n    if (object instanceof ArrayValue) {\n      return new ArrayValue(slice(object.value, start.value, stop.value, step.value));\n    } else {\n      return new StringValue(slice(Array.from(object.value), start.value, stop.value, step.value).join(\"\"));\n    }\n  }\n  evaluateMemberExpression(expr, environment) {\n    const object = this.evaluate(expr.object, environment);\n    let property;\n    if (expr.computed) {\n      if (expr.property.type === \"SliceExpression\") {\n        return this.evaluateSliceExpression(object, expr.property, environment);\n      } else {\n        property = this.evaluate(expr.property, environment);\n      }\n    } else {\n      property = new StringValue(expr.property.value);\n    }\n    let value;\n    if (object instanceof ObjectValue) {\n      if (!(property instanceof StringValue)) {\n        throw new Error(`Cannot access property with non-string: got ${property.type}`);\n      }\n      value = object.value.get(property.value) ?? object.builtins.get(property.value);\n    } else if (object instanceof ArrayValue || object instanceof StringValue) {\n      if (property instanceof IntegerValue) {\n        value = object.value.at(property.value);\n        if (object instanceof StringValue) {\n          value = new StringValue(object.value.at(property.value));\n        }\n      } else if (property instanceof StringValue) {\n        value = object.builtins.get(property.value);\n      } else {\n        throw new Error(`Cannot access property with non-string/non-number: got ${property.type}`);\n      }\n    } else {\n      if (!(property instanceof StringValue)) {\n        throw new Error(`Cannot access property with non-string: got ${property.type}`);\n      }\n      value = object.builtins.get(property.value);\n    }\n    return value instanceof RuntimeValue ? value : new UndefinedValue();\n  }\n  evaluateSet(node, environment) {\n    const rhs = node.value ? this.evaluate(node.value, environment) : this.evaluateBlock(node.body, environment);\n    if (node.assignee.type === \"Identifier\") {\n      const variableName = node.assignee.value;\n      environment.setVariable(variableName, rhs);\n    } else if (node.assignee.type === \"TupleLiteral\") {\n      const tuple = node.assignee;\n      if (!(rhs instanceof ArrayValue)) {\n        throw new Error(`Cannot unpack non-iterable type in set: ${rhs.type}`);\n      }\n      const arr = rhs.value;\n      if (arr.length !== tuple.value.length) {\n        throw new Error(`Too ${tuple.value.length > arr.length ? \"few\" : \"many\"} items to unpack in set`);\n      }\n      for (let i = 0; i < tuple.value.length; ++i) {\n        const elem = tuple.value[i];\n        if (elem.type !== \"Identifier\") {\n          throw new Error(`Cannot unpack to non-identifier in set: ${elem.type}`);\n        }\n        environment.setVariable(elem.value, arr[i]);\n      }\n    } else if (node.assignee.type === \"MemberExpression\") {\n      const member = node.assignee;\n      const object = this.evaluate(member.object, environment);\n      if (!(object instanceof ObjectValue)) {\n        throw new Error(\"Cannot assign to member of non-object\");\n      }\n      if (member.property.type !== \"Identifier\") {\n        throw new Error(\"Cannot assign to member with non-identifier property\");\n      }\n      object.value.set(member.property.value, rhs);\n    } else {\n      throw new Error(`Invalid LHS inside assignment expression: ${JSON.stringify(node.assignee)}`);\n    }\n    return new NullValue();\n  }\n  evaluateIf(node, environment) {\n    const test = this.evaluate(node.test, environment);\n    return this.evaluateBlock(test.__bool__().value ? node.body : node.alternate, environment);\n  }\n  evaluateFor(node, environment) {\n    const scope = new Environment(environment);\n    let test, iterable;\n    if (node.iterable.type === \"SelectExpression\") {\n      const select = node.iterable;\n      iterable = this.evaluate(select.lhs, scope);\n      test = select.test;\n    } else {\n      iterable = this.evaluate(node.iterable, scope);\n    }\n    if (!(iterable instanceof ArrayValue || iterable instanceof ObjectValue)) {\n      throw new Error(`Expected iterable or object type in for loop: got ${iterable.type}`);\n    }\n    if (iterable instanceof ObjectValue) {\n      iterable = iterable.keys();\n    }\n    const items = [];\n    const scopeUpdateFunctions = [];\n    for (let i = 0; i < iterable.value.length; ++i) {\n      const loopScope = new Environment(scope);\n      const current = iterable.value[i];\n      let scopeUpdateFunction;\n      if (node.loopvar.type === \"Identifier\") {\n        scopeUpdateFunction = (scope2) => scope2.setVariable(node.loopvar.value, current);\n      } else if (node.loopvar.type === \"TupleLiteral\") {\n        const loopvar = node.loopvar;\n        if (current.type !== \"ArrayValue\") {\n          throw new Error(`Cannot unpack non-iterable type: ${current.type}`);\n        }\n        const c = current;\n        if (loopvar.value.length !== c.value.length) {\n          throw new Error(`Too ${loopvar.value.length > c.value.length ? \"few\" : \"many\"} items to unpack`);\n        }\n        scopeUpdateFunction = (scope2) => {\n          for (let j = 0; j < loopvar.value.length; ++j) {\n            if (loopvar.value[j].type !== \"Identifier\") {\n              throw new Error(`Cannot unpack non-identifier type: ${loopvar.value[j].type}`);\n            }\n            scope2.setVariable(loopvar.value[j].value, c.value[j]);\n          }\n        };\n      } else {\n        throw new Error(`Invalid loop variable(s): ${node.loopvar.type}`);\n      }\n      if (test) {\n        scopeUpdateFunction(loopScope);\n        const testValue = this.evaluate(test, loopScope);\n        if (!testValue.__bool__().value) {\n          continue;\n        }\n      }\n      items.push(current);\n      scopeUpdateFunctions.push(scopeUpdateFunction);\n    }\n    let result = \"\";\n    let noIteration = true;\n    for (let i = 0; i < items.length; ++i) {\n      const loop = /* @__PURE__ */ new Map([\n        [\"index\", new IntegerValue(i + 1)],\n        [\"index0\", new IntegerValue(i)],\n        [\"revindex\", new IntegerValue(items.length - i)],\n        [\"revindex0\", new IntegerValue(items.length - i - 1)],\n        [\"first\", new BooleanValue(i === 0)],\n        [\"last\", new BooleanValue(i === items.length - 1)],\n        [\"length\", new IntegerValue(items.length)],\n        [\"previtem\", i > 0 ? items[i - 1] : new UndefinedValue()],\n        [\"nextitem\", i < items.length - 1 ? items[i + 1] : new UndefinedValue()]\n      ]);\n      scope.setVariable(\"loop\", new ObjectValue(loop));\n      scopeUpdateFunctions[i](scope);\n      try {\n        const evaluated = this.evaluateBlock(node.body, scope);\n        result += evaluated.value;\n      } catch (err) {\n        if (err instanceof ContinueControl) {\n          continue;\n        }\n        if (err instanceof BreakControl) {\n          break;\n        }\n        throw err;\n      }\n      noIteration = false;\n    }\n    if (noIteration) {\n      const defaultEvaluated = this.evaluateBlock(node.defaultBlock, scope);\n      result += defaultEvaluated.value;\n    }\n    return new StringValue(result);\n  }\n  /**\n   * See https://jinja.palletsprojects.com/en/3.1.x/templates/#macros for more information.\n   */\n  evaluateMacro(node, environment) {\n    environment.setVariable(\n      node.name.value,\n      new FunctionValue((args, scope) => {\n        const macroScope = new Environment(scope);\n        args = args.slice();\n        let kwargs;\n        if (args.at(-1)?.type === \"KeywordArgumentsValue\") {\n          kwargs = args.pop();\n        }\n        for (let i = 0; i < node.args.length; ++i) {\n          const nodeArg = node.args[i];\n          const passedArg = args[i];\n          if (nodeArg.type === \"Identifier\") {\n            const identifier = nodeArg;\n            if (!passedArg) {\n              throw new Error(`Missing positional argument: ${identifier.value}`);\n            }\n            macroScope.setVariable(identifier.value, passedArg);\n          } else if (nodeArg.type === \"KeywordArgumentExpression\") {\n            const kwarg = nodeArg;\n            const value = passedArg ?? // Try positional arguments first\n            kwargs?.value.get(kwarg.key.value) ?? // Look in user-passed kwargs\n            this.evaluate(kwarg.value, macroScope);\n            macroScope.setVariable(kwarg.key.value, value);\n          } else {\n            throw new Error(`Unknown argument type: ${nodeArg.type}`);\n          }\n        }\n        return this.evaluateBlock(node.body, macroScope);\n      })\n    );\n    return new NullValue();\n  }\n  evaluateCallStatement(node, environment) {\n    const callerFn = new FunctionValue((callerArgs, callerEnv) => {\n      const callBlockEnv = new Environment(callerEnv);\n      if (node.callerArgs) {\n        for (let i = 0; i < node.callerArgs.length; ++i) {\n          const param = node.callerArgs[i];\n          if (param.type !== \"Identifier\") {\n            throw new Error(`Caller parameter must be an identifier, got ${param.type}`);\n          }\n          callBlockEnv.setVariable(param.value, callerArgs[i] ?? new UndefinedValue());\n        }\n      }\n      return this.evaluateBlock(node.body, callBlockEnv);\n    });\n    const [macroArgs, macroKwargs] = this.evaluateArguments(node.call.args, environment);\n    macroArgs.push(new KeywordArgumentsValue(macroKwargs));\n    const fn = this.evaluate(node.call.callee, environment);\n    if (fn.type !== \"FunctionValue\") {\n      throw new Error(`Cannot call something that is not a function: got ${fn.type}`);\n    }\n    const newEnv = new Environment(environment);\n    newEnv.setVariable(\"caller\", callerFn);\n    return fn.value(macroArgs, newEnv);\n  }\n  evaluateFilterStatement(node, environment) {\n    const rendered = this.evaluateBlock(node.body, environment);\n    return this.applyFilter(rendered, node.filter, environment);\n  }\n  evaluate(statement, environment) {\n    if (!statement)\n      return new UndefinedValue();\n    switch (statement.type) {\n      case \"Program\":\n        return this.evalProgram(statement, environment);\n      case \"Set\":\n        return this.evaluateSet(statement, environment);\n      case \"If\":\n        return this.evaluateIf(statement, environment);\n      case \"For\":\n        return this.evaluateFor(statement, environment);\n      case \"Macro\":\n        return this.evaluateMacro(statement, environment);\n      case \"CallStatement\":\n        return this.evaluateCallStatement(statement, environment);\n      case \"Break\":\n        throw new BreakControl();\n      case \"Continue\":\n        throw new ContinueControl();\n      case \"IntegerLiteral\":\n        return new IntegerValue(statement.value);\n      case \"FloatLiteral\":\n        return new FloatValue(statement.value);\n      case \"StringLiteral\":\n        return new StringValue(statement.value);\n      case \"ArrayLiteral\":\n        return new ArrayValue(statement.value.map((x) => this.evaluate(x, environment)));\n      case \"TupleLiteral\":\n        return new TupleValue(statement.value.map((x) => this.evaluate(x, environment)));\n      case \"ObjectLiteral\": {\n        const mapping = /* @__PURE__ */ new Map();\n        for (const [key, value] of statement.value) {\n          const evaluatedKey = this.evaluate(key, environment);\n          if (!(evaluatedKey instanceof StringValue)) {\n            throw new Error(`Object keys must be strings: got ${evaluatedKey.type}`);\n          }\n          mapping.set(evaluatedKey.value, this.evaluate(value, environment));\n        }\n        return new ObjectValue(mapping);\n      }\n      case \"Identifier\":\n        return this.evaluateIdentifier(statement, environment);\n      case \"CallExpression\":\n        return this.evaluateCallExpression(statement, environment);\n      case \"MemberExpression\":\n        return this.evaluateMemberExpression(statement, environment);\n      case \"UnaryExpression\":\n        return this.evaluateUnaryExpression(statement, environment);\n      case \"BinaryExpression\":\n        return this.evaluateBinaryExpression(statement, environment);\n      case \"FilterExpression\":\n        return this.evaluateFilterExpression(statement, environment);\n      case \"FilterStatement\":\n        return this.evaluateFilterStatement(statement, environment);\n      case \"TestExpression\":\n        return this.evaluateTestExpression(statement, environment);\n      case \"SelectExpression\":\n        return this.evaluateSelectExpression(statement, environment);\n      case \"Ternary\":\n        return this.evaluateTernaryExpression(statement, environment);\n      case \"Comment\":\n        return new NullValue();\n      default:\n        throw new SyntaxError(`Unknown node type: ${statement.type}`);\n    }\n  }\n};\nfunction convertToRuntimeValues(input) {\n  switch (typeof input) {\n    case \"number\":\n      return Number.isInteger(input) ? new IntegerValue(input) : new FloatValue(input);\n    case \"string\":\n      return new StringValue(input);\n    case \"boolean\":\n      return new BooleanValue(input);\n    case \"undefined\":\n      return new UndefinedValue();\n    case \"object\":\n      if (input === null) {\n        return new NullValue();\n      } else if (Array.isArray(input)) {\n        return new ArrayValue(input.map(convertToRuntimeValues));\n      } else {\n        return new ObjectValue(\n          new Map(Object.entries(input).map(([key, value]) => [key, convertToRuntimeValues(value)]))\n        );\n      }\n    case \"function\":\n      return new FunctionValue((args, _scope) => {\n        const result = input(...args.map((x) => x.value)) ?? null;\n        return convertToRuntimeValues(result);\n      });\n    default:\n      throw new Error(`Cannot convert to runtime value: ${input}`);\n  }\n}\n\n// src/format.ts\nvar NEWLINE = \"\\n\";\nvar OPEN_STATEMENT = \"{%- \";\nvar CLOSE_STATEMENT = \" -%}\";\nfunction getBinaryOperatorPrecedence(expr) {\n  switch (expr.operator.type) {\n    case \"MultiplicativeBinaryOperator\":\n      return 4;\n    case \"AdditiveBinaryOperator\":\n      return 3;\n    case \"ComparisonBinaryOperator\":\n      return 2;\n    case \"Identifier\":\n      if (expr.operator.value === \"and\")\n        return 1;\n      if (expr.operator.value === \"in\" || expr.operator.value === \"not in\")\n        return 2;\n      return 0;\n  }\n  return 0;\n}\nfunction format(program, indent = \"\t\") {\n  const indentStr = typeof indent === \"number\" ? \" \".repeat(indent) : indent;\n  const body = formatStatements(program.body, 0, indentStr);\n  return body.replace(/\\n$/, \"\");\n}\nfunction createStatement(...text) {\n  return OPEN_STATEMENT + text.join(\" \") + CLOSE_STATEMENT;\n}\nfunction formatStatements(stmts, depth, indentStr) {\n  return stmts.map((stmt) => formatStatement(stmt, depth, indentStr)).join(NEWLINE);\n}\nfunction formatStatement(node, depth, indentStr) {\n  const pad = indentStr.repeat(depth);\n  switch (node.type) {\n    case \"Program\":\n      return formatStatements(node.body, depth, indentStr);\n    case \"If\":\n      return formatIf(node, depth, indentStr);\n    case \"For\":\n      return formatFor(node, depth, indentStr);\n    case \"Set\":\n      return formatSet(node, depth, indentStr);\n    case \"Macro\":\n      return formatMacro(node, depth, indentStr);\n    case \"Break\":\n      return pad + createStatement(\"break\");\n    case \"Continue\":\n      return pad + createStatement(\"continue\");\n    case \"CallStatement\":\n      return formatCallStatement(node, depth, indentStr);\n    case \"FilterStatement\":\n      return formatFilterStatement(node, depth, indentStr);\n    case \"Comment\":\n      return pad + \"{# \" + node.value + \" #}\";\n    default:\n      return pad + \"{{- \" + formatExpression(node) + \" -}}\";\n  }\n}\nfunction formatIf(node, depth, indentStr) {\n  const pad = indentStr.repeat(depth);\n  const clauses = [];\n  let current = node;\n  while (current) {\n    clauses.push({ test: current.test, body: current.body });\n    if (current.alternate.length === 1 && current.alternate[0].type === \"If\") {\n      current = current.alternate[0];\n    } else {\n      break;\n    }\n  }\n  let out = pad + createStatement(\"if\", formatExpression(clauses[0].test)) + NEWLINE + formatStatements(clauses[0].body, depth + 1, indentStr);\n  for (let i = 1; i < clauses.length; ++i) {\n    out += NEWLINE + pad + createStatement(\"elif\", formatExpression(clauses[i].test)) + NEWLINE + formatStatements(clauses[i].body, depth + 1, indentStr);\n  }\n  if (current && current.alternate.length > 0) {\n    out += NEWLINE + pad + createStatement(\"else\") + NEWLINE + formatStatements(current.alternate, depth + 1, indentStr);\n  }\n  out += NEWLINE + pad + createStatement(\"endif\");\n  return out;\n}\nfunction formatFor(node, depth, indentStr) {\n  const pad = indentStr.repeat(depth);\n  let formattedIterable = \"\";\n  if (node.iterable.type === \"SelectExpression\") {\n    const n = node.iterable;\n    formattedIterable = `${formatExpression(n.lhs)} if ${formatExpression(n.test)}`;\n  } else {\n    formattedIterable = formatExpression(node.iterable);\n  }\n  let out = pad + createStatement(\"for\", formatExpression(node.loopvar), \"in\", formattedIterable) + NEWLINE + formatStatements(node.body, depth + 1, indentStr);\n  if (node.defaultBlock.length > 0) {\n    out += NEWLINE + pad + createStatement(\"else\") + NEWLINE + formatStatements(node.defaultBlock, depth + 1, indentStr);\n  }\n  out += NEWLINE + pad + createStatement(\"endfor\");\n  return out;\n}\nfunction formatSet(node, depth, indentStr) {\n  const pad = indentStr.repeat(depth);\n  const left = formatExpression(node.assignee);\n  const right = node.value ? formatExpression(node.value) : \"\";\n  const value = pad + createStatement(\"set\", `${left}${node.value ? \" = \" + right : \"\"}`);\n  if (node.body.length === 0) {\n    return value;\n  }\n  return value + NEWLINE + formatStatements(node.body, depth + 1, indentStr) + NEWLINE + pad + createStatement(\"endset\");\n}\nfunction formatMacro(node, depth, indentStr) {\n  const pad = indentStr.repeat(depth);\n  const args = node.args.map(formatExpression).join(\", \");\n  return pad + createStatement(\"macro\", `${node.name.value}(${args})`) + NEWLINE + formatStatements(node.body, depth + 1, indentStr) + NEWLINE + pad + createStatement(\"endmacro\");\n}\nfunction formatCallStatement(node, depth, indentStr) {\n  const pad = indentStr.repeat(depth);\n  const params = node.callerArgs && node.callerArgs.length > 0 ? `(${node.callerArgs.map(formatExpression).join(\", \")})` : \"\";\n  const callExpr = formatExpression(node.call);\n  let out = pad + createStatement(`call${params}`, callExpr) + NEWLINE;\n  out += formatStatements(node.body, depth + 1, indentStr) + NEWLINE;\n  out += pad + createStatement(\"endcall\");\n  return out;\n}\nfunction formatFilterStatement(node, depth, indentStr) {\n  const pad = indentStr.repeat(depth);\n  const spec = node.filter.type === \"Identifier\" ? node.filter.value : formatExpression(node.filter);\n  let out = pad + createStatement(\"filter\", spec) + NEWLINE;\n  out += formatStatements(node.body, depth + 1, indentStr) + NEWLINE;\n  out += pad + createStatement(\"endfilter\");\n  return out;\n}\nfunction formatExpression(node, parentPrec = -1) {\n  switch (node.type) {\n    case \"SpreadExpression\": {\n      const n = node;\n      return `*${formatExpression(n.argument)}`;\n    }\n    case \"Identifier\":\n      return node.value;\n    case \"IntegerLiteral\":\n      return `${node.value}`;\n    case \"FloatLiteral\":\n      return `${node.value}`;\n    case \"StringLiteral\":\n      return JSON.stringify(node.value);\n    case \"BinaryExpression\": {\n      const n = node;\n      const thisPrecedence = getBinaryOperatorPrecedence(n);\n      const left = formatExpression(n.left, thisPrecedence);\n      const right = formatExpression(n.right, thisPrecedence + 1);\n      const expr = `${left} ${n.operator.value} ${right}`;\n      return thisPrecedence < parentPrec ? `(${expr})` : expr;\n    }\n    case \"UnaryExpression\": {\n      const n = node;\n      const val = n.operator.value + (n.operator.value === \"not\" ? \" \" : \"\") + formatExpression(n.argument, Infinity);\n      return val;\n    }\n    case \"CallExpression\": {\n      const n = node;\n      const args = n.args.map(formatExpression).join(\", \");\n      return `${formatExpression(n.callee)}(${args})`;\n    }\n    case \"MemberExpression\": {\n      const n = node;\n      let obj = formatExpression(n.object);\n      if (![\n        \"Identifier\",\n        \"MemberExpression\",\n        \"CallExpression\",\n        \"StringLiteral\",\n        \"IntegerLiteral\",\n        \"FloatLiteral\",\n        \"ArrayLiteral\",\n        \"TupleLiteral\",\n        \"ObjectLiteral\"\n      ].includes(n.object.type)) {\n        obj = `(${obj})`;\n      }\n      let prop = formatExpression(n.property);\n      if (!n.computed && n.property.type !== \"Identifier\") {\n        prop = `(${prop})`;\n      }\n      return n.computed ? `${obj}[${prop}]` : `${obj}.${prop}`;\n    }\n    case \"FilterExpression\": {\n      const n = node;\n      const operand = formatExpression(n.operand, Infinity);\n      if (n.filter.type === \"CallExpression\") {\n        return `${operand} | ${formatExpression(n.filter)}`;\n      }\n      return `${operand} | ${n.filter.value}`;\n    }\n    case \"SelectExpression\": {\n      const n = node;\n      return `${formatExpression(n.lhs)} if ${formatExpression(n.test)}`;\n    }\n    case \"TestExpression\": {\n      const n = node;\n      return `${formatExpression(n.operand)} is${n.negate ? \" not\" : \"\"} ${n.test.value}`;\n    }\n    case \"ArrayLiteral\":\n    case \"TupleLiteral\": {\n      const elems = node.value.map(formatExpression);\n      const brackets = node.type === \"ArrayLiteral\" ? \"[]\" : \"()\";\n      return `${brackets[0]}${elems.join(\", \")}${brackets[1]}`;\n    }\n    case \"ObjectLiteral\": {\n      const entries = Array.from(node.value.entries()).map(\n        ([k, v]) => `${formatExpression(k)}: ${formatExpression(v)}`\n      );\n      return `{${entries.join(\", \")}}`;\n    }\n    case \"SliceExpression\": {\n      const n = node;\n      const s = n.start ? formatExpression(n.start) : \"\";\n      const t = n.stop ? formatExpression(n.stop) : \"\";\n      const st = n.step ? `:${formatExpression(n.step)}` : \"\";\n      return `${s}:${t}${st}`;\n    }\n    case \"KeywordArgumentExpression\": {\n      const n = node;\n      return `${n.key.value}=${formatExpression(n.value)}`;\n    }\n    case \"Ternary\": {\n      const n = node;\n      const expr = `${formatExpression(n.trueExpr)} if ${formatExpression(n.condition, 0)} else ${formatExpression(\n        n.falseExpr\n      )}`;\n      return parentPrec > -1 ? `(${expr})` : expr;\n    }\n    default:\n      throw new Error(`Unknown expression type: ${node.type}`);\n  }\n}\n\n// src/index.ts\nvar Template = class {\n  parsed;\n  /**\n   * @param {string} template The template string\n   */\n  constructor(template) {\n    const tokens = tokenize(template, {\n      lstrip_blocks: true,\n      trim_blocks: true\n    });\n    this.parsed = parse(tokens);\n  }\n  render(items) {\n    const env = new Environment();\n    setupGlobals(env);\n    if (items) {\n      for (const [key, value] of Object.entries(items)) {\n        env.set(key, value);\n      }\n    }\n    const interpreter = new Interpreter(env);\n    const result = interpreter.run(this.parsed);\n    return result.value;\n  }\n  format(options) {\n    return format(this.parsed, options?.indent || \"\t\");\n  }\n};\nexport {\n  Environment,\n  Interpreter,\n  Template,\n  parse,\n  tokenize\n};\n","/**\n * Mapping from library name to its supported tasks.\n * HF-Inference API (serverless) should be disabled for all other (library, task) pairs beyond this mapping.\n * This mapping is partially generated automatically by \"python-api-export-tasks\" action in\n * huggingface/api-inference-community repo upon merge. For transformers, the mapping is manually\n * based on api-inference (hf_types.rs).\n */\nexport const LIBRARY_TASK_MAPPING = {\n    \"adapter-transformers\": [\"question-answering\", \"text-classification\", \"token-classification\"],\n    allennlp: [\"question-answering\"],\n    asteroid: [\n        // \"audio-source-separation\",\n        \"audio-to-audio\",\n    ],\n    bertopic: [\"text-classification\"],\n    diffusers: [\"image-to-image\", \"text-to-image\"],\n    doctr: [\"object-detection\"],\n    espnet: [\"text-to-speech\", \"automatic-speech-recognition\"],\n    fairseq: [\"text-to-speech\", \"audio-to-audio\"],\n    fastai: [\"image-classification\"],\n    fasttext: [\"feature-extraction\", \"text-classification\"],\n    flair: [\"token-classification\"],\n    k2: [\"automatic-speech-recognition\"],\n    keras: [\"image-classification\"],\n    nemo: [\"automatic-speech-recognition\"],\n    open_clip: [\"zero-shot-classification\", \"zero-shot-image-classification\"],\n    paddlenlp: [\"fill-mask\", \"summarization\", \"zero-shot-classification\"],\n    peft: [\"text-generation\"],\n    \"pyannote-audio\": [\"automatic-speech-recognition\"],\n    \"sentence-transformers\": [\"feature-extraction\", \"sentence-similarity\"],\n    setfit: [\"text-classification\"],\n    sklearn: [\"tabular-classification\", \"tabular-regression\", \"text-classification\"],\n    spacy: [\"token-classification\", \"text-classification\", \"sentence-similarity\"],\n    \"span-marker\": [\"token-classification\"],\n    speechbrain: [\"audio-classification\", \"audio-to-audio\", \"automatic-speech-recognition\", \"text-to-speech\"],\n    stanza: [\"token-classification\"],\n    timm: [\"image-classification\", \"image-feature-extraction\"],\n    transformers: [\n        \"audio-classification\",\n        \"automatic-speech-recognition\",\n        \"depth-estimation\",\n        \"document-question-answering\",\n        \"feature-extraction\",\n        \"fill-mask\",\n        \"image-classification\",\n        \"image-feature-extraction\",\n        \"image-segmentation\",\n        \"image-to-image\",\n        \"image-to-text\",\n        \"image-text-to-text\",\n        \"mask-generation\",\n        \"object-detection\",\n        \"question-answering\",\n        \"summarization\",\n        \"table-question-answering\",\n        \"text-classification\",\n        \"text-generation\",\n        \"text-to-audio\",\n        \"text-to-speech\",\n        \"token-classification\",\n        \"translation\",\n        \"video-classification\",\n        \"visual-question-answering\",\n        \"zero-shot-classification\",\n        \"zero-shot-image-classification\",\n        \"zero-shot-object-detection\",\n    ],\n    mindspore: [\"image-classification\"],\n};\n","/// NOTE TO CONTRIBUTORS:\n///\n/// When adding sample inputs for a new language, you don't\n/// necessarily have to translate the inputs from existing languages.\n/// (which were quite random to begin with)\n///\n/// i.e. Feel free to be creative and provide better samples.\n//\n/// The <mask> placeholder will be replaced by the correct mask token\n/// in the following examples, depending on the model type\n///\n/// see [INTERNAL] github.com/huggingface/moon-landing/blob/c5c3d45fe0ab27347b3ab27bdad646ef20732351/server/lib/App.ts#L254\n//\nconst MAPPING_EN = new Map([\n    [\"text-classification\", [`I like you. I love you`]],\n    [\n        \"token-classification\",\n        [\n            `My name is Wolfgang and I live in Berlin`,\n            `My name is Sarah and I live in London`,\n            `My name is Clara and I live in Berkeley, California.`,\n        ],\n    ],\n    [\n        \"table-question-answering\",\n        [\n            {\n                text: `How many stars does the transformers repository have?`,\n                table: {\n                    Repository: [\"Transformers\", \"Datasets\", \"Tokenizers\"],\n                    Stars: [36542, 4512, 3934],\n                    Contributors: [651, 77, 34],\n                    \"Programming language\": [\"Python\", \"Python\", \"Rust, Python and NodeJS\"],\n                },\n            },\n        ],\n    ],\n    [\n        \"question-answering\",\n        [\n            {\n                text: `Where do I live?`,\n                context: `My name is Wolfgang and I live in Berlin`,\n            },\n            {\n                text: `Where do I live?`,\n                context: `My name is Sarah and I live in London`,\n            },\n            {\n                text: `What's my name?`,\n                context: `My name is Clara and I live in Berkeley.`,\n            },\n            {\n                text: `Which name is also used to describe the Amazon rainforest in English?`,\n                context: `The Amazon rainforest (Portuguese: Floresta Amaznica or Amaznia; Spanish: Selva Amaznica, Amazona or usually Amazonia; French: Fort amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain \"Amazonas\" in their names. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.`,\n            },\n        ],\n    ],\n    [\n        \"zero-shot-classification\",\n        [\n            {\n                text: \"I have a problem with my iphone that needs to be resolved asap!\",\n                candidate_labels: \"urgent, not urgent, phone, tablet, computer\",\n                multi_class: true,\n            },\n            {\n                text: \"Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.\",\n                candidate_labels: \"mobile, website, billing, account access\",\n                multi_class: false,\n            },\n            {\n                text: \"A new model offers an explanation for how the Galilean satellites formed around the solar systems largest world. Konstantin Batygin did not set out to solve one of the solar systems most puzzling mysteries when he went for a run up a hill in Nice, France. Dr. Batygin, a Caltech researcher, best known for his contributions to the search for the solar systems missing Planet Nine, spotted a beer bottle. At a steep, 20 degree grade, he wondered why it wasnt rolling down the hill. He realized there was a breeze at his back holding the bottle in place. Then he had a thought that would only pop into the mind of a theoretical astrophysicist: Oh! This is how Europa formed. Europa is one of Jupiters four large Galilean moons. And in a paper published Monday in the Astrophysical Journal, Dr. Batygin and a co-author, Alessandro Morbidelli, a planetary scientist at the Cte dAzur Observatory in France, present a theory explaining how some moons form around gas giants like Jupiter and Saturn, suggesting that millimeter-sized grains of hail produced during the solar systems formation became trapped around these massive worlds, taking shape one at a time into the potentially habitable moons we know today.\",\n                candidate_labels: \"space & cosmos, scientific discovery, microbiology, robots, archeology\",\n                multi_class: true,\n            },\n        ],\n    ],\n    [\"translation\", [`My name is Wolfgang and I live in Berlin`, `My name is Sarah and I live in London`]],\n    [\n        \"summarization\",\n        [\n            `The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.`,\n        ],\n    ],\n    [\n        \"conversational\",\n        [\n            `Hi, what can you help me with?`,\n            `What is 84 * 3 / 2?`,\n            `Tell me an interesting fact about the universe!`,\n            `Explain quantum computing in simple terms.`,\n        ],\n    ],\n    [\n        \"text-generation\",\n        [\n            `My name is Julien and I like to`,\n            `I like traveling by train because`,\n            `Paris is an amazing place to visit,`,\n            `Once upon a time,`,\n        ],\n    ],\n    [\"fill-mask\", [`Paris is the <mask> of France.`, `The goal of life is <mask>.`]],\n    [\n        \"sentence-similarity\",\n        [\n            {\n                source_sentence: \"That is a happy person\",\n                sentences: [\"That is a happy dog\", \"That is a very happy person\", \"Today is a sunny day\"],\n            },\n        ],\n    ],\n]);\nconst MAPPING_ZH = new Map([\n    [\"text-classification\", [` `]],\n    [\"token-classification\", [``, ``, ``]],\n    [\n        \"question-answering\",\n        [\n            {\n                text: ``,\n                context: ``,\n            },\n            {\n                text: ``,\n                context: ``,\n            },\n            {\n                text: ``,\n                context: ``,\n            },\n        ],\n    ],\n    [\"translation\", [``, ``]],\n    [\n        \"zero-shot-classification\",\n        [\n            {\n                text: \"\",\n                candidate_labels: \", \",\n            },\n        ],\n    ],\n    [\n        \"summarization\",\n        [\n            `324106381 125410 411930300 19575.217 `,\n        ],\n    ],\n    [\n        \"text-generation\",\n        [``, ``, ``, ``, ``],\n    ],\n    [\"fill-mask\", [`<mask>`, `<mask>`]],\n    [\n        \"sentence-similarity\",\n        [\n            {\n                source_sentence: \" \",\n                sentences: [\" \", \" \", \"\"],\n            },\n        ],\n    ],\n]);\nconst MAPPING_FR = new Map([\n    [\"text-classification\", [`Je t'apprcie beaucoup. Je t'aime.`]],\n    [\"token-classification\", [`Mon nom est Wolfgang et je vis  Berlin`]],\n    [\n        \"question-answering\",\n        [\n            {\n                text: `O est-ce que je vis?`,\n                context: `Mon nom est Wolfgang et je vis  Berlin`,\n            },\n        ],\n    ],\n    [\"translation\", [`Mon nom est Wolfgang et je vis  Berlin`]],\n    [\n        \"summarization\",\n        [\n            `La tour fait 324 mtres (1,063 pieds) de haut, environ la mme hauteur qu'un immeuble de 81 tages, et est la plus haute structure de Paris. Sa base est carre, mesurant 125 mtres (410 pieds) sur chaque ct. Durant sa construction, la tour Eiffel surpassa le Washington Monument pour devenir la plus haute structure construite par l'homme dans le monde, un titre qu'elle conserva pendant 41 ans jusqu' l'achvement du Chrysler Building  New-York City en 1930. Ce fut la premire structure  atteindre une hauteur de 300 mtres. Avec l'ajout d'une antenne de radiodiffusion au sommet de la tour Eiffel en 1957, celle-ci redevint plus haute que le Chrysler Building de 5,2 mtres (17 pieds). En excluant les transmetteurs, elle est la seconde plus haute structure autoportante de France aprs le viaduc de Millau.`,\n        ],\n    ],\n    [\"text-generation\", [`Mon nom est Julien et j'aime`, `Mon nom est Thomas et mon principal`, `Il tait une fois`]],\n    [\"fill-mask\", [`Paris est la <mask> de la France.`]],\n    [\n        \"sentence-similarity\",\n        [\n            {\n                source_sentence: \"C'est une personne heureuse\",\n                sentences: [\n                    \"C'est un chien heureux\",\n                    \"C'est une personne trs heureuse\",\n                    \"Aujourd'hui est une journe ensoleille\",\n                ],\n            },\n        ],\n    ],\n]);\nconst MAPPING_ES = new Map([\n    [\"text-classification\", [`Te quiero. Te amo.`]],\n    [\"token-classification\", [`Me llamo Wolfgang y vivo en Berlin`]],\n    [\n        \"question-answering\",\n        [\n            {\n                text: `Dnde vivo?`,\n                context: `Me llamo Wolfgang y vivo en Berlin`,\n            },\n            {\n                text: `Quin invent el submarino?`,\n                context: `Isaac Peral fue un murciano que invent el submarino`,\n            },\n            {\n                text: `Cuntas personas hablan espaol?`,\n                context: `El espaol es el segundo idioma ms hablado del mundo con ms de 442 millones de hablantes`,\n            },\n        ],\n    ],\n    [\n        \"translation\",\n        [\n            `Me llamo Wolfgang y vivo en Berlin`,\n            `Los ingredientes de una tortilla de patatas son: huevos, patatas y cebolla`,\n        ],\n    ],\n    [\n        \"summarization\",\n        [\n            `La torre tiene 324 metros (1.063 pies) de altura, aproximadamente la misma altura que un edificio de 81 pisos y la estructura ms alta de Pars. Su base es cuadrada, mide 125 metros (410 pies) a cada lado. Durante su construccin, la Torre Eiffel super al Washington Monument para convertirse en la estructura artificial ms alta del mundo, un ttulo que mantuvo durante 41 aos hasta que el Chrysler Building en la ciudad de Nueva York se termin en 1930. Fue la primera estructura en llegar Una altura de 300 metros. Debido a la adicin de una antena de transmisin en la parte superior de la torre en 1957, ahora es ms alta que el Chrysler Building en 5,2 metros (17 pies). Excluyendo los transmisores, la Torre Eiffel es la segunda estructura independiente ms alta de Francia despus del Viaducto de Millau.`,\n        ],\n    ],\n    [\n        \"text-generation\",\n        [\n            `Me llamo Julien y me gusta`,\n            `Me llamo Thomas y mi principal`,\n            `Me llamo Manuel y trabajo en`,\n            `rase una vez,`,\n            `Si t me dices ven, `,\n        ],\n    ],\n    [\"fill-mask\", [`Mi nombre es <mask> y vivo en Nueva York.`, `El espaol es un idioma muy <mask> en el mundo.`]],\n    [\n        \"sentence-similarity\",\n        [\n            {\n                source_sentence: \"Esa es una persona feliz\",\n                sentences: [\"Ese es un perro feliz\", \"Esa es una persona muy feliz\", \"Hoy es un da soleado\"],\n            },\n        ],\n    ],\n]);\nconst MAPPING_RU = new Map([\n    [\"text-classification\", [`  .   `]],\n    [\"token-classification\", [`       `]],\n    [\n        \"question-answering\",\n        [\n            {\n                text: ` ?`,\n                context: `       `,\n            },\n        ],\n    ],\n    [\"translation\", [`       `]],\n    [\n        \"summarization\",\n        [\n            `   324  (1063 ),    ,   81- ,      .   ,  125  (410 )   .        ,       ,        41        -  1930 .       300 . -        1957        5,2  (17 ).   ,              .`,\n        ],\n    ],\n    [\"text-generation\", [`   `, `     `, ``]],\n    [\"fill-mask\", [`  <mask>      -.`]],\n    [\n        \"sentence-similarity\",\n        [\n            {\n                source_sentence: \"  \",\n                sentences: [\"  \", \"   \", \"  \"],\n            },\n        ],\n    ],\n]);\nconst MAPPING_UK = new Map([\n    [\"translation\", [`       .`]],\n    [\"fill-mask\", [`  <mask>.`]],\n]);\nconst MAPPING_IT = new Map([\n    [\"text-classification\", [`Mi piaci. Ti amo`]],\n    [\n        \"token-classification\",\n        [\n            `Mi chiamo Wolfgang e vivo a Berlino`,\n            `Mi chiamo Sarah e vivo a Londra`,\n            `Mi chiamo Clara e vivo a Berkeley in California.`,\n        ],\n    ],\n    [\n        \"question-answering\",\n        [\n            {\n                text: `Dove vivo?`,\n                context: `Mi chiamo Wolfgang e vivo a Berlino`,\n            },\n            {\n                text: `Dove vivo?`,\n                context: `Mi chiamo Sarah e vivo a Londra`,\n            },\n            {\n                text: `Come mio chiamo?`,\n                context: `Mi chiamo Clara e vivo a Berkeley.`,\n            },\n        ],\n    ],\n    [\"translation\", [`Mi chiamo Wolfgang e vivo a Berlino`, `Mi chiamo Sarah e vivo a Londra`]],\n    [\n        \"summarization\",\n        [\n            `La torre degli Asinelli  una delle cosiddette due torri di Bologna, simbolo della citt, situate in piazza di porta Ravegnana, all'incrocio tra le antiche strade San Donato (ora via Zamboni), San Vitale, Maggiore e Castiglione. Eretta, secondo la tradizione, fra il 1109 e il 1119 dal nobile Gherardo Asinelli, la torre  alta 97,20 metri, pende verso ovest per 2,23 metri e presenta all'interno una scalinata composta da 498 gradini. Ancora non si pu dire con certezza quando e da chi fu costruita la torre degli Asinelli. Si presume che la torre debba il proprio nome a Gherardo Asinelli, il nobile cavaliere di fazione ghibellina al quale se ne attribuisce la costruzione, iniziata secondo una consolidata tradizione l'11 ottobre 1109 e terminata dieci anni dopo, nel 1119.`,\n        ],\n    ],\n    [\n        \"text-generation\",\n        [\n            `Mi chiamo Loreto e mi piace`,\n            `Mi chiamo Thomas e il mio principale`,\n            `Mi chiamo Marianna, la mia cosa preferita`,\n            `Mi chiamo Clara e sono`,\n            `C'era una volta`,\n        ],\n    ],\n    [\"fill-mask\", [`Roma  la <mask> d'Italia.`, `Lo scopo della vita  <mask>.`]],\n    [\n        \"sentence-similarity\",\n        [\n            {\n                source_sentence: \"Questa  una persona felice\",\n                sentences: [\"Questo  un cane felice\", \"Questa  una persona molto felice\", \"Oggi  una giornata di sole\"],\n            },\n        ],\n    ],\n]);\nconst MAPPING_FA = new Map([\n    [\n        \"text-classification\",\n        [`         .`, `  .`, `   `, `  `],\n    ],\n    [\n        \"token-classification\",\n        [\n            `                .`,\n            `           .`,\n            `              .`,\n        ],\n    ],\n    [\n        \"question-answering\",\n        [\n            {\n                text: `   `,\n                context: `        .`,\n            },\n            {\n                text: `     `,\n                context: `        .`,\n            },\n            {\n                text: `  `,\n                context: `       .`,\n            },\n            {\n                text: `       `,\n                context: [\n                    \"                     \",\n                    \" .              .\",\n                    \"             .\",\n                ].join(\"\\n\"),\n            },\n        ],\n    ],\n    [\n        \"translation\",\n        [\n            \"              .\",\n            \"              .\",\n        ],\n    ],\n    [\n        \"summarization\",\n        [\n            [\n                \"            \",\n                \"              \",\n                \"           \",\n                \"         .    \",\n                \"                \",\n                \"  (         )   \",\n                \"           .\",\n                \"                 .\",\n                \"              \",\n                \"            .   \",\n                \"           \",\n                \"    .      \",\n                \"              \",\n                \"             .\",\n            ].join(\"\\n\"),\n        ],\n    ],\n    [\"text-generation\", [\"     \", \" \"]],\n    [\n        \"fill-mask\",\n        [\n            `        <mask>    !`,\n            `   :     <mask>     `,\n        ],\n    ],\n]);\nconst MAPPING_AR = new Map([\n    [\"text-classification\", [`. `]],\n    [\n        \"token-classification\",\n        [`    `, `    `, `      .`],\n    ],\n    [\n        \"question-answering\",\n        [\n            {\n                text: ` `,\n                context: `    `,\n            },\n            {\n                text: ` `,\n                context: `    `,\n            },\n            {\n                text: ` `,\n                context: `    .`,\n            },\n            {\n                text: `     `,\n                context: `                  .`,\n            },\n        ],\n    ],\n    [\"translation\", [`    `, `    `]],\n    [\n        \"summarization\",\n        [\n            `                                          .`,\n        ],\n    ],\n    [\n        \"text-generation\",\n        [\n            `   `,\n            `     -     .`,\n            `  `,\n            `     `,\n            `      `,\n        ],\n    ],\n    [\"fill-mask\", [` <mask> .`, `   <mask>.`]],\n    [\n        \"sentence-similarity\",\n        [\n            {\n                source_sentence: \"  \",\n                sentences: [\"  \", \"   \", \"   \"],\n            },\n        ],\n    ],\n]);\nconst MAPPING_BN = new Map([\n    [\"text-classification\", [`     `]],\n    [\n        \"token-classification\",\n        [`       `, `   `, `       `],\n    ],\n    [\"translation\", [`  ,    `, `    ?`]],\n    [\n        \"summarization\",\n        [\n            ` ,               ,        ,     ,                   ,                   ()     -    -                             ,   -       ,                 ,    -                `,\n        ],\n    ],\n    [\"text-generation\", [`   `, `   `, `  `]],\n    [\"fill-mask\", [`  <mask> `, ` <mask>   `]],\n    [\n        \"question-answering\",\n        [\n            {\n                text: `        ?`,\n                context: `                 ( )                                                                   `,\n            },\n            {\n                text: `        ?`,\n                context: `                           ,      `,\n            },\n            {\n                text: `       ?`,\n                context: `                                                 , ,                             `,\n            },\n        ],\n    ],\n    [\n        \"sentence-similarity\",\n        [\n            {\n                source_sentence: \"   \",\n                sentences: [\"  \", \"   \", \"   \"],\n            },\n        ],\n    ],\n]);\nconst MAPPING_MN = new Map([\n    [\"text-classification\", [`  `]],\n    [\n        \"token-classification\",\n        [\n            `  .   .`,\n            `  .    .`,\n            `    .`,\n        ],\n    ],\n    [\n        \"question-answering\",\n        [\n            {\n                text: `   ?`,\n                context: `  .   .`,\n            },\n            {\n                text: `   ?`,\n                context: `  .   .`,\n            },\n            {\n                text: `    ?`,\n                context: `  .    .`,\n            },\n        ],\n    ],\n    [\"translation\", [`  .   .`, `  .    .`]],\n    [\n        \"summarization\",\n        [\n            `  (1992  )         .   ,        .    .   ,    1  566  2  ,     19- . 2015       3   (135- ).    (95 ),  ,   . 16-    , 20-          .`,\n        ],\n    ],\n    [\n        \"text-generation\",\n        [`  . `, `   `, `   `, `  `],\n    ],\n    [\"fill-mask\", [`  <mask>    .`, `    <mask>.`]],\n    [\n        \"automatic-speech-recognition\",\n        [\n            {\n                label: `Common Voice Train Example`,\n                src: `https://cdn-media.huggingface.co/common_voice/train/common_voice_mn_18577472.wav`,\n            },\n            {\n                label: `Common Voice Test Example`,\n                src: `https://cdn-media.huggingface.co/common_voice/test/common_voice_mn_18577346.wav`,\n            },\n        ],\n    ],\n    [\n        \"text-to-speech\",\n        [\n            `   .`,\n            `        `,\n            `     ?`,\n        ],\n    ],\n    [\n        \"sentence-similarity\",\n        [\n            {\n                source_sentence: \"     \",\n                sentences: [\"     \", \"       \", \"   \"],\n            },\n        ],\n    ],\n]);\nconst MAPPING_SI = new Map([\n    [\"translation\", [`   .`, `     .`]],\n    [\"fill-mask\", [`  <mask>.`, `<mask>  .`]],\n]);\nconst MAPPING_DE = new Map([\n    [\n        \"question-answering\",\n        [\n            {\n                text: `Wo wohne ich?`,\n                context: `Mein Name ist Wolfgang und ich lebe in Berlin`,\n            },\n            {\n                text: `Welcher Name wird auch verwendet, um den Amazonas-Regenwald auf Englisch zu beschreiben?`,\n                context: `Der Amazonas-Regenwald, auf Englisch auch als Amazonien oder Amazonas-Dschungel bekannt, ist ein feuchter Laubwald, der den grten Teil des Amazonas-Beckens Sdamerikas bedeckt. Dieses Becken umfasst 7.000.000 Quadratkilometer (2.700.000 Quadratmeilen), von denen 5.500.000 Quadratkilometer (2.100.000 Quadratmeilen) vom Regenwald bedeckt sind. Diese Region umfasst Gebiete von neun Nationen. Der grte Teil des Waldes befindet sich in Brasilien mit 60% des Regenwaldes, gefolgt von Peru mit 13%, Kolumbien mit 10% und geringen Mengen in Venezuela, Ecuador, Bolivien, Guyana, Suriname und Franzsisch-Guayana. Staaten oder Abteilungen in vier Nationen enthalten \"Amazonas\" in ihren Namen. Der Amazonas reprsentiert mehr als die Hlfte der verbleibenden Regenwlder des Planeten und umfasst den grten und artenreichsten tropischen Regenwald der Welt mit geschtzten 390 Milliarden Einzelbumen, die in 16.000 Arten unterteilt sind.`,\n            },\n        ],\n    ],\n    [\n        \"sentence-similarity\",\n        [\n            {\n                source_sentence: \"Das ist eine glckliche Person\",\n                sentences: [\n                    \"Das ist ein glcklicher Hund\",\n                    \"Das ist eine sehr glckliche Person\",\n                    \"Heute ist ein sonniger Tag\",\n                ],\n            },\n        ],\n    ],\n]);\nconst MAPPING_DV = new Map([\n    [\"text-classification\", [` .  `]],\n    [\n        \"token-classification\",\n        [\n            `      `,\n            `      `,\n            `       `,\n        ],\n    ],\n    [\n        \"question-answering\",\n        [\n            {\n                text: `  `,\n                context: `      `,\n            },\n            {\n                text: `  `,\n                context: `      `,\n            },\n            {\n                text: `  `,\n                context: `      `,\n            },\n            {\n                text: `      `,\n                context: `  (:     :  ,     :   : )         ,          .      7    (2.7   (.   5.5    (2.1   )   .   9    .  60%      .   13%    10%        , , , ,       .   4  \"\"      .           .          .   16    390     `,\n            },\n        ],\n    ],\n    [\n        \"translation\",\n        [\n            `      `,\n            `      `,\n        ],\n    ],\n    [\n        \"summarization\",\n        [\n            `  324    81   .      .        125 . (410 )                   .  1930        41    .  300      . 1957               5.2  (17 ) .           2     `,\n        ],\n    ],\n    [\n        \"text-generation\",\n        [\n            `     `,\n            `     `,\n            `    `,\n            ` `,\n        ],\n    ],\n    [\"fill-mask\", [`.<mask>   `, `   <mask> .`]],\n]);\nexport const MAPPING_DEFAULT_WIDGET = new Map([\n    [\"en\", MAPPING_EN],\n    [\"zh\", MAPPING_ZH],\n    [\"fr\", MAPPING_FR],\n    [\"es\", MAPPING_ES],\n    [\"ru\", MAPPING_RU],\n    [\"uk\", MAPPING_UK],\n    [\"it\", MAPPING_IT],\n    [\"fa\", MAPPING_FA],\n    [\"ar\", MAPPING_AR],\n    [\"bn\", MAPPING_BN],\n    [\"mn\", MAPPING_MN],\n    [\"si\", MAPPING_SI],\n    [\"de\", MAPPING_DE],\n    [\"dv\", MAPPING_DV],\n]);\n","export const MODALITIES = [\"multimodal\", \"nlp\", \"cv\", \"audio\", \"tabular\", \"rl\", \"other\"];\nexport const MODALITY_LABELS = {\n    multimodal: \"Multimodal\",\n    nlp: \"Natural Language Processing\",\n    audio: \"Audio\",\n    cv: \"Computer Vision\",\n    rl: \"Reinforcement Learning\",\n    tabular: \"Tabular\",\n    other: \"Other\",\n};\n/// Coarse-grained taxonomy of tasks\n///\n/// This type is used in multiple places in the Hugging Face\n/// ecosystem:\n///  - To determine which widget to show.\n///  - To determine which endpoint of Inference Endpoints to use.\n///  - As filters at the left of models and datasets page.\n///\n/// Note that this is sensitive to order.\n/// For each domain, the order should be of decreasing specificity.\n/// This will impact the default pipeline tag of a model when not\n/// specified.\nexport const PIPELINE_DATA = {\n    \"text-classification\": {\n        name: \"Text Classification\",\n        subtasks: [\n            {\n                type: \"acceptability-classification\",\n                name: \"Acceptability Classification\",\n            },\n            {\n                type: \"entity-linking-classification\",\n                name: \"Entity Linking Classification\",\n            },\n            {\n                type: \"fact-checking\",\n                name: \"Fact Checking\",\n            },\n            {\n                type: \"intent-classification\",\n                name: \"Intent Classification\",\n            },\n            {\n                type: \"language-identification\",\n                name: \"Language Identification\",\n            },\n            {\n                type: \"multi-class-classification\",\n                name: \"Multi Class Classification\",\n            },\n            {\n                type: \"multi-label-classification\",\n                name: \"Multi Label Classification\",\n            },\n            {\n                type: \"multi-input-text-classification\",\n                name: \"Multi-input Text Classification\",\n            },\n            {\n                type: \"natural-language-inference\",\n                name: \"Natural Language Inference\",\n            },\n            {\n                type: \"semantic-similarity-classification\",\n                name: \"Semantic Similarity Classification\",\n            },\n            {\n                type: \"sentiment-classification\",\n                name: \"Sentiment Classification\",\n            },\n            {\n                type: \"topic-classification\",\n                name: \"Topic Classification\",\n            },\n            {\n                type: \"semantic-similarity-scoring\",\n                name: \"Semantic Similarity Scoring\",\n            },\n            {\n                type: \"sentiment-scoring\",\n                name: \"Sentiment Scoring\",\n            },\n            {\n                type: \"sentiment-analysis\",\n                name: \"Sentiment Analysis\",\n            },\n            {\n                type: \"hate-speech-detection\",\n                name: \"Hate Speech Detection\",\n            },\n            {\n                type: \"text-scoring\",\n                name: \"Text Scoring\",\n            },\n        ],\n        modality: \"nlp\",\n    },\n    \"token-classification\": {\n        name: \"Token Classification\",\n        subtasks: [\n            {\n                type: \"named-entity-recognition\",\n                name: \"Named Entity Recognition\",\n            },\n            {\n                type: \"part-of-speech\",\n                name: \"Part of Speech\",\n            },\n            {\n                type: \"parsing\",\n                name: \"Parsing\",\n            },\n            {\n                type: \"lemmatization\",\n                name: \"Lemmatization\",\n            },\n            {\n                type: \"word-sense-disambiguation\",\n                name: \"Word Sense Disambiguation\",\n            },\n            {\n                type: \"coreference-resolution\",\n                name: \"Coreference-resolution\",\n            },\n        ],\n        modality: \"nlp\",\n    },\n    \"table-question-answering\": {\n        name: \"Table Question Answering\",\n        modality: \"nlp\",\n    },\n    \"question-answering\": {\n        name: \"Question Answering\",\n        subtasks: [\n            {\n                type: \"extractive-qa\",\n                name: \"Extractive QA\",\n            },\n            {\n                type: \"open-domain-qa\",\n                name: \"Open Domain QA\",\n            },\n            {\n                type: \"closed-domain-qa\",\n                name: \"Closed Domain QA\",\n            },\n        ],\n        modality: \"nlp\",\n    },\n    \"zero-shot-classification\": {\n        name: \"Zero-Shot Classification\",\n        modality: \"nlp\",\n    },\n    translation: {\n        name: \"Translation\",\n        modality: \"nlp\",\n    },\n    summarization: {\n        name: \"Summarization\",\n        subtasks: [\n            {\n                type: \"news-articles-summarization\",\n                name: \"News Articles Summarization\",\n            },\n            {\n                type: \"news-articles-headline-generation\",\n                name: \"News Articles Headline Generation\",\n            },\n        ],\n        modality: \"nlp\",\n    },\n    \"feature-extraction\": {\n        name: \"Feature Extraction\",\n        modality: \"nlp\",\n    },\n    \"text-generation\": {\n        name: \"Text Generation\",\n        subtasks: [\n            {\n                type: \"dialogue-modeling\",\n                name: \"Dialogue Modeling\",\n            },\n            {\n                type: \"dialogue-generation\",\n                name: \"Dialogue Generation\",\n            },\n            {\n                type: \"conversational\",\n                name: \"Conversational\",\n            },\n            {\n                type: \"language-modeling\",\n                name: \"Language Modeling\",\n            },\n            {\n                type: \"text-simplification\",\n                name: \"Text simplification\",\n            },\n            {\n                type: \"explanation-generation\",\n                name: \"Explanation Generation\",\n            },\n            {\n                type: \"abstractive-qa\",\n                name: \"Abstractive QA\",\n            },\n            {\n                type: \"open-domain-abstractive-qa\",\n                name: \"Open Domain Abstractive QA\",\n            },\n            {\n                type: \"closed-domain-qa\",\n                name: \"Closed Domain QA\",\n            },\n            {\n                type: \"open-book-qa\",\n                name: \"Open Book QA\",\n            },\n            {\n                type: \"closed-book-qa\",\n                name: \"Closed Book QA\",\n            },\n            {\n                type: \"text2text-generation\",\n                name: \"Text2Text Generation\",\n            },\n        ],\n        modality: \"nlp\",\n    },\n    \"fill-mask\": {\n        name: \"Fill-Mask\",\n        subtasks: [\n            {\n                type: \"slot-filling\",\n                name: \"Slot Filling\",\n            },\n            {\n                type: \"masked-language-modeling\",\n                name: \"Masked Language Modeling\",\n            },\n        ],\n        modality: \"nlp\",\n    },\n    \"sentence-similarity\": {\n        name: \"Sentence Similarity\",\n        modality: \"nlp\",\n    },\n    \"text-to-speech\": {\n        name: \"Text-to-Speech\",\n        modality: \"audio\",\n    },\n    \"text-to-audio\": {\n        name: \"Text-to-Audio\",\n        modality: \"audio\",\n    },\n    \"automatic-speech-recognition\": {\n        name: \"Automatic Speech Recognition\",\n        modality: \"audio\",\n    },\n    \"audio-to-audio\": {\n        name: \"Audio-to-Audio\",\n        modality: \"audio\",\n    },\n    \"audio-classification\": {\n        name: \"Audio Classification\",\n        subtasks: [\n            {\n                type: \"keyword-spotting\",\n                name: \"Keyword Spotting\",\n            },\n            {\n                type: \"speaker-identification\",\n                name: \"Speaker Identification\",\n            },\n            {\n                type: \"audio-intent-classification\",\n                name: \"Audio Intent Classification\",\n            },\n            {\n                type: \"audio-emotion-recognition\",\n                name: \"Audio Emotion Recognition\",\n            },\n            {\n                type: \"audio-language-identification\",\n                name: \"Audio Language Identification\",\n            },\n        ],\n        modality: \"audio\",\n    },\n    \"audio-text-to-text\": {\n        name: \"Audio-Text-to-Text\",\n        modality: \"multimodal\",\n        hideInDatasets: true,\n    },\n    \"voice-activity-detection\": {\n        name: \"Voice Activity Detection\",\n        modality: \"audio\",\n    },\n    \"depth-estimation\": {\n        name: \"Depth Estimation\",\n        modality: \"cv\",\n    },\n    \"image-classification\": {\n        name: \"Image Classification\",\n        subtasks: [\n            {\n                type: \"multi-label-image-classification\",\n                name: \"Multi Label Image Classification\",\n            },\n            {\n                type: \"multi-class-image-classification\",\n                name: \"Multi Class Image Classification\",\n            },\n        ],\n        modality: \"cv\",\n    },\n    \"object-detection\": {\n        name: \"Object Detection\",\n        subtasks: [\n            {\n                type: \"face-detection\",\n                name: \"Face Detection\",\n            },\n            {\n                type: \"vehicle-detection\",\n                name: \"Vehicle Detection\",\n            },\n        ],\n        modality: \"cv\",\n    },\n    \"image-segmentation\": {\n        name: \"Image Segmentation\",\n        subtasks: [\n            {\n                type: \"instance-segmentation\",\n                name: \"Instance Segmentation\",\n            },\n            {\n                type: \"semantic-segmentation\",\n                name: \"Semantic Segmentation\",\n            },\n            {\n                type: \"panoptic-segmentation\",\n                name: \"Panoptic Segmentation\",\n            },\n        ],\n        modality: \"cv\",\n    },\n    \"text-to-image\": {\n        name: \"Text-to-Image\",\n        modality: \"cv\",\n    },\n    \"image-to-text\": {\n        name: \"Image-to-Text\",\n        subtasks: [\n            {\n                type: \"image-captioning\",\n                name: \"Image Captioning\",\n            },\n        ],\n        modality: \"cv\",\n    },\n    \"image-to-image\": {\n        name: \"Image-to-Image\",\n        subtasks: [\n            {\n                type: \"image-inpainting\",\n                name: \"Image Inpainting\",\n            },\n            {\n                type: \"image-colorization\",\n                name: \"Image Colorization\",\n            },\n            {\n                type: \"super-resolution\",\n                name: \"Super Resolution\",\n            },\n        ],\n        modality: \"cv\",\n    },\n    \"image-to-video\": {\n        name: \"Image-to-Video\",\n        modality: \"cv\",\n    },\n    \"unconditional-image-generation\": {\n        name: \"Unconditional Image Generation\",\n        modality: \"cv\",\n    },\n    \"video-classification\": {\n        name: \"Video Classification\",\n        modality: \"cv\",\n    },\n    \"reinforcement-learning\": {\n        name: \"Reinforcement Learning\",\n        modality: \"rl\",\n    },\n    robotics: {\n        name: \"Robotics\",\n        modality: \"rl\",\n        subtasks: [\n            {\n                type: \"grasping\",\n                name: \"Grasping\",\n            },\n            {\n                type: \"task-planning\",\n                name: \"Task Planning\",\n            },\n        ],\n    },\n    \"tabular-classification\": {\n        name: \"Tabular Classification\",\n        modality: \"tabular\",\n        subtasks: [\n            {\n                type: \"tabular-multi-class-classification\",\n                name: \"Tabular Multi Class Classification\",\n            },\n            {\n                type: \"tabular-multi-label-classification\",\n                name: \"Tabular Multi Label Classification\",\n            },\n        ],\n    },\n    \"tabular-regression\": {\n        name: \"Tabular Regression\",\n        modality: \"tabular\",\n        subtasks: [\n            {\n                type: \"tabular-single-column-regression\",\n                name: \"Tabular Single Column Regression\",\n            },\n        ],\n    },\n    \"tabular-to-text\": {\n        name: \"Tabular to Text\",\n        modality: \"tabular\",\n        subtasks: [\n            {\n                type: \"rdf-to-text\",\n                name: \"RDF to text\",\n            },\n        ],\n        hideInModels: true,\n    },\n    \"table-to-text\": {\n        name: \"Table to Text\",\n        modality: \"nlp\",\n        hideInModels: true,\n    },\n    \"multiple-choice\": {\n        name: \"Multiple Choice\",\n        subtasks: [\n            {\n                type: \"multiple-choice-qa\",\n                name: \"Multiple Choice QA\",\n            },\n            {\n                type: \"multiple-choice-coreference-resolution\",\n                name: \"Multiple Choice Coreference Resolution\",\n            },\n        ],\n        modality: \"nlp\",\n        hideInModels: true,\n    },\n    \"text-ranking\": {\n        name: \"Text Ranking\",\n        modality: \"nlp\",\n    },\n    \"text-retrieval\": {\n        name: \"Text Retrieval\",\n        subtasks: [\n            {\n                type: \"document-retrieval\",\n                name: \"Document Retrieval\",\n            },\n            {\n                type: \"utterance-retrieval\",\n                name: \"Utterance Retrieval\",\n            },\n            {\n                type: \"entity-linking-retrieval\",\n                name: \"Entity Linking Retrieval\",\n            },\n            {\n                type: \"fact-checking-retrieval\",\n                name: \"Fact Checking Retrieval\",\n            },\n        ],\n        modality: \"nlp\",\n        hideInModels: true,\n    },\n    \"time-series-forecasting\": {\n        name: \"Time Series Forecasting\",\n        modality: \"tabular\",\n        subtasks: [\n            {\n                type: \"univariate-time-series-forecasting\",\n                name: \"Univariate Time Series Forecasting\",\n            },\n            {\n                type: \"multivariate-time-series-forecasting\",\n                name: \"Multivariate Time Series Forecasting\",\n            },\n        ],\n    },\n    \"text-to-video\": {\n        name: \"Text-to-Video\",\n        modality: \"cv\",\n    },\n    \"image-text-to-text\": {\n        name: \"Image-Text-to-Text\",\n        modality: \"multimodal\",\n    },\n    \"image-text-to-image\": {\n        name: \"Image-Text-to-Image\",\n        modality: \"multimodal\",\n    },\n    \"image-text-to-video\": {\n        name: \"Image-Text-to-Video\",\n        modality: \"multimodal\",\n    },\n    \"visual-question-answering\": {\n        name: \"Visual Question Answering\",\n        subtasks: [\n            {\n                type: \"visual-question-answering\",\n                name: \"Visual Question Answering\",\n            },\n        ],\n        modality: \"multimodal\",\n    },\n    \"document-question-answering\": {\n        name: \"Document Question Answering\",\n        subtasks: [\n            {\n                type: \"document-question-answering\",\n                name: \"Document Question Answering\",\n            },\n        ],\n        modality: \"multimodal\",\n        hideInDatasets: true,\n    },\n    \"zero-shot-image-classification\": {\n        name: \"Zero-Shot Image Classification\",\n        modality: \"cv\",\n    },\n    \"graph-ml\": {\n        name: \"Graph Machine Learning\",\n        modality: \"other\",\n    },\n    \"mask-generation\": {\n        name: \"Mask Generation\",\n        modality: \"cv\",\n    },\n    \"zero-shot-object-detection\": {\n        name: \"Zero-Shot Object Detection\",\n        modality: \"cv\",\n    },\n    \"text-to-3d\": {\n        name: \"Text-to-3D\",\n        modality: \"cv\",\n    },\n    \"image-to-3d\": {\n        name: \"Image-to-3D\",\n        modality: \"cv\",\n    },\n    \"image-feature-extraction\": {\n        name: \"Image Feature Extraction\",\n        modality: \"cv\",\n    },\n    \"video-text-to-text\": {\n        name: \"Video-Text-to-Text\",\n        modality: \"multimodal\",\n        hideInDatasets: false,\n    },\n    \"keypoint-detection\": {\n        name: \"Keypoint Detection\",\n        subtasks: [\n            {\n                type: \"pose-estimation\",\n                name: \"Pose Estimation\",\n            },\n        ],\n        modality: \"cv\",\n        hideInDatasets: true,\n    },\n    \"visual-document-retrieval\": {\n        name: \"Visual Document Retrieval\",\n        modality: \"multimodal\",\n    },\n    \"any-to-any\": {\n        name: \"Any-to-Any\",\n        modality: \"multimodal\",\n    },\n    \"video-to-video\": {\n        name: \"Video-to-Video\",\n        modality: \"cv\",\n        hideInDatasets: true,\n    },\n    other: {\n        name: \"Other\",\n        modality: \"other\",\n        hideInModels: true,\n        hideInDatasets: true,\n    },\n};\nexport const PIPELINE_TYPES = Object.keys(PIPELINE_DATA);\nexport const SUBTASK_TYPES = Object.values(PIPELINE_DATA)\n    .flatMap((data) => (\"subtasks\" in data ? data.subtasks : []))\n    .map((s) => s.type);\nexport const PIPELINE_TYPES_SET = new Set(PIPELINE_TYPES);\n","const taskData = {\n    datasets: [\n        {\n            description: \"A benchmark of 10 different audio tasks.\",\n            id: \"s3prl/superb\",\n        },\n        {\n            description: \"A dataset of YouTube clips and their sound categories.\",\n            id: \"agkphysics/AudioSet\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"audio.wav\",\n                type: \"audio\",\n            },\n        ],\n        outputs: [\n            {\n                data: [\n                    {\n                        label: \"Up\",\n                        score: 0.2,\n                    },\n                    {\n                        label: \"Down\",\n                        score: 0.8,\n                    },\n                ],\n                type: \"chart\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"\",\n            id: \"accuracy\",\n        },\n        {\n            description: \"\",\n            id: \"recall\",\n        },\n        {\n            description: \"\",\n            id: \"precision\",\n        },\n        {\n            description: \"\",\n            id: \"f1\",\n        },\n    ],\n    models: [\n        {\n            description: \"An easy-to-use model for command recognition.\",\n            id: \"speechbrain/google_speech_command_xvector\",\n        },\n        {\n            description: \"An emotion recognition model.\",\n            id: \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\",\n        },\n        {\n            description: \"A language identification model.\",\n            id: \"facebook/mms-lid-126\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that can classify music into different genre.\",\n            id: \"kurianbenoy/audioclassification\",\n        },\n    ],\n    summary: \"Audio classification is the task of assigning a label or class to a given audio. It can be used for recognizing which command a user is giving or the emotion of a statement, as well as identifying a speaker.\",\n    widgetModels: [\"MIT/ast-finetuned-audioset-10-10-0.4593\"],\n    youtubeId: \"KWwzcmG98Ds\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"A dataset containing audio conversations with questionanswer pairs.\",\n            id: \"nvidia/AF-Think\",\n        },\n        {\n            description: \"A more advanced and comprehensive dataset that contains characteristics of the audio as well\",\n            id: \"tsinghua-ee/QualiSpeech\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"audio.wav\",\n                type: \"audio\",\n            },\n            {\n                label: \"Text Prompt\",\n                content: \"What is the gender of the speaker?\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                label: \"Generated Text\",\n                content: \"The gender of the speaker is female.\",\n                type: \"text\",\n            },\n        ],\n    },\n    metrics: [],\n    models: [\n        {\n            description: \"A lightweight model that has capabilities of taking both audio and text as inputs and generating responses.\",\n            id: \"fixie-ai/ultravox-v0_5-llama-3_2-1b\",\n        },\n        {\n            description: \"A multimodal model that supports voice chat and audio analysis.\",\n            id: \"Qwen/Qwen2-Audio-7B-Instruct\",\n        },\n        {\n            description: \"A model for audio understanding, speech translation, and transcription.\",\n            id: \"mistralai/Voxtral-Small-24B-2507\",\n        },\n        {\n            description: \"A new model capable of audio question answering and reasoning.\",\n            id: \"nvidia/audio-flamingo-3\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"A space that takes input as both audio and text and generates answers.\",\n            id: \"iamomtiwari/ATTT\",\n        },\n        {\n            description: \"A web application that demonstrates chatting with the Qwen2Audio Model.\",\n            id: \"freddyaboulton/talk-to-qwen-webrtc\",\n        },\n    ],\n    summary: \"Audio-text-to-text models take both an audio clip and a text prompt as input, and generate natural language text as output. These models can answer questions about spoken content, summarize meetings, analyze music, or interpret speech beyond simple transcription. They are useful for applications that combine speech understanding with reasoning or conversation.\",\n    widgetModels: [],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"512-element X-vector embeddings of speakers from CMU ARCTIC dataset.\",\n            id: \"Matthijs/cmu-arctic-xvectors\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"input.wav\",\n                type: \"audio\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"label-0.wav\",\n                type: \"audio\",\n            },\n            {\n                filename: \"label-1.wav\",\n                type: \"audio\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"The Signal-to-Noise ratio is the relationship between the target signal level and the background noise level. It is calculated as the logarithm of the target signal divided by the background noise, in decibels.\",\n            id: \"snri\",\n        },\n        {\n            description: \"The Signal-to-Distortion ratio is the relationship between the target signal and the sum of noise, interference, and artifact errors\",\n            id: \"sdri\",\n        },\n    ],\n    models: [\n        {\n            description: \"A speech enhancement model.\",\n            id: \"ResembleAI/resemble-enhance\",\n        },\n        {\n            description: \"A model that can change the voice in a speech recording.\",\n            id: \"microsoft/speecht5_vc\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application for speech separation.\",\n            id: \"younver/speechbrain-speech-separation\",\n        },\n        {\n            description: \"An application for audio style transfer.\",\n            id: \"nakas/audio-diffusion_style_transfer\",\n        },\n    ],\n    summary: \"Audio-to-Audio is a family of tasks in which the input is an audio and the output is one or multiple generated audios. Some example tasks are speech enhancement and source separation.\",\n    widgetModels: [\"speechbrain/sepformer-wham\"],\n    youtubeId: \"iohj7nCCYoM\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"31,175 hours of multilingual audio-text dataset in 108 languages.\",\n            id: \"mozilla-foundation/common_voice_17_0\",\n        },\n        {\n            description: \"Multilingual and diverse audio dataset with 101k hours of audio.\",\n            id: \"amphion/Emilia-Dataset\",\n        },\n        {\n            description: \"A dataset with 44.6k hours of English speaker data and 6k hours of other language speakers.\",\n            id: \"parler-tts/mls_eng\",\n        },\n        {\n            description: \"A multilingual audio dataset with 370K hours of audio.\",\n            id: \"espnet/yodas\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"input.flac\",\n                type: \"audio\",\n            },\n        ],\n        outputs: [\n            {\n                /// GOING ALONG SLUSHY COUNTRY ROADS AND SPEAKING TO DAMP AUDIENCES I\n                label: \"Transcript\",\n                content: \"Going along slushy country roads and speaking to damp audiences in...\",\n                type: \"text\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"\",\n            id: \"wer\",\n        },\n        {\n            description: \"\",\n            id: \"cer\",\n        },\n    ],\n    models: [\n        {\n            description: \"A powerful ASR model by OpenAI.\",\n            id: \"openai/whisper-large-v3\",\n        },\n        {\n            description: \"A good generic speech model by MetaAI for fine-tuning.\",\n            id: \"facebook/w2v-bert-2.0\",\n        },\n        {\n            description: \"An end-to-end model that performs ASR and Speech Translation by MetaAI.\",\n            id: \"facebook/seamless-m4t-v2-large\",\n        },\n        {\n            description: \"A powerful multilingual ASR and Speech Translation model by Nvidia.\",\n            id: \"nvidia/canary-1b\",\n        },\n        {\n            description: \"Powerful speaker diarization model.\",\n            id: \"pyannote/speaker-diarization-3.1\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"A powerful general-purpose speech recognition application.\",\n            id: \"hf-audio/whisper-large-v3\",\n        },\n        {\n            description: \"Latest ASR model from Useful Sensors.\",\n            id: \"mrfakename/Moonshinex\",\n        },\n        {\n            description: \"A high quality speech and text translation model by Meta.\",\n            id: \"facebook/seamless_m4t\",\n        },\n        {\n            description: \"A powerful multilingual ASR and Speech Translation model by Nvidia\",\n            id: \"nvidia/canary-1b\",\n        },\n    ],\n    summary: \"Automatic Speech Recognition (ASR), also known as Speech to Text (STT), is the task of transcribing a given audio to text. It has many applications, such as voice user interfaces.\",\n    widgetModels: [\"openai/whisper-large-v3\"],\n    youtubeId: \"TksaY_FDgnk\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"Largest document understanding dataset.\",\n            id: \"HuggingFaceM4/Docmatix\",\n        },\n        {\n            description: \"Dataset from the 2020 DocVQA challenge. The documents are taken from the UCSF Industry Documents Library.\",\n            id: \"eliolio/docvqa\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Question\",\n                content: \"What is the idea behind the consumer relations efficiency team?\",\n                type: \"text\",\n            },\n            {\n                filename: \"document-question-answering-input.png\",\n                type: \"img\",\n            },\n        ],\n        outputs: [\n            {\n                label: \"Answer\",\n                content: \"Balance cost efficiency with quality customer service\",\n                type: \"text\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"The evaluation metric for the DocVQA challenge is the Average Normalized Levenshtein Similarity (ANLS). This metric is flexible to character regognition errors and compares the predicted answer with the ground truth answer.\",\n            id: \"anls\",\n        },\n        {\n            description: \"Exact Match is a metric based on the strict character match of the predicted answer and the right answer. For answers predicted correctly, the Exact Match will be 1. Even if only one character is different, Exact Match will be 0\",\n            id: \"exact-match\",\n        },\n    ],\n    models: [\n        {\n            description: \"A robust document question answering model.\",\n            id: \"impira/layoutlm-document-qa\",\n        },\n        {\n            description: \"A document question answering model specialized in invoices.\",\n            id: \"impira/layoutlm-invoices\",\n        },\n        {\n            description: \"A special model for OCR-free document question answering.\",\n            id: \"microsoft/udop-large\",\n        },\n        {\n            description: \"A powerful model for document question answering.\",\n            id: \"google/pix2struct-docvqa-large\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"A robust document question answering application.\",\n            id: \"impira/docquery\",\n        },\n        {\n            description: \"An application that can answer questions from invoices.\",\n            id: \"impira/invoices\",\n        },\n        {\n            description: \"An application to compare different document question answering models.\",\n            id: \"merve/compare_docvqa_models\",\n        },\n    ],\n    summary: \"Document Question Answering (also known as Document Visual Question Answering) is the task of answering questions on document images. Document question answering models take a (document, question) pair as input and return an answer in natural language. Models usually rely on multi-modal features, combining text, position of words (bounding-boxes) and image.\",\n    widgetModels: [\"impira/layoutlm-invoices\"],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"Wikipedia dataset containing cleaned articles of all languages. Can be used to train `feature-extraction` models.\",\n            id: \"wikipedia\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Input\",\n                content: \"India, officially the Republic of India, is a country in South Asia.\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                table: [\n                    [\"Dimension 1\", \"Dimension 2\", \"Dimension 3\"],\n                    [\"2.583383083343506\", \"2.757075071334839\", \"0.9023529887199402\"],\n                    [\"8.29393482208252\", \"1.1071064472198486\", \"2.03399395942688\"],\n                    [\"-0.7754912972450256\", \"-1.647324562072754\", \"-0.6113331913948059\"],\n                    [\"0.07087723910808563\", \"1.5942802429199219\", \"1.4610432386398315\"],\n                ],\n                type: \"tabular\",\n            },\n        ],\n    },\n    metrics: [],\n    models: [\n        {\n            description: \"A powerful feature extraction model for natural language processing tasks.\",\n            id: \"thenlper/gte-large\",\n        },\n        {\n            description: \"A strong feature extraction model for retrieval.\",\n            id: \"Alibaba-NLP/gte-Qwen1.5-7B-instruct\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"A leaderboard to rank text feature extraction models based on a benchmark.\",\n            id: \"mteb/leaderboard\",\n        },\n        {\n            description: \"A leaderboard to rank best feature extraction models based on human feedback.\",\n            id: \"mteb/arena\",\n        },\n    ],\n    summary: \"Feature extraction is the task of extracting features learnt in a model.\",\n    widgetModels: [\"facebook/bart-base\"],\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"A common dataset that is used to train models for many languages.\",\n            id: \"wikipedia\",\n        },\n        {\n            description: \"A large English dataset with text crawled from the web.\",\n            id: \"c4\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Input\",\n                content: \"The <mask> barked at me\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                type: \"chart\",\n                data: [\n                    {\n                        label: \"wolf\",\n                        score: 0.487,\n                    },\n                    {\n                        label: \"dog\",\n                        score: 0.061,\n                    },\n                    {\n                        label: \"cat\",\n                        score: 0.058,\n                    },\n                    {\n                        label: \"fox\",\n                        score: 0.047,\n                    },\n                    {\n                        label: \"squirrel\",\n                        score: 0.025,\n                    },\n                ],\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"Cross Entropy is a metric that calculates the difference between two probability distributions. Each probability distribution is the distribution of predicted words\",\n            id: \"cross_entropy\",\n        },\n        {\n            description: \"Perplexity is the exponential of the cross-entropy loss. It evaluates the probabilities assigned to the next word by the model. Lower perplexity indicates better performance\",\n            id: \"perplexity\",\n        },\n    ],\n    models: [\n        {\n            description: \"State-of-the-art masked language model.\",\n            id: \"answerdotai/ModernBERT-large\",\n        },\n        {\n            description: \"A multilingual model trained on 100 languages.\",\n            id: \"FacebookAI/xlm-roberta-base\",\n        },\n    ],\n    spaces: [],\n    summary: \"Masked language modeling is the task of masking some of the words in a sentence and predicting which words should replace those masks. These models are useful when we want to get a statistical understanding of the language in which the model is trained in.\",\n    widgetModels: [\"distilroberta-base\"],\n    youtubeId: \"mqElG5QJWUg\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            // TODO write proper description\n            description: \"Benchmark dataset used for image classification with images that belong to 100 classes.\",\n            id: \"cifar100\",\n        },\n        {\n            // TODO write proper description\n            description: \"Dataset consisting of images of garments.\",\n            id: \"fashion_mnist\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"image-classification-input.jpeg\",\n                type: \"img\",\n            },\n        ],\n        outputs: [\n            {\n                type: \"chart\",\n                data: [\n                    {\n                        label: \"Egyptian cat\",\n                        score: 0.514,\n                    },\n                    {\n                        label: \"Tabby cat\",\n                        score: 0.193,\n                    },\n                    {\n                        label: \"Tiger cat\",\n                        score: 0.068,\n                    },\n                ],\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"\",\n            id: \"accuracy\",\n        },\n        {\n            description: \"\",\n            id: \"recall\",\n        },\n        {\n            description: \"\",\n            id: \"precision\",\n        },\n        {\n            description: \"\",\n            id: \"f1\",\n        },\n    ],\n    models: [\n        {\n            description: \"A strong image classification model.\",\n            id: \"google/vit-base-patch16-224\",\n        },\n        {\n            description: \"A robust image classification model.\",\n            id: \"facebook/deit-base-distilled-patch16-224\",\n        },\n        {\n            description: \"A strong image classification model.\",\n            id: \"facebook/convnext-large-224\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"A leaderboard to evaluate different image classification models.\",\n            id: \"timm/leaderboard\",\n        },\n    ],\n    summary: \"Image classification is the task of assigning a label or class to an entire image. Images are expected to have only one class for each image. Image classification models take an image as input and return a prediction about which class the image belongs to.\",\n    widgetModels: [\"google/vit-base-patch16-224\"],\n    youtubeId: \"tjAIM7BOYhw\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"ImageNet-1K is a image classification dataset in which images are used to train image-feature-extraction models.\",\n            id: \"imagenet-1k\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"mask-generation-input.png\",\n                type: \"img\",\n            },\n        ],\n        outputs: [\n            {\n                table: [\n                    [\"Dimension 1\", \"Dimension 2\", \"Dimension 3\"],\n                    [\"0.21236686408519745\", \"1.0919708013534546\", \"0.8512550592422485\"],\n                    [\"0.809657871723175\", \"-0.18544459342956543\", \"-0.7851548194885254\"],\n                    [\"1.3103108406066895\", \"-0.2479034662246704\", \"-0.9107287526130676\"],\n                    [\"1.8536205291748047\", \"-0.36419737339019775\", \"0.09717650711536407\"],\n                ],\n                type: \"tabular\",\n            },\n        ],\n    },\n    metrics: [],\n    models: [\n        {\n            description: \"A powerful image feature extraction model.\",\n            id: \"timm/vit_large_patch14_dinov2.lvd142m\",\n        },\n        {\n            description: \"A strong image feature extraction model.\",\n            id: \"nvidia/MambaVision-T-1K\",\n        },\n        {\n            description: \"A robust image feature extraction model.\",\n            id: \"facebook/dino-vitb16\",\n        },\n        {\n            description: \"Cutting-edge image feature extraction model.\",\n            id: \"apple/aimv2-large-patch14-336-distilled\",\n        },\n        {\n            description: \"Strong image feature extraction model that can be used on images and documents.\",\n            id: \"OpenGVLab/InternViT-6B-448px-V1-2\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"A leaderboard to evaluate different image-feature-extraction models on classification performances\",\n            id: \"timm/leaderboard\",\n        },\n    ],\n    summary: \"Image feature extraction is the task of extracting features learnt in a computer vision model.\",\n    widgetModels: [],\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"Synthetic dataset, for image relighting\",\n            id: \"VIDIT\",\n        },\n        {\n            description: \"Multiple images of celebrities, used for facial expression translation\",\n            id: \"huggan/CelebA-faces\",\n        },\n        {\n            description: \"12M image-caption pairs.\",\n            id: \"Spawning/PD12M\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"image-to-image-input.jpeg\",\n                type: \"img\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"image-to-image-output.png\",\n                type: \"img\",\n            },\n        ],\n    },\n    isPlaceholder: false,\n    metrics: [\n        {\n            description: \"Peak Signal to Noise Ratio (PSNR) is an approximation of the human perception, considering the ratio of the absolute intensity with respect to the variations. Measured in dB, a high value indicates a high fidelity.\",\n            id: \"PSNR\",\n        },\n        {\n            description: \"Structural Similarity Index (SSIM) is a perceptual metric which compares the luminance, contrast and structure of two images. The values of SSIM range between -1 and 1, and higher values indicate closer resemblance to the original image.\",\n            id: \"SSIM\",\n        },\n        {\n            description: \"Inception Score (IS) is an analysis of the labels predicted by an image classification model when presented with a sample of the generated images.\",\n            id: \"IS\",\n        },\n    ],\n    models: [\n        {\n            description: \"An image-to-image model to improve image resolution.\",\n            id: \"fal/AuraSR-v2\",\n        },\n        {\n            description: \"Powerful image editing model.\",\n            id: \"black-forest-labs/FLUX.1-Kontext-dev\",\n        },\n        {\n            description: \"Virtual try-on model.\",\n            id: \"yisol/IDM-VTON\",\n        },\n        {\n            description: \"Image re-lighting model.\",\n            id: \"kontext-community/relighting-kontext-dev-lora-v3\",\n        },\n        {\n            description: \"Strong model for inpainting and outpainting.\",\n            id: \"black-forest-labs/FLUX.1-Fill-dev\",\n        },\n        {\n            description: \"Strong model for image editing using depth maps.\",\n            id: \"black-forest-labs/FLUX.1-Depth-dev-lora\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"Image editing application.\",\n            id: \"black-forest-labs/FLUX.1-Kontext-Dev\",\n        },\n        {\n            description: \"Image relighting application.\",\n            id: \"lllyasviel/iclight-v2-vary\",\n        },\n        {\n            description: \"An application for image upscaling.\",\n            id: \"jasperai/Flux.1-dev-Controlnet-Upscaler\",\n        },\n    ],\n    summary: \"Image-to-image is the task of transforming an input image through a variety of possible manipulations and enhancements, such as super-resolution, image inpainting, colorization, and more.\",\n    widgetModels: [\"Qwen/Qwen-Image\"],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            // TODO write proper description\n            description: \"Dataset from 12M image-text of Reddit\",\n            id: \"red_caps\",\n        },\n        {\n            // TODO write proper description\n            description: \"Dataset from 3.3M images of Google\",\n            id: \"datasets/conceptual_captions\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"savanna.jpg\",\n                type: \"img\",\n            },\n        ],\n        outputs: [\n            {\n                label: \"Detailed description\",\n                content: \"a herd of giraffes and zebras grazing in a field\",\n                type: \"text\",\n            },\n        ],\n    },\n    metrics: [],\n    models: [\n        {\n            description: \"Strong OCR model.\",\n            id: \"allenai/olmOCR-7B-0725\",\n        },\n        {\n            description: \"Powerful image captioning model.\",\n            id: \"fancyfeast/llama-joycaption-beta-one-hf-llava\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"SVG generator app from images.\",\n            id: \"multimodalart/OmniSVG-3B\",\n        },\n        {\n            description: \"An application that converts documents to markdown.\",\n            id: \"numind/NuMarkdown-8B-Thinking\",\n        },\n        {\n            description: \"An application that can caption images.\",\n            id: \"fancyfeast/joy-caption-beta-one\",\n        },\n    ],\n    summary: \"Image to text models output a text from a given image. Image captioning or optical character recognition can be considered as the most common applications of image to text.\",\n    widgetModels: [\"Salesforce/blip-image-captioning-large\"],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"Instructions composed of image and text.\",\n            id: \"liuhaotian/LLaVA-Instruct-150K\",\n        },\n        {\n            description: \"Collection of image-text pairs on scientific topics.\",\n            id: \"DAMO-NLP-SG/multimodal_textbook\",\n        },\n        {\n            description: \"A collection of datasets made for model fine-tuning.\",\n            id: \"HuggingFaceM4/the_cauldron\",\n        },\n        {\n            description: \"Screenshots of websites with their HTML/CSS codes.\",\n            id: \"HuggingFaceM4/WebSight\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"image-text-to-text-input.png\",\n                type: \"img\",\n            },\n            {\n                label: \"Text Prompt\",\n                content: \"Describe the position of the bee in detail.\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                label: \"Answer\",\n                content: \"The bee is sitting on a pink flower, surrounded by other flowers. The bee is positioned in the center of the flower, with its head and front legs sticking out.\",\n                type: \"text\",\n            },\n        ],\n    },\n    metrics: [],\n    models: [\n        {\n            description: \"Small and efficient yet powerful vision language model.\",\n            id: \"HuggingFaceTB/SmolVLM-Instruct\",\n        },\n        {\n            description: \"Cutting-edge reasoning vision language model.\",\n            id: \"zai-org/GLM-4.5V\",\n        },\n        {\n            description: \"Cutting-edge small vision language model to convert documents to text.\",\n            id: \"rednote-hilab/dots.ocr\",\n        },\n        {\n            description: \"Small yet powerful model.\",\n            id: \"Qwen/Qwen2.5-VL-3B-Instruct\",\n        },\n        {\n            description: \"Image-text-to-text model with agentic capabilities.\",\n            id: \"microsoft/Magma-8B\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"Leaderboard to evaluate vision language models.\",\n            id: \"opencompass/open_vlm_leaderboard\",\n        },\n        {\n            description: \"An application that compares object detection capabilities of different vision language models.\",\n            id: \"sergiopaniego/vlm_object_understanding\",\n        },\n        {\n            description: \"An application to compare different OCR models.\",\n            id: \"prithivMLmods/Multimodal-OCR\",\n        },\n    ],\n    summary: \"Image-text-to-text models take in an image and text prompt and output text. These models are also called vision-language models, or VLMs. The difference from image-to-text models is that these models take an additional text input, not restricting the model to certain use cases like image captioning, and may also be trained to accept a conversation as input.\",\n    widgetModels: [\"zai-org/GLM-4.5V\"],\n    youtubeId: \"IoGaGfU1CIg\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [],\n    demo: {\n        inputs: [\n            {\n                filename: \"image-text-to-image-input.jpeg\",\n                type: \"img\",\n            },\n            {\n                label: \"Input\",\n                content: \"A city above clouds, pastel colors, Victorian style\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"image-text-to-image-output.png\",\n                type: \"img\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"The Frchet Inception Distance (FID) calculates the distance between distributions between synthetic and real samples. A lower FID score indicates better similarity between the distributions of real and generated images.\",\n            id: \"FID\",\n        },\n        {\n            description: \"CLIP Score measures the similarity between the generated image and the text prompt using CLIP embeddings. A higher score indicates better alignment with the text prompt.\",\n            id: \"CLIP\",\n        },\n    ],\n    models: [\n        {\n            description: \"A powerful model for image-text-to-image generation.\",\n            id: \"black-forest-labs/FLUX.2-dev\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application for image-text-to-image generation.\",\n            id: \"black-forest-labs/FLUX.2-dev\",\n        },\n    ],\n    summary: \"Image-text-to-image models take an image and a text prompt as input and generate a new image based on the reference image and text instructions. These models are useful for image editing, style transfer, image variations, and guided image generation tasks.\",\n    widgetModels: [\"black-forest-labs/FLUX.2-dev\"],\n    youtubeId: undefined,\n};\nexport default taskData;\n","const taskData = {\n    datasets: [],\n    demo: {\n        inputs: [\n            {\n                filename: \"image-text-to-video-input.jpg\",\n                type: \"img\",\n            },\n            {\n                label: \"Input\",\n                content: \"Darth Vader is surfing on the waves.\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"image-text-to-video-output.gif\",\n                type: \"img\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"Frechet Video Distance uses a model that captures coherence for changes in frames and the quality of each frame. A smaller score indicates better video generation.\",\n            id: \"fvd\",\n        },\n        {\n            description: \"CLIPSIM measures similarity between video frames and text using an image-text similarity model. A higher score indicates better video generation.\",\n            id: \"clipsim\",\n        },\n    ],\n    models: [\n        {\n            description: \"A powerful model for image-text-to-video generation.\",\n            id: \"Lightricks/LTX-Video\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application for image-text-to-video generation.\",\n            id: \"Lightricks/ltx-video-distilled\",\n        },\n    ],\n    summary: \"Image-text-to-video models take an reference image and a text instructions as and generate a video based on them. These models are useful for animating still images, creating dynamic content from static references, and generating videos with specific motion or transformation guidance.\",\n    widgetModels: [\"Lightricks/LTX-Video\"],\n    youtubeId: undefined,\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"Scene segmentation dataset.\",\n            id: \"scene_parse_150\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"image-segmentation-input.jpeg\",\n                type: \"img\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"image-segmentation-output.png\",\n                type: \"img\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"Average Precision (AP) is the Area Under the PR Curve (AUC-PR). It is calculated for each semantic class separately\",\n            id: \"Average Precision\",\n        },\n        {\n            description: \"Mean Average Precision (mAP) is the overall average of the AP values\",\n            id: \"Mean Average Precision\",\n        },\n        {\n            description: \"Intersection over Union (IoU) is the overlap of segmentation masks. Mean IoU is the average of the IoU of all semantic classes\",\n            id: \"Mean Intersection over Union\",\n        },\n        {\n            description: \"AP is the Average Precision at the IoU threshold of a  value, for example, AP50 and AP75\",\n            id: \"AP\",\n        },\n    ],\n    models: [\n        {\n            // TO DO: write description\n            description: \"Solid panoptic segmentation model trained on COCO.\",\n            id: \"tue-mps/coco_panoptic_eomt_large_640\",\n        },\n        {\n            description: \"Background removal model.\",\n            id: \"briaai/RMBG-1.4\",\n        },\n        {\n            description: \"A multipurpose image segmentation model for high resolution images.\",\n            id: \"ZhengPeng7/BiRefNet\",\n        },\n        {\n            description: \"Powerful human-centric image segmentation model.\",\n            id: \"facebook/sapiens-seg-1b\",\n        },\n        {\n            description: \"Panoptic segmentation model trained on the COCO (common objects) dataset.\",\n            id: \"facebook/mask2former-swin-large-coco-panoptic\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"A semantic segmentation application that can predict unseen instances out of the box.\",\n            id: \"facebook/ov-seg\",\n        },\n        {\n            description: \"One of the strongest segmentation applications.\",\n            id: \"jbrinkma/segment-anything\",\n        },\n        {\n            description: \"A human-centric segmentation model.\",\n            id: \"facebook/sapiens-pose\",\n        },\n        {\n            description: \"An instance segmentation application to predict neuronal cell types from microscopy images.\",\n            id: \"rashmi/sartorius-cell-instance-segmentation\",\n        },\n        {\n            description: \"An application that segments videos.\",\n            id: \"ArtGAN/Segment-Anything-Video\",\n        },\n        {\n            description: \"An panoptic segmentation application built for outdoor environments.\",\n            id: \"segments/panoptic-segment-anything\",\n        },\n    ],\n    summary: \"Image Segmentation divides an image into segments where each pixel in the image is mapped to an object. This task has multiple variants such as instance segmentation, panoptic segmentation and semantic segmentation.\",\n    widgetModels: [\"nvidia/segformer-b0-finetuned-ade-512-512\"],\n    youtubeId: \"dKE8SIt9C-w\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"A benchmark dataset for reference image controlled video generation.\",\n            id: \"ali-vilab/VACE-Benchmark\",\n        },\n        {\n            description: \"A dataset of video generation style preferences.\",\n            id: \"Rapidata/sora-video-generation-style-likert-scoring\",\n        },\n        {\n            description: \"A dataset with videos and captions throughout the videos.\",\n            id: \"BestWishYsh/ChronoMagic\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"image-to-video-input.jpg\",\n                type: \"img\",\n            },\n            {\n                label: \"Optional Text Prompt\",\n                content: \"This penguin is dancing\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"image-to-video-output.gif\",\n                type: \"img\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"Frchet Video Distance (FVD) measures the perceptual similarity between the distributions of generated videos and a set of real videos, assessing overall visual quality and temporal coherence of the video generated from an input image.\",\n            id: \"fvd\",\n        },\n        {\n            description: \"CLIP Score measures the semantic similarity between a textual prompt (if provided alongside the input image) and the generated video frames. It evaluates how well the video's generated content and motion align with the textual description, conditioned on the initial image.\",\n            id: \"clip_score\",\n        },\n        {\n            description: \"First Frame Fidelity, often measured using LPIPS (Learned Perceptual Image Patch Similarity), PSNR, or SSIM, quantifies how closely the first frame of the generated video matches the input conditioning image.\",\n            id: \"lpips\",\n        },\n        {\n            description: \"Identity Preservation Score measures the consistency of identity (e.g., a person's face or a specific object's characteristics) between the input image and throughout the generated video frames, often calculated using features from specialized models like face recognition (e.g., ArcFace) or re-identification models.\",\n            id: \"identity_preservation\",\n        },\n        {\n            description: \"Motion Score evaluates the quality, realism, and temporal consistency of motion in the video generated from a static image. This can be based on optical flow analysis (e.g., smoothness, magnitude), consistency of object trajectories, or specific motion plausibility assessments.\",\n            id: \"motion_score\",\n        },\n    ],\n    models: [\n        {\n            description: \"LTX-Video, a 13B parameter model for high quality video generation\",\n            id: \"Lightricks/LTX-Video-0.9.7-dev\",\n        },\n        {\n            description: \"A 14B parameter model for reference image controlled video generation\",\n            id: \"Wan-AI/Wan2.1-VACE-14B\",\n        },\n        {\n            description: \"An image-to-video generation model using FramePack F1 methodology with Hunyuan-DiT architecture\",\n            id: \"lllyasviel/FramePack_F1_I2V_HY_20250503\",\n        },\n        {\n            description: \"A distilled version of the LTX-Video-0.9.7-dev model for faster inference\",\n            id: \"Lightricks/LTX-Video-0.9.7-distilled\",\n        },\n        {\n            description: \"An image-to-video generation model by Skywork AI, 14B parameters, producing 720p videos.\",\n            id: \"Skywork/SkyReels-V2-I2V-14B-720P\",\n        },\n        {\n            description: \"Image-to-video variant of Tencent's HunyuanVideo.\",\n            id: \"tencent/HunyuanVideo-I2V\",\n        },\n        {\n            description: \"A 14B parameter model for 720p image-to-video generation by Wan-AI.\",\n            id: \"Wan-AI/Wan2.1-I2V-14B-720P\",\n        },\n        {\n            description: \"A Diffusers version of the Wan2.1-I2V-14B-720P model for 720p image-to-video generation.\",\n            id: \"Wan-AI/Wan2.1-I2V-14B-720P-Diffusers\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application to generate videos fast.\",\n            id: \"Lightricks/ltx-video-distilled\",\n        },\n        {\n            description: \"Generate videos with the FramePack-F1\",\n            id: \"linoyts/FramePack-F1\",\n        },\n        {\n            description: \"Generate videos with the FramePack\",\n            id: \"lisonallen/framepack-i2v\",\n        },\n        {\n            description: \"Wan2.1 with CausVid LoRA\",\n            id: \"multimodalart/wan2-1-fast\",\n        },\n        {\n            description: \"A demo for Stable Video Diffusion\",\n            id: \"multimodalart/stable-video-diffusion\",\n        },\n    ],\n    summary: \"Image-to-video models take a still image as input and generate a video. These models can be guided by text prompts to influence the content and style of the output video.\",\n    widgetModels: [],\n    youtubeId: undefined,\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"Widely used benchmark dataset for multiple Vision tasks.\",\n            id: \"merve/coco2017\",\n        },\n        {\n            description: \"Medical Imaging dataset of the Human Brain for segmentation and mask generating tasks\",\n            id: \"rocky93/BraTS_segmentation\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"mask-generation-input.png\",\n                type: \"img\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"mask-generation-output.png\",\n                type: \"img\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"IoU is used to measure the overlap between predicted mask and the ground truth mask.\",\n            id: \"Intersection over Union (IoU)\",\n        },\n    ],\n    models: [\n        {\n            description: \"Small yet powerful mask generation model.\",\n            id: \"Zigeng/SlimSAM-uniform-50\",\n        },\n        {\n            description: \"Very strong mask generation model.\",\n            id: \"facebook/sam2-hiera-large\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that combines a mask generation model with a zero-shot object detection model for text-guided image segmentation.\",\n            id: \"merve/OWLSAM2\",\n        },\n        {\n            description: \"An application that compares the performance of a large and a small mask generation model.\",\n            id: \"merve/slimsam\",\n        },\n        {\n            description: \"An application based on an improved mask generation model.\",\n            id: \"SkalskiP/segment-anything-model-2\",\n        },\n        {\n            description: \"An application to remove objects from videos using mask generation models.\",\n            id: \"SkalskiP/SAM_and_ProPainter\",\n        },\n    ],\n    summary: \"Mask generation is the task of generating masks that identify a specific object or region of interest in a given image. Masks are often used in segmentation tasks, where they provide a precise way to isolate the object of interest for further processing or analysis.\",\n    widgetModels: [],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"Widely used benchmark dataset for multiple vision tasks.\",\n            id: \"merve/coco2017\",\n        },\n        {\n            description: \"Multi-task computer vision benchmark.\",\n            id: \"merve/pascal-voc\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"object-detection-input.jpg\",\n                type: \"img\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"object-detection-output.jpg\",\n                type: \"img\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"The Average Precision (AP) metric is the Area Under the PR Curve (AUC-PR). It is calculated for each class separately\",\n            id: \"Average Precision\",\n        },\n        {\n            description: \"The Mean Average Precision (mAP) metric is the overall average of the AP values\",\n            id: \"Mean Average Precision\",\n        },\n        {\n            description: \"The AP metric is the Average Precision at the IoU threshold of a  value, for example, AP50 and AP75\",\n            id: \"AP\",\n        },\n    ],\n    models: [\n        {\n            description: \"Solid object detection model pre-trained on the COCO 2017 dataset.\",\n            id: \"facebook/detr-resnet-50\",\n        },\n        {\n            description: \"Accurate object detection model.\",\n            id: \"IDEA-Research/dab-detr-resnet-50\",\n        },\n        {\n            description: \"Fast and accurate object detection model.\",\n            id: \"PekingU/rtdetr_v2_r50vd\",\n        },\n        {\n            description: \"Object detection model for low-lying objects.\",\n            id: \"StephanST/WALDO30\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"Real-time object detection demo.\",\n            id: \"Roboflow/RF-DETR\",\n        },\n        {\n            description: \"An application that contains various object detection models to try from.\",\n            id: \"Gradio-Blocks/Object-Detection-With-DETR-and-YOLOS\",\n        },\n        {\n            description: \"A cutting-edge object detection application.\",\n            id: \"sunsmarterjieleaf/yolov12\",\n        },\n        {\n            description: \"An object tracking, segmentation and inpainting application.\",\n            id: \"VIPLab/Track-Anything\",\n        },\n        {\n            description: \"Very fast object tracking application based on object detection.\",\n            id: \"merve/RT-DETR-tracking-coco\",\n        },\n    ],\n    summary: \"Object Detection models allow users to identify objects of certain defined classes. Object detection models receive an image as input and output the images with bounding boxes and labels on detected objects.\",\n    widgetModels: [\"facebook/detr-resnet-50\"],\n    youtubeId: \"WdAeKSOpxhw\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"NYU Depth V2 Dataset: Video dataset containing both RGB and depth sensor data.\",\n            id: \"sayakpaul/nyu_depth_v2\",\n        },\n        {\n            description: \"Monocular depth estimation benchmark based without noise and errors.\",\n            id: \"depth-anything/DA-2K\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"depth-estimation-input.jpg\",\n                type: \"img\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"depth-estimation-output.png\",\n                type: \"img\",\n            },\n        ],\n    },\n    metrics: [],\n    models: [\n        {\n            description: \"Cutting-edge depth estimation model.\",\n            id: \"depth-anything/Depth-Anything-V2-Large\",\n        },\n        {\n            description: \"A strong monocular depth estimation model.\",\n            id: \"jingheya/lotus-depth-g-v1-0\",\n        },\n        {\n            description: \"A depth estimation model that predicts depth in videos.\",\n            id: \"tencent/DepthCrafter\",\n        },\n        {\n            description: \"A robust depth estimation model.\",\n            id: \"apple/DepthPro-hf\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that predicts the depth of an image and then reconstruct the 3D model as voxels.\",\n            id: \"radames/dpt-depth-estimation-3d-voxels\",\n        },\n        {\n            description: \"An application for bleeding-edge depth estimation.\",\n            id: \"akhaliq/depth-pro\",\n        },\n        {\n            description: \"An application on cutting-edge depth estimation in videos.\",\n            id: \"tencent/DepthCrafter\",\n        },\n        {\n            description: \"A human-centric depth estimation application.\",\n            id: \"facebook/sapiens-depth\",\n        },\n    ],\n    summary: \"Depth estimation is the task of predicting depth of the objects present in an image.\",\n    widgetModels: [\"\"],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [],\n    demo: {\n        inputs: [],\n        outputs: [],\n    },\n    isPlaceholder: true,\n    metrics: [],\n    models: [],\n    spaces: [],\n    summary: \"\",\n    widgetModels: [],\n    youtubeId: undefined,\n    /// If this is a subtask, link to the most general task ID\n    /// (eg, text-generation is the canonical ID of text-simplification)\n    canonicalId: undefined,\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"A curation of widely used datasets for Data Driven Deep Reinforcement Learning (D4RL)\",\n            id: \"edbeeching/decision_transformer_gym_replay\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"State\",\n                content: \"Red traffic light, pedestrians are about to pass.\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                label: \"Action\",\n                content: \"Stop the car.\",\n                type: \"text\",\n            },\n            {\n                label: \"Next State\",\n                content: \"Yellow light, pedestrians have crossed.\",\n                type: \"text\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"Accumulated reward across all time steps discounted by a factor that ranges between 0 and 1 and determines how much the agent optimizes for future relative to immediate rewards. Measures how good is the policy ultimately found by a given algorithm considering uncertainty over the future.\",\n            id: \"Discounted Total Reward\",\n        },\n        {\n            description: \"Average return obtained after running the policy for a certain number of evaluation episodes. As opposed to total reward, mean reward considers how much reward a given algorithm receives while learning.\",\n            id: \"Mean Reward\",\n        },\n        {\n            description: \"Measures how good a given algorithm is after a predefined time. Some algorithms may be guaranteed to converge to optimal behavior across many time steps. However, an agent that reaches an acceptable level of optimality after a given time horizon may be preferable to one that ultimately reaches optimality but takes a long time.\",\n            id: \"Level of Performance After Some Time\",\n        },\n    ],\n    models: [\n        {\n            description: \"A Reinforcement Learning model trained on expert data from the Gym Hopper environment\",\n            id: \"edbeeching/decision-transformer-gym-hopper-expert\",\n        },\n        {\n            description: \"A PPO agent playing seals/CartPole-v0 using the stable-baselines3 library and the RL Zoo.\",\n            id: \"HumanCompatibleAI/ppo-seals-CartPole-v0\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application for a cute puppy agent learning to catch a stick.\",\n            id: \"ThomasSimonini/Huggy\",\n        },\n        {\n            description: \"An application to play Snowball Fight with a reinforcement learning agent.\",\n            id: \"ThomasSimonini/SnowballFight\",\n        },\n    ],\n    summary: \"Reinforcement learning is the computational approach of learning from action by interacting with an environment through trial and error and receiving rewards (negative or positive) as feedback\",\n    widgetModels: [],\n    youtubeId: \"q0BiUn5LiBc\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            // TODO write proper description\n            description: \"A famous question answering dataset based on English articles from Wikipedia.\",\n            id: \"squad_v2\",\n        },\n        {\n            // TODO write proper description\n            description: \"A dataset of aggregated anonymized actual queries issued to the Google search engine.\",\n            id: \"natural_questions\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Question\",\n                content: \"Which name is also used to describe the Amazon rainforest in English?\",\n                type: \"text\",\n            },\n            {\n                label: \"Context\",\n                content: \"The Amazon rainforest, also known in English as Amazonia or the Amazon Jungle\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                label: \"Answer\",\n                content: \"Amazonia\",\n                type: \"text\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"Exact Match is a metric based on the strict character match of the predicted answer and the right answer. For answers predicted correctly, the Exact Match will be 1. Even if only one character is different, Exact Match will be 0\",\n            id: \"exact-match\",\n        },\n        {\n            description: \" The F1-Score metric is useful if we value both false positives and false negatives equally. The F1-Score is calculated on each word in the predicted sequence against the correct answer\",\n            id: \"f1\",\n        },\n    ],\n    models: [\n        {\n            description: \"A robust baseline model for most question answering domains.\",\n            id: \"deepset/roberta-base-squad2\",\n        },\n        {\n            description: \"Small yet robust model that can answer questions.\",\n            id: \"distilbert/distilbert-base-cased-distilled-squad\",\n        },\n        {\n            description: \"A special model that can answer questions from tables.\",\n            id: \"google/tapas-base-finetuned-wtq\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that can answer a long question from Wikipedia.\",\n            id: \"deepset/wikipedia-assistant\",\n        },\n    ],\n    summary: \"Question Answering models can retrieve the answer to a question from a given text, which is useful for searching for an answer in a document. Some question answering models can generate answers without context!\",\n    widgetModels: [\"deepset/roberta-base-squad2\"],\n    youtubeId: \"ajPx5LwJD-I\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"Bing queries with relevant passages from various web sources.\",\n            id: \"microsoft/ms_marco\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Source sentence\",\n                content: \"Machine learning is so easy.\",\n                type: \"text\",\n            },\n            {\n                label: \"Sentences to compare to\",\n                content: \"Deep learning is so straightforward.\",\n                type: \"text\",\n            },\n            {\n                label: \"\",\n                content: \"This is so difficult, like rocket science.\",\n                type: \"text\",\n            },\n            {\n                label: \"\",\n                content: \"I can't believe how much I struggled with this.\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                type: \"chart\",\n                data: [\n                    {\n                        label: \"Deep learning is so straightforward.\",\n                        score: 0.623,\n                    },\n                    {\n                        label: \"This is so difficult, like rocket science.\",\n                        score: 0.413,\n                    },\n                    {\n                        label: \"I can't believe how much I struggled with this.\",\n                        score: 0.256,\n                    },\n                ],\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"Reciprocal Rank is a measure used to rank the relevancy of documents given a set of documents. Reciprocal Rank is the reciprocal of the rank of the document retrieved, meaning, if the rank is 3, the Reciprocal Rank is 0.33. If the rank is 1, the Reciprocal Rank is 1\",\n            id: \"Mean Reciprocal Rank\",\n        },\n        {\n            description: \"The similarity of the embeddings is evaluated mainly on cosine similarity. It is calculated as the cosine of the angle between two vectors. It is particularly useful when your texts are not the same length\",\n            id: \"Cosine Similarity\",\n        },\n    ],\n    models: [\n        {\n            description: \"This model works well for sentences and paragraphs and can be used for clustering/grouping and semantic searches.\",\n            id: \"sentence-transformers/all-mpnet-base-v2\",\n        },\n        {\n            description: \"A multilingual robust sentence similarity model.\",\n            id: \"BAAI/bge-m3\",\n        },\n        {\n            description: \"A robust sentence similarity model.\",\n            id: \"HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1.5\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that leverages sentence similarity to answer questions from YouTube videos.\",\n            id: \"Gradio-Blocks/Ask_Questions_To_YouTube_Videos\",\n        },\n        {\n            description: \"An application that retrieves relevant PubMed abstracts for a given online article which can be used as further references.\",\n            id: \"Gradio-Blocks/pubmed-abstract-retriever\",\n        },\n        {\n            description: \"An application that leverages sentence similarity to summarize text.\",\n            id: \"nickmuchi/article-text-summarizer\",\n        },\n        {\n            description: \"A guide that explains how Sentence Transformers can be used for semantic search.\",\n            id: \"sentence-transformers/Sentence_Transformers_for_semantic_search\",\n        },\n    ],\n    summary: \"Sentence Similarity is the task of determining how similar two texts are. Sentence similarity models convert input texts into vectors (embeddings) that capture semantic information and calculate how close (similar) they are between them. This task is particularly useful for information retrieval and clustering/grouping.\",\n    widgetModels: [\"sentence-transformers/all-MiniLM-L6-v2\"],\n    youtubeId: \"VCZq5AkbNEU\",\n};\nexport default taskData;\n","const taskData = {\n    canonicalId: \"text-generation\",\n    datasets: [\n        {\n            description: \"News articles in five different languages along with their summaries. Widely used for benchmarking multilingual summarization models.\",\n            id: \"mlsum\",\n        },\n        {\n            description: \"English conversations and their summaries. Useful for benchmarking conversational agents.\",\n            id: \"samsum\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Input\",\n                content: \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. It was the first structure to reach a height of 300 metres. Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                label: \"Output\",\n                content: \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building. It was the first structure to reach a height of 300 metres.\",\n                type: \"text\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"The generated sequence is compared against its summary, and the overlap of tokens are counted. ROUGE-N refers to overlap of N subsequent tokens, ROUGE-1 refers to overlap of single tokens and ROUGE-2 is the overlap of two subsequent tokens.\",\n            id: \"rouge\",\n        },\n    ],\n    models: [\n        {\n            description: \"A strong summarization model trained on English news articles. Excels at generating factual summaries.\",\n            id: \"facebook/bart-large-cnn\",\n        },\n        {\n            description: \"A summarization model trained on medical articles.\",\n            id: \"Falconsai/medical_summarization\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that can summarize long paragraphs.\",\n            id: \"pszemraj/summarize-long-text\",\n        },\n        {\n            description: \"A much needed summarization application for terms and conditions.\",\n            id: \"ml6team/distilbart-tos-summarizer-tosdr\",\n        },\n        {\n            description: \"An application that summarizes long documents.\",\n            id: \"pszemraj/document-summarization\",\n        },\n        {\n            description: \"An application that can detect errors in abstractive summarization.\",\n            id: \"ml6team/post-processing-summarization\",\n        },\n    ],\n    summary: \"Summarization is the task of producing a shorter version of a document while preserving its important information. Some models can extract text from the original input, while other models can generate entirely new text.\",\n    widgetModels: [\"facebook/bart-large-cnn\"],\n    youtubeId: \"yHnr5Dk2zCI\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"The WikiTableQuestions dataset is a large-scale dataset for the task of question answering on semi-structured tables.\",\n            id: \"wikitablequestions\",\n        },\n        {\n            description: \"WikiSQL is a dataset of 80654 hand-annotated examples of questions and SQL queries distributed across 24241 tables from Wikipedia.\",\n            id: \"wikisql\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                table: [\n                    [\"Rank\", \"Name\", \"No.of reigns\", \"Combined days\"],\n                    [\"1\", \"lou Thesz\", \"3\", \"3749\"],\n                    [\"2\", \"Ric Flair\", \"8\", \"3103\"],\n                    [\"3\", \"Harley Race\", \"7\", \"1799\"],\n                ],\n                type: \"tabular\",\n            },\n            { label: \"Question\", content: \"What is the number of reigns for Harley Race?\", type: \"text\" },\n        ],\n        outputs: [{ label: \"Result\", content: \"7\", type: \"text\" }],\n    },\n    metrics: [\n        {\n            description: \"Checks whether the predicted answer(s) is the same as the ground-truth answer(s).\",\n            id: \"Denotation Accuracy\",\n        },\n    ],\n    models: [\n        {\n            description: \"A table question answering model that is capable of neural SQL execution, i.e., employ TAPEX to execute a SQL query on a given table.\",\n            id: \"microsoft/tapex-base\",\n        },\n        {\n            description: \"A robust table question answering model.\",\n            id: \"google/tapas-base-finetuned-wtq\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that answers questions based on table CSV files.\",\n            id: \"katanaml/table-query\",\n        },\n    ],\n    summary: \"Table Question Answering (Table QA) is the answering a question about an information on a given table.\",\n    widgetModels: [\"google/tapas-base-finetuned-wtq\"],\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"A comprehensive curation of datasets covering all benchmarks.\",\n            id: \"inria-soda/tabular-benchmark\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                table: [\n                    [\"Glucose\", \"Blood Pressure \", \"Skin Thickness\", \"Insulin\", \"BMI\"],\n                    [\"148\", \"72\", \"35\", \"0\", \"33.6\"],\n                    [\"150\", \"50\", \"30\", \"0\", \"35.1\"],\n                    [\"141\", \"60\", \"29\", \"1\", \"39.2\"],\n                ],\n                type: \"tabular\",\n            },\n        ],\n        outputs: [\n            {\n                table: [[\"Diabetes\"], [\"1\"], [\"1\"], [\"0\"]],\n                type: \"tabular\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"\",\n            id: \"accuracy\",\n        },\n        {\n            description: \"\",\n            id: \"recall\",\n        },\n        {\n            description: \"\",\n            id: \"precision\",\n        },\n        {\n            description: \"\",\n            id: \"f1\",\n        },\n    ],\n    models: [\n        {\n            description: \"Breast cancer prediction model based on decision trees.\",\n            id: \"scikit-learn/cancer-prediction-trees\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that can predict defective products on a production line.\",\n            id: \"scikit-learn/tabular-playground\",\n        },\n        {\n            description: \"An application that compares various tabular classification techniques on different datasets.\",\n            id: \"scikit-learn/classification\",\n        },\n    ],\n    summary: \"Tabular classification is the task of classifying a target category (a group) based on set of attributes.\",\n    widgetModels: [\"scikit-learn/tabular-playground\"],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"A comprehensive curation of datasets covering all benchmarks.\",\n            id: \"inria-soda/tabular-benchmark\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                table: [\n                    [\"Car Name\", \"Horsepower\", \"Weight\"],\n                    [\"ford torino\", \"140\", \"3,449\"],\n                    [\"amc hornet\", \"97\", \"2,774\"],\n                    [\"toyota corolla\", \"65\", \"1,773\"],\n                ],\n                type: \"tabular\",\n            },\n        ],\n        outputs: [\n            {\n                table: [[\"MPG (miles per gallon)\"], [\"17\"], [\"18\"], [\"31\"]],\n                type: \"tabular\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"\",\n            id: \"mse\",\n        },\n        {\n            description: \"Coefficient of determination (or R-squared) is a measure of how well the model fits the data. Higher R-squared is considered a better fit.\",\n            id: \"r-squared\",\n        },\n    ],\n    models: [\n        {\n            description: \"Fish weight prediction based on length measurements and species.\",\n            id: \"scikit-learn/Fish-Weight\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that can predict weight of a fish based on set of attributes.\",\n            id: \"scikit-learn/fish-weight-prediction\",\n        },\n    ],\n    summary: \"Tabular regression is the task of predicting a numerical value given a set of attributes.\",\n    widgetModels: [\"scikit-learn/Fish-Weight\"],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"RedCaps is a large-scale dataset of 12M image-text pairs collected from Reddit.\",\n            id: \"red_caps\",\n        },\n        {\n            description: \"Conceptual Captions is a dataset consisting of ~3.3M images annotated with captions.\",\n            id: \"conceptual_captions\",\n        },\n        {\n            description: \"12M image-caption pairs.\",\n            id: \"Spawning/PD12M\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Input\",\n                content: \"A city above clouds, pastel colors, Victorian style\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"image.jpeg\",\n                type: \"img\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"The Inception Score (IS) measure assesses diversity and meaningfulness. It uses a generated image sample to predict its label. A higher score signifies more diverse and meaningful images.\",\n            id: \"IS\",\n        },\n        {\n            description: \"The Frchet Inception Distance (FID) calculates the distance between distributions between synthetic and real samples. A lower FID score indicates better similarity between the distributions of real and generated images.\",\n            id: \"FID\",\n        },\n        {\n            description: \"R-precision assesses how the generated image aligns with the provided text description. It uses the generated images as queries to retrieve relevant text descriptions. The top 'r' relevant descriptions are selected and used to calculate R-precision as r/R, where 'R' is the number of ground truth descriptions associated with the generated images. A higher R-precision value indicates a better model.\",\n            id: \"R-Precision\",\n        },\n    ],\n    models: [\n        {\n            description: \"One of the most powerful image generation models that can generate realistic outputs.\",\n            id: \"black-forest-labs/FLUX.1-Krea-dev\",\n        },\n        {\n            description: \"A powerful image generation model.\",\n            id: \"Qwen/Qwen-Image\",\n        },\n        {\n            description: \"Powerful and fast image generation model.\",\n            id: \"ByteDance/SDXL-Lightning\",\n        },\n        {\n            description: \"A powerful text-to-image model.\",\n            id: \"ByteDance/Hyper-SD\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"A powerful text-to-image application.\",\n            id: \"stabilityai/stable-diffusion-3-medium\",\n        },\n        {\n            description: \"A text-to-image application to generate comics.\",\n            id: \"jbilcke-hf/ai-comic-factory\",\n        },\n        {\n            description: \"An application to match multiple custom image generation models.\",\n            id: \"multimodalart/flux-lora-lab\",\n        },\n        {\n            description: \"A powerful yet very fast image generation application.\",\n            id: \"latent-consistency/lcm-lora-for-sdxl\",\n        },\n        {\n            description: \"A gallery to explore various text-to-image models.\",\n            id: \"multimodalart/LoraTheExplorer\",\n        },\n        {\n            description: \"An application for `text-to-image`, `image-to-image` and image inpainting.\",\n            id: \"ArtGAN/Stable-Diffusion-ControlNet-WebUI\",\n        },\n        {\n            description: \"An application to generate realistic images given photos of a person and a prompt.\",\n            id: \"InstantX/InstantID\",\n        },\n    ],\n    summary: \"Text-to-image is the task of generating images from input text. These pipelines can also be used to modify and edit images based on text prompts.\",\n    widgetModels: [\"black-forest-labs/FLUX.1-dev\"],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    canonicalId: \"text-to-audio\",\n    datasets: [\n        {\n            description: \"10K hours of multi-speaker English dataset.\",\n            id: \"parler-tts/mls_eng_10k\",\n        },\n        {\n            description: \"Multi-speaker English dataset.\",\n            id: \"mythicinfinity/libritts_r\",\n        },\n        {\n            description: \"Multi-lingual dataset.\",\n            id: \"facebook/multilingual_librispeech\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Input\",\n                content: \"I love audio models on the Hub!\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"audio.wav\",\n                type: \"audio\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"The Mel Cepstral Distortion (MCD) metric is used to calculate the quality of generated speech.\",\n            id: \"mel cepstral distortion\",\n        },\n    ],\n    models: [\n        {\n            description: \"Small yet powerful TTS model.\",\n            id: \"KittenML/kitten-tts-nano-0.1\",\n        },\n        {\n            description: \"Bleeding edge TTS model.\",\n            id: \"ResembleAI/chatterbox\",\n        },\n        {\n            description: \"A massively multi-lingual TTS model.\",\n            id: \"fishaudio/fish-speech-1.5\",\n        },\n        {\n            description: \"A text-to-dialogue model.\",\n            id: \"nari-labs/Dia-1.6B-0626\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application for generate high quality speech in different languages.\",\n            id: \"hexgrad/Kokoro-TTS\",\n        },\n        {\n            description: \"A multilingual text-to-speech application.\",\n            id: \"fishaudio/fish-speech-1\",\n        },\n        {\n            description: \"Performant TTS application.\",\n            id: \"ResembleAI/Chatterbox\",\n        },\n        {\n            description: \"An application to compare different TTS models.\",\n            id: \"TTS-AGI/TTS-Arena-V2\",\n        },\n        {\n            description: \"An application that generates podcast episodes.\",\n            id: \"ngxson/kokoro-podcast-generator\",\n        },\n    ],\n    summary: \"Text-to-Speech (TTS) is the task of generating natural sounding speech given text input. TTS models can be extended to have a single model that generates speech for multiple speakers and multiple languages.\",\n    widgetModels: [\"suno/bark\"],\n    youtubeId: \"NW62DpzJ274\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"A widely used dataset useful to benchmark named entity recognition models.\",\n            id: \"eriktks/conll2003\",\n        },\n        {\n            description: \"A multilingual dataset of Wikipedia articles annotated for named entity recognition in over 150 different languages.\",\n            id: \"unimelb-nlp/wikiann\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Input\",\n                content: \"My name is Omar and I live in Zrich.\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                text: \"My name is Omar and I live in Zrich.\",\n                tokens: [\n                    {\n                        type: \"PERSON\",\n                        start: 11,\n                        end: 15,\n                    },\n                    {\n                        type: \"GPE\",\n                        start: 30,\n                        end: 36,\n                    },\n                ],\n                type: \"text-with-tokens\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"\",\n            id: \"accuracy\",\n        },\n        {\n            description: \"\",\n            id: \"recall\",\n        },\n        {\n            description: \"\",\n            id: \"precision\",\n        },\n        {\n            description: \"\",\n            id: \"f1\",\n        },\n    ],\n    models: [\n        {\n            description: \"A robust performance model to identify people, locations, organizations and names of miscellaneous entities.\",\n            id: \"dslim/bert-base-NER\",\n        },\n        {\n            description: \"A strong model to identify people, locations, organizations and names in multiple languages.\",\n            id: \"FacebookAI/xlm-roberta-large-finetuned-conll03-english\",\n        },\n        {\n            description: \"A token classification model specialized on medical entity recognition.\",\n            id: \"blaze999/Medical-NER\",\n        },\n        {\n            description: \"Flair models are typically the state of the art in named entity recognition tasks.\",\n            id: \"flair/ner-english\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that can recognizes entities, extracts noun chunks and recognizes various linguistic features of each token.\",\n            id: \"spacy/gradio_pipeline_visualizer\",\n        },\n    ],\n    summary: \"Token classification is a natural language understanding task in which a label is assigned to some tokens in a text. Some popular token classification subtasks are Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging. NER models could be trained to identify specific entities in a text, such as dates, individuals and places; and PoS tagging would identify, for example, which words in a text are verbs, nouns, and punctuation marks.\",\n    widgetModels: [\"FacebookAI/xlm-roberta-large-finetuned-conll03-english\"],\n    youtubeId: \"wVHdVlPScxA\",\n};\nexport default taskData;\n","const taskData = {\n    canonicalId: \"text-generation\",\n    datasets: [\n        {\n            description: \"A dataset of copyright-free books translated into 16 different languages.\",\n            id: \"Helsinki-NLP/opus_books\",\n        },\n        {\n            description: \"An example of translation between programming languages. This dataset consists of functions in Java and C#.\",\n            id: \"google/code_x_glue_cc_code_to_code_trans\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Input\",\n                content: \"My name is Omar and I live in Zrich.\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                label: \"Output\",\n                content: \"Mein Name ist Omar und ich wohne in Zrich.\",\n                type: \"text\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"BLEU score is calculated by counting the number of shared single or subsequent tokens between the generated sequence and the reference. Subsequent n tokens are called n-grams. Unigram refers to a single token while bi-gram refers to token pairs and n-grams refer to n subsequent tokens. The score ranges from 0 to 1, where 1 means the translation perfectly matched and 0 did not match at all\",\n            id: \"bleu\",\n        },\n        {\n            description: \"\",\n            id: \"sacrebleu\",\n        },\n    ],\n    models: [\n        {\n            description: \"Very powerful model that can translate many languages between each other, especially low-resource languages.\",\n            id: \"facebook/nllb-200-1.3B\",\n        },\n        {\n            description: \"A general-purpose Transformer that can be used to translate from English to German, French, or Romanian.\",\n            id: \"google-t5/t5-base\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that can translate between 100 languages.\",\n            id: \"Iker/Translate-100-languages\",\n        },\n        {\n            description: \"An application that can translate between many languages.\",\n            id: \"Geonmo/nllb-translation-demo\",\n        },\n    ],\n    summary: \"Translation is the task of converting text from one language to another.\",\n    widgetModels: [\"facebook/mbart-large-50-many-to-many-mmt\"],\n    youtubeId: \"1JvfrvZgi6c\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"A widely used dataset used to benchmark multiple variants of text classification.\",\n            id: \"nyu-mll/glue\",\n        },\n        {\n            description: \"A text classification dataset used to benchmark natural language inference models\",\n            id: \"stanfordnlp/snli\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Input\",\n                content: \"I love Hugging Face!\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                type: \"chart\",\n                data: [\n                    {\n                        label: \"POSITIVE\",\n                        score: 0.9,\n                    },\n                    {\n                        label: \"NEUTRAL\",\n                        score: 0.1,\n                    },\n                    {\n                        label: \"NEGATIVE\",\n                        score: 0.0,\n                    },\n                ],\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"\",\n            id: \"accuracy\",\n        },\n        {\n            description: \"\",\n            id: \"recall\",\n        },\n        {\n            description: \"\",\n            id: \"precision\",\n        },\n        {\n            description: \"The F1 metric is the harmonic mean of the precision and recall. It can be calculated as: F1 = 2 * (precision * recall) / (precision + recall)\",\n            id: \"f1\",\n        },\n    ],\n    models: [\n        {\n            description: \"A robust model trained for sentiment analysis.\",\n            id: \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n        },\n        {\n            description: \"A sentiment analysis model specialized in financial sentiment.\",\n            id: \"ProsusAI/finbert\",\n        },\n        {\n            description: \"A sentiment analysis model specialized in analyzing tweets.\",\n            id: \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n        },\n        {\n            description: \"A model that can classify languages.\",\n            id: \"papluca/xlm-roberta-base-language-detection\",\n        },\n        {\n            description: \"A model that can classify text generation attacks.\",\n            id: \"meta-llama/Prompt-Guard-86M\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that can classify financial sentiment.\",\n            id: \"IoannisTr/Tech_Stocks_Trading_Assistant\",\n        },\n        {\n            description: \"A dashboard that contains various text classification tasks.\",\n            id: \"miesnerjacob/Multi-task-NLP\",\n        },\n        {\n            description: \"An application that analyzes user reviews in healthcare.\",\n            id: \"spacy/healthsea-demo\",\n        },\n    ],\n    summary: \"Text Classification is the task of assigning a label or class to a given text. Some use cases are sentiment analysis, natural language inference, and assessing grammatical correctness.\",\n    widgetModels: [\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"],\n    youtubeId: \"leNG9fN9FQU\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"Multilingual dataset used to evaluate text generation models.\",\n            id: \"CohereForAI/Global-MMLU\",\n        },\n        {\n            description: \"High quality multilingual data used to train text-generation models.\",\n            id: \"HuggingFaceFW/fineweb-2\",\n        },\n        {\n            description: \"Truly open-source, curated and cleaned dialogue dataset.\",\n            id: \"HuggingFaceH4/ultrachat_200k\",\n        },\n        {\n            description: \"A reasoning dataset.\",\n            id: \"open-r1/OpenThoughts-114k-math\",\n        },\n        {\n            description: \"A multilingual instruction dataset with preference ratings on responses.\",\n            id: \"allenai/tulu-3-sft-mixture\",\n        },\n        {\n            description: \"A large synthetic dataset for alignment of text generation models.\",\n            id: \"HuggingFaceTB/smoltalk\",\n        },\n        {\n            description: \"A dataset made for training text generation models solving math questions.\",\n            id: \"HuggingFaceTB/finemath\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Input\",\n                content: \"Once upon a time,\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                label: \"Output\",\n                content: \"Once upon a time, we knew that our ancestors were on the verge of extinction. The great explorers and poets of the Old World, from Alexander the Great to Chaucer, are dead and gone. A good many of our ancient explorers and poets have\",\n                type: \"text\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"Cross Entropy is a metric that calculates the difference between two probability distributions. Each probability distribution is the distribution of predicted words\",\n            id: \"Cross Entropy\",\n        },\n        {\n            description: \"The Perplexity metric is the exponential of the cross-entropy loss. It evaluates the probabilities assigned to the next word by the model. Lower perplexity indicates better performance\",\n            id: \"Perplexity\",\n        },\n    ],\n    models: [\n        { description: \"A text-generation model trained to follow instructions.\", id: \"google/gemma-2-2b-it\" },\n        {\n            description: \"Powerful text generation model for coding.\",\n            id: \"Qwen/Qwen3-Coder-480B-A35B-Instruct\",\n        },\n        {\n            description: \"Great text generation model with top-notch tool calling capabilities.\",\n            id: \"openai/gpt-oss-120b\",\n        },\n        {\n            description: \"Powerful text generation model.\",\n            id: \"zai-org/GLM-4.5\",\n        },\n        {\n            description: \"A powerful small model with reasoning capabilities.\",\n            id: \"Qwen/Qwen3-4B-Thinking-2507\",\n        },\n        {\n            description: \"Strong conversational model that supports very long instructions.\",\n            id: \"Qwen/Qwen2.5-7B-Instruct-1M\",\n        },\n        {\n            description: \"Text generation model used to write code.\",\n            id: \"Qwen/Qwen2.5-Coder-32B-Instruct\",\n        },\n        {\n            description: \"Powerful reasoning based open large language model.\",\n            id: \"deepseek-ai/DeepSeek-R1\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that writes and executes code from text instructions and supports many models.\",\n            id: \"akhaliq/anycoder\",\n        },\n        {\n            description: \"An application that builds websites from natural language prompts.\",\n            id: \"enzostvs/deepsite\",\n        },\n        {\n            description: \"A leaderboard for comparing chain-of-thought performance of models.\",\n            id: \"logikon/open_cot_leaderboard\",\n        },\n        {\n            description: \"An text generation based application based on a very powerful LLaMA2 model.\",\n            id: \"ysharma/Explore_llamav2_with_TGI\",\n        },\n        {\n            description: \"An text generation based application to converse with Zephyr model.\",\n            id: \"HuggingFaceH4/zephyr-chat\",\n        },\n        {\n            description: \"A leaderboard that ranks text generation models based on blind votes from people.\",\n            id: \"lmsys/chatbot-arena-leaderboard\",\n        },\n        {\n            description: \"An chatbot to converse with a very powerful text generation model.\",\n            id: \"mlabonne/phixtral-chat\",\n        },\n    ],\n    summary: \"Generating text is the task of generating new text given another text. These models can, for example, fill in incomplete text or paraphrase.\",\n    widgetModels: [\"mistralai/Mistral-Nemo-Instruct-2407\"],\n    youtubeId: \"e9gNEAlsOvU\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"Bing queries with relevant passages from various web sources.\",\n            id: \"microsoft/ms_marco\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Source sentence\",\n                content: \"Machine learning is so easy.\",\n                type: \"text\",\n            },\n            {\n                label: \"Sentences to compare to\",\n                content: \"Deep learning is so straightforward.\",\n                type: \"text\",\n            },\n            {\n                label: \"\",\n                content: \"This is so difficult, like rocket science.\",\n                type: \"text\",\n            },\n            {\n                label: \"\",\n                content: \"I can't believe how much I struggled with this.\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                type: \"chart\",\n                data: [\n                    {\n                        label: \"Deep learning is so straightforward.\",\n                        score: 2.2006407,\n                    },\n                    {\n                        label: \"This is so difficult, like rocket science.\",\n                        score: -6.2634873,\n                    },\n                    {\n                        label: \"I can't believe how much I struggled with this.\",\n                        score: -10.251488,\n                    },\n                ],\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"Discounted Cumulative Gain (DCG) measures the gain, or usefulness, of search results discounted by their position. The normalization is done by dividing the DCG by the ideal DCG, which is the DCG of the perfect ranking.\",\n            id: \"Normalized Discounted Cumulative Gain\",\n        },\n        {\n            description: \"Reciprocal Rank is a measure used to rank the relevancy of documents given a set of documents. Reciprocal Rank is the reciprocal of the rank of the document retrieved, meaning, if the rank is 3, the Reciprocal Rank is 0.33. If the rank is 1, the Reciprocal Rank is 1\",\n            id: \"Mean Reciprocal Rank\",\n        },\n        {\n            description: \"Mean Average Precision (mAP) is the overall average of the Average Precision (AP) values, where AP is the Area Under the PR Curve (AUC-PR)\",\n            id: \"Mean Average Precision\",\n        },\n    ],\n    models: [\n        {\n            description: \"An extremely efficient text ranking model trained on a web search dataset.\",\n            id: \"cross-encoder/ms-marco-MiniLM-L6-v2\",\n        },\n        {\n            description: \"A strong multilingual text reranker model.\",\n            id: \"Alibaba-NLP/gte-multilingual-reranker-base\",\n        },\n        {\n            description: \"An efficient text ranking model that punches above its weight.\",\n            id: \"Alibaba-NLP/gte-reranker-modernbert-base\",\n        },\n    ],\n    spaces: [],\n    summary: \"Text Ranking is the task of ranking a set of texts based on their relevance to a query. Text ranking models are trained on large datasets of queries and relevant documents to learn how to rank documents based on their relevance to the query. This task is particularly useful for search engines and information retrieval systems.\",\n    widgetModels: [\"cross-encoder/ms-marco-MiniLM-L6-v2\"],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"Microsoft Research Video to Text is a large-scale dataset for open domain video captioning\",\n            id: \"iejMac/CLIP-MSR-VTT\",\n        },\n        {\n            description: \"UCF101 Human Actions dataset consists of 13,320 video clips from YouTube, with 101 classes.\",\n            id: \"quchenyuan/UCF101-ZIP\",\n        },\n        {\n            description: \"A high-quality dataset for human action recognition in YouTube videos.\",\n            id: \"nateraw/kinetics\",\n        },\n        {\n            description: \"A dataset of video clips of humans performing pre-defined basic actions with everyday objects.\",\n            id: \"HuggingFaceM4/something_something_v2\",\n        },\n        {\n            description: \"This dataset consists of text-video pairs and contains noisy samples with irrelevant video descriptions\",\n            id: \"HuggingFaceM4/webvid\",\n        },\n        {\n            description: \"A dataset of short Flickr videos for the temporal localization of events with descriptions.\",\n            id: \"iejMac/CLIP-DiDeMo\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Input\",\n                content: \"Darth Vader is surfing on the waves.\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"text-to-video-output.gif\",\n                type: \"img\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"Inception Score uses an image classification model that predicts class labels and evaluates how distinct and diverse the images are. A higher score indicates better video generation.\",\n            id: \"is\",\n        },\n        {\n            description: \"Frechet Inception Distance uses an image classification model to obtain image embeddings. The metric compares mean and standard deviation of the embeddings of real and generated images. A smaller score indicates better video generation.\",\n            id: \"fid\",\n        },\n        {\n            description: \"Frechet Video Distance uses a model that captures coherence for changes in frames and the quality of each frame. A smaller score indicates better video generation.\",\n            id: \"fvd\",\n        },\n        {\n            description: \"CLIPSIM measures similarity between video frames and text using an image-text similarity model. A higher score indicates better video generation.\",\n            id: \"clipsim\",\n        },\n    ],\n    models: [\n        {\n            description: \"A strong model for consistent video generation.\",\n            id: \"tencent/HunyuanVideo\",\n        },\n        {\n            description: \"A text-to-video model with high fidelity motion and strong prompt adherence.\",\n            id: \"Lightricks/LTX-Video\",\n        },\n        {\n            description: \"A text-to-video model focusing on physics-aware applications like robotics.\",\n            id: \"nvidia/Cosmos-1.0-Diffusion-7B-Text2World\",\n        },\n        {\n            description: \"Very fast model for video generation.\",\n            id: \"Lightricks/LTX-Video-0.9.8-13B-distilled\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that generates video from text.\",\n            id: \"VideoCrafter/VideoCrafter\",\n        },\n        {\n            description: \"Consistent video generation application.\",\n            id: \"Wan-AI/Wan2.1\",\n        },\n        {\n            description: \"A cutting edge video generation application.\",\n            id: \"Pyramid-Flow/pyramid-flow\",\n        },\n    ],\n    summary: \"Text-to-video models can be used in any application that requires generating consistent sequence of images from text. \",\n    widgetModels: [\"Wan-AI/Wan2.2-TI2V-5B\"],\n    youtubeId: undefined,\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"The CIFAR-100 dataset consists of 60000 32x32 colour images in 100 classes, with 600 images per class.\",\n            id: \"cifar100\",\n        },\n        {\n            description: \"Multiple images of celebrities, used for facial expression translation.\",\n            id: \"CelebA\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Seed\",\n                content: \"42\",\n                type: \"text\",\n            },\n            {\n                label: \"Number of images to generate:\",\n                content: \"4\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"unconditional-image-generation-output.jpeg\",\n                type: \"img\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"The inception score (IS) evaluates the quality of generated images. It measures the diversity of the generated images (the model predictions are evenly distributed across all possible labels) and their 'distinction' or 'sharpness' (the model confidently predicts a single label for each image).\",\n            id: \"Inception score (IS)\",\n        },\n        {\n            description: \"The Frchet Inception Distance (FID) evaluates the quality of images created by a generative model by calculating the distance between feature vectors for real and generated images.\",\n            id: \"Frehet Inception Distance (FID)\",\n        },\n    ],\n    models: [\n        {\n            description: \"High-quality image generation model trained on the CIFAR-10 dataset. It synthesizes images of the ten classes presented in the dataset using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics.\",\n            id: \"google/ddpm-cifar10-32\",\n        },\n        {\n            description: \"High-quality image generation model trained on the 256x256 CelebA-HQ dataset. It synthesizes images of faces using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics.\",\n            id: \"google/ddpm-celebahq-256\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that can generate realistic faces.\",\n            id: \"CompVis/celeba-latent-diffusion\",\n        },\n    ],\n    summary: \"Unconditional image generation is the task of generating images with no condition in any context (like a prompt text or another image). Once trained, the model will create images that resemble its training data distribution.\",\n    widgetModels: [\"\"],\n    // TODO: Add related video\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            // TODO write proper description\n            description: \"Benchmark dataset used for video classification with videos that belong to 400 classes.\",\n            id: \"kinetics400\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"video-classification-input.gif\",\n                type: \"img\",\n            },\n        ],\n        outputs: [\n            {\n                type: \"chart\",\n                data: [\n                    {\n                        label: \"Playing Guitar\",\n                        score: 0.514,\n                    },\n                    {\n                        label: \"Playing Tennis\",\n                        score: 0.193,\n                    },\n                    {\n                        label: \"Cooking\",\n                        score: 0.068,\n                    },\n                ],\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"\",\n            id: \"accuracy\",\n        },\n        {\n            description: \"\",\n            id: \"recall\",\n        },\n        {\n            description: \"\",\n            id: \"precision\",\n        },\n        {\n            description: \"\",\n            id: \"f1\",\n        },\n    ],\n    models: [\n        {\n            // TO DO: write description\n            description: \"Strong Video Classification model trained on the Kinetics 400 dataset.\",\n            id: \"google/vivit-b-16x2-kinetics400\",\n        },\n        {\n            // TO DO: write description\n            description: \"Strong Video Classification model trained on the Kinetics 400 dataset.\",\n            id: \"microsoft/xclip-base-patch32\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that classifies video at different timestamps.\",\n            id: \"nateraw/lavila\",\n        },\n        {\n            description: \"An application that classifies video.\",\n            id: \"fcakyon/video-classification\",\n        },\n    ],\n    summary: \"Video classification is the task of assigning a label or class to an entire video. Videos are expected to have only one class for each video. Video classification models take a video as input and return a prediction about which class the video belongs to.\",\n    widgetModels: [],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"A large dataset used to train visual document retrieval models.\",\n            id: \"vidore/colpali_train_set\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"input.png\",\n                type: \"img\",\n            },\n            {\n                label: \"Question\",\n                content: \"Is the model in this paper the fastest for inference?\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                type: \"chart\",\n                data: [\n                    {\n                        label: \"Page 10\",\n                        score: 0.7,\n                    },\n                    {\n                        label: \"Page 11\",\n                        score: 0.06,\n                    },\n                    {\n                        label: \"Page 9\",\n                        score: 0.003,\n                    },\n                ],\n            },\n        ],\n    },\n    isPlaceholder: false,\n    metrics: [\n        {\n            description: \"NDCG@k scores ranked recommendation lists for top-k results. 0 is the worst, 1 is the best.\",\n            id: \"Normalized Discounted Cumulative Gain at K\",\n        },\n    ],\n    models: [\n        {\n            description: \"Very accurate visual document retrieval model for multilingual queries and documents.\",\n            id: \"vidore/colqwen2-v1.0\",\n        },\n        {\n            description: \"Very fast and efficient visual document retrieval model that can also take in other modalities like audio.\",\n            id: \"Tevatron/OmniEmbed-v0.1\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"A leaderboard of visual document retrieval models.\",\n            id: \"vidore/vidore-leaderboard\",\n        },\n        {\n            description: \"Visual retrieval augmented generation demo based on ColQwen2 model.\",\n            id: \"vidore/visual-rag-tool\",\n        },\n    ],\n    summary: \"Visual document retrieval is the task of searching for relevant image-based documents, such as PDFs. These models take a text query and multiple documents as input and return the top-most relevant documents and relevancy scores as output.\",\n    widgetModels: [\"\"],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"A widely used dataset containing questions (with answers) about images.\",\n            id: \"Graphcore/vqa\",\n        },\n        {\n            description: \"A dataset to benchmark visual reasoning based on text in images.\",\n            id: \"facebook/textvqa\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"elephant.jpeg\",\n                type: \"img\",\n            },\n            {\n                label: \"Question\",\n                content: \"What is in this image?\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                type: \"chart\",\n                data: [\n                    {\n                        label: \"elephant\",\n                        score: 0.97,\n                    },\n                    {\n                        label: \"elephants\",\n                        score: 0.06,\n                    },\n                    {\n                        label: \"animal\",\n                        score: 0.003,\n                    },\n                ],\n            },\n        ],\n    },\n    isPlaceholder: false,\n    metrics: [\n        {\n            description: \"\",\n            id: \"accuracy\",\n        },\n        {\n            description: \"Measures how much a predicted answer differs from the ground truth based on the difference in their semantic meaning.\",\n            id: \"wu-palmer similarity\",\n        },\n    ],\n    models: [\n        {\n            description: \"A visual question answering model trained to convert charts and plots to text.\",\n            id: \"google/deplot\",\n        },\n        {\n            description: \"A visual question answering model trained for mathematical reasoning and chart derendering from images.\",\n            id: \"google/matcha-base\",\n        },\n        {\n            description: \"A strong visual question answering that answers questions from book covers.\",\n            id: \"google/pix2struct-ocrvqa-large\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that compares visual question answering models across different tasks.\",\n            id: \"merve/pix2struct\",\n        },\n        {\n            description: \"An application that can answer questions based on images.\",\n            id: \"nielsr/vilt-vqa\",\n        },\n        {\n            description: \"An application that can caption images and answer questions about a given image. \",\n            id: \"Salesforce/BLIP\",\n        },\n        {\n            description: \"An application that can caption images and answer questions about a given image. \",\n            id: \"vumichien/Img2Prompt\",\n        },\n    ],\n    summary: \"Visual Question Answering is the task of answering open-ended questions based on an image. They output natural language responses to natural language questions.\",\n    widgetModels: [\"dandelin/vilt-b32-finetuned-vqa\"],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"A widely used dataset used to benchmark multiple variants of text classification.\",\n            id: \"nyu-mll/glue\",\n        },\n        {\n            description: \"The Multi-Genre Natural Language Inference (MultiNLI) corpus is a crowd-sourced collection of 433k sentence pairs annotated with textual entailment information.\",\n            id: \"nyu-mll/multi_nli\",\n        },\n        {\n            description: \"FEVER is a publicly available dataset for fact extraction and verification against textual sources.\",\n            id: \"fever/fever\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Text Input\",\n                content: \"Dune is the best movie ever.\",\n                type: \"text\",\n            },\n            {\n                label: \"Candidate Labels\",\n                content: \"CINEMA, ART, MUSIC\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                type: \"chart\",\n                data: [\n                    {\n                        label: \"CINEMA\",\n                        score: 0.9,\n                    },\n                    {\n                        label: \"ART\",\n                        score: 0.1,\n                    },\n                    {\n                        label: \"MUSIC\",\n                        score: 0.0,\n                    },\n                ],\n            },\n        ],\n    },\n    metrics: [],\n    models: [\n        {\n            description: \"Powerful zero-shot text classification model.\",\n            id: \"facebook/bart-large-mnli\",\n        },\n        {\n            description: \"Cutting-edge zero-shot multilingual text classification model.\",\n            id: \"MoritzLaurer/ModernBERT-large-zeroshot-v2.0\",\n        },\n        {\n            description: \"Zero-shot text classification model that can be used for topic and sentiment classification.\",\n            id: \"knowledgator/gliclass-modern-base-v2.0-init\",\n        },\n    ],\n    spaces: [],\n    summary: \"Zero-shot text classification is a task in natural language processing where a model is trained on a set of labeled examples but is then able to classify new examples from previously unseen classes.\",\n    widgetModels: [\"facebook/bart-large-mnli\"],\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            // TODO write proper description\n            description: \"\",\n            id: \"\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"image-classification-input.jpeg\",\n                type: \"img\",\n            },\n            {\n                label: \"Classes\",\n                content: \"cat, dog, bird\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                type: \"chart\",\n                data: [\n                    {\n                        label: \"Cat\",\n                        score: 0.664,\n                    },\n                    {\n                        label: \"Dog\",\n                        score: 0.329,\n                    },\n                    {\n                        label: \"Bird\",\n                        score: 0.008,\n                    },\n                ],\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"Computes the number of times the correct label appears in top K labels predicted\",\n            id: \"top-K accuracy\",\n        },\n    ],\n    models: [\n        {\n            description: \"Multilingual image classification model for 80 languages.\",\n            id: \"visheratin/mexma-siglip\",\n        },\n        {\n            description: \"Strong zero-shot image classification model.\",\n            id: \"google/siglip2-base-patch16-224\",\n        },\n        {\n            description: \"Robust zero-shot image classification model.\",\n            id: \"intfloat/mmE5-mllama-11b-instruct\",\n        },\n        {\n            description: \"Powerful zero-shot image classification model supporting 94 languages.\",\n            id: \"jinaai/jina-clip-v2\",\n        },\n        {\n            description: \"Strong image classification model for biomedical domain.\",\n            id: \"microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that leverages zero-shot image classification to find best captions to generate an image. \",\n            id: \"pharma/CLIP-Interrogator\",\n        },\n        {\n            description: \"An application to compare different zero-shot image classification models. \",\n            id: \"merve/compare_clip_siglip\",\n        },\n    ],\n    summary: \"Zero-shot image classification is the task of classifying previously unseen classes during training of a model.\",\n    widgetModels: [\"google/siglip-so400m-patch14-224\"],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [],\n    demo: {\n        inputs: [\n            {\n                filename: \"zero-shot-object-detection-input.jpg\",\n                type: \"img\",\n            },\n            {\n                label: \"Classes\",\n                content: \"cat, dog, bird\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"zero-shot-object-detection-output.jpg\",\n                type: \"img\",\n            },\n        ],\n    },\n    metrics: [\n        {\n            description: \"The Average Precision (AP) metric is the Area Under the PR Curve (AUC-PR). It is calculated for each class separately\",\n            id: \"Average Precision\",\n        },\n        {\n            description: \"The Mean Average Precision (mAP) metric is the overall average of the AP values\",\n            id: \"Mean Average Precision\",\n        },\n        {\n            description: \"The AP metric is the Average Precision at the IoU threshold of a  value, for example, AP50 and AP75\",\n            id: \"AP\",\n        },\n    ],\n    models: [\n        {\n            description: \"Solid zero-shot object detection model.\",\n            id: \"openmmlab-community/mm_grounding_dino_large_all\",\n        },\n        {\n            description: \"Cutting-edge zero-shot object detection model.\",\n            id: \"fushh7/LLMDet\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"A demo to compare different zero-shot object detection models per output and latency.\",\n            id: \"ariG23498/zero-shot-od\",\n        },\n        {\n            description: \"A demo that combines a zero-shot object detection and mask generation model for zero-shot segmentation.\",\n            id: \"merve/OWLSAM\",\n        },\n    ],\n    summary: \"Zero-shot object detection is a computer vision task to detect objects and their classes in images, without any prior training or knowledge of the classes. Zero-shot object detection models receive an image as input, as well as a list of candidate classes, and output the bounding boxes and labels where the objects have been detected.\",\n    widgetModels: [],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"A large dataset of over 10 million 3D objects.\",\n            id: \"allenai/objaverse-xl\",\n        },\n        {\n            description: \"A dataset of isolated object images for evaluating image-to-3D models.\",\n            id: \"dylanebert/iso3d\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"image-to-3d-image-input.png\",\n                type: \"img\",\n            },\n        ],\n        outputs: [\n            {\n                label: \"Result\",\n                content: \"image-to-3d-3d-output-filename.glb\",\n                type: \"text\",\n            },\n        ],\n    },\n    metrics: [],\n    models: [\n        {\n            description: \"Fast image-to-3D mesh model by Tencent.\",\n            id: \"TencentARC/InstantMesh\",\n        },\n        {\n            description: \"3D world generation model.\",\n            id: \"tencent/HunyuanWorld-1\",\n        },\n        {\n            description: \"A scaled up image-to-3D mesh model derived from TripoSR.\",\n            id: \"hwjiang/Real3D\",\n        },\n        {\n            description: \"Consistent image-to-3d generation model.\",\n            id: \"stabilityai/stable-point-aware-3d\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"Leaderboard to evaluate image-to-3D models.\",\n            id: \"dylanebert/3d-arena\",\n        },\n        {\n            description: \"Image-to-3D demo with mesh outputs.\",\n            id: \"TencentARC/InstantMesh\",\n        },\n        {\n            description: \"Image-to-3D demo.\",\n            id: \"stabilityai/stable-point-aware-3d\",\n        },\n        {\n            description: \"Image-to-3D demo with mesh outputs.\",\n            id: \"hwjiang/Real3D\",\n        },\n        {\n            description: \"Image-to-3D demo with splat outputs.\",\n            id: \"dylanebert/LGM-mini\",\n        },\n    ],\n    summary: \"Image-to-3D models take in image input and produce 3D output.\",\n    widgetModels: [],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"A large dataset of over 10 million 3D objects.\",\n            id: \"allenai/objaverse-xl\",\n        },\n        {\n            description: \"Descriptive captions for 3D objects in Objaverse.\",\n            id: \"tiange/Cap3D\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                label: \"Prompt\",\n                content: \"a cat statue\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                label: \"Result\",\n                content: \"text-to-3d-3d-output-filename.glb\",\n                type: \"text\",\n            },\n        ],\n    },\n    metrics: [],\n    models: [\n        {\n            description: \"Text-to-3D mesh model by OpenAI\",\n            id: \"openai/shap-e\",\n        },\n        {\n            description: \"Generative 3D gaussian splatting model.\",\n            id: \"ashawkey/LGM\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"Text-to-3D demo with mesh outputs.\",\n            id: \"hysts/Shap-E\",\n        },\n        {\n            description: \"Text/image-to-3D demo with splat outputs.\",\n            id: \"ashawkey/LGM\",\n        },\n    ],\n    summary: \"Text-to-3D models take in text input and produce 3D output.\",\n    widgetModels: [],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"A dataset of hand keypoints of over 500k examples.\",\n            id: \"Vincent-luo/hagrid-mediapipe-hands\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"keypoint-detection-input.png\",\n                type: \"img\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"keypoint-detection-output.png\",\n                type: \"img\",\n            },\n        ],\n    },\n    metrics: [],\n    models: [\n        {\n            description: \"A robust keypoint detection model.\",\n            id: \"magic-leap-community/superpoint\",\n        },\n        {\n            description: \"A robust keypoint matching model.\",\n            id: \"magic-leap-community/superglue_outdoor\",\n        },\n        {\n            description: \"Strong keypoint detection model used to detect human pose.\",\n            id: \"qualcomm/RTMPose-Body2d\",\n        },\n        {\n            description: \"Powerful keypoint matching model.\",\n            id: \"ETH-CVG/lightglue_disk\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application that detects hand keypoints in real-time.\",\n            id: \"datasciencedojo/Hand-Keypoint-Detection-Realtime\",\n        },\n        {\n            description: \"An application for keypoint detection and matching.\",\n            id: \"ETH-CVG/LightGlue\",\n        },\n    ],\n    summary: \"Keypoint detection is the task of identifying meaningful distinctive points or features in an image.\",\n    widgetModels: [],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"Multiple-choice questions and answers about videos.\",\n            id: \"lmms-lab/Video-MME\",\n        },\n        {\n            description: \"A dataset of instructions and question-answer pairs about videos.\",\n            id: \"lmms-lab/VideoChatGPT\",\n        },\n        {\n            description: \"Large video understanding dataset.\",\n            id: \"HuggingFaceFV/finevideo\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"video-text-to-text-input.gif\",\n                type: \"img\",\n            },\n            {\n                label: \"Text Prompt\",\n                content: \"What is happening in this video?\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                label: \"Answer\",\n                content: \"The video shows a series of images showing a fountain with water jets and a variety of colorful flowers and butterflies in the background.\",\n                type: \"text\",\n            },\n        ],\n    },\n    metrics: [],\n    models: [\n        {\n            description: \"A robust video-text-to-text model.\",\n            id: \"Vision-CAIR/LongVU_Qwen2_7B\",\n        },\n        {\n            description: \"Strong video-text-to-text model with reasoning capabilities.\",\n            id: \"GoodiesHere/Apollo-LMMs-Apollo-7B-t32\",\n        },\n        {\n            description: \"Strong video-text-to-text model.\",\n            id: \"HuggingFaceTB/SmolVLM2-2.2B-Instruct\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application to chat with a video-text-to-text model.\",\n            id: \"llava-hf/video-llava\",\n        },\n        {\n            description: \"A leaderboard for various video-text-to-text models.\",\n            id: \"opencompass/openvlm_video_leaderboard\",\n        },\n        {\n            description: \"An application to generate highlights from a video.\",\n            id: \"HuggingFaceTB/SmolVLM2-HighlightGenerator\",\n        },\n    ],\n    summary: \"Video-text-to-text models take in a video and a text prompt and output text. These models are also called video-language models.\",\n    widgetModels: [\"\"],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const taskData = {\n    datasets: [\n        {\n            description: \"Dataset with detailed annotations for training and benchmarking video instance editing.\",\n            id: \"suimu/VIRESET\",\n        },\n        {\n            description: \"Dataset to evaluate models on long video generation and understanding.\",\n            id: \"zhangsh2001/LongV-EVAL\",\n        },\n        {\n            description: \"Collection of 104 demo videos from the SeedVR/SeedVR2 series showcasing model outputs.\",\n            id: \"Iceclear/SeedVR_VideoDemos\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"input.gif\",\n                type: \"img\",\n            },\n        ],\n        outputs: [\n            {\n                filename: \"output.gif\",\n                type: \"img\",\n            },\n        ],\n    },\n    metrics: [],\n    models: [\n        {\n            description: \"Model for editing outfits, character, and scenery in videos.\",\n            id: \"decart-ai/Lucy-Edit-Dev\",\n        },\n        {\n            description: \"Framework that uses 3D mesh proxies for precise, consistent video editing.\",\n            id: \"LeoLau/Shape-for-Motion\",\n        },\n        {\n            description: \"Model for generating physics-aware videos from input videos and control conditions.\",\n            id: \"nvidia/Cosmos-Transfer2.5-2B\",\n        },\n        {\n            description: \"A model to upscale videos at input, designed for seamless use with ComfyUI.\",\n            id: \"numz/SeedVR2_comfyUI\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"Interactive demo space for Lucy-Edit-Dev video editing.\",\n            id: \"decart-ai/lucy-edit-dev\",\n        },\n        {\n            description: \"Demo space for SeedVR2-3B showcasing video upscaling and restoration.\",\n            id: \"ByteDance-Seed/SeedVR2-3B\",\n        },\n    ],\n    summary: \"Video-to-video models take one or more videos as input and generate new videos as output. They can enhance quality, interpolate frames, modify styles, or create new motion dynamics, enabling creative applications, video production, and research.\",\n    widgetModels: [],\n    youtubeId: \"\",\n};\nexport default taskData;\n","import { PIPELINE_DATA } from \"../pipelines.js\";\nimport anyToAny from \"./any-to-any/data.js\";\nimport audioClassification from \"./audio-classification/data.js\";\nimport audioTextToText from \"./audio-text-to-text/data.js\";\nimport audioToAudio from \"./audio-to-audio/data.js\";\nimport automaticSpeechRecognition from \"./automatic-speech-recognition/data.js\";\nimport documentQuestionAnswering from \"./document-question-answering/data.js\";\nimport featureExtraction from \"./feature-extraction/data.js\";\nimport fillMask from \"./fill-mask/data.js\";\nimport imageClassification from \"./image-classification/data.js\";\nimport imageFeatureExtraction from \"./image-feature-extraction/data.js\";\nimport imageToImage from \"./image-to-image/data.js\";\nimport imageToText from \"./image-to-text/data.js\";\nimport imageTextToText from \"./image-text-to-text/data.js\";\nimport imageTextToImage from \"./image-text-to-image/data.js\";\nimport imageTextToVideo from \"./image-text-to-video/data.js\";\nimport imageSegmentation from \"./image-segmentation/data.js\";\nimport imageToVideo from \"./image-to-video/data.js\";\nimport maskGeneration from \"./mask-generation/data.js\";\nimport objectDetection from \"./object-detection/data.js\";\nimport depthEstimation from \"./depth-estimation/data.js\";\nimport placeholder from \"./placeholder/data.js\";\nimport reinforcementLearning from \"./reinforcement-learning/data.js\";\nimport questionAnswering from \"./question-answering/data.js\";\nimport sentenceSimilarity from \"./sentence-similarity/data.js\";\nimport summarization from \"./summarization/data.js\";\nimport tableQuestionAnswering from \"./table-question-answering/data.js\";\nimport tabularClassification from \"./tabular-classification/data.js\";\nimport tabularRegression from \"./tabular-regression/data.js\";\nimport textToImage from \"./text-to-image/data.js\";\nimport textToSpeech from \"./text-to-speech/data.js\";\nimport tokenClassification from \"./token-classification/data.js\";\nimport translation from \"./translation/data.js\";\nimport textClassification from \"./text-classification/data.js\";\nimport textGeneration from \"./text-generation/data.js\";\nimport textRanking from \"./text-ranking/data.js\";\nimport textToVideo from \"./text-to-video/data.js\";\nimport unconditionalImageGeneration from \"./unconditional-image-generation/data.js\";\nimport videoClassification from \"./video-classification/data.js\";\nimport visualDocumentRetrieval from \"./visual-document-retrieval/data.js\";\nimport visualQuestionAnswering from \"./visual-question-answering/data.js\";\nimport zeroShotClassification from \"./zero-shot-classification/data.js\";\nimport zeroShotImageClassification from \"./zero-shot-image-classification/data.js\";\nimport zeroShotObjectDetection from \"./zero-shot-object-detection/data.js\";\nimport imageTo3D from \"./image-to-3d/data.js\";\nimport textTo3D from \"./text-to-3d/data.js\";\nimport keypointDetection from \"./keypoint-detection/data.js\";\nimport videoTextToText from \"./video-text-to-text/data.js\";\nimport videoToVideo from \"./video-to-video/data.js\";\n/**\n * Model libraries compatible with each ML task\n */\nexport const TASKS_MODEL_LIBRARIES = {\n    \"audio-classification\": [\"speechbrain\", \"transformers\", \"transformers.js\"],\n    \"audio-to-audio\": [\"asteroid\", \"fairseq\", \"speechbrain\"],\n    \"automatic-speech-recognition\": [\"espnet\", \"nemo\", \"speechbrain\", \"transformers\", \"transformers.js\"],\n    \"audio-text-to-text\": [\"transformers\"],\n    \"depth-estimation\": [\"transformers\", \"transformers.js\"],\n    \"document-question-answering\": [\"transformers\", \"transformers.js\"],\n    \"feature-extraction\": [\"sentence-transformers\", \"transformers\", \"transformers.js\"],\n    \"fill-mask\": [\"transformers\", \"transformers.js\"],\n    \"graph-ml\": [\"transformers\"],\n    \"image-classification\": [\"keras\", \"timm\", \"transformers\", \"transformers.js\"],\n    \"image-feature-extraction\": [\"timm\", \"transformers\"],\n    \"image-segmentation\": [\"transformers\", \"transformers.js\"],\n    \"image-text-to-text\": [\"transformers\"],\n    \"image-text-to-image\": [\"diffusers\"],\n    \"image-text-to-video\": [\"diffusers\"],\n    \"image-to-image\": [\"diffusers\", \"transformers\", \"transformers.js\"],\n    \"image-to-text\": [\"transformers\", \"transformers.js\"],\n    \"image-to-video\": [\"diffusers\"],\n    \"keypoint-detection\": [\"transformers\"],\n    \"video-classification\": [\"transformers\"],\n    \"mask-generation\": [\"transformers\"],\n    \"multiple-choice\": [\"transformers\"],\n    \"object-detection\": [\"transformers\", \"transformers.js\", \"ultralytics\"],\n    other: [],\n    \"question-answering\": [\"adapter-transformers\", \"allennlp\", \"transformers\", \"transformers.js\"],\n    robotics: [],\n    \"reinforcement-learning\": [\"transformers\", \"stable-baselines3\", \"ml-agents\", \"sample-factory\"],\n    \"sentence-similarity\": [\"sentence-transformers\", \"spacy\", \"transformers.js\"],\n    summarization: [\"transformers\", \"transformers.js\"],\n    \"table-question-answering\": [\"transformers\"],\n    \"table-to-text\": [\"transformers\"],\n    \"tabular-classification\": [\"sklearn\"],\n    \"tabular-regression\": [\"sklearn\"],\n    \"tabular-to-text\": [\"transformers\"],\n    \"text-classification\": [\"adapter-transformers\", \"setfit\", \"spacy\", \"transformers\", \"transformers.js\"],\n    \"text-generation\": [\"transformers\", \"transformers.js\"],\n    \"text-ranking\": [\"sentence-transformers\", \"transformers\"],\n    \"text-retrieval\": [],\n    \"text-to-image\": [\"diffusers\"],\n    \"text-to-speech\": [\"espnet\", \"tensorflowtts\", \"transformers\", \"transformers.js\"],\n    \"text-to-audio\": [\"transformers\", \"transformers.js\"],\n    \"text-to-video\": [\"diffusers\"],\n    \"time-series-forecasting\": [],\n    \"token-classification\": [\n        \"adapter-transformers\",\n        \"flair\",\n        \"spacy\",\n        \"span-marker\",\n        \"stanza\",\n        \"transformers\",\n        \"transformers.js\",\n    ],\n    translation: [\"transformers\", \"transformers.js\"],\n    \"unconditional-image-generation\": [\"diffusers\"],\n    \"video-text-to-text\": [\"transformers\"],\n    \"visual-question-answering\": [\"transformers\", \"transformers.js\"],\n    \"voice-activity-detection\": [],\n    \"zero-shot-classification\": [\"transformers\", \"transformers.js\"],\n    \"zero-shot-image-classification\": [\"transformers\", \"transformers.js\"],\n    \"zero-shot-object-detection\": [\"transformers\", \"transformers.js\"],\n    \"text-to-3d\": [\"diffusers\"],\n    \"image-to-3d\": [\"diffusers\"],\n    \"any-to-any\": [\"transformers\"],\n    \"visual-document-retrieval\": [\"transformers\"],\n    \"video-to-video\": [\"diffusers\"],\n};\n/**\n * Return the whole TaskData object for a certain task.\n * If the partialTaskData argument is left undefined,\n * the default placeholder data will be used.\n */\nfunction getData(type, partialTaskData = placeholder) {\n    return {\n        ...partialTaskData,\n        id: type,\n        label: PIPELINE_DATA[type].name,\n        libraries: TASKS_MODEL_LIBRARIES[type],\n    };\n}\n// To make comparisons easier, task order is the same as in const.ts\n// Tasks set to undefined won't have an associated task page.\n// Tasks that call getData() without the second argument will\n// have a \"placeholder\" page.\nexport const TASKS_DATA = {\n    \"any-to-any\": getData(\"any-to-any\", anyToAny),\n    \"audio-classification\": getData(\"audio-classification\", audioClassification),\n    \"audio-to-audio\": getData(\"audio-to-audio\", audioToAudio),\n    \"audio-text-to-text\": getData(\"audio-text-to-text\", audioTextToText),\n    \"automatic-speech-recognition\": getData(\"automatic-speech-recognition\", automaticSpeechRecognition),\n    \"depth-estimation\": getData(\"depth-estimation\", depthEstimation),\n    \"document-question-answering\": getData(\"document-question-answering\", documentQuestionAnswering),\n    \"visual-document-retrieval\": getData(\"visual-document-retrieval\", visualDocumentRetrieval),\n    \"feature-extraction\": getData(\"feature-extraction\", featureExtraction),\n    \"fill-mask\": getData(\"fill-mask\", fillMask),\n    \"graph-ml\": undefined,\n    \"image-classification\": getData(\"image-classification\", imageClassification),\n    \"image-feature-extraction\": getData(\"image-feature-extraction\", imageFeatureExtraction),\n    \"image-segmentation\": getData(\"image-segmentation\", imageSegmentation),\n    \"image-to-image\": getData(\"image-to-image\", imageToImage),\n    \"image-text-to-text\": getData(\"image-text-to-text\", imageTextToText),\n    \"image-text-to-image\": getData(\"image-text-to-image\", imageTextToImage),\n    \"image-text-to-video\": getData(\"image-text-to-video\", imageTextToVideo),\n    \"image-to-text\": getData(\"image-to-text\", imageToText),\n    \"image-to-video\": getData(\"image-to-video\", imageToVideo),\n    \"keypoint-detection\": getData(\"keypoint-detection\", keypointDetection),\n    \"mask-generation\": getData(\"mask-generation\", maskGeneration),\n    \"multiple-choice\": undefined,\n    \"object-detection\": getData(\"object-detection\", objectDetection),\n    \"video-classification\": getData(\"video-classification\", videoClassification),\n    other: undefined,\n    \"question-answering\": getData(\"question-answering\", questionAnswering),\n    \"reinforcement-learning\": getData(\"reinforcement-learning\", reinforcementLearning),\n    robotics: undefined,\n    \"sentence-similarity\": getData(\"sentence-similarity\", sentenceSimilarity),\n    summarization: getData(\"summarization\", summarization),\n    \"table-question-answering\": getData(\"table-question-answering\", tableQuestionAnswering),\n    \"table-to-text\": undefined,\n    \"tabular-classification\": getData(\"tabular-classification\", tabularClassification),\n    \"tabular-regression\": getData(\"tabular-regression\", tabularRegression),\n    \"tabular-to-text\": undefined,\n    \"text-classification\": getData(\"text-classification\", textClassification),\n    \"text-generation\": getData(\"text-generation\", textGeneration),\n    \"text-ranking\": getData(\"text-ranking\", textRanking),\n    \"text-retrieval\": undefined,\n    \"text-to-image\": getData(\"text-to-image\", textToImage),\n    \"text-to-speech\": getData(\"text-to-speech\", textToSpeech),\n    \"text-to-audio\": undefined,\n    \"text-to-video\": getData(\"text-to-video\", textToVideo),\n    \"time-series-forecasting\": undefined,\n    \"token-classification\": getData(\"token-classification\", tokenClassification),\n    translation: getData(\"translation\", translation),\n    \"unconditional-image-generation\": getData(\"unconditional-image-generation\", unconditionalImageGeneration),\n    \"video-text-to-text\": getData(\"video-text-to-text\", videoTextToText),\n    \"video-to-video\": getData(\"video-to-video\", videoToVideo),\n    \"visual-question-answering\": getData(\"visual-question-answering\", visualQuestionAnswering),\n    \"voice-activity-detection\": undefined,\n    \"zero-shot-classification\": getData(\"zero-shot-classification\", zeroShotClassification),\n    \"zero-shot-image-classification\": getData(\"zero-shot-image-classification\", zeroShotImageClassification),\n    \"zero-shot-object-detection\": getData(\"zero-shot-object-detection\", zeroShotObjectDetection),\n    \"text-to-3d\": getData(\"text-to-3d\", textTo3D),\n    \"image-to-3d\": getData(\"image-to-3d\", imageTo3D),\n};\n","const taskData = {\n    datasets: [\n        {\n            description: \"A dataset with multiple modality input and output pairs.\",\n            id: \"PKU-Alignment/align-anything\",\n        },\n    ],\n    demo: {\n        inputs: [\n            {\n                filename: \"any-to-any-input.jpg\",\n                type: \"img\",\n            },\n            {\n                label: \"Text Prompt\",\n                content: \"What is the significance of this place?\",\n                type: \"text\",\n            },\n        ],\n        outputs: [\n            {\n                label: \"Generated Text\",\n                content: \"The place in the picture is Osaka Castle, located in Osaka, Japan. Osaka Castle is a historic castle that was originally built in the 16th century by Toyotomi Hideyoshi, a powerful warlord of the time. It is one of the most famous landmarks in Osaka and is known for its distinctive white walls and black roof tiles. The castle has been rebuilt several times over the centuries and is now a popular tourist attraction, offering visitors a glimpse into Japan's rich history and culture.\",\n                type: \"text\",\n            },\n            {\n                filename: \"any-to-any-output.wav\",\n                type: \"audio\",\n            },\n        ],\n    },\n    metrics: [],\n    models: [\n        {\n            description: \"Strong model that can take in video, audio, image, text and output text and natural speech.\",\n            id: \"Qwen/Qwen2.5-Omni-7B\",\n        },\n        {\n            description: \"Robust model that can take in image and text and generate image and text.\",\n            id: \"OmniGen2/OmniGen2\",\n        },\n        {\n            description: \"Any-to-any model with speech, video, audio, image and text understanding capabilities.\",\n            id: \"openbmb/MiniCPM-o-2_6\",\n        },\n        {\n            description: \"A model that can understand image and text and generate image and text.\",\n            id: \"ByteDance-Seed/BAGEL-7B-MoT\",\n        },\n    ],\n    spaces: [\n        {\n            description: \"An application to chat with an any-to-any (image & text) model.\",\n            id: \"OmniGen2/OmniGen2\",\n        },\n    ],\n    summary: \"Any-to-any models can understand two or more modalities and output two or more modalities.\",\n    widgetModels: [],\n    youtubeId: \"\",\n};\nexport default taskData;\n","const inputsZeroShotClassification = () => `\"Hi, I recently bought a device from your company but it is not working as advertised and I would like to get reimbursed!\"`;\nconst inputsTranslation = () => `\"       \"`;\nconst inputsSummarization = () => `\"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\"`;\nconst inputsTableQuestionAnswering = () => `{\n    \"query\": \"How many stars does the transformers repository have?\",\n    \"table\": {\n        \"Repository\": [\"Transformers\", \"Datasets\", \"Tokenizers\"],\n        \"Stars\": [\"36542\", \"4512\", \"3934\"],\n        \"Contributors\": [\"651\", \"77\", \"34\"],\n        \"Programming language\": [\n            \"Python\",\n            \"Python\",\n            \"Rust, Python and NodeJS\"\n        ]\n    }\n}`;\nconst inputsVisualQuestionAnswering = () => `{\n        \"image\": \"cat.png\",\n        \"question\": \"What is in this image?\"\n    }`;\nconst inputsQuestionAnswering = () => `{\n    \"question\": \"What is my name?\",\n    \"context\": \"My name is Clara and I live in Berkeley.\"\n}`;\nconst inputsTextClassification = () => `\"I like you. I love you\"`;\nconst inputsTokenClassification = () => `\"My name is Sarah Jessica Parker but you can call me Jessica\"`;\nconst inputsTextGeneration = (model) => {\n    if (model.tags.includes(\"conversational\")) {\n        return model.pipeline_tag === \"text-generation\"\n            ? [{ role: \"user\", content: \"What is the capital of France?\" }]\n            : [\n                {\n                    role: \"user\",\n                    content: [\n                        {\n                            type: \"text\",\n                            text: \"Describe this image in one sentence.\",\n                        },\n                        {\n                            type: \"image_url\",\n                            image_url: {\n                                url: \"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\",\n                            },\n                        },\n                    ],\n                },\n            ];\n    }\n    return `\"Can you please let us know more details about your \"`;\n};\nconst inputsFillMask = (model) => `\"The answer to the universe is ${model.mask_token}.\"`;\nconst inputsSentenceSimilarity = () => `{\n    \"source_sentence\": \"That is a happy person\",\n    \"sentences\": [\n        \"That is a happy dog\",\n        \"That is a very happy person\",\n        \"Today is a sunny day\"\n    ]\n}`;\nconst inputsFeatureExtraction = () => `\"Today is a sunny day and I will get some ice cream.\"`;\nconst inputsImageClassification = () => `\"cats.jpg\"`;\nconst inputsImageToText = () => `\"cats.jpg\"`;\nconst inputsImageToImage = () => `{\n    \"image\": \"cat.png\",\n    \"prompt\": \"Turn the cat into a tiger.\"\n}`;\nconst inputsImageToVideo = () => `{\n    \"image\": \"cat.png\",\n    \"prompt\": \"The cat starts to dance\"\n}`;\nconst inputsImageTextToImage = () => `{\n    \"image\": \"cat.png\",\n    \"prompt\": \"Turn the cat into a tiger.\"\n}`;\nconst inputsImageTextToVideo = () => `{\n    \"image\": \"cat.png\",\n    \"prompt\": \"The cat starts to dance\"\n}`;\nconst inputsImageSegmentation = () => `\"cats.jpg\"`;\nconst inputsObjectDetection = () => `\"cats.jpg\"`;\nconst inputsAudioToAudio = () => `\"sample1.flac\"`;\nconst inputsAudioClassification = () => `\"sample1.flac\"`;\nconst inputsTextToImage = () => `\"Astronaut riding a horse\"`;\nconst inputsTextToVideo = () => `\"A young man walking on the street\"`;\nconst inputsTextToSpeech = () => `\"The answer to the universe is 42\"`;\nconst inputsTextToAudio = () => `\"liquid drum and bass, atmospheric synths, airy sounds\"`;\nconst inputsAutomaticSpeechRecognition = () => `\"sample1.flac\"`;\nconst inputsTabularPrediction = () => `'{\"Height\":[11.52,12.48],\"Length1\":[23.2,24.0],\"Length2\":[25.4,26.3],\"Species\": [\"Bream\",\"Bream\"]}'`;\nconst inputsZeroShotImageClassification = () => `\"cats.jpg\"`;\nconst modelInputSnippets = {\n    \"audio-to-audio\": inputsAudioToAudio,\n    \"audio-classification\": inputsAudioClassification,\n    \"automatic-speech-recognition\": inputsAutomaticSpeechRecognition,\n    \"document-question-answering\": inputsVisualQuestionAnswering,\n    \"feature-extraction\": inputsFeatureExtraction,\n    \"fill-mask\": inputsFillMask,\n    \"image-classification\": inputsImageClassification,\n    \"image-to-text\": inputsImageToText,\n    \"image-to-image\": inputsImageToImage,\n    \"image-to-video\": inputsImageToVideo,\n    \"image-text-to-image\": inputsImageTextToImage,\n    \"image-text-to-video\": inputsImageTextToVideo,\n    \"image-segmentation\": inputsImageSegmentation,\n    \"object-detection\": inputsObjectDetection,\n    \"question-answering\": inputsQuestionAnswering,\n    \"sentence-similarity\": inputsSentenceSimilarity,\n    summarization: inputsSummarization,\n    \"table-question-answering\": inputsTableQuestionAnswering,\n    \"tabular-regression\": inputsTabularPrediction,\n    \"tabular-classification\": inputsTabularPrediction,\n    \"text-classification\": inputsTextClassification,\n    \"text-generation\": inputsTextGeneration,\n    \"image-text-to-text\": inputsTextGeneration,\n    \"text-to-image\": inputsTextToImage,\n    \"text-to-video\": inputsTextToVideo,\n    \"text-to-speech\": inputsTextToSpeech,\n    \"text-to-audio\": inputsTextToAudio,\n    \"token-classification\": inputsTokenClassification,\n    translation: inputsTranslation,\n    \"zero-shot-classification\": inputsZeroShotClassification,\n    \"zero-shot-image-classification\": inputsZeroShotImageClassification,\n};\n// Use noWrap to put the whole snippet on a single line (removing new lines and tabulations)\n// Use noQuotes to strip quotes from start & end (example: \"abc\" -> abc)\nexport function getModelInputSnippet(model, noWrap = false, noQuotes = false) {\n    if (model.pipeline_tag) {\n        const inputs = modelInputSnippets[model.pipeline_tag];\n        if (inputs) {\n            let result = inputs(model);\n            if (typeof result === \"string\") {\n                if (noWrap) {\n                    result = result.replace(/(?:(?:\\r?\\n|\\r)\\t*)|\\t+/g, \" \");\n                }\n                if (noQuotes) {\n                    const REGEX_QUOTES = /^\"(.+)\"$/s;\n                    const match = result.match(REGEX_QUOTES);\n                    result = match ? match[1] : result;\n                }\n            }\n            return result;\n        }\n    }\n    return \"No input example has been defined for this model task.\";\n}\n","export function stringifyMessages(messages, opts) {\n    let messagesStr = JSON.stringify(messages, null, \"\\t\");\n    if (opts?.indent) {\n        messagesStr = messagesStr.replaceAll(\"\\n\", `\\n${opts.indent}`);\n    }\n    if (!opts?.attributeKeyQuotes) {\n        messagesStr = messagesStr.replace(/\"([^\"]+)\":/g, \"$1:\");\n    }\n    if (opts?.customContentEscaper) {\n        messagesStr = opts.customContentEscaper(messagesStr);\n    }\n    return messagesStr;\n}\nexport function stringifyGenerationConfig(config, opts) {\n    const quote = opts.attributeKeyQuotes ? `\"` : \"\";\n    return Object.entries(config)\n        .map(([key, val]) => `${quote}${key}${quote}${opts.attributeValueConnector}${val},`)\n        .join(`${opts.indent}`);\n}\n","import { LIBRARY_TASK_MAPPING } from \"./library-to-tasks.js\";\nimport { getModelInputSnippet } from \"./snippets/inputs.js\";\nimport { stringifyMessages } from \"./snippets/common.js\";\nconst TAG_CUSTOM_CODE = \"custom_code\";\nfunction nameWithoutNamespace(modelId) {\n    const splitted = modelId.split(\"/\");\n    return splitted.length === 1 ? splitted[0] : splitted[1];\n}\nconst escapeStringForJson = (str) => JSON.stringify(str).slice(1, -1); // slice is needed to remove surrounding quotes added by JSON.stringify\n//#region snippets\nexport const adapters = (model) => [\n    `from adapters import AutoAdapterModel\n\nmodel = AutoAdapterModel.from_pretrained(\"${model.config?.adapter_transformers?.model_name}\")\nmodel.load_adapter(\"${model.id}\", set_active=True)`,\n];\nconst allennlpUnknown = (model) => [\n    `import allennlp_models\nfrom allennlp.predictors.predictor import Predictor\n\npredictor = Predictor.from_path(\"hf://${model.id}\")`,\n];\nconst allennlpQuestionAnswering = (model) => [\n    `import allennlp_models\nfrom allennlp.predictors.predictor import Predictor\n\npredictor = Predictor.from_path(\"hf://${model.id}\")\npredictor_input = {\"passage\": \"My name is Wolfgang and I live in Berlin\", \"question\": \"Where do I live?\"}\npredictions = predictor.predict_json(predictor_input)`,\n];\nexport const allennlp = (model) => {\n    if (model.tags.includes(\"question-answering\")) {\n        return allennlpQuestionAnswering(model);\n    }\n    return allennlpUnknown(model);\n};\nexport const araclip = (model) => [\n    `from araclip import AraClip\n\nmodel = AraClip.from_pretrained(\"${model.id}\")`,\n];\nexport const asteroid = (model) => [\n    `from asteroid.models import BaseModel\n\nmodel = BaseModel.from_pretrained(\"${model.id}\")`,\n];\nexport const audioseal = (model) => {\n    const watermarkSnippet = `# Watermark Generator\nfrom audioseal import AudioSeal\n\nmodel = AudioSeal.load_generator(\"${model.id}\")\n# pass a tensor (tensor_wav) of shape (batch, channels, samples) and a sample rate\nwav, sr = tensor_wav, 16000\n\t\nwatermark = model.get_watermark(wav, sr)\nwatermarked_audio = wav + watermark`;\n    const detectorSnippet = `# Watermark Detector\nfrom audioseal import AudioSeal\n\ndetector = AudioSeal.load_detector(\"${model.id}\")\n\t\nresult, message = detector.detect_watermark(watermarked_audio, sr)`;\n    return [watermarkSnippet, detectorSnippet];\n};\nfunction get_base_diffusers_model(model) {\n    return model.cardData?.base_model?.toString() ?? \"fill-in-base-model\";\n}\nfunction get_prompt_from_diffusers_model(model) {\n    const prompt = model.widgetData?.[0]?.text ?? model.cardData?.instance_prompt;\n    if (prompt) {\n        return escapeStringForJson(prompt);\n    }\n}\nexport const ben2 = (model) => [\n    `import requests\nfrom PIL import Image\nfrom ben2 import AutoModel\n\nurl = \"https://huggingface.co/datasets/mishig/sample_images/resolve/main/teapot.jpg\"\nimage = Image.open(requests.get(url, stream=True).raw)\n\nmodel = AutoModel.from_pretrained(\"${model.id}\")\nmodel.to(\"cuda\").eval()\nforeground = model.inference(image)\n`,\n];\nexport const bertopic = (model) => [\n    `from bertopic import BERTopic\n\nmodel = BERTopic.load(\"${model.id}\")`,\n];\nexport const bm25s = (model) => [\n    `from bm25s.hf import BM25HF\n\nretriever = BM25HF.load_from_hub(\"${model.id}\")`,\n];\nexport const chatterbox = () => [\n    `# pip install chatterbox-tts\nimport torchaudio as ta\nfrom chatterbox.tts import ChatterboxTTS\n\nmodel = ChatterboxTTS.from_pretrained(device=\"cuda\")\n\ntext = \"Ezreal and Jinx teamed up with Ahri, Yasuo, and Teemo to take down the enemy's Nexus in an epic late-game pentakill.\"\nwav = model.generate(text)\nta.save(\"test-1.wav\", wav, model.sr)\n\n# If you want to synthesize with a different voice, specify the audio prompt\nAUDIO_PROMPT_PATH=\"YOUR_FILE.wav\"\nwav = model.generate(text, audio_prompt_path=AUDIO_PROMPT_PATH)\nta.save(\"test-2.wav\", wav, model.sr)`,\n];\nexport const chronos_forecasting = (model) => {\n    const installSnippet = `pip install chronos-forecasting`;\n    const exampleSnippet = `import pandas as pd\nfrom chronos import BaseChronosPipeline\n\npipeline = BaseChronosPipeline.from_pretrained(\"${model.id}\", device_map=\"cuda\")\n\n# Load historical data\ncontext_df = pd.read_csv(\"https://autogluon.s3.us-west-2.amazonaws.com/datasets/timeseries/misc/AirPassengers.csv\")\n\n# Generate predictions\npred_df = pipeline.predict_df(\n    context_df,\n    prediction_length=36,  # Number of steps to forecast\n    quantile_levels=[0.1, 0.5, 0.9],  # Quantiles for probabilistic forecast\n    id_column=\"item_id\",  # Column identifying different time series\n    timestamp_column=\"Month\",  # Column with datetime information\n    target=\"#Passengers\",  # Column(s) with time series values to predict\n)`;\n    return [installSnippet, exampleSnippet];\n};\nexport const sap_rpt_one_oss = () => {\n    const installSnippet = `pip install git+https://github.com/SAP-samples/sap-rpt-1-oss`;\n    const classificationSnippet = `# Run a classification task\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nfrom sap_rpt_oss import SAP_RPT_OSS_Classifier\n\n# Load sample data\nX, y = load_breast_cancer(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n\n# Initialize a classifier, 8k context and 8-fold bagging gives best performance, reduce if running out of memory\nclf = SAP_RPT_OSS_Classifier(max_context_size=8192, bagging=8)\n\nclf.fit(X_train, y_train)\n\n# Predict probabilities\nprediction_probabilities = clf.predict_proba(X_test)\n# Predict labels\npredictions = clf.predict(X_test)\nprint(\"Accuracy\", accuracy_score(y_test, predictions))`;\n    const regressionsSnippet = `# Run a regression task\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\n\nfrom sap_rpt_oss import SAP_RPT_OSS_Regressor\n\n# Load sample data\ndf = fetch_openml(data_id=531, as_frame=True)\nX = df.data\ny = df.target.astype(float)\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n\n# Initialize the regressor, 8k context and 8-fold bagging gives best performance, reduce if running out of memory\nregressor = SAP_RPT_OSS_Regressor(max_context_size=8192, bagging=8)\n\nregressor.fit(X_train, y_train)\n\n# Predict on the test set\npredictions = regressor.predict(X_test)\n\nr2 = r2_score(y_test, predictions)\nprint(\"R Score:\", r2)`;\n    return [installSnippet, classificationSnippet, regressionsSnippet];\n};\nexport const cxr_foundation = () => [\n    `# pip install git+https://github.com/Google-Health/cxr-foundation.git#subdirectory=python\n\n# Load image as grayscale (Stillwaterising, CC0, via Wikimedia Commons)\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\nimage_url = \"https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png\"\nimg = Image.open(requests.get(image_url, headers={'User-Agent': 'Demo'}, stream=True).raw).convert('L')\n\n# Run inference\nfrom clientside.clients import make_hugging_face_client\ncxr_client = make_hugging_face_client('cxr_model')\nprint(cxr_client.get_image_embeddings_from_images([img]))`,\n];\nexport const depth_anything_v2 = (model) => {\n    let encoder;\n    let features;\n    let out_channels;\n    encoder = \"<ENCODER>\";\n    features = \"<NUMBER_OF_FEATURES>\";\n    out_channels = \"<OUT_CHANNELS>\";\n    if (model.id === \"depth-anything/Depth-Anything-V2-Small\") {\n        encoder = \"vits\";\n        features = \"64\";\n        out_channels = \"[48, 96, 192, 384]\";\n    }\n    else if (model.id === \"depth-anything/Depth-Anything-V2-Base\") {\n        encoder = \"vitb\";\n        features = \"128\";\n        out_channels = \"[96, 192, 384, 768]\";\n    }\n    else if (model.id === \"depth-anything/Depth-Anything-V2-Large\") {\n        encoder = \"vitl\";\n        features = \"256\";\n        out_channels = \"[256, 512, 1024, 1024\";\n    }\n    return [\n        `\n# Install from https://github.com/DepthAnything/Depth-Anything-V2\n\n# Load the model and infer depth from an image\nimport cv2\nimport torch\n\nfrom depth_anything_v2.dpt import DepthAnythingV2\n\n# instantiate the model\nmodel = DepthAnythingV2(encoder=\"${encoder}\", features=${features}, out_channels=${out_channels})\n\n# load the weights\nfilepath = hf_hub_download(repo_id=\"${model.id}\", filename=\"depth_anything_v2_${encoder}.pth\", repo_type=\"model\")\nstate_dict = torch.load(filepath, map_location=\"cpu\")\nmodel.load_state_dict(state_dict).eval()\n\nraw_img = cv2.imread(\"your/image/path\")\ndepth = model.infer_image(raw_img) # HxW raw depth map in numpy\n    `,\n    ];\n};\nexport const depth_pro = (model) => {\n    const installSnippet = `# Download checkpoint\npip install huggingface-hub\nhuggingface-cli download --local-dir checkpoints ${model.id}`;\n    const inferenceSnippet = `import depth_pro\n\n# Load model and preprocessing transform\nmodel, transform = depth_pro.create_model_and_transforms()\nmodel.eval()\n\n# Load and preprocess an image.\nimage, _, f_px = depth_pro.load_rgb(\"example.png\")\nimage = transform(image)\n\n# Run inference.\nprediction = model.infer(image, f_px=f_px)\n\n# Results: 1. Depth in meters\ndepth = prediction[\"depth\"]\n# Results: 2. Focal length in pixels\nfocallength_px = prediction[\"focallength_px\"]`;\n    return [installSnippet, inferenceSnippet];\n};\nexport const derm_foundation = () => [\n    `from huggingface_hub import from_pretrained_keras\nimport tensorflow as tf, requests\n\n# Load and format input\nIMAGE_URL = \"https://storage.googleapis.com/dx-scin-public-data/dataset/images/3445096909671059178.png\"\ninput_tensor = tf.train.Example(\n    features=tf.train.Features(\n        feature={\n            \"image/encoded\": tf.train.Feature(\n                bytes_list=tf.train.BytesList(value=[requests.get(IMAGE_URL, stream=True).content])\n            )\n        }\n    )\n).SerializeToString()\n\n# Load model and run inference\nloaded_model = from_pretrained_keras(\"google/derm-foundation\")\ninfer = loaded_model.signatures[\"serving_default\"]\nprint(infer(inputs=tf.constant([input_tensor])))`,\n];\nexport const dia = (model) => [\n    `import soundfile as sf\nfrom dia.model import Dia\n\nmodel = Dia.from_pretrained(\"${model.id}\")\ntext = \"[S1] Dia is an open weights text to dialogue model. [S2] You get full control over scripts and voices. [S1] Wow. Amazing. (laughs) [S2] Try it now on Git hub or Hugging Face.\"\noutput = model.generate(text)\n\nsf.write(\"simple.mp3\", output, 44100)`,\n];\nexport const dia2 = (model) => [\n    `from dia2 import Dia2, GenerationConfig, SamplingConfig\n\ndia = Dia2.from_repo(\"${model.id}\", device=\"cuda\", dtype=\"bfloat16\")\nconfig = GenerationConfig(\n    cfg_scale=2.0,\n    audio=SamplingConfig(temperature=0.8, top_k=50),\n    use_cuda_graph=True,\n)\nresult = dia.generate(\"[S1] Hello Dia2!\", config=config, output_wav=\"hello.wav\", verbose=True)\n`,\n];\nexport const describe_anything = (model) => [\n    `# pip install git+https://github.com/NVlabs/describe-anything\nfrom huggingface_hub import snapshot_download\nfrom dam import DescribeAnythingModel\n\nsnapshot_download(${model.id}, local_dir=\"checkpoints\")\n\ndam = DescribeAnythingModel(\n\tmodel_path=\"checkpoints\",\n\tconv_mode=\"v1\",\n\tprompt_mode=\"focal_prompt\",\n)`,\n];\nconst diffusers_install = \"pip install -U diffusers transformers accelerate\";\nconst diffusersDefaultPrompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\";\nconst diffusersImg2ImgDefaultPrompt = \"Turn this cat into a dog\";\nconst diffusersVideoDefaultPrompt = \"A man with short gray hair plays a red electric guitar.\";\nconst diffusers_default = (model) => [\n    `import torch\nfrom diffusers import DiffusionPipeline\n\n# switch to \"mps\" for apple devices\npipe = DiffusionPipeline.from_pretrained(\"${model.id}\", dtype=torch.bfloat16, device_map=\"cuda\")\n\nprompt = \"${get_prompt_from_diffusers_model(model) ?? diffusersDefaultPrompt}\"\nimage = pipe(prompt).images[0]`,\n];\nconst diffusers_image_to_image = (model) => [\n    `import torch\nfrom diffusers import DiffusionPipeline\nfrom diffusers.utils import load_image\n\n# switch to \"mps\" for apple devices\npipe = DiffusionPipeline.from_pretrained(\"${model.id}\", dtype=torch.bfloat16, device_map=\"cuda\")\n\nprompt = \"${get_prompt_from_diffusers_model(model) ?? diffusersImg2ImgDefaultPrompt}\"\ninput_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png\")\n\nimage = pipe(image=input_image, prompt=prompt).images[0]`,\n];\nconst diffusers_image_to_video = (model) => [\n    `import torch\nfrom diffusers import DiffusionPipeline\nfrom diffusers.utils import load_image, export_to_video\n\n# switch to \"mps\" for apple devices\npipe = DiffusionPipeline.from_pretrained(\"${model.id}\", dtype=torch.bfloat16, device_map=\"cuda\")\npipe.to(\"cuda\")\n\nprompt = \"${get_prompt_from_diffusers_model(model) ?? diffusersVideoDefaultPrompt}\"\nimage = load_image(\n    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/guitar-man.png\"\n)\n\noutput = pipe(image=image, prompt=prompt).frames[0]\nexport_to_video(output, \"output.mp4\")`,\n];\nconst diffusers_controlnet = (model) => [\n    `from diffusers import ControlNetModel, StableDiffusionControlNetPipeline\n\ncontrolnet = ControlNetModel.from_pretrained(\"${model.id}\")\npipe = StableDiffusionControlNetPipeline.from_pretrained(\n\t\"${get_base_diffusers_model(model)}\", controlnet=controlnet\n)`,\n];\nconst diffusers_lora = (model) => [\n    `import torch\nfrom diffusers import DiffusionPipeline\n\n# switch to \"mps\" for apple devices\npipe = DiffusionPipeline.from_pretrained(\"${get_base_diffusers_model(model)}\", dtype=torch.bfloat16, device_map=\"cuda\")\npipe.load_lora_weights(\"${model.id}\")\n\nprompt = \"${get_prompt_from_diffusers_model(model) ?? diffusersDefaultPrompt}\"\nimage = pipe(prompt).images[0]`,\n];\nconst diffusers_lora_image_to_image = (model) => [\n    `import torch\nfrom diffusers import DiffusionPipeline\nfrom diffusers.utils import load_image\n\n# switch to \"mps\" for apple devices\npipe = DiffusionPipeline.from_pretrained(\"${get_base_diffusers_model(model)}\", dtype=torch.bfloat16, device_map=\"cuda\")\npipe.load_lora_weights(\"${model.id}\")\n\nprompt = \"${get_prompt_from_diffusers_model(model) ?? diffusersImg2ImgDefaultPrompt}\"\ninput_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png\")\n\nimage = pipe(image=input_image, prompt=prompt).images[0]`,\n];\nconst diffusers_lora_text_to_video = (model) => [\n    `import torch\nfrom diffusers import DiffusionPipeline\nfrom diffusers.utils import export_to_video\n\n# switch to \"mps\" for apple devices\npipe = DiffusionPipeline.from_pretrained(\"${get_base_diffusers_model(model)}\", dtype=torch.bfloat16, device_map=\"cuda\")\npipe.load_lora_weights(\"${model.id}\")\n\nprompt = \"${get_prompt_from_diffusers_model(model) ?? diffusersVideoDefaultPrompt}\"\n\noutput = pipe(prompt=prompt).frames[0]\nexport_to_video(output, \"output.mp4\")`,\n];\nconst diffusers_lora_image_to_video = (model) => [\n    `import torch\nfrom diffusers import DiffusionPipeline\nfrom diffusers.utils import load_image, export_to_video\n\n# switch to \"mps\" for apple devices\npipe = DiffusionPipeline.from_pretrained(\"${get_base_diffusers_model(model)}\", dtype=torch.bfloat16, device_map=\"cuda\")\npipe.load_lora_weights(\"${model.id}\")\n\nprompt = \"${get_prompt_from_diffusers_model(model) ?? diffusersVideoDefaultPrompt}\"\ninput_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/guitar-man.png\")\n\nimage = pipe(image=input_image, prompt=prompt).frames[0]\nexport_to_video(output, \"output.mp4\")`,\n];\nconst diffusers_textual_inversion = (model) => [\n    `import torch\nfrom diffusers import DiffusionPipeline\n\n# switch to \"mps\" for apple devices\npipe = DiffusionPipeline.from_pretrained(\"${get_base_diffusers_model(model)}\", dtype=torch.bfloat16, device_map=\"cuda\")\npipe.load_textual_inversion(\"${model.id}\")`,\n];\nconst diffusers_flux_fill = (model) => [\n    `import torch\nfrom diffusers import FluxFillPipeline\nfrom diffusers.utils import load_image\n\nimage = load_image(\"https://huggingface.co/datasets/diffusers/diffusers-images-docs/resolve/main/cup.png\")\nmask = load_image(\"https://huggingface.co/datasets/diffusers/diffusers-images-docs/resolve/main/cup_mask.png\")\n\n# switch to \"mps\" for apple devices\npipe = FluxFillPipeline.from_pretrained(\"${model.id}\", dtype=torch.bfloat16, device_map=\"cuda\")\nimage = pipe(\n    prompt=\"a white paper cup\",\n    image=image,\n    mask_image=mask,\n    height=1632,\n    width=1232,\n    guidance_scale=30,\n    num_inference_steps=50,\n    max_sequence_length=512,\n    generator=torch.Generator(\"cpu\").manual_seed(0)\n).images[0]\nimage.save(f\"flux-fill-dev.png\")`,\n];\nconst diffusers_inpainting = (model) => [\n    `import torch\nfrom diffusers import AutoPipelineForInpainting\nfrom diffusers.utils import load_image\n\n# switch to \"mps\" for apple devices\npipe = AutoPipelineForInpainting.from_pretrained(\"${model.id}\", dtype=torch.float16, variant=\"fp16\", device_map=\"cuda\")\n\nimg_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\nmask_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n\nimage = load_image(img_url).resize((1024, 1024))\nmask_image = load_image(mask_url).resize((1024, 1024))\n\nprompt = \"a tiger sitting on a park bench\"\ngenerator = torch.Generator(device=\"cuda\").manual_seed(0)\n\nimage = pipe(\n  prompt=prompt,\n  image=image,\n  mask_image=mask_image,\n  guidance_scale=8.0,\n  num_inference_steps=20,  # steps between 15 and 30 work well for us\n  strength=0.99,  # make sure to use \\`strength\\` below 1.0\n  generator=generator,\n).images[0]`,\n];\nexport const diffusers = (model) => {\n    let codeSnippets;\n    if (model.tags.includes(\"StableDiffusionInpaintPipeline\") ||\n        model.tags.includes(\"StableDiffusionXLInpaintPipeline\")) {\n        codeSnippets = diffusers_inpainting(model);\n    }\n    else if (model.tags.includes(\"controlnet\")) {\n        codeSnippets = diffusers_controlnet(model);\n    }\n    else if (model.tags.includes(\"lora\")) {\n        if (model.pipeline_tag === \"image-to-image\") {\n            codeSnippets = diffusers_lora_image_to_image(model);\n        }\n        else if (model.pipeline_tag === \"image-to-video\") {\n            codeSnippets = diffusers_lora_image_to_video(model);\n        }\n        else if (model.pipeline_tag === \"text-to-video\") {\n            codeSnippets = diffusers_lora_text_to_video(model);\n        }\n        else {\n            codeSnippets = diffusers_lora(model);\n        }\n    }\n    else if (model.tags.includes(\"textual_inversion\")) {\n        codeSnippets = diffusers_textual_inversion(model);\n    }\n    else if (model.tags.includes(\"FluxFillPipeline\")) {\n        codeSnippets = diffusers_flux_fill(model);\n    }\n    else if (model.pipeline_tag === \"image-to-video\") {\n        codeSnippets = diffusers_image_to_video(model);\n    }\n    else if (model.pipeline_tag === \"image-to-image\") {\n        codeSnippets = diffusers_image_to_image(model);\n    }\n    else {\n        codeSnippets = diffusers_default(model);\n    }\n    return [diffusers_install, ...codeSnippets];\n};\nexport const diffusionkit = (model) => {\n    const sd3Snippet = `# Pipeline for Stable Diffusion 3\nfrom diffusionkit.mlx import DiffusionPipeline\n\npipeline = DiffusionPipeline(\n\tshift=3.0,\n\tuse_t5=False,\n\tmodel_version=${model.id},\n\tlow_memory_mode=True,\n\ta16=True,\n\tw16=True,\n)`;\n    const fluxSnippet = `# Pipeline for Flux\nfrom diffusionkit.mlx import FluxPipeline\n\npipeline = FluxPipeline(\n  shift=1.0,\n  model_version=${model.id},\n  low_memory_mode=True,\n  a16=True,\n  w16=True,\n)`;\n    const generateSnippet = `# Image Generation\nHEIGHT = 512\nWIDTH = 512\nNUM_STEPS = ${model.tags.includes(\"flux\") ? 4 : 50}\nCFG_WEIGHT = ${model.tags.includes(\"flux\") ? 0 : 5}\n\nimage, _ = pipeline.generate_image(\n  \"a photo of a cat\",\n  cfg_weight=CFG_WEIGHT,\n  num_steps=NUM_STEPS,\n  latent_size=(HEIGHT // 8, WIDTH // 8),\n)`;\n    const pipelineSnippet = model.tags.includes(\"flux\") ? fluxSnippet : sd3Snippet;\n    return [pipelineSnippet, generateSnippet];\n};\nexport const cartesia_pytorch = (model) => [\n    `# pip install --no-binary :all: cartesia-pytorch\nfrom cartesia_pytorch import ReneLMHeadModel\nfrom transformers import AutoTokenizer\n\nmodel = ReneLMHeadModel.from_pretrained(\"${model.id}\")\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/OLMo-1B-hf\")\n\nin_message = [\"Rene Descartes was\"]\ninputs = tokenizer(in_message, return_tensors=\"pt\")\n\noutputs = model.generate(inputs.input_ids, max_length=50, top_k=100, top_p=0.99)\nout_message = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n\nprint(out_message)\n)`,\n];\nexport const cartesia_mlx = (model) => [\n    `import mlx.core as mx\nimport cartesia_mlx as cmx\n\nmodel = cmx.from_pretrained(\"${model.id}\")\nmodel.set_dtype(mx.float32)   \n\nprompt = \"Rene Descartes was\"\n\nfor text in model.generate(\n    prompt,\n    max_tokens=500,\n    eval_every_n=5,\n    verbose=True,\n    top_p=0.99,\n    temperature=0.85,\n):\n    print(text, end=\"\", flush=True)\n`,\n];\nexport const edsnlp = (model) => {\n    const packageName = nameWithoutNamespace(model.id).replaceAll(\"-\", \"_\");\n    return [\n        `# Load it from the Hub directly\nimport edsnlp\nnlp = edsnlp.load(\"${model.id}\")\n`,\n        `# Or install it as a package\n!pip install git+https://huggingface.co/${model.id}\n\n# and import it as a module\nimport ${packageName}\n\nnlp = ${packageName}.load()  # or edsnlp.load(\"${packageName}\")\n`,\n    ];\n};\nexport const espnetTTS = (model) => [\n    `from espnet2.bin.tts_inference import Text2Speech\n\nmodel = Text2Speech.from_pretrained(\"${model.id}\")\n\nspeech, *_ = model(\"text to generate speech from\")`,\n];\nexport const espnetASR = (model) => [\n    `from espnet2.bin.asr_inference import Speech2Text\n\nmodel = Speech2Text.from_pretrained(\n  \"${model.id}\"\n)\n\nspeech, rate = soundfile.read(\"speech.wav\")\ntext, *_ = model(speech)[0]`,\n];\nconst espnetUnknown = () => [`unknown model type (must be text-to-speech or automatic-speech-recognition)`];\nexport const espnet = (model) => {\n    if (model.tags.includes(\"text-to-speech\")) {\n        return espnetTTS(model);\n    }\n    else if (model.tags.includes(\"automatic-speech-recognition\")) {\n        return espnetASR(model);\n    }\n    return espnetUnknown();\n};\nexport const fairseq = (model) => [\n    `from fairseq.checkpoint_utils import load_model_ensemble_and_task_from_hf_hub\n\nmodels, cfg, task = load_model_ensemble_and_task_from_hf_hub(\n    \"${model.id}\"\n)`,\n];\nexport const flair = (model) => [\n    `from flair.models import SequenceTagger\n\ntagger = SequenceTagger.load(\"${model.id}\")`,\n];\nexport const gliner = (model) => [\n    `from gliner import GLiNER\n\nmodel = GLiNER.from_pretrained(\"${model.id}\")`,\n];\nexport const gliner2 = (model) => [\n    `from gliner2 import GLiNER2\n\nmodel = GLiNER2.from_pretrained(\"${model.id}\")\n\n# Extract entities\ntext = \"Apple CEO Tim Cook announced iPhone 15 in Cupertino yesterday.\"\nresult = extractor.extract_entities(text, [\"company\", \"person\", \"product\", \"location\"])\n\nprint(result)`,\n];\nexport const indextts = (model) => [\n    `# Download model\nfrom huggingface_hub import snapshot_download\n\nsnapshot_download(${model.id}, local_dir=\"checkpoints\")\n\nfrom indextts.infer import IndexTTS\n\n# Ensure config.yaml is present in the checkpoints directory\ntts = IndexTTS(model_dir=\"checkpoints\", cfg_path=\"checkpoints/config.yaml\")\n\nvoice = \"path/to/your/reference_voice.wav\"  # Path to the voice reference audio file\ntext = \"Hello, how are you?\"\noutput_path = \"output_index.wav\"\n\ntts.infer(voice, text, output_path)`,\n];\nexport const htrflow = (model) => [\n    `# CLI usage\n# see docs: https://ai-riksarkivet.github.io/htrflow/latest/getting_started/quick_start.html\nhtrflow pipeline <path/to/pipeline.yaml> <path/to/image>`,\n    `# Python usage\nfrom htrflow.pipeline.pipeline import Pipeline\nfrom htrflow.pipeline.steps import Task\nfrom htrflow.models.framework.model import ModelClass\n\npipeline = Pipeline(\n    [\n        Task(\n            ModelClass, {\"model\": \"${model.id}\"}, {}\n        ),\n    ])`,\n];\nexport const keras = (model) => [\n    `# Available backend options are: \"jax\", \"torch\", \"tensorflow\".\nimport os\nos.environ[\"KERAS_BACKEND\"] = \"jax\"\n\t\nimport keras\n\nmodel = keras.saving.load_model(\"hf://${model.id}\")\n`,\n];\nconst _keras_hub_causal_lm = (modelId) => `\nimport keras_hub\n\n# Load CausalLM model (optional: use half precision for inference)\ncausal_lm = keras_hub.models.CausalLM.from_preset(\"hf://${modelId}\", dtype=\"bfloat16\")\ncausal_lm.compile(sampler=\"greedy\")  # (optional) specify a sampler\n\n# Generate text\ncausal_lm.generate(\"Keras: deep learning for\", max_length=64)\n`;\nconst _keras_hub_text_to_image = (modelId) => `\nimport keras_hub\n\n# Load TextToImage model (optional: use half precision for inference)\ntext_to_image = keras_hub.models.TextToImage.from_preset(\"hf://${modelId}\", dtype=\"bfloat16\")\n\n# Generate images with a TextToImage model.\ntext_to_image.generate(\"Astronaut in a jungle\")\n`;\nconst _keras_hub_text_classifier = (modelId) => `\nimport keras_hub\n\n# Load TextClassifier model\ntext_classifier = keras_hub.models.TextClassifier.from_preset(\n    \"hf://${modelId}\",\n    num_classes=2,\n)\n# Fine-tune\ntext_classifier.fit(x=[\"Thilling adventure!\", \"Total snoozefest.\"], y=[1, 0])\n# Classify text\ntext_classifier.predict([\"Not my cup of tea.\"])\n`;\nconst _keras_hub_image_classifier = (modelId) => `\nimport keras_hub\nimport keras\n\n# Load ImageClassifier model\nimage_classifier = keras_hub.models.ImageClassifier.from_preset(\n    \"hf://${modelId}\",\n    num_classes=2,\n)\n# Fine-tune\nimage_classifier.fit(\n    x=keras.random.randint((32, 64, 64, 3), 0, 256),\n    y=keras.random.randint((32, 1), 0, 2),\n)\n# Classify image\nimage_classifier.predict(keras.random.randint((1, 64, 64, 3), 0, 256))\n`;\nconst _keras_hub_tasks_with_example = {\n    CausalLM: _keras_hub_causal_lm,\n    TextToImage: _keras_hub_text_to_image,\n    TextClassifier: _keras_hub_text_classifier,\n    ImageClassifier: _keras_hub_image_classifier,\n};\nconst _keras_hub_task_without_example = (task, modelId) => `\nimport keras_hub\n\n# Create a ${task} model\ntask = keras_hub.models.${task}.from_preset(\"hf://${modelId}\")\n`;\nconst _keras_hub_generic_backbone = (modelId) => `\nimport keras_hub\n\n# Create a Backbone model unspecialized for any task\nbackbone = keras_hub.models.Backbone.from_preset(\"hf://${modelId}\")\n`;\nexport const keras_hub = (model) => {\n    const modelId = model.id;\n    const tasks = model.config?.keras_hub?.tasks ?? [];\n    const snippets = [];\n    // First, generate tasks with examples\n    for (const [task, snippet] of Object.entries(_keras_hub_tasks_with_example)) {\n        if (tasks.includes(task)) {\n            snippets.push(snippet(modelId));\n        }\n    }\n    // Then, add remaining tasks\n    for (const task of tasks) {\n        if (!Object.keys(_keras_hub_tasks_with_example).includes(task)) {\n            snippets.push(_keras_hub_task_without_example(task, modelId));\n        }\n    }\n    // Finally, add generic backbone snippet\n    snippets.push(_keras_hub_generic_backbone(modelId));\n    return snippets;\n};\nexport const kernels = (model) => [\n    `# !pip install kernels\n\nfrom kernels import get_kernel\n\nkernel = get_kernel(\"${model.id}\")`,\n];\nexport const kimi_audio = (model) => [\n    `# Example usage for KimiAudio\n# pip install git+https://github.com/MoonshotAI/Kimi-Audio.git\n\nfrom kimia_infer.api.kimia import KimiAudio\n\nmodel = KimiAudio(model_path=\"${model.id}\", load_detokenizer=True)\n\nsampling_params = {\n    \"audio_temperature\": 0.8,\n    \"audio_top_k\": 10,\n    \"text_temperature\": 0.0,\n    \"text_top_k\": 5,\n}\n\n# For ASR\nasr_audio = \"asr_example.wav\"\nmessages_asr = [\n    {\"role\": \"user\", \"message_type\": \"text\", \"content\": \"Please transcribe the following audio:\"},\n    {\"role\": \"user\", \"message_type\": \"audio\", \"content\": asr_audio}\n]\n_, text = model.generate(messages_asr, **sampling_params, output_type=\"text\")\nprint(text)\n\n# For Q&A\nqa_audio = \"qa_example.wav\"\nmessages_conv = [{\"role\": \"user\", \"message_type\": \"audio\", \"content\": qa_audio}]\nwav, text = model.generate(messages_conv, **sampling_params, output_type=\"both\")\nsf.write(\"output_audio.wav\", wav.cpu().view(-1).numpy(), 24000)\nprint(text)\n`,\n];\nexport const kittentts = (model) => [\n    `from kittentts import KittenTTS\nm = KittenTTS(\"${model.id}\")\n\naudio = m.generate(\"This high quality TTS model works without a GPU\")\n\n# Save the audio\nimport soundfile as sf\nsf.write('output.wav', audio, 24000)`,\n];\nexport const lightning_ir = (model) => {\n    if (model.tags.includes(\"bi-encoder\")) {\n        return [\n            `#install from https://github.com/webis-de/lightning-ir\n\nfrom lightning_ir import BiEncoderModule\nmodel = BiEncoderModule(\"${model.id}\")\n\nmodel.score(\"query\", [\"doc1\", \"doc2\", \"doc3\"])`,\n        ];\n    }\n    else if (model.tags.includes(\"cross-encoder\")) {\n        return [\n            `#install from https://github.com/webis-de/lightning-ir\n\nfrom lightning_ir import CrossEncoderModule\nmodel = CrossEncoderModule(\"${model.id}\")\n\nmodel.score(\"query\", [\"doc1\", \"doc2\", \"doc3\"])`,\n        ];\n    }\n    return [\n        `#install from https://github.com/webis-de/lightning-ir\n\nfrom lightning_ir import BiEncoderModule, CrossEncoderModule\n\n# depending on the model type, use either BiEncoderModule or CrossEncoderModule\nmodel = BiEncoderModule(\"${model.id}\") \n# model = CrossEncoderModule(\"${model.id}\")\n\nmodel.score(\"query\", [\"doc1\", \"doc2\", \"doc3\"])`,\n    ];\n};\nexport const llama_cpp_python = (model) => {\n    const snippets = [\n        `# !pip install llama-cpp-python\n\nfrom llama_cpp import Llama\n\nllm = Llama.from_pretrained(\n\trepo_id=\"${model.id}\",\n\tfilename=\"{{GGUF_FILE}}\",\n)\n`,\n    ];\n    if (model.tags.includes(\"conversational\")) {\n        const messages = getModelInputSnippet(model);\n        snippets.push(`llm.create_chat_completion(\n\tmessages = ${stringifyMessages(messages, { attributeKeyQuotes: true, indent: \"\\t\" })}\n)`);\n    }\n    else {\n        snippets.push(`output = llm(\n\t\"Once upon a time,\",\n\tmax_tokens=512,\n\techo=True\n)\nprint(output)`);\n    }\n    return snippets;\n};\nexport const lerobot = (model) => {\n    if (model.tags.includes(\"smolvla\")) {\n        const smolvlaSnippets = [\n            // Installation snippet\n            `# See https://github.com/huggingface/lerobot?tab=readme-ov-file#installation for more details\ngit clone https://github.com/huggingface/lerobot.git\ncd lerobot\npip install -e .[smolvla]`,\n            // Finetune snippet\n            `# Launch finetuning on your dataset\npython lerobot/scripts/train.py \\\\\n--policy.path=${model.id} \\\\\n--dataset.repo_id=lerobot/svla_so101_pickplace \\\\ \n--batch_size=64 \\\\\n--steps=20000 \\\\\n--output_dir=outputs/train/my_smolvla \\\\\n--job_name=my_smolvla_training \\\\\n--policy.device=cuda \\\\\n--wandb.enable=true`,\n        ];\n        if (model.id !== \"lerobot/smolvla_base\") {\n            // Inference snippet (only if not base model)\n            smolvlaSnippets.push(`# Run the policy using the record function\t\npython -m lerobot.record \\\\\n  --robot.type=so101_follower \\\\\n  --robot.port=/dev/ttyACM0 \\\\ # <- Use your port\n  --robot.id=my_blue_follower_arm \\\\ # <- Use your robot id\n  --robot.cameras=\"{ front: {type: opencv, index_or_path: 8, width: 640, height: 480, fps: 30}}\" \\\\ # <- Use your cameras\n  --dataset.single_task=\"Grasp a lego block and put it in the bin.\" \\\\ # <- Use the same task description you used in your dataset recording\n  --dataset.repo_id=HF_USER/dataset_name \\\\  # <- This will be the dataset name on HF Hub\n  --dataset.episode_time_s=50 \\\\\n  --dataset.num_episodes=10 \\\\\n  --policy.path=${model.id}`);\n        }\n        return smolvlaSnippets;\n    }\n    return [];\n};\nexport const tf_keras = (model) => [\n    `# Note: 'keras<3.x' or 'tf_keras' must be installed (legacy)\n# See https://github.com/keras-team/tf-keras for more details.\nfrom huggingface_hub import from_pretrained_keras\n\nmodel = from_pretrained_keras(\"${model.id}\")\n`,\n];\nexport const mamba_ssm = (model) => [\n    `from mamba_ssm import MambaLMHeadModel\n\nmodel = MambaLMHeadModel.from_pretrained(\"${model.id}\")`,\n];\nexport const mars5_tts = (model) => [\n    `# Install from https://github.com/Camb-ai/MARS5-TTS\n\nfrom inference import Mars5TTS\nmars5 = Mars5TTS.from_pretrained(\"${model.id}\")`,\n];\nexport const matanyone = (model) => [\n    `# Install from https://github.com/pq-yang/MatAnyone.git\n\nfrom matanyone.model.matanyone import MatAnyone\nmodel = MatAnyone.from_pretrained(\"${model.id}\")`,\n    `\nfrom matanyone import InferenceCore\nprocessor = InferenceCore(\"${model.id}\")`,\n];\nexport const mesh_anything = () => [\n    `# Install from https://github.com/buaacyw/MeshAnything.git\n\nfrom MeshAnything.models.meshanything import MeshAnything\n\n# refer to https://github.com/buaacyw/MeshAnything/blob/main/main.py#L91 on how to define args\n# and https://github.com/buaacyw/MeshAnything/blob/main/app.py regarding usage\nmodel = MeshAnything(args)`,\n];\nexport const open_clip = (model) => [\n    `import open_clip\n\nmodel, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:${model.id}')\ntokenizer = open_clip.get_tokenizer('hf-hub:${model.id}')`,\n];\nexport const paddlenlp = (model) => {\n    if (model.config?.architectures?.[0]) {\n        const architecture = model.config.architectures[0];\n        return [\n            [\n                `from paddlenlp.transformers import AutoTokenizer, ${architecture}`,\n                \"\",\n                `tokenizer = AutoTokenizer.from_pretrained(\"${model.id}\", from_hf_hub=True)`,\n                `model = ${architecture}.from_pretrained(\"${model.id}\", from_hf_hub=True)`,\n            ].join(\"\\n\"),\n        ];\n    }\n    else {\n        return [\n            [\n                `#  Type of model unknown`,\n                `from paddlenlp.transformers import AutoTokenizer, AutoModel`,\n                \"\",\n                `tokenizer = AutoTokenizer.from_pretrained(\"${model.id}\", from_hf_hub=True)`,\n                `model = AutoModel.from_pretrained(\"${model.id}\", from_hf_hub=True)`,\n            ].join(\"\\n\"),\n        ];\n    }\n};\nexport const paddleocr = (model) => {\n    const mapping = {\n        textline_detection: { className: \"TextDetection\" },\n        textline_recognition: { className: \"TextRecognition\" },\n        seal_text_detection: { className: \"SealTextDetection\" },\n        doc_img_unwarping: { className: \"TextImageUnwarping\" },\n        doc_img_orientation_classification: { className: \"DocImgOrientationClassification\" },\n        textline_orientation_classification: { className: \"TextLineOrientationClassification\" },\n        chart_parsing: { className: \"ChartParsing\" },\n        formula_recognition: { className: \"FormulaRecognition\" },\n        layout_detection: { className: \"LayoutDetection\" },\n        table_cells_detection: { className: \"TableCellsDetection\" },\n        wired_table_classification: { className: \"TableClassification\" },\n        table_structure_recognition: { className: \"TableStructureRecognition\" },\n    };\n    if (model.tags.includes(\"doc_vlm\")) {\n        return [\n            `# 1. See https://www.paddlepaddle.org.cn/en/install to install paddlepaddle\n# 2. pip install paddleocr\n\nfrom paddleocr import DocVLM\nmodel = DocVLM(model_name=\"${nameWithoutNamespace(model.id)}\")\noutput = model.predict(\n    input={\"image\": \"path/to/image.png\", \"query\": \"Parsing this image and output the content in Markdown format.\"},\n    batch_size=1\n)\nfor res in output:\n    res.print()\n    res.save_to_json(save_path=\"./output/res.json\")`,\n        ];\n    }\n    if (model.tags.includes(\"document-parse\")) {\n        return [\n            `# See https://www.paddleocr.ai/latest/version3.x/pipeline_usage/PaddleOCR-VL.html to installation\n\nfrom paddleocr import PaddleOCRVL\npipeline = PaddleOCRVL()\noutput = pipeline.predict(\"path/to/document_image.png\")\nfor res in output:\n\tres.print()\n\tres.save_to_json(save_path=\"output\")\n\tres.save_to_markdown(save_path=\"output\")`,\n        ];\n    }\n    for (const tag of model.tags) {\n        if (tag in mapping) {\n            const { className } = mapping[tag];\n            return [\n                `# 1. See https://www.paddlepaddle.org.cn/en/install to install paddlepaddle\n# 2. pip install paddleocr\n\nfrom paddleocr import ${className}\nmodel = ${className}(model_name=\"${nameWithoutNamespace(model.id)}\")\noutput = model.predict(input=\"path/to/image.png\", batch_size=1)\nfor res in output:\n    res.print()\n    res.save_to_img(save_path=\"./output/\")\n    res.save_to_json(save_path=\"./output/res.json\")`,\n            ];\n        }\n    }\n    return [\n        `# Please refer to the document for information on how to use the model. \n# https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/module_usage/module_overview.html`,\n    ];\n};\nexport const perception_encoder = (model) => {\n    const clip_model = `# Use PE-Core models as CLIP models\nimport core.vision_encoder.pe as pe\n\nmodel = pe.CLIP.from_config(\"${model.id}\", pretrained=True)`;\n    const vision_encoder = `# Use any PE model as a vision encoder\nimport core.vision_encoder.pe as pe\n\nmodel = pe.VisionTransformer.from_config(\"${model.id}\", pretrained=True)`;\n    if (model.id.includes(\"Core\")) {\n        return [clip_model, vision_encoder];\n    }\n    else {\n        return [vision_encoder];\n    }\n};\nexport const phantom_wan = (model) => [\n    `from huggingface_hub import snapshot_download\nfrom phantom_wan import WANI2V, configs\n\ncheckpoint_dir = snapshot_download(\"${model.id}\")\nwan_i2v = WanI2V(\n            config=configs.WAN_CONFIGS['i2v-14B'],\n            checkpoint_dir=checkpoint_dir,\n        )\n video = wan_i2v.generate(text_prompt, image_prompt)`,\n];\nexport const pyannote_audio_pipeline = (model) => [\n    `from pyannote.audio import Pipeline\n  \npipeline = Pipeline.from_pretrained(\"${model.id}\")\n\n# inference on the whole file\npipeline(\"file.wav\")\n\n# inference on an excerpt\nfrom pyannote.core import Segment\nexcerpt = Segment(start=2.0, end=5.0)\n\nfrom pyannote.audio import Audio\nwaveform, sample_rate = Audio().crop(\"file.wav\", excerpt)\npipeline({\"waveform\": waveform, \"sample_rate\": sample_rate})`,\n];\nconst pyannote_audio_model = (model) => [\n    `from pyannote.audio import Model, Inference\n\nmodel = Model.from_pretrained(\"${model.id}\")\ninference = Inference(model)\n\n# inference on the whole file\ninference(\"file.wav\")\n\n# inference on an excerpt\nfrom pyannote.core import Segment\nexcerpt = Segment(start=2.0, end=5.0)\ninference.crop(\"file.wav\", excerpt)`,\n];\nexport const pyannote_audio = (model) => {\n    if (model.tags.includes(\"pyannote-audio-pipeline\")) {\n        return pyannote_audio_pipeline(model);\n    }\n    return pyannote_audio_model(model);\n};\nexport const relik = (model) => [\n    `from relik import Relik\n \nrelik = Relik.from_pretrained(\"${model.id}\")`,\n];\nexport const renderformer = (model) => [\n    `# Install from https://github.com/microsoft/renderformer\n\nfrom renderformer import RenderFormerRenderingPipeline\npipeline = RenderFormerRenderingPipeline.from_pretrained(\"${model.id}\")`,\n];\nconst tensorflowttsTextToMel = (model) => [\n    `from tensorflow_tts.inference import AutoProcessor, TFAutoModel\n\nprocessor = AutoProcessor.from_pretrained(\"${model.id}\")\nmodel = TFAutoModel.from_pretrained(\"${model.id}\")\n`,\n];\nconst tensorflowttsMelToWav = (model) => [\n    `from tensorflow_tts.inference import TFAutoModel\n\nmodel = TFAutoModel.from_pretrained(\"${model.id}\")\naudios = model.inference(mels)\n`,\n];\nconst tensorflowttsUnknown = (model) => [\n    `from tensorflow_tts.inference import TFAutoModel\n\nmodel = TFAutoModel.from_pretrained(\"${model.id}\")\n`,\n];\nexport const tensorflowtts = (model) => {\n    if (model.tags.includes(\"text-to-mel\")) {\n        return tensorflowttsTextToMel(model);\n    }\n    else if (model.tags.includes(\"mel-to-wav\")) {\n        return tensorflowttsMelToWav(model);\n    }\n    return tensorflowttsUnknown(model);\n};\nexport const timm = (model) => [\n    `import timm\n\nmodel = timm.create_model(\"hf_hub:${model.id}\", pretrained=True)`,\n];\nexport const saelens = ( /* model: ModelData */) => [\n    `# pip install sae-lens\nfrom sae_lens import SAE\n\nsae, cfg_dict, sparsity = SAE.from_pretrained(\n    release = \"RELEASE_ID\", # e.g., \"gpt2-small-res-jb\". See other options in https://github.com/jbloomAus/SAELens/blob/main/sae_lens/pretrained_saes.yaml\n    sae_id = \"SAE_ID\", # e.g., \"blocks.8.hook_resid_pre\". Won't always be a hook point\n)`,\n];\nexport const seed_story = () => [\n    `# seed_story_cfg_path refers to 'https://github.com/TencentARC/SEED-Story/blob/master/configs/clm_models/agent_7b_sft.yaml'\n# llm_cfg_path refers to 'https://github.com/TencentARC/SEED-Story/blob/master/configs/clm_models/llama2chat7b_lora.yaml'\nfrom omegaconf import OmegaConf\nimport hydra\n\n# load Llama2\nllm_cfg = OmegaConf.load(llm_cfg_path)\nllm = hydra.utils.instantiate(llm_cfg, torch_dtype=\"fp16\")\n\n# initialize seed_story\nseed_story_cfg = OmegaConf.load(seed_story_cfg_path)\nseed_story = hydra.utils.instantiate(seed_story_cfg, llm=llm) `,\n];\nconst skopsPickle = (model, modelFile) => {\n    return [\n        `import joblib\nfrom skops.hub_utils import download\ndownload(\"${model.id}\", \"path_to_folder\")\nmodel = joblib.load(\n\t\"${modelFile}\"\n)\n# only load pickle files from sources you trust\n# read more about it here https://skops.readthedocs.io/en/stable/persistence.html`,\n    ];\n};\nconst skopsFormat = (model, modelFile) => {\n    return [\n        `from skops.hub_utils import download\nfrom skops.io import load\ndownload(\"${model.id}\", \"path_to_folder\")\n# make sure model file is in skops format\n# if model is a pickle file, make sure it's from a source you trust\nmodel = load(\"path_to_folder/${modelFile}\")`,\n    ];\n};\nconst skopsJobLib = (model) => {\n    return [\n        `from huggingface_hub import hf_hub_download\nimport joblib\nmodel = joblib.load(\n\thf_hub_download(\"${model.id}\", \"sklearn_model.joblib\")\n)\n# only load pickle files from sources you trust\n# read more about it here https://skops.readthedocs.io/en/stable/persistence.html`,\n    ];\n};\nexport const sklearn = (model) => {\n    if (model.tags.includes(\"skops\")) {\n        const skopsmodelFile = model.config?.sklearn?.model?.file;\n        const skopssaveFormat = model.config?.sklearn?.model_format;\n        if (!skopsmodelFile) {\n            return [`#  Model filename not specified in config.json`];\n        }\n        if (skopssaveFormat === \"pickle\") {\n            return skopsPickle(model, skopsmodelFile);\n        }\n        else {\n            return skopsFormat(model, skopsmodelFile);\n        }\n    }\n    else {\n        return skopsJobLib(model);\n    }\n};\nexport const stable_audio_tools = (model) => [\n    `import torch\nimport torchaudio\nfrom einops import rearrange\nfrom stable_audio_tools import get_pretrained_model\nfrom stable_audio_tools.inference.generation import generate_diffusion_cond\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Download model\nmodel, model_config = get_pretrained_model(\"${model.id}\")\nsample_rate = model_config[\"sample_rate\"]\nsample_size = model_config[\"sample_size\"]\n\nmodel = model.to(device)\n\n# Set up text and timing conditioning\nconditioning = [{\n\t\"prompt\": \"128 BPM tech house drum loop\",\n}]\n\n# Generate stereo audio\noutput = generate_diffusion_cond(\n\tmodel,\n\tconditioning=conditioning,\n\tsample_size=sample_size,\n\tdevice=device\n)\n\n# Rearrange audio batch to a single sequence\noutput = rearrange(output, \"b d n -> d (b n)\")\n\n# Peak normalize, clip, convert to int16, and save to file\noutput = output.to(torch.float32).div(torch.max(torch.abs(output))).clamp(-1, 1).mul(32767).to(torch.int16).cpu()\ntorchaudio.save(\"output.wav\", output, sample_rate)`,\n];\nexport const fastai = (model) => [\n    `from huggingface_hub import from_pretrained_fastai\n\nlearn = from_pretrained_fastai(\"${model.id}\")`,\n];\nexport const sam2 = (model) => {\n    const image_predictor = `# Use SAM2 with images\nimport torch\nfrom sam2.sam2_image_predictor import SAM2ImagePredictor\n\npredictor = SAM2ImagePredictor.from_pretrained(${model.id})\n\nwith torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n    predictor.set_image(<your_image>)\n    masks, _, _ = predictor.predict(<input_prompts>)`;\n    const video_predictor = `# Use SAM2 with videos\nimport torch\nfrom sam2.sam2_video_predictor import SAM2VideoPredictor\n\t\npredictor = SAM2VideoPredictor.from_pretrained(${model.id})\n\nwith torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n    state = predictor.init_state(<your_video>)\n\n    # add new prompts and instantly get the output on the same frame\n    frame_idx, object_ids, masks = predictor.add_new_points(state, <your_prompts>):\n\n    # propagate the prompts to get masklets throughout the video\n    for frame_idx, object_ids, masks in predictor.propagate_in_video(state):\n        ...`;\n    return [image_predictor, video_predictor];\n};\nexport const sam_3d_objects = (model) => [\n    `from inference import Inference, load_image, load_single_mask\nfrom huggingface_hub import hf_hub_download\n\npath = hf_hub_download(\"${model.id}\", \"pipeline.yaml\")\ninference = Inference(path, compile=False)\n\nimage = load_image(\"path_to_image.png\")\nmask = load_single_mask(\"path_to_mask.png\", index=14)\n\noutput = inference(image, mask)`,\n];\nexport const sam_3d_body = (model) => [\n    `from notebook.utils import setup_sam_3d_body\n\nestimator = setup_sam_3d_body(${model.id})\noutputs = estimator.process_one_image(image)\nrend_img = visualize_sample_together(image, outputs, estimator.faces)`,\n];\nexport const sampleFactory = (model) => [\n    `python -m sample_factory.huggingface.load_from_hub -r ${model.id} -d ./train_dir`,\n];\nfunction get_widget_examples_from_st_model(model) {\n    const widgetExample = model.widgetData?.[0];\n    if (widgetExample?.source_sentence && widgetExample?.sentences?.length) {\n        return [widgetExample.source_sentence, ...widgetExample.sentences];\n    }\n}\nexport const sentenceTransformers = (model) => {\n    const remote_code_snippet = model.tags.includes(TAG_CUSTOM_CODE) ? \", trust_remote_code=True\" : \"\";\n    if (model.tags.includes(\"PyLate\")) {\n        return [\n            `from pylate import models\n\nqueries = [\n    \"Which planet is known as the Red Planet?\",\n    \"What is the largest planet in our solar system?\",\n]\n\ndocuments = [\n    [\"Mars is the Red Planet.\", \"Venus is Earth's twin.\"],\n    [\"Jupiter is the largest planet.\", \"Saturn has rings.\"],\n]\n\nmodel = models.ColBERT(model_name_or_path=\"${model.id}\")\n\nqueries_emb = model.encode(queries, is_query=True)\ndocs_emb = model.encode(documents, is_query=False)`,\n        ];\n    }\n    if (model.tags.includes(\"cross-encoder\") || model.pipeline_tag == \"text-ranking\") {\n        return [\n            `from sentence_transformers import CrossEncoder\n\nmodel = CrossEncoder(\"${model.id}\"${remote_code_snippet})\n\nquery = \"Which planet is known as the Red Planet?\"\npassages = [\n\t\"Venus is often called Earth's twin because of its similar size and proximity.\",\n\t\"Mars, known for its reddish appearance, is often referred to as the Red Planet.\",\n\t\"Jupiter, the largest planet in our solar system, has a prominent red spot.\",\n\t\"Saturn, famous for its rings, is sometimes mistaken for the Red Planet.\"\n]\n\nscores = model.predict([(query, passage) for passage in passages])\nprint(scores)`,\n        ];\n    }\n    const exampleSentences = get_widget_examples_from_st_model(model) ?? [\n        \"The weather is lovely today.\",\n        \"It's so sunny outside!\",\n        \"He drove to the stadium.\",\n    ];\n    return [\n        `from sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer(\"${model.id}\"${remote_code_snippet})\n\nsentences = ${JSON.stringify(exampleSentences, null, 4)}\nembeddings = model.encode(sentences)\n\nsimilarities = model.similarity(embeddings, embeddings)\nprint(similarities.shape)\n# [${exampleSentences.length}, ${exampleSentences.length}]`,\n    ];\n};\nexport const setfit = (model) => [\n    `from setfit import SetFitModel\n\nmodel = SetFitModel.from_pretrained(\"${model.id}\")`,\n];\nexport const spacy = (model) => [\n    `!pip install https://huggingface.co/${model.id}/resolve/main/${nameWithoutNamespace(model.id)}-any-py3-none-any.whl\n\n# Using spacy.load().\nimport spacy\nnlp = spacy.load(\"${nameWithoutNamespace(model.id)}\")\n\n# Importing as module.\nimport ${nameWithoutNamespace(model.id)}\nnlp = ${nameWithoutNamespace(model.id)}.load()`,\n];\nexport const span_marker = (model) => [\n    `from span_marker import SpanMarkerModel\n\nmodel = SpanMarkerModel.from_pretrained(\"${model.id}\")`,\n];\nexport const stanza = (model) => [\n    `import stanza\n\nstanza.download(\"${nameWithoutNamespace(model.id).replace(\"stanza-\", \"\")}\")\nnlp = stanza.Pipeline(\"${nameWithoutNamespace(model.id).replace(\"stanza-\", \"\")}\")`,\n];\nconst speechBrainMethod = (speechbrainInterface) => {\n    switch (speechbrainInterface) {\n        case \"EncoderClassifier\":\n            return \"classify_file\";\n        case \"EncoderDecoderASR\":\n        case \"EncoderASR\":\n            return \"transcribe_file\";\n        case \"SpectralMaskEnhancement\":\n            return \"enhance_file\";\n        case \"SepformerSeparation\":\n            return \"separate_file\";\n        default:\n            return undefined;\n    }\n};\nexport const speechbrain = (model) => {\n    const speechbrainInterface = model.config?.speechbrain?.speechbrain_interface;\n    if (speechbrainInterface === undefined) {\n        return [`# interface not specified in config.json`];\n    }\n    const speechbrainMethod = speechBrainMethod(speechbrainInterface);\n    if (speechbrainMethod === undefined) {\n        return [`# interface in config.json invalid`];\n    }\n    return [\n        `from speechbrain.pretrained import ${speechbrainInterface}\nmodel = ${speechbrainInterface}.from_hparams(\n  \"${model.id}\"\n)\nmodel.${speechbrainMethod}(\"file.wav\")`,\n    ];\n};\nexport const terratorch = (model) => [\n    `from terratorch.registry import BACKBONE_REGISTRY\n\nmodel = BACKBONE_REGISTRY.build(\"${model.id}\")`,\n];\nconst hasChatTemplate = (model) => model.config?.tokenizer_config?.chat_template !== undefined ||\n    model.config?.processor_config?.chat_template !== undefined ||\n    model.config?.chat_template_jinja !== undefined;\nexport const transformers = (model) => {\n    const info = model.transformersInfo;\n    if (!info) {\n        return [`#  Type of model unknown`];\n    }\n    const remote_code_snippet = model.tags.includes(TAG_CUSTOM_CODE) ? \", trust_remote_code=True\" : \"\";\n    const autoSnippet = [];\n    if (info.processor) {\n        const processorVarName = info.processor === \"AutoTokenizer\"\n            ? \"tokenizer\"\n            : info.processor === \"AutoFeatureExtractor\"\n                ? \"extractor\"\n                : \"processor\";\n        autoSnippet.push(\"# Load model directly\", `from transformers import ${info.processor}, ${info.auto_model}`, \"\", `${processorVarName} = ${info.processor}.from_pretrained(\"${model.id}\"` + remote_code_snippet + \")\", `model = ${info.auto_model}.from_pretrained(\"${model.id}\"` + remote_code_snippet + \")\");\n        if (model.tags.includes(\"conversational\") && hasChatTemplate(model)) {\n            if (model.tags.includes(\"image-text-to-text\")) {\n                autoSnippet.push(\"messages = [\", [\n                    \"    {\",\n                    '        \"role\": \"user\",',\n                    '        \"content\": [',\n                    '            {\"type\": \"image\", \"url\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/p-blog/candy.JPG\"},',\n                    '            {\"type\": \"text\", \"text\": \"What animal is on the candy?\"}',\n                    \"        ]\",\n                    \"    },\",\n                ].join(\"\\n\"), \"]\");\n            }\n            else {\n                autoSnippet.push(\"messages = [\", '    {\"role\": \"user\", \"content\": \"Who are you?\"},', \"]\");\n            }\n            autoSnippet.push(`inputs = ${processorVarName}.apply_chat_template(`, \"\tmessages,\", \"\tadd_generation_prompt=True,\", \"\ttokenize=True,\", \"\treturn_dict=True,\", '\treturn_tensors=\"pt\",', \").to(model.device)\", \"\", \"outputs = model.generate(**inputs, max_new_tokens=40)\", `print(${processorVarName}.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:]))`);\n        }\n    }\n    else {\n        autoSnippet.push(\"# Load model directly\", `from transformers import ${info.auto_model}`, `model = ${info.auto_model}.from_pretrained(\"${model.id}\"` + remote_code_snippet + ', dtype=\"auto\")');\n    }\n    if (model.pipeline_tag && LIBRARY_TASK_MAPPING.transformers?.includes(model.pipeline_tag)) {\n        const pipelineSnippet = [\n            \"# Use a pipeline as a high-level helper\",\n            \"from transformers import pipeline\",\n            \"\",\n            `pipe = pipeline(\"${model.pipeline_tag}\", model=\"${model.id}\"` + remote_code_snippet + \")\",\n        ];\n        if (model.tags.includes(\"conversational\")) {\n            if (model.tags.includes(\"image-text-to-text\")) {\n                pipelineSnippet.push(\"messages = [\", [\n                    \"    {\",\n                    '        \"role\": \"user\",',\n                    '        \"content\": [',\n                    '            {\"type\": \"image\", \"url\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/p-blog/candy.JPG\"},',\n                    '            {\"type\": \"text\", \"text\": \"What animal is on the candy?\"}',\n                    \"        ]\",\n                    \"    },\",\n                ].join(\"\\n\"), \"]\");\n                pipelineSnippet.push(\"pipe(text=messages)\");\n            }\n            else {\n                pipelineSnippet.push(\"messages = [\", '    {\"role\": \"user\", \"content\": \"Who are you?\"},', \"]\");\n                pipelineSnippet.push(\"pipe(messages)\");\n            }\n        }\n        else if (model.pipeline_tag === \"zero-shot-image-classification\") {\n            pipelineSnippet.push(\"pipe(\", '    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/parrots.png\",', '    candidate_labels=[\"animals\", \"humans\", \"landscape\"],', \")\");\n        }\n        else if (model.pipeline_tag === \"image-classification\") {\n            pipelineSnippet.push('pipe(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/parrots.png\")');\n        }\n        return [pipelineSnippet.join(\"\\n\"), autoSnippet.join(\"\\n\")];\n    }\n    return [autoSnippet.join(\"\\n\")];\n};\nexport const transformersJS = (model) => {\n    if (!model.pipeline_tag) {\n        return [`//  Unknown pipeline tag`];\n    }\n    const libName = \"@huggingface/transformers\";\n    return [\n        `// npm i ${libName}\nimport { pipeline } from '${libName}';\n\n// Allocate pipeline\nconst pipe = await pipeline('${model.pipeline_tag}', '${model.id}');`,\n    ];\n};\nconst peftTask = (peftTaskType) => {\n    switch (peftTaskType) {\n        case \"CAUSAL_LM\":\n            return \"CausalLM\";\n        case \"SEQ_2_SEQ_LM\":\n            return \"Seq2SeqLM\";\n        case \"TOKEN_CLS\":\n            return \"TokenClassification\";\n        case \"SEQ_CLS\":\n            return \"SequenceClassification\";\n        default:\n            return undefined;\n    }\n};\nexport const peft = (model) => {\n    const { base_model_name_or_path: peftBaseModel, task_type: peftTaskType } = model.config?.peft ?? {};\n    const pefttask = peftTask(peftTaskType);\n    if (!pefttask) {\n        return [`Task type is invalid.`];\n    }\n    if (!peftBaseModel) {\n        return [`Base model is not found.`];\n    }\n    return [\n        `from peft import PeftModel\nfrom transformers import AutoModelFor${pefttask}\n\nbase_model = AutoModelFor${pefttask}.from_pretrained(\"${peftBaseModel}\")\nmodel = PeftModel.from_pretrained(base_model, \"${model.id}\")`,\n    ];\n};\nexport const fasttext = (model) => [\n    `from huggingface_hub import hf_hub_download\nimport fasttext\n\nmodel = fasttext.load_model(hf_hub_download(\"${model.id}\", \"model.bin\"))`,\n];\nexport const stableBaselines3 = (model) => [\n    `from huggingface_sb3 import load_from_hub\ncheckpoint = load_from_hub(\n\trepo_id=\"${model.id}\",\n\tfilename=\"{MODEL FILENAME}.zip\",\n)`,\n];\nconst nemoDomainResolver = (domain, model) => {\n    switch (domain) {\n        case \"ASR\":\n            return [\n                `import nemo.collections.asr as nemo_asr\nasr_model = nemo_asr.models.ASRModel.from_pretrained(\"${model.id}\")\n\ntranscriptions = asr_model.transcribe([\"file.wav\"])`,\n            ];\n        default:\n            return undefined;\n    }\n};\nexport const mlAgents = (model) => [\n    `mlagents-load-from-hf --repo-id=\"${model.id}\" --local-dir=\"./download: string[]s\"`,\n];\nexport const sentis = ( /* model: ModelData */) => [\n    `string modelName = \"[Your model name here].sentis\";\nModel model = ModelLoader.Load(Application.streamingAssetsPath + \"/\" + modelName);\nIWorker engine = WorkerFactory.CreateWorker(BackendType.GPUCompute, model);\n// Please see provided C# file for more details\n`,\n];\nexport const sana = (model) => [\n    `\n# Load the model and infer image from text\nimport torch\nfrom app.sana_pipeline import SanaPipeline\nfrom torchvision.utils import save_image\n\nsana = SanaPipeline(\"configs/sana_config/1024ms/Sana_1600M_img1024.yaml\")\nsana.from_pretrained(\"hf://${model.id}\")\n\nimage = sana(\n    prompt='a cyberpunk cat with a neon sign that says \"Sana\"',\n    height=1024,\n    width=1024,\n    guidance_scale=5.0,\n    pag_guidance_scale=2.0,\n    num_inference_steps=18,\n) `,\n];\nexport const vibevoice = (model) => [\n    `import torch, soundfile as sf, librosa, numpy as np\nfrom vibevoice.processor.vibevoice_processor import VibeVoiceProcessor\nfrom vibevoice.modular.modeling_vibevoice_inference import VibeVoiceForConditionalGenerationInference\n\n# Load voice sample (should be 24kHz mono)\nvoice, sr = sf.read(\"path/to/voice_sample.wav\")\nif voice.ndim > 1: voice = voice.mean(axis=1)\nif sr != 24000: voice = librosa.resample(voice, sr, 24000)\n\nprocessor = VibeVoiceProcessor.from_pretrained(\"${model.id}\")\nmodel = VibeVoiceForConditionalGenerationInference.from_pretrained(\n    \"${model.id}\", torch_dtype=torch.bfloat16\n).to(\"cuda\").eval()\nmodel.set_ddpm_inference_steps(5)\n\ninputs = processor(text=[\"Speaker 0: Hello!\\\\nSpeaker 1: Hi there!\"],\n                   voice_samples=[[voice]], return_tensors=\"pt\")\naudio = model.generate(**inputs, cfg_scale=1.3,\n                       tokenizer=processor.tokenizer).speech_outputs[0]\nsf.write(\"output.wav\", audio.cpu().numpy().squeeze(), 24000)`,\n];\nexport const videoprism = (model) => [\n    `# Install from https://github.com/google-deepmind/videoprism\nimport jax\nfrom videoprism import models as vp\n\nflax_model = vp.get_model(\"${model.id}\")\nloaded_state = vp.load_pretrained_weights(\"${model.id}\")\n\n@jax.jit\ndef forward_fn(inputs, train=False):\n  return flax_model.apply(loaded_state, inputs, train=train)`,\n];\nexport const vfimamba = (model) => [\n    `from Trainer_finetune import Model\n\nmodel = Model.from_pretrained(\"${model.id}\")`,\n];\nexport const lvface = (model) => [\n    `from huggingface_hub import hf_hub_download\n\t from inference_onnx import LVFaceONNXInferencer\n\nmodel_path = hf_hub_download(\"${model.id}\", \"LVFace-L_Glint360K/LVFace-L_Glint360K.onnx\")\ninferencer = LVFaceONNXInferencer(model_path, use_gpu=True, timeout=300)\nimg_path = 'path/to/image1.jpg'\nembedding = inferencer.infer_from_image(img_path)`,\n];\nexport const voicecraft = (model) => [\n    `from voicecraft import VoiceCraft\n\nmodel = VoiceCraft.from_pretrained(\"${model.id}\")`,\n];\nexport const voxcpm = (model) => [\n    `import soundfile as sf\nfrom voxcpm import VoxCPM\n\nmodel = VoxCPM.from_pretrained(\"${model.id}\")\n\nwav = model.generate(\n    text=\"VoxCPM is an innovative end-to-end TTS model from ModelBest, designed to generate highly expressive speech.\",\n    prompt_wav_path=None,      # optional: path to a prompt speech for voice cloning\n    prompt_text=None,          # optional: reference text\n    cfg_value=2.0,             # LM guidance on LocDiT, higher for better adherence to the prompt, but maybe worse\n    inference_timesteps=10,   # LocDiT inference timesteps, higher for better result, lower for fast speed\n    normalize=True,           # enable external TN tool\n    denoise=True,             # enable external Denoise tool\n    retry_badcase=True,        # enable retrying mode for some bad cases (unstoppable)\n    retry_badcase_max_times=3,  # maximum retrying times\n    retry_badcase_ratio_threshold=6.0, # maximum length restriction for bad case detection (simple but effective), it could be adjusted for slow pace speech\n)\n\nsf.write(\"output.wav\", wav, 16000)\nprint(\"saved: output.wav\")`,\n];\nexport const vui = () => [\n    `# !pip install git+https://github.com/fluxions-ai/vui\n\nimport torchaudio\n\nfrom vui.inference import render\nfrom vui.model import Vui,\n\nmodel = Vui.from_pretrained().cuda()\nwaveform = render(\n    model,\n    \"Hey, here is some random stuff, usually something quite long as the shorter the text the less likely the model can cope!\",\n)\nprint(waveform.shape)\ntorchaudio.save(\"out.opus\", waveform[0], 22050)\n`,\n];\nexport const chattts = () => [\n    `import ChatTTS\nimport torchaudio\n\nchat = ChatTTS.Chat()\nchat.load_models(compile=False) # Set to True for better performance\n\ntexts = [\"PUT YOUR TEXT HERE\",]\n\nwavs = chat.infer(texts, )\n\ntorchaudio.save(\"output1.wav\", torch.from_numpy(wavs[0]), 24000)`,\n];\nexport const ultralytics = (model) => {\n    // ultralytics models must have a version tag (e.g. `yolov8`)\n    const versionTag = model.tags.find((tag) => tag.match(/^yolov\\d+$/));\n    const className = versionTag ? `YOLOv${versionTag.slice(4)}` : \"YOLOvXX\";\n    const prefix = versionTag\n        ? \"\"\n        : `# Couldn't find a valid YOLO version tag.\\n# Replace XX with the correct version.\\n`;\n    return [\n        prefix +\n            `from ultralytics import ${className}\n\nmodel = ${className}.from_pretrained(\"${model.id}\")\nsource = 'http://images.cocodataset.org/val2017/000000039769.jpg'\nmodel.predict(source=source, save=True)`,\n    ];\n};\nexport const birefnet = (model) => [\n    `# Option 1: use with transformers\n\nfrom transformers import AutoModelForImageSegmentation\nbirefnet = AutoModelForImageSegmentation.from_pretrained(\"${model.id}\", trust_remote_code=True)\n`,\n    `# Option 2: use with BiRefNet\n\n# Install from https://github.com/ZhengPeng7/BiRefNet\n\nfrom models.birefnet import BiRefNet\nmodel = BiRefNet.from_pretrained(\"${model.id}\")`,\n];\nexport const supertonic = () => [\n    `from supertonic import TTS\n\ntts = TTS(auto_download=True)\n\nstyle = tts.get_voice_style(voice_name=\"M1\")\n\ntext = \"The train delay was announced at 4:45 PM on Wed, Apr 3, 2024 due to track maintenance.\"\nwav, duration = tts.synthesize(text, voice_style=style)\n\ntts.save_audio(wav, \"output.wav\")`,\n];\nexport const swarmformer = (model) => [\n    `from swarmformer import SwarmFormerModel\n\nmodel = SwarmFormerModel.from_pretrained(\"${model.id}\")\n`,\n];\nexport const univa = (model) => [\n    `# Follow installation instructions at https://github.com/PKU-YuanGroup/UniWorld-V1\n\nfrom univa.models.qwen2p5vl.modeling_univa_qwen2p5vl import UnivaQwen2p5VLForConditionalGeneration\n\tmodel = UnivaQwen2p5VLForConditionalGeneration.from_pretrained(\n        \"${model.id}\",\n        torch_dtype=torch.bfloat16,\n        attn_implementation=\"flash_attention_2\",\n    ).to(\"cuda\")\n\tprocessor = AutoProcessor.from_pretrained(\"${model.id}\")\n`,\n];\nconst mlx_unknown = (model) => [\n    `# Download the model from the Hub\npip install huggingface_hub[hf_xet]\n\nhuggingface-cli download --local-dir ${nameWithoutNamespace(model.id)} ${model.id}`,\n];\nconst mlxlm = (model) => [\n    `# Make sure mlx-lm is installed\n# pip install --upgrade mlx-lm\n# if on a CUDA device, also pip install mlx[cuda]\n\n# Generate text with mlx-lm\nfrom mlx_lm import load, generate\n\nmodel, tokenizer = load(\"${model.id}\")\n\nprompt = \"Once upon a time in\"\ntext = generate(model, tokenizer, prompt=prompt, verbose=True)`,\n];\nconst mlxchat = (model) => [\n    `# Make sure mlx-lm is installed\n# pip install --upgrade mlx-lm\n\n# Generate text with mlx-lm\nfrom mlx_lm import load, generate\n\nmodel, tokenizer = load(\"${model.id}\")\n\nprompt = \"Write a story about Einstein\"\nmessages = [{\"role\": \"user\", \"content\": prompt}]\nprompt = tokenizer.apply_chat_template(\n    messages, add_generation_prompt=True\n)\n\ntext = generate(model, tokenizer, prompt=prompt, verbose=True)`,\n];\nconst mlxvlm = (model) => [\n    `# Make sure mlx-vlm is installed\n# pip install --upgrade mlx-vlm\n\nfrom mlx_vlm import load, generate\nfrom mlx_vlm.prompt_utils import apply_chat_template\nfrom mlx_vlm.utils import load_config\n\n# Load the model\nmodel, processor = load(\"${model.id}\")\nconfig = load_config(\"${model.id}\")\n\n# Prepare input\nimage = [\"http://images.cocodataset.org/val2017/000000039769.jpg\"]\nprompt = \"Describe this image.\"\n\n# Apply chat template\nformatted_prompt = apply_chat_template(\n    processor, config, prompt, num_images=1\n)\n\n# Generate output\noutput = generate(model, processor, formatted_prompt, image)\nprint(output)`,\n];\nexport const mlxim = (model) => [\n    `from mlxim.model import create_model\n\nmodel = create_model(${model.id})`,\n];\nexport const mlx = (model) => {\n    if (model.pipeline_tag === \"image-text-to-text\") {\n        return mlxvlm(model);\n    }\n    if (model.pipeline_tag === \"text-generation\") {\n        if (model.tags.includes(\"conversational\")) {\n            return mlxchat(model);\n        }\n        else {\n            return mlxlm(model);\n        }\n    }\n    return mlx_unknown(model);\n};\nexport const model2vec = (model) => [\n    `from model2vec import StaticModel\n\nmodel = StaticModel.from_pretrained(\"${model.id}\")`,\n];\nexport const pruna = (model) => {\n    let snippets;\n    if (model.tags.includes(\"diffusers\")) {\n        snippets = pruna_diffusers(model);\n    }\n    else if (model.tags.includes(\"transformers\")) {\n        snippets = pruna_transformers(model);\n    }\n    else {\n        snippets = pruna_default(model);\n    }\n    const ensurePrunaModelImport = (snippet) => {\n        if (!/^from pruna import PrunaModel/m.test(snippet)) {\n            return `from pruna import PrunaModel\\n${snippet}`;\n        }\n        return snippet;\n    };\n    snippets = snippets.map(ensurePrunaModelImport);\n    if (model.tags.includes(\"pruna_pro-ai\")) {\n        return snippets.map((snippet) => snippet.replace(/\\bpruna\\b/g, \"pruna_pro\").replace(/\\bPrunaModel\\b/g, \"PrunaProModel\"));\n    }\n    return snippets;\n};\nconst pruna_diffusers = (model) => {\n    const diffusersSnippets = diffusers(model);\n    return diffusersSnippets.map((snippet) => snippet\n        // Replace pipeline classes with PrunaModel\n        .replace(/\\b\\w*Pipeline\\w*\\b/g, \"PrunaModel\")\n        // Clean up diffusers imports containing PrunaModel\n        .replace(/from diffusers import ([^,\\n]*PrunaModel[^,\\n]*)/g, \"\")\n        .replace(/from diffusers import ([^,\\n]+),?\\s*([^,\\n]*PrunaModel[^,\\n]*)/g, \"from diffusers import $1\")\n        .replace(/from diffusers import\\s*(\\n|$)/g, \"\")\n        // Fix PrunaModel imports\n        .replace(/from diffusers import PrunaModel/g, \"from pruna import PrunaModel\")\n        .replace(/from diffusers import ([^,\\n]+), PrunaModel/g, \"from diffusers import $1\")\n        .replace(/from diffusers import PrunaModel, ([^,\\n]+)/g, \"from diffusers import $1\")\n        // Clean up whitespace\n        .replace(/\\n\\n+/g, \"\\n\")\n        .trim());\n};\nconst pruna_transformers = (model) => {\n    const info = model.transformersInfo;\n    const transformersSnippets = transformers(model);\n    // Replace pipeline with PrunaModel\n    let processedSnippets = transformersSnippets.map((snippet) => snippet\n        .replace(/from transformers import pipeline/g, \"from pruna import PrunaModel\")\n        .replace(/pipeline\\([^)]*\\)/g, `PrunaModel.from_pretrained(\"${model.id}\")`));\n    // Additional cleanup if auto_model info is available\n    if (info?.auto_model) {\n        processedSnippets = processedSnippets.map((snippet) => snippet\n            .replace(new RegExp(`from transformers import ${info.auto_model}\\n?`, \"g\"), \"\")\n            .replace(new RegExp(`${info.auto_model}.from_pretrained`, \"g\"), \"PrunaModel.from_pretrained\")\n            .replace(new RegExp(`^.*from.*import.*(, *${info.auto_model})+.*$`, \"gm\"), (line) => line.replace(new RegExp(`, *${info.auto_model}`, \"g\"), \"\")));\n    }\n    return processedSnippets;\n};\nconst pruna_default = (model) => [\n    `from pruna import PrunaModel\nmodel = PrunaModel.from_pretrained(\"${model.id}\")\n`,\n];\nexport const nemo = (model) => {\n    let command = undefined;\n    // Resolve the tag to a nemo domain/sub-domain\n    if (model.tags.includes(\"automatic-speech-recognition\")) {\n        command = nemoDomainResolver(\"ASR\", model);\n    }\n    return command ?? [`# tag did not correspond to a valid NeMo domain.`];\n};\nexport const outetts = (model) => {\n    // Dont show this block on GGUF / ONNX mirrors\n    const t = model.tags ?? [];\n    if (t.includes(\"gguf\") || t.includes(\"onnx\"))\n        return [];\n    // v1.0 HF  minimal runnable snippet\n    return [\n        `\n  import outetts\n  \n  enum = outetts.Models(\"${model.id}\".split(\"/\", 1)[1])       # VERSION_1_0_SIZE_1B\n  cfg  = outetts.ModelConfig.auto_config(enum, outetts.Backend.HF)\n  tts  = outetts.Interface(cfg)\n  \n  speaker = tts.load_default_speaker(\"EN-FEMALE-1-NEUTRAL\")\n  tts.generate(\n\t  outetts.GenerationConfig(\n\t\t  text=\"Hello there, how are you doing?\",\n\t\t  speaker=speaker,\n\t  )\n  ).save(\"output.wav\")\n  `,\n    ];\n};\nexport const pxia = (model) => [\n    `from pxia import AutoModel\n\nmodel = AutoModel.from_pretrained(\"${model.id}\")`,\n];\nexport const pythae = (model) => [\n    `from pythae.models import AutoModel\n\nmodel = AutoModel.load_from_hf_hub(\"${model.id}\")`,\n];\nconst musicgen = (model) => [\n    `from audiocraft.models import MusicGen\n\nmodel = MusicGen.get_pretrained(\"${model.id}\")\n\ndescriptions = ['happy rock', 'energetic EDM', 'sad jazz']\nwav = model.generate(descriptions)  # generates 3 samples.`,\n];\nconst magnet = (model) => [\n    `from audiocraft.models import MAGNeT\n\t\nmodel = MAGNeT.get_pretrained(\"${model.id}\")\n\ndescriptions = ['disco beat', 'energetic EDM', 'funky groove']\nwav = model.generate(descriptions)  # generates 3 samples.`,\n];\nconst audiogen = (model) => [\n    `from audiocraft.models import AudioGen\n\t\nmodel = AudioGen.get_pretrained(\"${model.id}\")\nmodel.set_generation_params(duration=5)  # generate 5 seconds.\ndescriptions = ['dog barking', 'sirene of an emergency vehicle', 'footsteps in a corridor']\nwav = model.generate(descriptions)  # generates 3 samples.`,\n];\nexport const anemoi = (model) => [\n    `from anemoi.inference.runners.default import DefaultRunner\nfrom anemoi.inference.config.run import RunConfiguration\n# Create Configuration\nconfig = RunConfiguration(checkpoint = {\"huggingface\":\"${model.id}\"})\n# Load Runner\nrunner = DefaultRunner(config)`,\n];\nexport const audiocraft = (model) => {\n    if (model.tags.includes(\"musicgen\")) {\n        return musicgen(model);\n    }\n    else if (model.tags.includes(\"audiogen\")) {\n        return audiogen(model);\n    }\n    else if (model.tags.includes(\"magnet\")) {\n        return magnet(model);\n    }\n    else {\n        return [`# Type of model unknown.`];\n    }\n};\nexport const whisperkit = () => [\n    `# Install CLI with Homebrew on macOS device\nbrew install whisperkit-cli\n\n# View all available inference options\nwhisperkit-cli transcribe --help\n\t\n# Download and run inference using whisper base model\nwhisperkit-cli transcribe --audio-path /path/to/audio.mp3\n\n# Or use your preferred model variant\nwhisperkit-cli transcribe --model \"large-v3\" --model-prefix \"distil\" --audio-path /path/to/audio.mp3 --verbose`,\n];\nexport const threedtopia_xl = (model) => [\n    `from threedtopia_xl.models import threedtopia_xl\n\nmodel = threedtopia_xl.from_pretrained(\"${model.id}\")\nmodel.generate(cond=\"path/to/image.png\")`,\n];\nexport const hezar = (model) => [\n    `from hezar import Model\n\nmodel = Model.load(\"${model.id}\")`,\n];\nexport const zonos = (model) => [\n    `# pip install git+https://github.com/Zyphra/Zonos.git\nimport torchaudio\nfrom zonos.model import Zonos\nfrom zonos.conditioning import make_cond_dict\n\nmodel = Zonos.from_pretrained(\"${model.id}\", device=\"cuda\")\n\nwav, sr = torchaudio.load(\"speaker.wav\")           # 5-10s reference clip\nspeaker = model.make_speaker_embedding(wav, sr)\n\ncond  = make_cond_dict(text=\"Hello, world!\", speaker=speaker, language=\"en-us\")\ncodes = model.generate(model.prepare_conditioning(cond))\n\naudio = model.autoencoder.decode(codes)[0].cpu()\ntorchaudio.save(\"sample.wav\", audio, model.autoencoder.sampling_rate)\n`,\n];\n//#endregion\n","import * as snippets from \"./model-libraries-snippets.js\";\n/**\n * Add your new library here.\n *\n * This is for modeling (= architectures) libraries, not for file formats (like ONNX, etc).\n * (unlike libraries, file formats live in an enum inside the internal codebase.)\n *\n * Doc on how to add a library to the Hub:\n *\n * https://huggingface.co/docs/hub/models-adding-libraries\n *\n * /!\\ IMPORTANT\n *\n * The key you choose is the tag your models have in their library_name on the Hub.\n */\nexport const MODEL_LIBRARIES_UI_ELEMENTS = {\n    acestep: {\n        prettyLabel: \"ACE-Step\",\n        repoName: \"ACE-Step\",\n        repoUrl: \"https://github.com/ace-step/ACE-Step\",\n        filter: false,\n        countDownloads: `path:\"ace_step_transformer/config.json\"`,\n    },\n    \"adapter-transformers\": {\n        prettyLabel: \"Adapters\",\n        repoName: \"adapters\",\n        repoUrl: \"https://github.com/Adapter-Hub/adapters\",\n        docsUrl: \"https://huggingface.co/docs/hub/adapters\",\n        snippets: snippets.adapters,\n        filter: true,\n        countDownloads: `path:\"adapter_config.json\"`,\n    },\n    allennlp: {\n        prettyLabel: \"AllenNLP\",\n        repoName: \"AllenNLP\",\n        repoUrl: \"https://github.com/allenai/allennlp\",\n        docsUrl: \"https://huggingface.co/docs/hub/allennlp\",\n        snippets: snippets.allennlp,\n        filter: true,\n    },\n    anemoi: {\n        prettyLabel: \"AnemoI\",\n        repoName: \"AnemoI\",\n        repoUrl: \"https://github.com/ecmwf/anemoi-inference\",\n        docsUrl: \"https://anemoi.readthedocs.io/en/latest/\",\n        filter: false,\n        countDownloads: `path_extension:\"ckpt\"`,\n        snippets: snippets.anemoi,\n    },\n    araclip: {\n        prettyLabel: \"AraClip\",\n        repoName: \"AraClip\",\n        repoUrl: \"https://huggingface.co/Arabic-Clip/araclip\",\n        filter: false,\n        snippets: snippets.araclip,\n    },\n    asteroid: {\n        prettyLabel: \"Asteroid\",\n        repoName: \"Asteroid\",\n        repoUrl: \"https://github.com/asteroid-team/asteroid\",\n        docsUrl: \"https://huggingface.co/docs/hub/asteroid\",\n        snippets: snippets.asteroid,\n        filter: true,\n        countDownloads: `path:\"pytorch_model.bin\"`,\n    },\n    audiocraft: {\n        prettyLabel: \"Audiocraft\",\n        repoName: \"audiocraft\",\n        repoUrl: \"https://github.com/facebookresearch/audiocraft\",\n        snippets: snippets.audiocraft,\n        filter: false,\n        countDownloads: `path:\"state_dict.bin\"`,\n    },\n    audioseal: {\n        prettyLabel: \"AudioSeal\",\n        repoName: \"audioseal\",\n        repoUrl: \"https://github.com/facebookresearch/audioseal\",\n        filter: false,\n        countDownloads: `path_extension:\"pth\"`,\n        snippets: snippets.audioseal,\n    },\n    \"bagel-mot\": {\n        prettyLabel: \"Bagel\",\n        repoName: \"Bagel\",\n        repoUrl: \"https://github.com/ByteDance-Seed/Bagel/\",\n        filter: false,\n        countDownloads: `path:\"llm_config.json\"`,\n    },\n    bboxmaskpose: {\n        prettyLabel: \"BBoxMaskPose\",\n        repoName: \"BBoxMaskPose\",\n        repoUrl: \"https://github.com/MiraPurkrabek/BBoxMaskPose\",\n        filter: false,\n        countDownloads: `path_extension:\"pth\"`,\n    },\n    ben2: {\n        prettyLabel: \"BEN2\",\n        repoName: \"BEN2\",\n        repoUrl: \"https://github.com/PramaLLC/BEN2\",\n        snippets: snippets.ben2,\n        filter: false,\n    },\n    bertopic: {\n        prettyLabel: \"BERTopic\",\n        repoName: \"BERTopic\",\n        repoUrl: \"https://github.com/MaartenGr/BERTopic\",\n        snippets: snippets.bertopic,\n        filter: true,\n    },\n    big_vision: {\n        prettyLabel: \"Big Vision\",\n        repoName: \"big_vision\",\n        repoUrl: \"https://github.com/google-research/big_vision\",\n        filter: false,\n        countDownloads: `path_extension:\"npz\"`,\n    },\n    birder: {\n        prettyLabel: \"Birder\",\n        repoName: \"Birder\",\n        repoUrl: \"https://gitlab.com/birder/birder\",\n        filter: false,\n        countDownloads: `path_extension:\"pt\"`,\n    },\n    birefnet: {\n        prettyLabel: \"BiRefNet\",\n        repoName: \"BiRefNet\",\n        repoUrl: \"https://github.com/ZhengPeng7/BiRefNet\",\n        snippets: snippets.birefnet,\n        filter: false,\n    },\n    bm25s: {\n        prettyLabel: \"BM25S\",\n        repoName: \"bm25s\",\n        repoUrl: \"https://github.com/xhluca/bm25s\",\n        snippets: snippets.bm25s,\n        filter: false,\n        countDownloads: `path:\"params.index.json\"`,\n    },\n    boltzgen: {\n        prettyLabel: \"BoltzGen\",\n        repoName: \"BoltzGen\",\n        repoUrl: \"https://github.com/HannesStark/boltzgen\",\n        filter: false,\n        countDownloads: `path:\"boltzgen1_diverse.ckpt\"`,\n    },\n    cancertathomev2: {\n        prettyLabel: \"Cancer@HomeV2\",\n        repoName: \"Cancer@HomeV2\",\n        repoUrl: \"https://huggingface.co/OpenPeerAI/CancerAtHomeV2\",\n        filter: false,\n        countDownloads: `path:\"run.py\"`,\n    },\n    cartesia_pytorch: {\n        prettyLabel: \"Cartesia Pytorch\",\n        repoName: \"Cartesia Pytorch\",\n        repoUrl: \"https://github.com/cartesia-ai/cartesia_pytorch\",\n        snippets: snippets.cartesia_pytorch,\n    },\n    cartesia_mlx: {\n        prettyLabel: \"Cartesia MLX\",\n        repoName: \"Cartesia MLX\",\n        repoUrl: \"https://github.com/cartesia-ai/cartesia_mlx\",\n        snippets: snippets.cartesia_mlx,\n    },\n    champ: {\n        prettyLabel: \"Champ\",\n        repoName: \"Champ\",\n        repoUrl: \"https://github.com/fudan-generative-vision/champ\",\n        countDownloads: `path:\"champ/motion_module.pth\"`,\n    },\n    chatterbox: {\n        prettyLabel: \"Chatterbox\",\n        repoName: \"Chatterbox\",\n        repoUrl: \"https://github.com/resemble-ai/chatterbox\",\n        snippets: snippets.chatterbox,\n        countDownloads: `path:\"tokenizer.json\"`,\n        filter: false,\n    },\n    chaossim: {\n        prettyLabel: \"ChaosSIM\",\n        repoName: \"ChaosSIM\",\n        repoUrl: \"https://huggingface.co/OpenPeerAI/ChaosSIM/\",\n        countDownloads: `path:\"ChaosSim.nb\"`,\n        filter: false,\n    },\n    chat_tts: {\n        prettyLabel: \"ChatTTS\",\n        repoName: \"ChatTTS\",\n        repoUrl: \"https://github.com/2noise/ChatTTS.git\",\n        snippets: snippets.chattts,\n        filter: false,\n        countDownloads: `path:\"asset/GPT.pt\"`,\n    },\n    \"chronos-forecasting\": {\n        prettyLabel: \"Chronos\",\n        repoName: \"Chronos\",\n        repoUrl: \"https://github.com/amazon-science/chronos-forecasting\",\n        snippets: snippets.chronos_forecasting,\n    },\n    clara: {\n        prettyLabel: \"Clara\",\n        repoName: \"Clara\",\n        filter: false,\n        repoUrl: \"https://github.com/nvidia/clara\",\n        countDownloads: `path_extension:\"ckpt\" OR path:\"config.json\"`,\n    },\n    clipscope: {\n        prettyLabel: \"clipscope\",\n        repoName: \"clipscope\",\n        repoUrl: \"https://github.com/Lewington-pitsos/clipscope\",\n        filter: false,\n        countDownloads: `path_extension:\"pt\"`,\n    },\n    \"cloud-agents\": {\n        prettyLabel: \"Cloud Agents\",\n        repoName: \"Cloud Agents\",\n        repoUrl: \"https://huggingface.co/OpenPeerAI/Cloud-Agents\",\n        filter: false,\n        countDownloads: `path:\"setup.py\"`,\n    },\n    cosyvoice: {\n        prettyLabel: \"CosyVoice\",\n        repoName: \"CosyVoice\",\n        repoUrl: \"https://github.com/FunAudioLLM/CosyVoice\",\n        filter: false,\n        countDownloads: `path_extension:\"onnx\" OR path_extension:\"pt\"`,\n    },\n    cotracker: {\n        prettyLabel: \"CoTracker\",\n        repoName: \"CoTracker\",\n        repoUrl: \"https://github.com/facebookresearch/co-tracker\",\n        filter: false,\n        countDownloads: `path_extension:\"pth\"`,\n    },\n    colpali: {\n        prettyLabel: \"ColPali\",\n        repoName: \"ColPali\",\n        repoUrl: \"https://github.com/ManuelFay/colpali\",\n        filter: false,\n        countDownloads: `path:\"adapter_config.json\"`,\n    },\n    comet: {\n        prettyLabel: \"COMET\",\n        repoName: \"COMET\",\n        repoUrl: \"https://github.com/Unbabel/COMET/\",\n        countDownloads: `path:\"hparams.yaml\"`,\n    },\n    cosmos: {\n        prettyLabel: \"Cosmos\",\n        repoName: \"Cosmos\",\n        repoUrl: \"https://github.com/NVIDIA/Cosmos\",\n        countDownloads: `path:\"config.json\" OR path_extension:\"pt\"`,\n    },\n    \"cxr-foundation\": {\n        prettyLabel: \"CXR Foundation\",\n        repoName: \"cxr-foundation\",\n        repoUrl: \"https://github.com/google-health/cxr-foundation\",\n        snippets: snippets.cxr_foundation,\n        filter: false,\n        countDownloads: `path:\"precomputed_embeddings/embeddings.npz\" OR path:\"pax-elixr-b-text/saved_model.pb\"`,\n    },\n    deepforest: {\n        prettyLabel: \"DeepForest\",\n        repoName: \"deepforest\",\n        docsUrl: \"https://deepforest.readthedocs.io/en/latest/\",\n        repoUrl: \"https://github.com/weecology/DeepForest\",\n    },\n    \"depth-anything-v2\": {\n        prettyLabel: \"DepthAnythingV2\",\n        repoName: \"Depth Anything V2\",\n        repoUrl: \"https://github.com/DepthAnything/Depth-Anything-V2\",\n        snippets: snippets.depth_anything_v2,\n        filter: false,\n        countDownloads: `path_extension:\"pth\"`,\n    },\n    \"depth-pro\": {\n        prettyLabel: \"Depth Pro\",\n        repoName: \"Depth Pro\",\n        repoUrl: \"https://github.com/apple/ml-depth-pro\",\n        countDownloads: `path_extension:\"pt\"`,\n        snippets: snippets.depth_pro,\n        filter: false,\n    },\n    \"derm-foundation\": {\n        prettyLabel: \"Derm Foundation\",\n        repoName: \"derm-foundation\",\n        repoUrl: \"https://github.com/google-health/derm-foundation\",\n        snippets: snippets.derm_foundation,\n        filter: false,\n        countDownloads: `path:\"scin_dataset_precomputed_embeddings.npz\" OR path:\"saved_model.pb\"`,\n    },\n    \"describe-anything\": {\n        prettyLabel: \"Describe Anything\",\n        repoName: \"Describe Anything\",\n        repoUrl: \"https://github.com/NVlabs/describe-anything\",\n        snippets: snippets.describe_anything,\n        filter: false,\n    },\n    \"dia-tts\": {\n        prettyLabel: \"Dia\",\n        repoName: \"Dia\",\n        repoUrl: \"https://github.com/nari-labs/dia\",\n        snippets: snippets.dia,\n        filter: false,\n    },\n    dia2: {\n        prettyLabel: \"Dia2\",\n        repoName: \"Dia2\",\n        repoUrl: \"https://github.com/nari-labs/dia2\",\n        snippets: snippets.dia2,\n        filter: false,\n    },\n    \"diff-interpretation-tuning\": {\n        prettyLabel: \"Diff Interpretation Tuning\",\n        repoName: \"Diff Interpretation Tuning\",\n        repoUrl: \"https://github.com/Aviously/diff-interpretation-tuning\",\n        filter: false,\n        countDownloads: `path_extension:\"pt\"`,\n    },\n    diffree: {\n        prettyLabel: \"Diffree\",\n        repoName: \"Diffree\",\n        repoUrl: \"https://github.com/OpenGVLab/Diffree\",\n        filter: false,\n        countDownloads: `path:\"diffree-step=000010999.ckpt\"`,\n    },\n    diffusers: {\n        prettyLabel: \"Diffusers\",\n        repoName: \"/diffusers\",\n        repoUrl: \"https://github.com/huggingface/diffusers\",\n        docsUrl: \"https://huggingface.co/docs/hub/diffusers\",\n        snippets: snippets.diffusers,\n        filter: true,\n        /// diffusers has its own more complex \"countDownloads\" query\n    },\n    diffusionkit: {\n        prettyLabel: \"DiffusionKit\",\n        repoName: \"DiffusionKit\",\n        repoUrl: \"https://github.com/argmaxinc/DiffusionKit\",\n        snippets: snippets.diffusionkit,\n    },\n    \"docking-at-home\": {\n        prettyLabel: \"Docking@Home\",\n        repoName: \"Docking@Home\",\n        repoUrl: \"https://huggingface.co/OpenPeerAI/DockingAtHOME\",\n        filter: false,\n        countDownloads: `path:\"setup.py\"`,\n    },\n    doctr: {\n        prettyLabel: \"docTR\",\n        repoName: \"doctr\",\n        repoUrl: \"https://github.com/mindee/doctr\",\n    },\n    edsnlp: {\n        prettyLabel: \"EDS-NLP\",\n        repoName: \"edsnlp\",\n        repoUrl: \"https://github.com/aphp/edsnlp\",\n        docsUrl: \"https://aphp.github.io/edsnlp/latest/\",\n        filter: false,\n        snippets: snippets.edsnlp,\n        countDownloads: `path_filename:\"config\" AND path_extension:\"cfg\"`,\n    },\n    elm: {\n        prettyLabel: \"ELM\",\n        repoName: \"elm\",\n        repoUrl: \"https://github.com/slicex-ai/elm\",\n        filter: false,\n        countDownloads: `path_filename:\"slicex_elm_config\" AND path_extension:\"json\"`,\n    },\n    espnet: {\n        prettyLabel: \"ESPnet\",\n        repoName: \"ESPnet\",\n        repoUrl: \"https://github.com/espnet/espnet\",\n        docsUrl: \"https://huggingface.co/docs/hub/espnet\",\n        snippets: snippets.espnet,\n        filter: true,\n    },\n    fairseq: {\n        prettyLabel: \"Fairseq\",\n        repoName: \"fairseq\",\n        repoUrl: \"https://github.com/pytorch/fairseq\",\n        snippets: snippets.fairseq,\n        filter: true,\n    },\n    fastai: {\n        prettyLabel: \"fastai\",\n        repoName: \"fastai\",\n        repoUrl: \"https://github.com/fastai/fastai\",\n        docsUrl: \"https://huggingface.co/docs/hub/fastai\",\n        snippets: snippets.fastai,\n        filter: true,\n    },\n    fastprint: {\n        prettyLabel: \"Fast Print\",\n        repoName: \"Fast Print\",\n        repoUrl: \"https://huggingface.co/OpenPeerAI/FastPrint\",\n        countDownloads: `path_extension:\"cs\"`,\n    },\n    fasttext: {\n        prettyLabel: \"fastText\",\n        repoName: \"fastText\",\n        repoUrl: \"https://fasttext.cc/\",\n        snippets: snippets.fasttext,\n        filter: true,\n        countDownloads: `path_extension:\"bin\"`,\n    },\n    fixer: {\n        prettyLabel: \"Fixer\",\n        repoName: \"Fixer\",\n        repoUrl: \"https://github.com/nv-tlabs/Fixer\",\n        filter: false,\n        countDownloads: `path:\"pretrained/pretrained_fixer.pkl\"`,\n    },\n    flair: {\n        prettyLabel: \"Flair\",\n        repoName: \"Flair\",\n        repoUrl: \"https://github.com/flairNLP/flair\",\n        docsUrl: \"https://huggingface.co/docs/hub/flair\",\n        snippets: snippets.flair,\n        filter: true,\n        countDownloads: `path:\"pytorch_model.bin\"`,\n    },\n    fme: {\n        prettyLabel: \"Full Model Emulation\",\n        repoName: \"Full Model Emulation\",\n        repoUrl: \"https://github.com/ai2cm/ace\",\n        docsUrl: \"https://ai2-climate-emulator.readthedocs.io/en/latest/\",\n        filter: false,\n        countDownloads: `path_extension:\"tar\"`,\n    },\n    \"gemma.cpp\": {\n        prettyLabel: \"gemma.cpp\",\n        repoName: \"gemma.cpp\",\n        repoUrl: \"https://github.com/google/gemma.cpp\",\n        filter: false,\n        countDownloads: `path_extension:\"sbs\"`,\n    },\n    \"geometry-crafter\": {\n        prettyLabel: \"GeometryCrafter\",\n        repoName: \"GeometryCrafter\",\n        repoUrl: \"https://github.com/TencentARC/GeometryCrafter\",\n        countDownloads: `path:\"point_map_vae/diffusion_pytorch_model.safetensors\"`,\n    },\n    gliner: {\n        prettyLabel: \"GLiNER\",\n        repoName: \"GLiNER\",\n        repoUrl: \"https://github.com/urchade/GLiNER\",\n        snippets: snippets.gliner,\n        filter: false,\n        countDownloads: `path:\"gliner_config.json\"`,\n    },\n    gliner2: {\n        prettyLabel: \"GLiNER2\",\n        repoName: \"GLiNER2\",\n        repoUrl: \"https://github.com/fastino-ai/GLiNER2\",\n        snippets: snippets.gliner2,\n        filter: false,\n    },\n    \"glyph-byt5\": {\n        prettyLabel: \"Glyph-ByT5\",\n        repoName: \"Glyph-ByT5\",\n        repoUrl: \"https://github.com/AIGText/Glyph-ByT5\",\n        filter: false,\n        countDownloads: `path:\"checkpoints/byt5_model.pt\"`,\n    },\n    grok: {\n        prettyLabel: \"Grok\",\n        repoName: \"Grok\",\n        repoUrl: \"https://github.com/xai-org/grok-1\",\n        filter: false,\n        countDownloads: `path:\"ckpt/tensor00000_000\" OR path:\"ckpt-0/tensor00000_000\"`,\n    },\n    hallo: {\n        prettyLabel: \"Hallo\",\n        repoName: \"Hallo\",\n        repoUrl: \"https://github.com/fudan-generative-vision/hallo\",\n        countDownloads: `path:\"hallo/net.pth\"`,\n    },\n    hermes: {\n        prettyLabel: \"HERMES\",\n        repoName: \"HERMES\",\n        repoUrl: \"https://github.com/LMD0311/HERMES\",\n        filter: false,\n        countDownloads: `path:\"ckpt/hermes_final.pth\"`,\n    },\n    hezar: {\n        prettyLabel: \"Hezar\",\n        repoName: \"Hezar\",\n        repoUrl: \"https://github.com/hezarai/hezar\",\n        docsUrl: \"https://hezarai.github.io/hezar\",\n        countDownloads: `path:\"model_config.yaml\" OR path:\"embedding/embedding_config.yaml\"`,\n    },\n    htrflow: {\n        prettyLabel: \"HTRflow\",\n        repoName: \"HTRflow\",\n        repoUrl: \"https://github.com/AI-Riksarkivet/htrflow\",\n        docsUrl: \"https://ai-riksarkivet.github.io/htrflow\",\n        snippets: snippets.htrflow,\n    },\n    \"hunyuan-dit\": {\n        prettyLabel: \"HunyuanDiT\",\n        repoName: \"HunyuanDiT\",\n        repoUrl: \"https://github.com/Tencent/HunyuanDiT\",\n        countDownloads: `path:\"pytorch_model_ema.pt\" OR path:\"pytorch_model_distill.pt\"`,\n    },\n    \"hunyuan3d-2\": {\n        prettyLabel: \"Hunyuan3D-2\",\n        repoName: \"Hunyuan3D-2\",\n        repoUrl: \"https://github.com/Tencent/Hunyuan3D-2\",\n        countDownloads: `path_filename:\"model_index\" OR path_filename:\"config\"`,\n    },\n    \"hunyuanworld-voyager\": {\n        prettyLabel: \"HunyuanWorld-voyager\",\n        repoName: \"HunyuanWorld-voyager\",\n        repoUrl: \"https://github.com/Tencent-Hunyuan/HunyuanWorld-Voyager\",\n    },\n    \"hy-worldplay\": {\n        prettyLabel: \"HY-WorldPlay\",\n        repoName: \"HY-WorldPlay\",\n        repoUrl: \"https://github.com/Tencent-Hunyuan/HY-WorldPlay\",\n        filter: false,\n        countDownloads: `path_extension:\"json\"`,\n    },\n    \"image-matching-models\": {\n        prettyLabel: \"Image Matching Models\",\n        repoName: \"Image Matching Models\",\n        repoUrl: \"https://github.com/alexstoken/image-matching-models\",\n        filter: false,\n        countDownloads: `path_extension:\"safetensors\"`,\n    },\n    imstoucan: {\n        prettyLabel: \"IMS Toucan\",\n        repoName: \"IMS-Toucan\",\n        repoUrl: \"https://github.com/DigitalPhonetics/IMS-Toucan\",\n        countDownloads: `path:\"embedding_gan.pt\" OR path:\"Vocoder.pt\" OR path:\"ToucanTTS.pt\"`,\n    },\n    \"index-tts\": {\n        prettyLabel: \"IndexTTS\",\n        repoName: \"IndexTTS\",\n        repoUrl: \"https://github.com/index-tts/index-tts\",\n        snippets: snippets.indextts,\n        filter: false,\n    },\n    infinitetalk: {\n        prettyLabel: \"InfiniteTalk\",\n        repoName: \"InfiniteTalk\",\n        repoUrl: \"https://github.com/MeiGen-AI/InfiniteTalk\",\n        filter: false,\n        countDownloads: `path_extension:\"safetensors\"`,\n    },\n    \"infinite-you\": {\n        prettyLabel: \"InfiniteYou\",\n        repoName: \"InfiniteYou\",\n        repoUrl: \"https://github.com/bytedance/InfiniteYou\",\n        filter: false,\n        countDownloads: `path:\"infu_flux_v1.0/sim_stage1/image_proj_model.bin\" OR path:\"infu_flux_v1.0/aes_stage2/image_proj_model.bin\"`,\n    },\n    keras: {\n        prettyLabel: \"Keras\",\n        repoName: \"Keras\",\n        repoUrl: \"https://github.com/keras-team/keras\",\n        docsUrl: \"https://huggingface.co/docs/hub/keras\",\n        snippets: snippets.keras,\n        filter: true,\n        countDownloads: `path:\"config.json\" OR path_extension:\"keras\"`,\n    },\n    \"tf-keras\": {\n        // Legacy \"Keras 2\" library (tensorflow-only)\n        prettyLabel: \"TF-Keras\",\n        repoName: \"TF-Keras\",\n        repoUrl: \"https://github.com/keras-team/tf-keras\",\n        docsUrl: \"https://huggingface.co/docs/hub/tf-keras\",\n        snippets: snippets.tf_keras,\n        countDownloads: `path:\"saved_model.pb\"`,\n    },\n    \"keras-hub\": {\n        prettyLabel: \"KerasHub\",\n        repoName: \"KerasHub\",\n        repoUrl: \"https://github.com/keras-team/keras-hub\",\n        docsUrl: \"https://keras.io/keras_hub/\",\n        snippets: snippets.keras_hub,\n        filter: true,\n    },\n    kernels: {\n        prettyLabel: \"Kernels\",\n        repoName: \"Kernels\",\n        repoUrl: \"https://github.com/huggingface/kernels\",\n        docsUrl: \"https://huggingface.co/docs/kernels\",\n        snippets: snippets.kernels,\n        countDownloads: `path_filename:\"_ops\" AND path_extension:\"py\"`,\n    },\n    \"kimi-audio\": {\n        prettyLabel: \"KimiAudio\",\n        repoName: \"KimiAudio\",\n        repoUrl: \"https://github.com/MoonshotAI/Kimi-Audio\",\n        snippets: snippets.kimi_audio,\n        filter: false,\n    },\n    kittentts: {\n        prettyLabel: \"KittenTTS\",\n        repoName: \"KittenTTS\",\n        repoUrl: \"https://github.com/KittenML/KittenTTS\",\n        snippets: snippets.kittentts,\n    },\n    kronos: {\n        prettyLabel: \"KRONOS\",\n        repoName: \"KRONOS\",\n        repoUrl: \"https://github.com/mahmoodlab/KRONOS\",\n        filter: false,\n        countDownloads: `path_extension:\"pt\"`,\n    },\n    k2: {\n        prettyLabel: \"K2\",\n        repoName: \"k2\",\n        repoUrl: \"https://github.com/k2-fsa/k2\",\n    },\n    \"lightning-ir\": {\n        prettyLabel: \"Lightning IR\",\n        repoName: \"Lightning IR\",\n        repoUrl: \"https://github.com/webis-de/lightning-ir\",\n        snippets: snippets.lightning_ir,\n    },\n    litert: {\n        prettyLabel: \"LiteRT\",\n        repoName: \"LiteRT\",\n        repoUrl: \"https://github.com/google-ai-edge/LiteRT\",\n        filter: false,\n        countDownloads: `path_extension:\"tflite\"`,\n    },\n    \"litert-lm\": {\n        prettyLabel: \"LiteRT-LM\",\n        repoName: \"LiteRT-LM\",\n        repoUrl: \"https://github.com/google-ai-edge/LiteRT-LM\",\n        filter: false,\n        countDownloads: `path_extension:\"litertlm\" OR path_extension:\"task\"`,\n    },\n    lerobot: {\n        prettyLabel: \"LeRobot\",\n        repoName: \"LeRobot\",\n        repoUrl: \"https://github.com/huggingface/lerobot\",\n        docsUrl: \"https://huggingface.co/docs/lerobot\",\n        filter: false,\n        snippets: snippets.lerobot,\n    },\n    lightglue: {\n        prettyLabel: \"LightGlue\",\n        repoName: \"LightGlue\",\n        repoUrl: \"https://github.com/cvg/LightGlue\",\n        filter: false,\n        countDownloads: `path_extension:\"pth\" OR path:\"config.json\"`,\n    },\n    liveportrait: {\n        prettyLabel: \"LivePortrait\",\n        repoName: \"LivePortrait\",\n        repoUrl: \"https://github.com/KwaiVGI/LivePortrait\",\n        filter: false,\n        countDownloads: `path:\"liveportrait/landmark.onnx\"`,\n    },\n    \"llama-cpp-python\": {\n        prettyLabel: \"llama-cpp-python\",\n        repoName: \"llama-cpp-python\",\n        repoUrl: \"https://github.com/abetlen/llama-cpp-python\",\n        snippets: snippets.llama_cpp_python,\n    },\n    \"mini-omni2\": {\n        prettyLabel: \"Mini-Omni2\",\n        repoName: \"Mini-Omni2\",\n        repoUrl: \"https://github.com/gpt-omni/mini-omni2\",\n        countDownloads: `path:\"model_config.yaml\"`,\n    },\n    mindspore: {\n        prettyLabel: \"MindSpore\",\n        repoName: \"mindspore\",\n        repoUrl: \"https://github.com/mindspore-ai/mindspore\",\n    },\n    \"magi-1\": {\n        prettyLabel: \"MAGI-1\",\n        repoName: \"MAGI-1\",\n        repoUrl: \"https://github.com/SandAI-org/MAGI-1\",\n        countDownloads: `path:\"ckpt/vae/config.json\"`,\n    },\n    \"magenta-realtime\": {\n        prettyLabel: \"Magenta RT\",\n        repoName: \"Magenta RT\",\n        repoUrl: \"https://github.com/magenta/magenta-realtime\",\n        countDownloads: `path:\"checkpoints/llm_base_x4286_c1860k.tar\" OR path:\"checkpoints/llm_large_x3047_c1860k.tar\" OR path:\"checkpoints/llm_large_x3047_c1860k/checkpoint\"`,\n    },\n    \"mamba-ssm\": {\n        prettyLabel: \"MambaSSM\",\n        repoName: \"MambaSSM\",\n        repoUrl: \"https://github.com/state-spaces/mamba\",\n        filter: false,\n        snippets: snippets.mamba_ssm,\n    },\n    \"mars5-tts\": {\n        prettyLabel: \"MARS5-TTS\",\n        repoName: \"MARS5-TTS\",\n        repoUrl: \"https://github.com/Camb-ai/MARS5-TTS\",\n        filter: false,\n        countDownloads: `path:\"mars5_ar.safetensors\"`,\n        snippets: snippets.mars5_tts,\n    },\n    matanyone: {\n        prettyLabel: \"MatAnyone\",\n        repoName: \"MatAnyone\",\n        repoUrl: \"https://github.com/pq-yang/MatAnyone\",\n        snippets: snippets.matanyone,\n        filter: false,\n    },\n    \"mesh-anything\": {\n        prettyLabel: \"MeshAnything\",\n        repoName: \"MeshAnything\",\n        repoUrl: \"https://github.com/buaacyw/MeshAnything\",\n        filter: false,\n        countDownloads: `path:\"MeshAnything_350m.pth\"`,\n        snippets: snippets.mesh_anything,\n    },\n    merlin: {\n        prettyLabel: \"Merlin\",\n        repoName: \"Merlin\",\n        repoUrl: \"https://github.com/StanfordMIMI/Merlin\",\n        filter: false,\n        countDownloads: `path_extension:\"pt\"`,\n    },\n    medvae: {\n        prettyLabel: \"MedVAE\",\n        repoName: \"MedVAE\",\n        repoUrl: \"https://github.com/StanfordMIMI/MedVAE\",\n        filter: false,\n        countDownloads: `path_extension:\"ckpt\"`,\n    },\n    mitie: {\n        prettyLabel: \"MITIE\",\n        repoName: \"MITIE\",\n        repoUrl: \"https://github.com/mit-nlp/MITIE\",\n        countDownloads: `path_filename:\"total_word_feature_extractor\"`,\n    },\n    \"ml-agents\": {\n        prettyLabel: \"ml-agents\",\n        repoName: \"ml-agents\",\n        repoUrl: \"https://github.com/Unity-Technologies/ml-agents\",\n        docsUrl: \"https://huggingface.co/docs/hub/ml-agents\",\n        snippets: snippets.mlAgents,\n        filter: true,\n        countDownloads: `path_extension:\"onnx\"`,\n    },\n    \"ml-sharp\": {\n        prettyLabel: \"Sharp\",\n        repoName: \"Sharp\",\n        repoUrl: \"https://github.com/apple/ml-sharp\",\n        filter: false,\n        countDownloads: `path_extension:\"pt\"`,\n    },\n    mlx: {\n        prettyLabel: \"MLX\",\n        repoName: \"MLX\",\n        repoUrl: \"https://github.com/ml-explore/mlx-examples/tree/main\",\n        snippets: snippets.mlx,\n        filter: true,\n    },\n    \"mlx-image\": {\n        prettyLabel: \"mlx-image\",\n        repoName: \"mlx-image\",\n        repoUrl: \"https://github.com/riccardomusmeci/mlx-image\",\n        docsUrl: \"https://huggingface.co/docs/hub/mlx-image\",\n        snippets: snippets.mlxim,\n        filter: false,\n        countDownloads: `path:\"model.safetensors\"`,\n    },\n    \"mlc-llm\": {\n        prettyLabel: \"MLC-LLM\",\n        repoName: \"MLC-LLM\",\n        repoUrl: \"https://github.com/mlc-ai/mlc-llm\",\n        docsUrl: \"https://llm.mlc.ai/docs/\",\n        filter: false,\n        countDownloads: `path:\"mlc-chat-config.json\"`,\n    },\n    model2vec: {\n        prettyLabel: \"Model2Vec\",\n        repoName: \"model2vec\",\n        repoUrl: \"https://github.com/MinishLab/model2vec\",\n        snippets: snippets.model2vec,\n        filter: false,\n    },\n    moshi: {\n        prettyLabel: \"Moshi\",\n        repoName: \"Moshi\",\n        repoUrl: \"https://github.com/kyutai-labs/moshi\",\n        filter: false,\n        countDownloads: `path:\"tokenizer-e351c8d8-checkpoint125.safetensors\"`,\n    },\n    mtvcraft: {\n        prettyLabel: \"MTVCraft\",\n        repoName: \"MTVCraft\",\n        repoUrl: \"https://github.com/baaivision/MTVCraft\",\n        filter: false,\n        countDownloads: `path:\"vae/3d-vae.pt\"`,\n    },\n    nemo: {\n        prettyLabel: \"NeMo\",\n        repoName: \"NeMo\",\n        repoUrl: \"https://github.com/NVIDIA/NeMo\",\n        snippets: snippets.nemo,\n        filter: true,\n        countDownloads: `path_extension:\"nemo\" OR path:\"model_config.yaml\" OR path_extension:\"json\"`,\n    },\n    \"open-oasis\": {\n        prettyLabel: \"open-oasis\",\n        repoName: \"open-oasis\",\n        repoUrl: \"https://github.com/etched-ai/open-oasis\",\n        countDownloads: `path:\"oasis500m.safetensors\"`,\n    },\n    open_clip: {\n        prettyLabel: \"OpenCLIP\",\n        repoName: \"OpenCLIP\",\n        repoUrl: \"https://github.com/mlfoundations/open_clip\",\n        snippets: snippets.open_clip,\n        filter: true,\n        countDownloads: `path:\"open_clip_model.safetensors\"\n\t\t\tOR path:\"model.safetensors\"\n\t\t\tOR path:\"open_clip_pytorch_model.bin\"\n\t\t\tOR path:\"pytorch_model.bin\"`,\n    },\n    openpeerllm: {\n        prettyLabel: \"OpenPeerLLM\",\n        repoName: \"OpenPeerLLM\",\n        repoUrl: \"https://huggingface.co/openpeerai/openpeerllm\",\n        docsUrl: \"https://huggingface.co/OpenPeerAI/OpenPeerLLM/blob/main/README.md\",\n        countDownloads: `path:\".meta-huggingface.json\"`,\n        filter: false,\n    },\n    \"open-sora\": {\n        prettyLabel: \"Open-Sora\",\n        repoName: \"Open-Sora\",\n        repoUrl: \"https://github.com/hpcaitech/Open-Sora\",\n        filter: false,\n        countDownloads: `path:\"Open_Sora_v2.safetensors\"`,\n    },\n    outetts: {\n        prettyLabel: \"OuteTTS\",\n        repoName: \"OuteTTS\",\n        repoUrl: \"https://github.com/edwko/OuteTTS\",\n        snippets: snippets.outetts,\n        filter: false,\n    },\n    paddlenlp: {\n        prettyLabel: \"paddlenlp\",\n        repoName: \"PaddleNLP\",\n        repoUrl: \"https://github.com/PaddlePaddle/PaddleNLP\",\n        docsUrl: \"https://huggingface.co/docs/hub/paddlenlp\",\n        snippets: snippets.paddlenlp,\n        filter: true,\n        countDownloads: `path:\"model_config.json\"`,\n    },\n    PaddleOCR: {\n        prettyLabel: \"PaddleOCR\",\n        repoName: \"PaddleOCR\",\n        repoUrl: \"https://github.com/PaddlePaddle/PaddleOCR\",\n        docsUrl: \"https://www.paddleocr.ai/\",\n        snippets: snippets.paddleocr,\n        filter: true,\n        countDownloads: `path_extension:\"safetensors\" OR path:\"inference.pdiparams\"`,\n    },\n    peft: {\n        prettyLabel: \"PEFT\",\n        repoName: \"PEFT\",\n        repoUrl: \"https://github.com/huggingface/peft\",\n        snippets: snippets.peft,\n        filter: true,\n        countDownloads: `path:\"adapter_config.json\"`,\n    },\n    \"perception-encoder\": {\n        prettyLabel: \"PerceptionEncoder\",\n        repoName: \"PerceptionModels\",\n        repoUrl: \"https://github.com/facebookresearch/perception_models\",\n        filter: false,\n        snippets: snippets.perception_encoder,\n        countDownloads: `path_extension:\"pt\"`,\n    },\n    \"phantom-wan\": {\n        prettyLabel: \"Phantom\",\n        repoName: \"Phantom\",\n        repoUrl: \"https://github.com/Phantom-video/Phantom\",\n        snippets: snippets.phantom_wan,\n        filter: false,\n        countDownloads: `path_extension:\"pth\"`,\n    },\n    \"pruna-ai\": {\n        prettyLabel: \"Pruna AI\",\n        repoName: \"Pruna AI\",\n        repoUrl: \"https://github.com/PrunaAI/pruna\",\n        snippets: snippets.pruna,\n        docsUrl: \"https://docs.pruna.ai\",\n    },\n    pxia: {\n        prettyLabel: \"pxia\",\n        repoName: \"pxia\",\n        repoUrl: \"https://github.com/not-lain/pxia\",\n        snippets: snippets.pxia,\n        filter: false,\n    },\n    \"pyannote-audio\": {\n        prettyLabel: \"pyannote.audio\",\n        repoName: \"pyannote-audio\",\n        repoUrl: \"https://github.com/pyannote/pyannote-audio\",\n        snippets: snippets.pyannote_audio,\n        filter: true,\n    },\n    \"py-feat\": {\n        prettyLabel: \"Py-Feat\",\n        repoName: \"Py-Feat\",\n        repoUrl: \"https://github.com/cosanlab/py-feat\",\n        docsUrl: \"https://py-feat.org/\",\n        filter: false,\n    },\n    pythae: {\n        prettyLabel: \"pythae\",\n        repoName: \"pythae\",\n        repoUrl: \"https://github.com/clementchadebec/benchmark_VAE\",\n        snippets: snippets.pythae,\n        filter: false,\n    },\n    quantumpeer: {\n        prettyLabel: \"QuantumPeer\",\n        repoName: \"QuantumPeer\",\n        repoUrl: \"https://github.com/OpenPeer-AI/QuantumPeer\",\n        filter: false,\n        countDownloads: `path_extension:\"setup.py\"`,\n    },\n    recurrentgemma: {\n        prettyLabel: \"RecurrentGemma\",\n        repoName: \"recurrentgemma\",\n        repoUrl: \"https://github.com/google-deepmind/recurrentgemma\",\n        filter: false,\n        countDownloads: `path:\"tokenizer.model\"`,\n    },\n    relik: {\n        prettyLabel: \"Relik\",\n        repoName: \"Relik\",\n        repoUrl: \"https://github.com/SapienzaNLP/relik\",\n        snippets: snippets.relik,\n        filter: false,\n    },\n    refiners: {\n        prettyLabel: \"Refiners\",\n        repoName: \"Refiners\",\n        repoUrl: \"https://github.com/finegrain-ai/refiners\",\n        docsUrl: \"https://refine.rs/\",\n        filter: false,\n        countDownloads: `path:\"model.safetensors\"`,\n    },\n    renderformer: {\n        prettyLabel: \"RenderFormer\",\n        repoName: \"RenderFormer\",\n        repoUrl: \"https://github.com/microsoft/renderformer\",\n        snippets: snippets.renderformer,\n        filter: false,\n    },\n    reverb: {\n        prettyLabel: \"Reverb\",\n        repoName: \"Reverb\",\n        repoUrl: \"https://github.com/revdotcom/reverb\",\n        filter: false,\n    },\n    rkllm: {\n        prettyLabel: \"RKLLM\",\n        repoName: \"RKLLM\",\n        repoUrl: \"https://github.com/airockchip/rknn-llm\",\n        countDownloads: `path_extension:\"rkllm\"`,\n    },\n    saelens: {\n        prettyLabel: \"SAELens\",\n        repoName: \"SAELens\",\n        repoUrl: \"https://github.com/jbloomAus/SAELens\",\n        snippets: snippets.saelens,\n        filter: false,\n    },\n    sam2: {\n        prettyLabel: \"sam2\",\n        repoName: \"sam2\",\n        repoUrl: \"https://github.com/facebookresearch/segment-anything-2\",\n        filter: false,\n        snippets: snippets.sam2,\n        countDownloads: `path_extension:\"pt\"`,\n    },\n    \"sam-3d-body\": {\n        prettyLabel: \"SAM 3D Body\",\n        repoName: \"SAM 3D Body\",\n        repoUrl: \"https://github.com/facebookresearch/sam-3d-body\",\n        filter: false,\n        snippets: snippets.sam_3d_body,\n        countDownloads: `path:\"model_config.yaml\"`,\n    },\n    \"sam-3d-objects\": {\n        prettyLabel: \"SAM 3D Objects\",\n        repoName: \"SAM 3D Objects\",\n        repoUrl: \"https://github.com/facebookresearch/sam-3d-objects\",\n        filter: false,\n        snippets: snippets.sam_3d_objects,\n        countDownloads: `path:\"checkpoints/pipeline.yaml\"`,\n    },\n    same: {\n        prettyLabel: \"SAME\",\n        repoName: \"SAME\",\n        repoUrl: \"https://github.com/GengzeZhou/SAME\",\n        filter: false,\n        countDownloads: `path:\"ckpt/SAME.pt\" OR path:\"pretrain/Attnq_pretrained_ckpt.pt\"`,\n    },\n    \"sample-factory\": {\n        prettyLabel: \"sample-factory\",\n        repoName: \"sample-factory\",\n        repoUrl: \"https://github.com/alex-petrenko/sample-factory\",\n        docsUrl: \"https://huggingface.co/docs/hub/sample-factory\",\n        snippets: snippets.sampleFactory,\n        filter: true,\n        countDownloads: `path:\"cfg.json\"`,\n    },\n    \"sap-rpt-1-oss\": {\n        prettyLabel: \"sap-rpt-1-oss\",\n        repoName: \"sap-rpt-1-oss\",\n        repoUrl: \"https://github.com/SAP-samples/sap-rpt-1-oss\",\n        countDownloads: `path_extension:\"pt\"`,\n        snippets: snippets.sap_rpt_one_oss,\n    },\n    sapiens: {\n        prettyLabel: \"sapiens\",\n        repoName: \"sapiens\",\n        repoUrl: \"https://github.com/facebookresearch/sapiens\",\n        filter: false,\n        countDownloads: `path_extension:\"pt2\" OR path_extension:\"pth\" OR path_extension:\"onnx\"`,\n    },\n    seedvr: {\n        prettyLabel: \"SeedVR\",\n        repoName: \"SeedVR\",\n        repoUrl: \"https://github.com/ByteDance-Seed/SeedVR\",\n        filter: false,\n        countDownloads: `path_extension:\"pth\"`,\n    },\n    \"self-forcing\": {\n        prettyLabel: \"SelfForcing\",\n        repoName: \"SelfForcing\",\n        repoUrl: \"https://github.com/guandeh17/Self-Forcing\",\n        filter: false,\n        countDownloads: `path_extension:\"pt\"`,\n    },\n    \"sentence-transformers\": {\n        prettyLabel: \"sentence-transformers\",\n        repoName: \"sentence-transformers\",\n        repoUrl: \"https://github.com/UKPLab/sentence-transformers\",\n        docsUrl: \"https://huggingface.co/docs/hub/sentence-transformers\",\n        snippets: snippets.sentenceTransformers,\n        filter: true,\n    },\n    setfit: {\n        prettyLabel: \"setfit\",\n        repoName: \"setfit\",\n        repoUrl: \"https://github.com/huggingface/setfit\",\n        docsUrl: \"https://huggingface.co/docs/hub/setfit\",\n        snippets: snippets.setfit,\n        filter: true,\n    },\n    sklearn: {\n        prettyLabel: \"Scikit-learn\",\n        repoName: \"Scikit-learn\",\n        repoUrl: \"https://github.com/scikit-learn/scikit-learn\",\n        snippets: snippets.sklearn,\n        filter: true,\n        countDownloads: `path:\"sklearn_model.joblib\"`,\n    },\n    spacy: {\n        prettyLabel: \"spaCy\",\n        repoName: \"spaCy\",\n        repoUrl: \"https://github.com/explosion/spaCy\",\n        docsUrl: \"https://huggingface.co/docs/hub/spacy\",\n        snippets: snippets.spacy,\n        filter: true,\n        countDownloads: `path_extension:\"whl\"`,\n    },\n    \"span-marker\": {\n        prettyLabel: \"SpanMarker\",\n        repoName: \"SpanMarkerNER\",\n        repoUrl: \"https://github.com/tomaarsen/SpanMarkerNER\",\n        docsUrl: \"https://huggingface.co/docs/hub/span_marker\",\n        snippets: snippets.span_marker,\n        filter: true,\n    },\n    speechbrain: {\n        prettyLabel: \"speechbrain\",\n        repoName: \"speechbrain\",\n        repoUrl: \"https://github.com/speechbrain/speechbrain\",\n        docsUrl: \"https://huggingface.co/docs/hub/speechbrain\",\n        snippets: snippets.speechbrain,\n        filter: true,\n        countDownloads: `path:\"hyperparams.yaml\"`,\n    },\n    \"ssr-speech\": {\n        prettyLabel: \"SSR-Speech\",\n        repoName: \"SSR-Speech\",\n        repoUrl: \"https://github.com/WangHelin1997/SSR-Speech\",\n        filter: false,\n        countDownloads: `path_extension:\".pth\"`,\n    },\n    \"stable-audio-tools\": {\n        prettyLabel: \"Stable Audio Tools\",\n        repoName: \"stable-audio-tools\",\n        repoUrl: \"https://github.com/Stability-AI/stable-audio-tools.git\",\n        filter: false,\n        countDownloads: `path:\"model.safetensors\"`,\n        snippets: snippets.stable_audio_tools,\n    },\n    monkeyocr: {\n        prettyLabel: \"MonkeyOCR\",\n        repoName: \"monkeyocr\",\n        repoUrl: \"https://github.com/Yuliang-Liu/MonkeyOCR\",\n        filter: false,\n        countDownloads: `path:\"Recognition/config.json\"`,\n    },\n    \"diffusion-single-file\": {\n        prettyLabel: \"Diffusion Single File\",\n        repoName: \"diffusion-single-file\",\n        repoUrl: \"https://github.com/comfyanonymous/ComfyUI\",\n        filter: false,\n        countDownloads: `path_extension:\"safetensors\"`,\n    },\n    \"seed-story\": {\n        prettyLabel: \"SEED-Story\",\n        repoName: \"SEED-Story\",\n        repoUrl: \"https://github.com/TencentARC/SEED-Story\",\n        filter: false,\n        countDownloads: `path:\"cvlm_llama2_tokenizer/tokenizer.model\"`,\n        snippets: snippets.seed_story,\n    },\n    soloaudio: {\n        prettyLabel: \"SoloAudio\",\n        repoName: \"SoloAudio\",\n        repoUrl: \"https://github.com/WangHelin1997/SoloAudio\",\n        filter: false,\n        countDownloads: `path:\"soloaudio_v2.pt\"`,\n    },\n    songbloom: {\n        prettyLabel: \"SongBloom\",\n        repoName: \"SongBloom\",\n        repoUrl: \"https://github.com/Cypress-Yang/SongBloom\",\n        filter: false,\n        countDownloads: `path_extension:\"pt\"`,\n    },\n    \"stable-baselines3\": {\n        prettyLabel: \"stable-baselines3\",\n        repoName: \"stable-baselines3\",\n        repoUrl: \"https://github.com/huggingface/huggingface_sb3\",\n        docsUrl: \"https://huggingface.co/docs/hub/stable-baselines3\",\n        snippets: snippets.stableBaselines3,\n        filter: true,\n        countDownloads: `path_extension:\"zip\"`,\n    },\n    stanza: {\n        prettyLabel: \"Stanza\",\n        repoName: \"stanza\",\n        repoUrl: \"https://github.com/stanfordnlp/stanza\",\n        docsUrl: \"https://huggingface.co/docs/hub/stanza\",\n        snippets: snippets.stanza,\n        filter: true,\n        countDownloads: `path:\"models/default.zip\"`,\n    },\n    supertonic: {\n        prettyLabel: \"Supertonic\",\n        repoName: \"Supertonic\",\n        repoUrl: \"https://github.com/supertone-inc/supertonic\",\n        snippets: snippets.supertonic,\n        filter: false,\n    },\n    swarmformer: {\n        prettyLabel: \"SwarmFormer\",\n        repoName: \"SwarmFormer\",\n        repoUrl: \"https://github.com/takara-ai/SwarmFormer\",\n        snippets: snippets.swarmformer,\n        filter: false,\n    },\n    \"f5-tts\": {\n        prettyLabel: \"F5-TTS\",\n        repoName: \"F5-TTS\",\n        repoUrl: \"https://github.com/SWivid/F5-TTS\",\n        filter: false,\n        countDownloads: `path_extension:\"safetensors\" OR path_extension:\"pt\"`,\n    },\n    genmo: {\n        prettyLabel: \"Genmo\",\n        repoName: \"Genmo\",\n        repoUrl: \"https://github.com/genmoai/models\",\n        filter: false,\n        countDownloads: `path:\"vae_stats.json\"`,\n    },\n    \"tencent-song-generation\": {\n        prettyLabel: \"SongGeneration\",\n        repoName: \"SongGeneration\",\n        repoUrl: \"https://github.com/tencent-ailab/songgeneration\",\n        filter: false,\n        countDownloads: `path:\"ckpt/songgeneration_base/model.pt\"`,\n    },\n    tensorflowtts: {\n        prettyLabel: \"TensorFlowTTS\",\n        repoName: \"TensorFlowTTS\",\n        repoUrl: \"https://github.com/TensorSpeech/TensorFlowTTS\",\n        snippets: snippets.tensorflowtts,\n    },\n    tensorrt: {\n        prettyLabel: \"TensorRT\",\n        repoName: \"TensorRT\",\n        repoUrl: \"https://github.com/NVIDIA/TensorRT\",\n        countDownloads: `path_extension:\"onnx\"`,\n    },\n    tabpfn: {\n        prettyLabel: \"TabPFN\",\n        repoName: \"TabPFN\",\n        repoUrl: \"https://github.com/PriorLabs/TabPFN\",\n    },\n    terratorch: {\n        prettyLabel: \"TerraTorch\",\n        repoName: \"TerraTorch\",\n        repoUrl: \"https://github.com/IBM/terratorch\",\n        docsUrl: \"https://ibm.github.io/terratorch/\",\n        filter: false,\n        countDownloads: `path_extension:\"pt\" OR path_extension:\"ckpt\"`,\n        snippets: snippets.terratorch,\n    },\n    \"tic-clip\": {\n        prettyLabel: \"TiC-CLIP\",\n        repoName: \"TiC-CLIP\",\n        repoUrl: \"https://github.com/apple/ml-tic-clip\",\n        filter: false,\n        countDownloads: `path_extension:\"pt\" AND path_prefix:\"checkpoints/\"`,\n    },\n    timesfm: {\n        prettyLabel: \"TimesFM\",\n        repoName: \"timesfm\",\n        repoUrl: \"https://github.com/google-research/timesfm\",\n        filter: false,\n        countDownloads: `path:\"checkpoints/checkpoint_1100000/state/checkpoint\" OR path:\"checkpoints/checkpoint_2150000/state/checkpoint\" OR path_extension:\"ckpt\"`,\n    },\n    timm: {\n        prettyLabel: \"timm\",\n        repoName: \"pytorch-image-models\",\n        repoUrl: \"https://github.com/rwightman/pytorch-image-models\",\n        docsUrl: \"https://huggingface.co/docs/hub/timm\",\n        snippets: snippets.timm,\n        filter: true,\n        countDownloads: `path:\"pytorch_model.bin\" OR path:\"model.safetensors\"`,\n    },\n    tirex: {\n        prettyLabel: \"TiRex\",\n        repoName: \"TiRex\",\n        repoUrl: \"https://github.com/NX-AI/tirex\",\n        countDownloads: `path_extension:\"ckpt\"`,\n    },\n    torchgeo: {\n        prettyLabel: \"TorchGeo\",\n        repoName: \"TorchGeo\",\n        repoUrl: \"https://github.com/microsoft/torchgeo\",\n        docsUrl: \"https://torchgeo.readthedocs.io/\",\n        filter: false,\n        countDownloads: `path_extension:\"pt\" OR path_extension:\"pth\"`,\n    },\n    transformers: {\n        prettyLabel: \"Transformers\",\n        repoName: \"/transformers\",\n        repoUrl: \"https://github.com/huggingface/transformers\",\n        docsUrl: \"https://huggingface.co/docs/hub/transformers\",\n        snippets: snippets.transformers,\n        filter: true,\n    },\n    \"transformers.js\": {\n        prettyLabel: \"Transformers.js\",\n        repoName: \"transformers.js\",\n        repoUrl: \"https://github.com/huggingface/transformers.js\",\n        docsUrl: \"https://huggingface.co/docs/hub/transformers-js\",\n        snippets: snippets.transformersJS,\n        filter: true,\n    },\n    trellis: {\n        prettyLabel: \"Trellis\",\n        repoName: \"Trellis\",\n        repoUrl: \"https://github.com/microsoft/TRELLIS\",\n        countDownloads: `path_extension:\"safetensors\"`,\n    },\n    ultralytics: {\n        prettyLabel: \"ultralytics\",\n        repoName: \"ultralytics\",\n        repoUrl: \"https://github.com/ultralytics/ultralytics\",\n        docsUrl: \"https://github.com/ultralytics/ultralytics\",\n        filter: false,\n        countDownloads: `path_extension:\"pt\"`,\n        snippets: snippets.ultralytics,\n    },\n    univa: {\n        prettyLabel: \"univa\",\n        repoName: \"univa\",\n        repoUrl: \"https://github.com/PKU-YuanGroup/UniWorld-V1\",\n        snippets: snippets.univa,\n        filter: true,\n        countDownloads: `path:\"config.json\"`,\n    },\n    \"uni-3dar\": {\n        prettyLabel: \"Uni-3DAR\",\n        repoName: \"Uni-3DAR\",\n        repoUrl: \"https://github.com/dptech-corp/Uni-3DAR\",\n        docsUrl: \"https://github.com/dptech-corp/Uni-3DAR\",\n        countDownloads: `path_extension:\"pt\"`,\n    },\n    \"unity-sentis\": {\n        prettyLabel: \"unity-sentis\",\n        repoName: \"unity-sentis\",\n        repoUrl: \"https://github.com/Unity-Technologies/sentis-samples\",\n        snippets: snippets.sentis,\n        filter: true,\n        countDownloads: `path_extension:\"sentis\"`,\n    },\n    sana: {\n        prettyLabel: \"Sana\",\n        repoName: \"Sana\",\n        repoUrl: \"https://github.com/NVlabs/Sana\",\n        countDownloads: `path_extension:\"pth\"`,\n        snippets: snippets.sana,\n    },\n    videoprism: {\n        prettyLabel: \"VideoPrism\",\n        repoName: \"VideoPrism\",\n        repoUrl: \"https://github.com/google-deepmind/videoprism\",\n        countDownloads: `path_extension:\"npz\"`,\n        snippets: snippets.videoprism,\n    },\n    \"vfi-mamba\": {\n        prettyLabel: \"VFIMamba\",\n        repoName: \"VFIMamba\",\n        repoUrl: \"https://github.com/MCG-NJU/VFIMamba\",\n        countDownloads: `path_extension:\"pkl\"`,\n        snippets: snippets.vfimamba,\n    },\n    lvface: {\n        prettyLabel: \"LVFace\",\n        repoName: \"LVFace\",\n        repoUrl: \"https://github.com/bytedance/LVFace\",\n        countDownloads: `path_extension:\"pt\" OR path_extension:\"onnx\"`,\n        snippets: snippets.lvface,\n    },\n    voicecraft: {\n        prettyLabel: \"VoiceCraft\",\n        repoName: \"VoiceCraft\",\n        repoUrl: \"https://github.com/jasonppy/VoiceCraft\",\n        docsUrl: \"https://github.com/jasonppy/VoiceCraft\",\n        snippets: snippets.voicecraft,\n    },\n    voxcpm: {\n        prettyLabel: \"VoxCPM\",\n        repoName: \"VoxCPM\",\n        repoUrl: \"https://github.com/OpenBMB/VoxCPM\",\n        snippets: snippets.voxcpm,\n        filter: false,\n    },\n    vui: {\n        prettyLabel: \"Vui\",\n        repoName: \"Vui\",\n        repoUrl: \"https://github.com/vui-ai/vui\",\n        countDownloads: `path_extension:\"pt\"`,\n        snippets: snippets.vui,\n    },\n    vibevoice: {\n        prettyLabel: \"VibeVoice\",\n        repoName: \"VibeVoice\",\n        repoUrl: \"https://github.com/microsoft/VibeVoice\",\n        snippets: snippets.vibevoice,\n        filter: false,\n    },\n    videox_fun: {\n        prettyLabel: \"VideoX Fun\",\n        repoName: \"VideoX Fun\",\n        repoUrl: \"https://github.com/aigc-apps/VideoX-Fun\",\n        filter: false,\n        countDownloads: `path_extension:\"safetensors\"`,\n    },\n    \"wan2.2\": {\n        prettyLabel: \"Wan2.2\",\n        repoName: \"Wan2.2\",\n        repoUrl: \"https://github.com/Wan-Video/Wan2.2\",\n        countDownloads: `path_filename:\"config\" AND path_extension:\"json\"`,\n    },\n    wham: {\n        prettyLabel: \"WHAM\",\n        repoName: \"wham\",\n        repoUrl: \"https://huggingface.co/microsoft/wham\",\n        docsUrl: \"https://huggingface.co/microsoft/wham/blob/main/README.md\",\n        countDownloads: `path_extension:\"ckpt\"`,\n    },\n    whisperkit: {\n        prettyLabel: \"WhisperKit\",\n        repoName: \"WhisperKit\",\n        repoUrl: \"https://github.com/argmaxinc/WhisperKit\",\n        docsUrl: \"https://github.com/argmaxinc/WhisperKit?tab=readme-ov-file#homebrew\",\n        snippets: snippets.whisperkit,\n        countDownloads: `path_filename:\"model\" AND path_extension:\"mil\" AND _exists_:\"path_prefix\"`,\n    },\n    yolov10: {\n        // YOLOv10 is a fork of ultraLytics. Code snippets and download count are the same but the repo is different.\n        prettyLabel: \"YOLOv10\",\n        repoName: \"YOLOv10\",\n        repoUrl: \"https://github.com/THU-MIG/yolov10\",\n        docsUrl: \"https://github.com/THU-MIG/yolov10\",\n        countDownloads: `path_extension:\"pt\" OR path_extension:\"safetensors\"`,\n        snippets: snippets.ultralytics,\n    },\n    zonos: {\n        prettyLabel: \"Zonos\",\n        repoName: \"Zonos\",\n        repoUrl: \"https://github.com/Zyphra/Zonos\",\n        docsUrl: \"https://github.com/Zyphra/Zonos\",\n        snippets: snippets.zonos,\n        filter: false,\n    },\n    \"3dtopia-xl\": {\n        prettyLabel: \"3DTopia-XL\",\n        repoName: \"3DTopia-XL\",\n        repoUrl: \"https://github.com/3DTopia/3DTopia-XL\",\n        filter: false,\n        countDownloads: `path:\"model_vae_fp16.pt\"`,\n        snippets: snippets.threedtopia_xl,\n    },\n};\nexport const ALL_MODEL_LIBRARY_KEYS = Object.keys(MODEL_LIBRARIES_UI_ELEMENTS);\nexport const ALL_DISPLAY_MODEL_LIBRARY_KEYS = Object.entries(MODEL_LIBRARIES_UI_ELEMENTS)\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    .filter(([_, v]) => v.filter)\n    .map(([k]) => k);\n","// This list is copied from gguf/types.ts, but will all types available (for backward compatibility)\n// NOT to be confused with GGMLQuantizationType, a FileQuantization can contain multiple GGMLQuantizationType\n// For example, Q4_K_M model can contains Q4_K and Q6_K tensors\nexport var GGMLFileQuantizationType;\n(function (GGMLFileQuantizationType) {\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"F32\"] = 0] = \"F32\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"F16\"] = 1] = \"F16\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q4_0\"] = 2] = \"Q4_0\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q4_1\"] = 3] = \"Q4_1\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q4_1_SOME_F16\"] = 4] = \"Q4_1_SOME_F16\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q4_2\"] = 5] = \"Q4_2\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q4_3\"] = 6] = \"Q4_3\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q8_0\"] = 7] = \"Q8_0\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q5_0\"] = 8] = \"Q5_0\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q5_1\"] = 9] = \"Q5_1\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q2_K\"] = 10] = \"Q2_K\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q3_K_S\"] = 11] = \"Q3_K_S\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q3_K_M\"] = 12] = \"Q3_K_M\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q3_K_L\"] = 13] = \"Q3_K_L\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q4_K_S\"] = 14] = \"Q4_K_S\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q4_K_M\"] = 15] = \"Q4_K_M\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q5_K_S\"] = 16] = \"Q5_K_S\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q5_K_M\"] = 17] = \"Q5_K_M\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q6_K\"] = 18] = \"Q6_K\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"IQ2_XXS\"] = 19] = \"IQ2_XXS\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"IQ2_XS\"] = 20] = \"IQ2_XS\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q2_K_S\"] = 21] = \"Q2_K_S\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"IQ3_XS\"] = 22] = \"IQ3_XS\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"IQ3_XXS\"] = 23] = \"IQ3_XXS\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"IQ1_S\"] = 24] = \"IQ1_S\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"IQ4_NL\"] = 25] = \"IQ4_NL\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"IQ3_S\"] = 26] = \"IQ3_S\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"IQ3_M\"] = 27] = \"IQ3_M\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"IQ2_S\"] = 28] = \"IQ2_S\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"IQ2_M\"] = 29] = \"IQ2_M\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"IQ4_XS\"] = 30] = \"IQ4_XS\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"IQ1_M\"] = 31] = \"IQ1_M\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"BF16\"] = 32] = \"BF16\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q4_0_4_4\"] = 33] = \"Q4_0_4_4\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q4_0_4_8\"] = 34] = \"Q4_0_4_8\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q4_0_8_8\"] = 35] = \"Q4_0_8_8\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"TQ1_0\"] = 36] = \"TQ1_0\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"TQ2_0\"] = 37] = \"TQ2_0\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"MXFP4_MOE\"] = 38] = \"MXFP4_MOE\";\n    // custom quants used by unsloth\n    // they are not officially a scheme enum value in GGUF, but only here for naming\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q2_K_XL\"] = 1000] = \"Q2_K_XL\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q3_K_XL\"] = 1001] = \"Q3_K_XL\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q4_K_XL\"] = 1002] = \"Q4_K_XL\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q5_K_XL\"] = 1003] = \"Q5_K_XL\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q6_K_XL\"] = 1004] = \"Q6_K_XL\";\n    GGMLFileQuantizationType[GGMLFileQuantizationType[\"Q8_K_XL\"] = 1005] = \"Q8_K_XL\";\n})(GGMLFileQuantizationType || (GGMLFileQuantizationType = {}));\nconst ggufQuants = Object.values(GGMLFileQuantizationType).filter((v) => typeof v === \"string\");\nexport const GGUF_QUANT_RE = new RegExp(`(?<quant>${ggufQuants.join(\"|\")})` + \"(_(?<sizeVariation>[A-Z]+))?\");\nexport const GGUF_QUANT_RE_GLOBAL = new RegExp(GGUF_QUANT_RE, \"g\");\nexport function parseGGUFQuantLabel(fname) {\n    const quantLabel = fname.toUpperCase().match(GGUF_QUANT_RE_GLOBAL)?.at(-1); // if there is multiple quant substrings in a name, we prefer the last one\n    return quantLabel;\n}\n// order of quantization, from biggest to smallest\n// this list must be in sync with the order in GGMLFileQuantizationType\n// the gguf.spec.ts tests are using verify if the order is correct\nexport const GGUF_QUANT_ORDER = [\n    GGMLFileQuantizationType.F32,\n    GGMLFileQuantizationType.BF16,\n    GGMLFileQuantizationType.F16,\n    GGMLFileQuantizationType.Q8_K_XL,\n    GGMLFileQuantizationType.Q8_0,\n    // 6-bit quantizations\n    GGMLFileQuantizationType.Q6_K_XL,\n    GGMLFileQuantizationType.Q6_K,\n    // 5-bit quantizations\n    GGMLFileQuantizationType.Q5_K_XL,\n    GGMLFileQuantizationType.Q5_K_M,\n    GGMLFileQuantizationType.Q5_K_S,\n    GGMLFileQuantizationType.Q5_0,\n    GGMLFileQuantizationType.Q5_1,\n    // 4-bit quantizations\n    GGMLFileQuantizationType.Q4_K_XL,\n    GGMLFileQuantizationType.Q4_K_M,\n    GGMLFileQuantizationType.Q4_K_S,\n    GGMLFileQuantizationType.IQ4_NL,\n    GGMLFileQuantizationType.IQ4_XS,\n    GGMLFileQuantizationType.Q4_0_4_4,\n    GGMLFileQuantizationType.Q4_0_4_8,\n    GGMLFileQuantizationType.Q4_0_8_8,\n    GGMLFileQuantizationType.Q4_1_SOME_F16,\n    GGMLFileQuantizationType.Q4_0,\n    GGMLFileQuantizationType.Q4_1,\n    GGMLFileQuantizationType.Q4_2,\n    GGMLFileQuantizationType.Q4_3,\n    GGMLFileQuantizationType.MXFP4_MOE,\n    // 3-bit quantizations\n    GGMLFileQuantizationType.Q3_K_XL,\n    GGMLFileQuantizationType.Q3_K_L,\n    GGMLFileQuantizationType.Q3_K_M,\n    GGMLFileQuantizationType.Q3_K_S,\n    GGMLFileQuantizationType.IQ3_M,\n    GGMLFileQuantizationType.IQ3_S,\n    GGMLFileQuantizationType.IQ3_XS,\n    GGMLFileQuantizationType.IQ3_XXS,\n    // 2-bit quantizations\n    GGMLFileQuantizationType.Q2_K_XL,\n    GGMLFileQuantizationType.Q2_K,\n    GGMLFileQuantizationType.Q2_K_S,\n    GGMLFileQuantizationType.IQ2_M,\n    GGMLFileQuantizationType.IQ2_S,\n    GGMLFileQuantizationType.IQ2_XS,\n    GGMLFileQuantizationType.IQ2_XXS,\n    // 1-bit quantizations\n    GGMLFileQuantizationType.IQ1_S,\n    GGMLFileQuantizationType.IQ1_M,\n    GGMLFileQuantizationType.TQ1_0,\n    GGMLFileQuantizationType.TQ2_0,\n];\n// This function finds the nearest quantization type that is less than or equal to the given quantization type.\n// It returns undefined if no such quantization type is found.\nexport function findNearestQuantType(quant, availableQuants) {\n    // Create a map for quick index lookup from the defined order\n    const orderMap = new Map();\n    GGUF_QUANT_ORDER.forEach((q, index) => {\n        orderMap.set(q, index);\n    });\n    const targetIndex = orderMap.get(quant) ?? 0; // the 0 case should never happen\n    // Filter the available quantizations to include only those defined in the order map,\n    // then sort them according to the GGUF_QUANT_ORDER (from largest/index 0 to smallest/highest index).\n    const sortedAvailable = availableQuants\n        .filter((q) => orderMap.has(q))\n        .sort((a, b) => (orderMap.get(a) ?? Infinity) - (orderMap.get(b) ?? Infinity));\n    // If no valid quantizations are available after filtering\n    if (sortedAvailable.length === 0) {\n        return undefined;\n    }\n    // Iterate through the sorted available quantizations (largest to smallest).\n    // Find the first one whose order index is >= the target index.\n    // This means finding the largest quantization that is smaller than or equal to the target.\n    for (const availableQuant of sortedAvailable) {\n        // We know the key exists due to the filter above.\n        const availableIndex = orderMap.get(availableQuant) ?? 0;\n        if (availableIndex >= targetIndex) {\n            return availableQuant;\n        }\n    }\n    // If the loop completes, it means all available quantizations are larger (have a smaller index)\n    // than the target quantization. In this case, return the \"smallest\" available quantization,\n    // which is the last element in the sorted list (highest index among available).\n    return sortedAvailable[sortedAvailable.length - 1];\n}\n// This list is only used to calculate the size of the model, NOT to be confused with the quantization FILE type\nexport var GGMLQuantizationType;\n(function (GGMLQuantizationType) {\n    GGMLQuantizationType[GGMLQuantizationType[\"F32\"] = 0] = \"F32\";\n    GGMLQuantizationType[GGMLQuantizationType[\"F16\"] = 1] = \"F16\";\n    GGMLQuantizationType[GGMLQuantizationType[\"Q4_0\"] = 2] = \"Q4_0\";\n    GGMLQuantizationType[GGMLQuantizationType[\"Q4_1\"] = 3] = \"Q4_1\";\n    GGMLQuantizationType[GGMLQuantizationType[\"Q5_0\"] = 6] = \"Q5_0\";\n    GGMLQuantizationType[GGMLQuantizationType[\"Q5_1\"] = 7] = \"Q5_1\";\n    GGMLQuantizationType[GGMLQuantizationType[\"Q8_0\"] = 8] = \"Q8_0\";\n    GGMLQuantizationType[GGMLQuantizationType[\"Q8_1\"] = 9] = \"Q8_1\";\n    GGMLQuantizationType[GGMLQuantizationType[\"Q2_K\"] = 10] = \"Q2_K\";\n    GGMLQuantizationType[GGMLQuantizationType[\"Q3_K\"] = 11] = \"Q3_K\";\n    GGMLQuantizationType[GGMLQuantizationType[\"Q4_K\"] = 12] = \"Q4_K\";\n    GGMLQuantizationType[GGMLQuantizationType[\"Q5_K\"] = 13] = \"Q5_K\";\n    GGMLQuantizationType[GGMLQuantizationType[\"Q6_K\"] = 14] = \"Q6_K\";\n    GGMLQuantizationType[GGMLQuantizationType[\"Q8_K\"] = 15] = \"Q8_K\";\n    GGMLQuantizationType[GGMLQuantizationType[\"IQ2_XXS\"] = 16] = \"IQ2_XXS\";\n    GGMLQuantizationType[GGMLQuantizationType[\"IQ2_XS\"] = 17] = \"IQ2_XS\";\n    GGMLQuantizationType[GGMLQuantizationType[\"IQ3_XXS\"] = 18] = \"IQ3_XXS\";\n    GGMLQuantizationType[GGMLQuantizationType[\"IQ1_S\"] = 19] = \"IQ1_S\";\n    GGMLQuantizationType[GGMLQuantizationType[\"IQ4_NL\"] = 20] = \"IQ4_NL\";\n    GGMLQuantizationType[GGMLQuantizationType[\"IQ3_S\"] = 21] = \"IQ3_S\";\n    GGMLQuantizationType[GGMLQuantizationType[\"IQ2_S\"] = 22] = \"IQ2_S\";\n    GGMLQuantizationType[GGMLQuantizationType[\"IQ4_XS\"] = 23] = \"IQ4_XS\";\n    GGMLQuantizationType[GGMLQuantizationType[\"I8\"] = 24] = \"I8\";\n    GGMLQuantizationType[GGMLQuantizationType[\"I16\"] = 25] = \"I16\";\n    GGMLQuantizationType[GGMLQuantizationType[\"I32\"] = 26] = \"I32\";\n    GGMLQuantizationType[GGMLQuantizationType[\"I64\"] = 27] = \"I64\";\n    GGMLQuantizationType[GGMLQuantizationType[\"F64\"] = 28] = \"F64\";\n    GGMLQuantizationType[GGMLQuantizationType[\"IQ1_M\"] = 29] = \"IQ1_M\";\n    GGMLQuantizationType[GGMLQuantizationType[\"BF16\"] = 30] = \"BF16\";\n    GGMLQuantizationType[GGMLQuantizationType[\"TQ1_0\"] = 34] = \"TQ1_0\";\n    GGMLQuantizationType[GGMLQuantizationType[\"TQ2_0\"] = 35] = \"TQ2_0\";\n    GGMLQuantizationType[GGMLQuantizationType[\"MXFP4\"] = 39] = \"MXFP4\";\n})(GGMLQuantizationType || (GGMLQuantizationType = {}));\n","// Order of the elements in InferenceModal.svelte is determined by this const\nexport const inferenceSnippetLanguages = [\"python\", \"js\", \"sh\"];\n","import { parseGGUFQuantLabel } from \"./gguf.js\";\nimport { stringifyMessages } from \"./snippets/common.js\";\nimport { getModelInputSnippet } from \"./snippets/inputs.js\";\nfunction isAwqModel(model) {\n    return model.config?.quantization_config?.quant_method === \"awq\";\n}\nfunction isGptqModel(model) {\n    return model.config?.quantization_config?.quant_method === \"gptq\";\n}\nfunction isAqlmModel(model) {\n    return model.config?.quantization_config?.quant_method === \"aqlm\";\n}\nfunction isMarlinModel(model) {\n    return model.config?.quantization_config?.quant_method === \"marlin\";\n}\nfunction isTransformersModel(model) {\n    return model.tags.includes(\"transformers\");\n}\nfunction isTgiModel(model) {\n    return model.tags.includes(\"text-generation-inference\");\n}\nfunction isLlamaCppGgufModel(model) {\n    return !!model.gguf?.context_length;\n}\nfunction isAmdRyzenModel(model) {\n    return model.tags.includes(\"ryzenai-hybrid\") || model.tags.includes(\"ryzenai-npu\");\n}\nfunction isMlxModel(model) {\n    return model.tags.includes(\"mlx\");\n}\nfunction getQuantTag(filepath) {\n    const defaultTag = \":{{QUANT_TAG}}\";\n    if (!filepath) {\n        return defaultTag;\n    }\n    const quantLabel = parseGGUFQuantLabel(filepath);\n    return quantLabel ? `:${quantLabel}` : defaultTag;\n}\nconst snippetLlamacpp = (model, filepath) => {\n    const command = (binary) => {\n        const snippet = [\"# Load and run the model:\", `${binary} -hf ${model.id}${getQuantTag(filepath)}`];\n        return snippet.join(\"\\n\");\n    };\n    return [\n        {\n            title: \"Install from brew\",\n            setup: \"brew install llama.cpp\",\n            content: command(\"llama-server\"),\n        },\n        {\n            title: \"Install from WinGet (Windows)\",\n            setup: \"winget install llama.cpp\",\n            content: command(\"llama-server\"),\n        },\n        {\n            title: \"Use pre-built binary\",\n            setup: [\n                // prettier-ignore\n                \"# Download pre-built binary from:\",\n                \"# https://github.com/ggerganov/llama.cpp/releases\",\n            ].join(\"\\n\"),\n            content: command(\"./llama-server\"),\n        },\n        {\n            title: \"Build from source code\",\n            setup: [\n                \"git clone https://github.com/ggerganov/llama.cpp.git\",\n                \"cd llama.cpp\",\n                \"cmake -B build\",\n                \"cmake --build build -j --target llama-server\",\n            ].join(\"\\n\"),\n            content: command(\"./build/bin/llama-server\"),\n        },\n    ];\n};\nconst snippetNodeLlamaCppCli = (model, filepath) => {\n    const tagName = getQuantTag(filepath);\n    return [\n        {\n            title: \"Chat with the model\",\n            content: `npx -y node-llama-cpp chat hf:${model.id}${tagName}`,\n        },\n        {\n            title: \"Estimate the model compatibility with your hardware\",\n            content: `npx -y node-llama-cpp inspect estimate hf:${model.id}${tagName}`,\n        },\n    ];\n};\nconst snippetOllama = (model, filepath) => {\n    return `ollama run hf.co/${model.id}${getQuantTag(filepath)}`;\n};\nconst snippetLocalAI = (model, filepath) => {\n    const command = (binary) => [\"# Load and run the model:\", `${binary} huggingface://${model.id}/${filepath ?? \"{{GGUF_FILE}}\"}`].join(\"\\n\");\n    return [\n        {\n            title: \"Install from binary\",\n            setup: \"curl https://localai.io/install.sh | sh\",\n            content: command(\"local-ai run\"),\n        },\n        {\n            title: \"Use Docker images\",\n            setup: [\n                // prettier-ignore\n                \"# Pull the image:\",\n                \"docker pull localai/localai:latest-cpu\",\n            ].join(\"\\n\"),\n            content: command(\"docker run -p 8080:8080 --name localai -v $PWD/models:/build/models localai/localai:latest-cpu\"),\n        },\n    ];\n};\nconst snippetVllm = (model) => {\n    const messages = getModelInputSnippet(model);\n    const runCommandInstruct = `# Call the server using curl:\ncurl -X POST \"http://localhost:8000/v1/chat/completions\" \\\\\n\t-H \"Content-Type: application/json\" \\\\\n\t--data '{\n\t\t\"model\": \"${model.id}\",\n\t\t\"messages\": ${stringifyMessages(messages, {\n        indent: \"\\t\\t\",\n        attributeKeyQuotes: true,\n        customContentEscaper: (str) => str.replace(/'/g, \"'\\\\''\"),\n    })}\n\t}'`;\n    const runCommandNonInstruct = `# Call the server using curl:\ncurl -X POST \"http://localhost:8000/v1/completions\" \\\\\n\t-H \"Content-Type: application/json\" \\\\\n\t--data '{\n\t\t\"model\": \"${model.id}\",\n\t\t\"prompt\": \"Once upon a time,\",\n\t\t\"max_tokens\": 512,\n\t\t\"temperature\": 0.5\n\t}'`;\n    const runCommand = model.tags.includes(\"conversational\") ? runCommandInstruct : runCommandNonInstruct;\n    let setup;\n    let dockerCommand;\n    if (model.tags.includes(\"mistral-common\")) {\n        setup = [\n            \"# Install vLLM from pip:\",\n            \"pip install vllm\",\n            \"# Make sure you have the latest version of mistral-common installed:\",\n            \"pip install --upgrade mistral-common\",\n        ].join(\"\\n\");\n        dockerCommand = `# Load and run the model:\\ndocker exec -it my_vllm_container bash -c \"vllm serve ${model.id} --tokenizer_mode mistral --config_format mistral --load_format mistral --tool-call-parser mistral --enable-auto-tool-choice\"`;\n    }\n    else {\n        setup = [\"# Install vLLM from pip:\", \"pip install vllm\"].join(\"\\n\");\n        dockerCommand = `# Load and run the model:\\ndocker exec -it my_vllm_container bash -c \"vllm serve ${model.id}\"`;\n    }\n    return [\n        {\n            title: \"Install from pip\",\n            setup: setup,\n            content: [`# Load and run the model:\\nvllm serve \"${model.id}\"`, runCommand],\n        },\n        {\n            title: \"Use Docker images\",\n            setup: [\n                \"# Deploy with docker on Linux:\",\n                `docker run --runtime nvidia --gpus all \\\\`,\n                `\t--name my_vllm_container \\\\`,\n                `\t-v ~/.cache/huggingface:/root/.cache/huggingface \\\\`,\n                ` \t--env \"HUGGING_FACE_HUB_TOKEN=<secret>\" \\\\`,\n                `\t-p 8000:8000 \\\\`,\n                `\t--ipc=host \\\\`,\n                `\tvllm/vllm-openai:latest \\\\`,\n                `\t--model ${model.id}`,\n            ].join(\"\\n\"),\n            content: [dockerCommand, runCommand],\n        },\n    ];\n};\nconst snippetTgi = (model) => {\n    const runCommand = [\n        \"# Call the server using curl:\",\n        `curl -X POST \"http://localhost:8000/v1/chat/completions\" \\\\`,\n        `\t-H \"Content-Type: application/json\" \\\\`,\n        `\t--data '{`,\n        `\t\t\"model\": \"${model.id}\",`,\n        `\t\t\"messages\": [`,\n        `\t\t\t{\"role\": \"user\", \"content\": \"What is the capital of France?\"}`,\n        `\t\t]`,\n        `\t}'`,\n    ];\n    return [\n        {\n            title: \"Use Docker images\",\n            setup: [\n                \"# Deploy with docker on Linux:\",\n                `docker run --gpus all \\\\`,\n                `\t-v ~/.cache/huggingface:/root/.cache/huggingface \\\\`,\n                ` \t-e HF_TOKEN=\"<secret>\" \\\\`,\n                `\t-p 8000:80 \\\\`,\n                `\tghcr.io/huggingface/text-generation-inference:latest \\\\`,\n                `\t--model-id ${model.id}`,\n            ].join(\"\\n\"),\n            content: [runCommand.join(\"\\n\")],\n        },\n    ];\n};\nconst snippetMlxLm = (model) => {\n    const openaiCurl = [\n        \"# Calling the OpenAI-compatible server with curl\",\n        `curl -X POST \"http://localhost:8000/v1/chat/completions\" \\\\`,\n        `   -H \"Content-Type: application/json\" \\\\`,\n        `   --data '{`,\n        `     \"model\": \"${model.id}\",`,\n        `     \"messages\": [`,\n        `       {\"role\": \"user\", \"content\": \"Hello\"}`,\n        `     ]`,\n        `   }'`,\n    ];\n    return [\n        {\n            title: \"Generate or start a chat session\",\n            setup: [\"# Install MLX LM\", \"uv tool install mlx-lm\"].join(\"\\n\"),\n            content: [\n                ...(model.tags.includes(\"conversational\")\n                    ? [\"# Interactive chat REPL\", `mlx_lm.chat --model \"${model.id}\"`]\n                    : [\"# Generate some text\", `mlx_lm.generate --model \"${model.id}\" --prompt \"Once upon a time\"`]),\n            ].join(\"\\n\"),\n        },\n        ...(model.tags.includes(\"conversational\")\n            ? [\n                {\n                    title: \"Run an OpenAI-compatible server\",\n                    setup: [\"# Install MLX LM\", \"uv tool install mlx-lm\"].join(\"\\n\"),\n                    content: [\"# Start the server\", `mlx_lm.server --model \"${model.id}\"`, ...openaiCurl].join(\"\\n\"),\n                },\n            ]\n            : []),\n    ];\n};\nconst snippetDockerModelRunner = (model, filepath) => {\n    return `docker model run hf.co/${model.id}${getQuantTag(filepath)}`;\n};\nconst snippetLemonade = (model, filepath) => {\n    const tagName = getQuantTag(filepath);\n    const modelName = model.id.includes(\"/\") ? model.id.split(\"/\")[1] : model.id;\n    // Get recipe according to model type\n    let simplifiedModelName;\n    let recipe;\n    let checkpoint;\n    let requirements;\n    if (model.tags.some((tag) => [\"ryzenai-npu\", \"ryzenai-hybrid\"].includes(tag))) {\n        recipe = model.tags.includes(\"ryzenai-npu\") ? \"oga-npu\" : \"oga-hybrid\";\n        checkpoint = model.id;\n        requirements = \" (requires RyzenAI 300 series)\";\n        simplifiedModelName = modelName.split(\"-awq-\")[0];\n        simplifiedModelName += recipe === \"oga-npu\" ? \"-NPU\" : \"-Hybrid\";\n    }\n    else {\n        recipe = \"llamacpp\";\n        checkpoint = `${model.id}${tagName}`;\n        requirements = \"\";\n        simplifiedModelName = modelName;\n    }\n    return [\n        {\n            title: \"Pull the model\",\n            setup: \"# Download Lemonade from https://lemonade-server.ai/\",\n            content: [\n                `lemonade-server pull user.${simplifiedModelName} --checkpoint ${checkpoint} --recipe ${recipe}`,\n                \"# Note: If you installed from source, use the lemonade-server-dev command instead.\",\n            ].join(\"\\n\"),\n        },\n        {\n            title: `Run and chat with the model${requirements}`,\n            content: `lemonade-server run user.${simplifiedModelName}`,\n        },\n        {\n            title: \"List all available models\",\n            content: \"lemonade-server list\",\n        },\n    ];\n};\n/**\n * Add your new local app here.\n *\n * This is open to new suggestions and awesome upcoming apps.\n *\n * /!\\ IMPORTANT\n *\n * If possible, you need to support deeplinks and be as cross-platform as possible.\n *\n * Ping the HF team if we can help with anything!\n */\nexport const LOCAL_APPS = {\n    \"llama.cpp\": {\n        prettyLabel: \"llama.cpp\",\n        docsUrl: \"https://github.com/ggerganov/llama.cpp\",\n        mainTask: \"text-generation\",\n        displayOnModelPage: isLlamaCppGgufModel,\n        snippet: snippetLlamacpp,\n    },\n    \"node-llama-cpp\": {\n        prettyLabel: \"node-llama-cpp\",\n        docsUrl: \"https://node-llama-cpp.withcat.ai\",\n        mainTask: \"text-generation\",\n        displayOnModelPage: isLlamaCppGgufModel,\n        snippet: snippetNodeLlamaCppCli,\n    },\n    vllm: {\n        prettyLabel: \"vLLM\",\n        docsUrl: \"https://docs.vllm.ai\",\n        mainTask: \"text-generation\",\n        displayOnModelPage: (model) => (isAwqModel(model) ||\n            isGptqModel(model) ||\n            isAqlmModel(model) ||\n            isMarlinModel(model) ||\n            isLlamaCppGgufModel(model) ||\n            isTransformersModel(model)) &&\n            (model.pipeline_tag === \"text-generation\" || model.pipeline_tag === \"image-text-to-text\"),\n        snippet: snippetVllm,\n    },\n    \"mlx-lm\": {\n        prettyLabel: \"MLX LM\",\n        docsUrl: \"https://github.com/ml-explore/mlx-lm\",\n        mainTask: \"text-generation\",\n        displayOnModelPage: (model) => model.pipeline_tag === \"text-generation\" && isMlxModel(model),\n        snippet: snippetMlxLm,\n    },\n    tgi: {\n        prettyLabel: \"TGI\",\n        docsUrl: \"https://huggingface.co/docs/text-generation-inference/\",\n        mainTask: \"text-generation\",\n        displayOnModelPage: isTgiModel,\n        snippet: snippetTgi,\n    },\n    lmstudio: {\n        prettyLabel: \"LM Studio\",\n        docsUrl: \"https://lmstudio.ai\",\n        mainTask: \"text-generation\",\n        displayOnModelPage: (model) => isLlamaCppGgufModel(model) || isMlxModel(model),\n        deeplink: (model, filepath) => new URL(`lmstudio://open_from_hf?model=${model.id}${filepath ? `&file=${filepath}` : \"\"}`),\n    },\n    localai: {\n        prettyLabel: \"LocalAI\",\n        docsUrl: \"https://github.com/mudler/LocalAI\",\n        mainTask: \"text-generation\",\n        displayOnModelPage: isLlamaCppGgufModel,\n        snippet: snippetLocalAI,\n    },\n    jan: {\n        prettyLabel: \"Jan\",\n        docsUrl: \"https://jan.ai\",\n        mainTask: \"text-generation\",\n        displayOnModelPage: isLlamaCppGgufModel,\n        deeplink: (model) => new URL(`jan://models/huggingface/${model.id}`),\n    },\n    backyard: {\n        prettyLabel: \"Backyard AI\",\n        docsUrl: \"https://backyard.ai\",\n        mainTask: \"text-generation\",\n        displayOnModelPage: isLlamaCppGgufModel,\n        deeplink: (model) => new URL(`https://backyard.ai/hf/model/${model.id}`),\n    },\n    sanctum: {\n        prettyLabel: \"Sanctum\",\n        docsUrl: \"https://sanctum.ai\",\n        mainTask: \"text-generation\",\n        displayOnModelPage: isLlamaCppGgufModel,\n        deeplink: (model) => new URL(`sanctum://open_from_hf?model=${model.id}`),\n    },\n    jellybox: {\n        prettyLabel: \"Jellybox\",\n        docsUrl: \"https://jellybox.com\",\n        mainTask: \"text-generation\",\n        displayOnModelPage: (model) => isLlamaCppGgufModel(model) ||\n            (model.library_name === \"diffusers\" &&\n                model.tags.includes(\"safetensors\") &&\n                (model.pipeline_tag === \"text-to-image\" || model.tags.includes(\"lora\"))),\n        deeplink: (model) => {\n            if (isLlamaCppGgufModel(model)) {\n                return new URL(`jellybox://llm/models/huggingface/LLM/${model.id}`);\n            }\n            else if (model.tags.includes(\"lora\")) {\n                return new URL(`jellybox://image/models/huggingface/ImageLora/${model.id}`);\n            }\n            else {\n                return new URL(`jellybox://image/models/huggingface/Image/${model.id}`);\n            }\n        },\n    },\n    msty: {\n        prettyLabel: \"Msty\",\n        docsUrl: \"https://msty.app\",\n        mainTask: \"text-generation\",\n        displayOnModelPage: isLlamaCppGgufModel,\n        deeplink: (model) => new URL(`msty://models/search/hf/${model.id}`),\n    },\n    recursechat: {\n        prettyLabel: \"RecurseChat\",\n        docsUrl: \"https://recurse.chat\",\n        mainTask: \"text-generation\",\n        macOSOnly: true,\n        displayOnModelPage: isLlamaCppGgufModel,\n        deeplink: (model) => new URL(`recursechat://new-hf-gguf-model?hf-model-id=${model.id}`),\n    },\n    drawthings: {\n        prettyLabel: \"Draw Things\",\n        docsUrl: \"https://drawthings.ai\",\n        mainTask: \"text-to-image\",\n        macOSOnly: true,\n        displayOnModelPage: (model) => model.library_name === \"diffusers\" && (model.pipeline_tag === \"text-to-image\" || model.tags.includes(\"lora\")),\n        deeplink: (model) => {\n            if (model.tags.includes(\"lora\")) {\n                return new URL(`https://drawthings.ai/import/diffusers/pipeline.load_lora_weights?repo_id=${model.id}`);\n            }\n            else {\n                return new URL(`https://drawthings.ai/import/diffusers/pipeline.from_pretrained?repo_id=${model.id}`);\n            }\n        },\n    },\n    diffusionbee: {\n        prettyLabel: \"DiffusionBee\",\n        docsUrl: \"https://diffusionbee.com\",\n        mainTask: \"text-to-image\",\n        macOSOnly: true,\n        displayOnModelPage: (model) => model.library_name === \"diffusers\" && model.pipeline_tag === \"text-to-image\",\n        deeplink: (model) => new URL(`https://diffusionbee.com/huggingface_import?model_id=${model.id}`),\n    },\n    joyfusion: {\n        prettyLabel: \"JoyFusion\",\n        docsUrl: \"https://joyfusion.app\",\n        mainTask: \"text-to-image\",\n        macOSOnly: true,\n        displayOnModelPage: (model) => model.tags.includes(\"coreml\") && model.tags.includes(\"joyfusion\") && model.pipeline_tag === \"text-to-image\",\n        deeplink: (model) => new URL(`https://joyfusion.app/import_from_hf?repo_id=${model.id}`),\n    },\n    ollama: {\n        prettyLabel: \"Ollama\",\n        docsUrl: \"https://ollama.com\",\n        mainTask: \"text-generation\",\n        displayOnModelPage: isLlamaCppGgufModel,\n        snippet: snippetOllama,\n    },\n    \"docker-model-runner\": {\n        prettyLabel: \"Docker Model Runner\",\n        docsUrl: \"https://docs.docker.com/ai/model-runner/\",\n        mainTask: \"text-generation\",\n        displayOnModelPage: isLlamaCppGgufModel,\n        snippet: snippetDockerModelRunner,\n    },\n    lemonade: {\n        prettyLabel: \"Lemonade\",\n        docsUrl: \"https://lemonade-server.ai\",\n        mainTask: \"text-generation\",\n        displayOnModelPage: (model) => isLlamaCppGgufModel(model) || isAmdRyzenModel(model),\n        snippet: snippetLemonade,\n    },\n};\n","// Generated file - do not edit directly\nexport const templates = {\n    \"js\": {\n        \"fetch\": {\n            \"basic\": \"async function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"application/json\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.json();\\n\\treturn result;\\n}\\n\\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\\n    console.log(JSON.stringify(response));\\n});\",\n            \"basicAudio\": \"async function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"audio/flac\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.json();\\n\\treturn result;\\n}\\n\\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\\n    console.log(JSON.stringify(response));\\n});\",\n            \"basicImage\": \"async function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"image/jpeg\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.json();\\n\\treturn result;\\n}\\n\\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\\n    console.log(JSON.stringify(response));\\n});\",\n            \"conversational\": \"async function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"application/json\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.json();\\n\\treturn result;\\n}\\n\\nquery({ \\n{{ autoInputs.asTsString }}\\n}).then((response) => {\\n    console.log(JSON.stringify(response));\\n});\",\n            \"imageToImage\": \"const image = fs.readFileSync(\\\"{{inputs.asObj.inputs}}\\\");\\n\\nasync function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"image/jpeg\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: {\\n\\t\\t\\t\\t\\\"inputs\\\": `data:image/png;base64,${data.inputs.encode(\\\"base64\\\")}`,\\n\\t\\t\\t\\t\\\"parameters\\\": data.parameters,\\n\\t\\t\\t}\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.json();\\n\\treturn result;\\n}\\n\\nquery({ \\n\\tinputs: image,\\n\\tparameters: {\\n\\t\\tprompt: \\\"{{ inputs.asObj.parameters.prompt }}\\\",\\n\\t}\\n}).then((response) => {\\n    console.log(JSON.stringify(response));\\n});\",\n            \"imageToVideo\": \"const image = fs.readFileSync(\\\"{{inputs.asObj.inputs}}\\\");\\n\\nasync function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"image/jpeg\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: {\\n\\t\\t\\t\\t\\\"image_url\\\": `data:image/png;base64,${data.image.encode(\\\"base64\\\")}`,\\n\\t\\t\\t\\t\\\"prompt\\\": data.prompt,\\n\\t\\t\\t}\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.json();\\n\\treturn result;\\n}\\n\\nquery({\\n\\t\\\"image\\\": image,\\n\\t\\\"prompt\\\": \\\"{{inputs.asObj.parameters.prompt}}\\\",\\n}).then((response) => {\\n    // Use video\\n});\",\n            \"textToAudio\": \"{% if model.library_name == \\\"transformers\\\" %}\\nasync function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"application/json\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.blob();\\n    return result;\\n}\\n\\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\\n    // Returns a byte object of the Audio wavform. Use it directly!\\n});\\n{% else %}\\nasync function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"application/json\\\",\\n\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n    const result = await response.json();\\n    return result;\\n}\\n\\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\\n    console.log(JSON.stringify(response));\\n});\\n{% endif %} \",\n            \"textToImage\": \"async function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"application/json\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.blob();\\n\\treturn result;\\n}\\n\\n\\nquery({ {{ providerInputs.asTsString }} }).then((response) => {\\n    // Use image\\n});\",\n            \"textToSpeech\": \"{% if model.library_name == \\\"transformers\\\" %}\\nasync function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"application/json\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.blob();\\n    return result;\\n}\\n\\nquery({ text: {{ inputs.asObj.inputs }} }).then((response) => {\\n    // Returns a byte object of the Audio wavform. Use it directly!\\n});\\n{% else %}\\nasync function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"application/json\\\",\\n\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n    const result = await response.json();\\n    return result;\\n}\\n\\nquery({ text: {{ inputs.asObj.inputs }} }).then((response) => {\\n    console.log(JSON.stringify(response));\\n});\\n{% endif %} \",\n            \"zeroShotClassification\": \"async function query(data) {\\n    const response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n        {\\n            headers: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n                \\\"Content-Type\\\": \\\"application/json\\\",\\n{% if billTo %}\\n                \\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}         },\\n            method: \\\"POST\\\",\\n            body: JSON.stringify(data),\\n        }\\n    );\\n    const result = await response.json();\\n    return result;\\n}\\n\\nquery({\\n    inputs: {{ providerInputs.asObj.inputs }},\\n    parameters: { candidate_labels: [\\\"refund\\\", \\\"legal\\\", \\\"faq\\\"] }\\n}).then((response) => {\\n    console.log(JSON.stringify(response));\\n});\"\n        },\n        \"huggingface.js\": {\n            \"basic\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst output = await client.{{ methodName }}({\\n{% if endpointUrl %}\\n    endpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n\\tmodel: \\\"{{ model.id }}\\\",\\n\\tinputs: {{ inputs.asObj.inputs }},\\n\\tprovider: \\\"{{ provider }}\\\",\\n}{% if billTo %}, {\\n\\tbillTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n\\nconsole.log(output);\",\n            \"basicAudio\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst data = fs.readFileSync({{inputs.asObj.inputs}});\\n\\nconst output = await client.{{ methodName }}({\\n{% if endpointUrl %}\\n    endpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n\\tdata,\\n\\tmodel: \\\"{{ model.id }}\\\",\\n\\tprovider: \\\"{{ provider }}\\\",\\n}{% if billTo %}, {\\n\\tbillTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n\\nconsole.log(output);\",\n            \"basicImage\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst data = fs.readFileSync({{inputs.asObj.inputs}});\\n\\nconst output = await client.{{ methodName }}({\\n{% if endpointUrl %}\\n    endpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n\\tdata,\\n\\tmodel: \\\"{{ model.id }}\\\",\\n\\tprovider: \\\"{{ provider }}\\\",\\n}{% if billTo %}, {\\n\\tbillTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n\\nconsole.log(output);\",\n            \"conversational\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst chatCompletion = await client.chatCompletion({\\n{% if endpointUrl %}\\n    endpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n{% if directRequest %}\\n    provider: \\\"{{ provider }}\\\",\\n    model: \\\"{{ model.id }}\\\",\\n{% else %}\\n    model: \\\"{{ providerModelId }}\\\",\\n{% endif %}\\n{{ inputs.asTsString }}\\n}{% if billTo %}, {\\n    billTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n\\nconsole.log(chatCompletion.choices[0].message);\",\n            \"conversationalStream\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nlet out = \\\"\\\";\\n\\nconst stream = client.chatCompletionStream({\\n{% if endpointUrl %}\\n    endpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n    model: \\\"{{ providerModelId }}\\\",\\n{{ inputs.asTsString }}\\n}{% if billTo %}, {\\n    billTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n\\nfor await (const chunk of stream) {\\n\\tif (chunk.choices && chunk.choices.length > 0) {\\n\\t\\tconst newContent = chunk.choices[0].delta.content;\\n\\t\\tout += newContent;\\n\\t\\tconsole.log(newContent);\\n\\t}\\n}\",\n            \"imageToImage\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst data = fs.readFileSync(\\\"{{inputs.asObj.inputs}}\\\");\\n\\nconst image = await client.imageToImage({\\n{% if endpointUrl %}\\n\\tendpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n\\tprovider: \\\"{{provider}}\\\",\\n\\tmodel: \\\"{{model.id}}\\\",\\n\\tinputs: data,\\n\\tparameters: { prompt: \\\"{{inputs.asObj.parameters.prompt}}\\\", },\\n}{% if billTo %}, {\\n\\tbillTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n/// Use the generated image (it's a Blob)\\n// For example, you can save it to a file or display it in an image element\\n\",\n            \"imageToVideo\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst data = fs.readFileSync(\\\"{{inputs.asObj.inputs}}\\\");\\n\\nconst video = await client.imageToVideo({\\n{% if endpointUrl %}\\n\\tendpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n\\tprovider: \\\"{{provider}}\\\",\\n\\tmodel: \\\"{{model.id}}\\\",\\n\\tinputs: data,\\n\\tparameters: { prompt: \\\"{{inputs.asObj.parameters.prompt}}\\\", },\\n}{% if billTo %}, {\\n\\tbillTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n\\n/// Use the generated video (it's a Blob)\\n// For example, you can save it to a file or display it in a video element\\n\",\n            \"textToImage\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst image = await client.textToImage({\\n{% if endpointUrl %}\\n    endpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n    provider: \\\"{{ provider }}\\\",\\n    model: \\\"{{ model.id }}\\\",\\n\\tinputs: {{ inputs.asObj.inputs }},\\n\\tparameters: { num_inference_steps: 5 },\\n}{% if billTo %}, {\\n    billTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n/// Use the generated image (it's a Blob)\",\n            \"textToSpeech\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst audio = await client.textToSpeech({\\n{% if endpointUrl %}\\n    endpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n    provider: \\\"{{ provider }}\\\",\\n    model: \\\"{{ model.id }}\\\",\\n\\tinputs: {{ inputs.asObj.inputs }},\\n}{% if billTo %}, {\\n    billTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n// Use the generated audio (it's a Blob)\",\n            \"textToVideo\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst video = await client.textToVideo({\\n{% if endpointUrl %}\\n    endpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n    provider: \\\"{{ provider }}\\\",\\n    model: \\\"{{ model.id }}\\\",\\n\\tinputs: {{ inputs.asObj.inputs }},\\n}{% if billTo %}, {\\n    billTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n// Use the generated video (it's a Blob)\"\n        },\n        \"openai\": {\n            \"conversational\": \"import { OpenAI } from \\\"openai\\\";\\n\\nconst client = new OpenAI({\\n\\tbaseURL: \\\"{{ baseUrl }}\\\",\\n\\tapiKey: \\\"{{ accessToken }}\\\",\\n{% if billTo %}\\n\\tdefaultHeaders: {\\n\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\" \\n\\t}\\n{% endif %}\\n});\\n\\nconst chatCompletion = await client.chat.completions.create({\\n\\tmodel: \\\"{{ providerModelId }}\\\",\\n{{ inputs.asTsString }}\\n});\\n\\nconsole.log(chatCompletion.choices[0].message);\",\n            \"conversationalStream\": \"import { OpenAI } from \\\"openai\\\";\\n\\nconst client = new OpenAI({\\n\\tbaseURL: \\\"{{ baseUrl }}\\\",\\n\\tapiKey: \\\"{{ accessToken }}\\\",\\n{% if billTo %}\\n    defaultHeaders: {\\n\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\" \\n\\t}\\n{% endif %}\\n});\\n\\nconst stream = await client.chat.completions.create({\\n    model: \\\"{{ providerModelId }}\\\",\\n{{ inputs.asTsString }}\\n    stream: true,\\n});\\n\\nfor await (const chunk of stream) {\\n    process.stdout.write(chunk.choices[0]?.delta?.content || \\\"\\\");\\n}\"\n        }\n    },\n    \"python\": {\n        \"fal_client\": {\n            \"imageToImage\": \"{%if provider == \\\"fal-ai\\\" %}\\nimport fal_client\\nimport base64\\n\\ndef on_queue_update(update):\\n    if isinstance(update, fal_client.InProgress):\\n        for log in update.logs:\\n           print(log[\\\"message\\\"])\\n\\nwith open(\\\"{{inputs.asObj.inputs}}\\\", \\\"rb\\\") as image_file:\\n    image_base_64 = base64.b64encode(image_file.read()).decode('utf-8')\\n\\nresult = fal_client.subscribe(\\n    \\\"fal-ai/flux-kontext/dev\\\",\\n    arguments={\\n        \\\"prompt\\\": f\\\"data:image/png;base64,{image_base_64}\\\",\\n        \\\"image_url\\\": \\\"{{ providerInputs.asObj.inputs }}\\\",\\n    },\\n    with_logs=True,\\n    on_queue_update=on_queue_update,\\n)\\nprint(result)\\n{%endif%}\\n\",\n            \"imageToVideo\": \"{%if provider == \\\"fal-ai\\\" %}\\nimport fal_client\\nimport base64\\n\\ndef on_queue_update(update):\\n    if isinstance(update, fal_client.InProgress):\\n        for log in update.logs:\\n           print(log[\\\"message\\\"])\\n\\nwith open(\\\"{{inputs.asObj.inputs}}\\\", \\\"rb\\\") as image_file:\\n    image_base_64 = base64.b64encode(image_file.read()).decode('utf-8')\\n\\nresult = fal_client.subscribe(\\n    \\\"{{model.id}}\\\",\\n    arguments={\\n        \\\"image_url\\\": f\\\"data:image/png;base64,{image_base_64}\\\",\\n        \\\"prompt\\\": \\\"{{inputs.asObj.parameters.prompt}}\\\",\\n    },\\n    with_logs=True,\\n    on_queue_update=on_queue_update,\\n)\\nprint(result)\\n{%endif%}\\n\",\n            \"textToImage\": \"{% if provider == \\\"fal-ai\\\" %}\\nimport fal_client\\n\\n{% if providerInputs.asObj.loras is defined and providerInputs.asObj.loras != none %}\\nresult = fal_client.subscribe(\\n    \\\"{{ providerModelId }}\\\",\\n    arguments={\\n        \\\"prompt\\\": {{ inputs.asObj.inputs }},\\n        \\\"loras\\\":{{ providerInputs.asObj.loras | tojson }},\\n    },\\n)\\n{% else %}\\nresult = fal_client.subscribe(\\n    \\\"{{ providerModelId }}\\\",\\n    arguments={\\n        \\\"prompt\\\": {{ inputs.asObj.inputs }},\\n    },\\n)\\n{% endif %} \\nprint(result)\\n{% endif %} \"\n        },\n        \"huggingface_hub\": {\n            \"basic\": \"result = client.{{ methodName }}(\\n    {{ inputs.asObj.inputs }},\\n    model=\\\"{{ model.id }}\\\",\\n)\",\n            \"basicAudio\": \"output = client.{{ methodName }}({{ inputs.asObj.inputs }}, model=\\\"{{ model.id }}\\\")\",\n            \"basicImage\": \"output = client.{{ methodName }}({{ inputs.asObj.inputs }}, model=\\\"{{ model.id }}\\\")\",\n            \"conversational\": \"completion = client.chat.completions.create(\\n{% if directRequest %}\\n    model=\\\"{{ model.id }}\\\",\\n{% else %}\\n    model=\\\"{{ providerModelId }}\\\",\\n{% endif %}\\n{{ inputs.asPythonString }}\\n)\\n\\nprint(completion.choices[0].message) \",\n            \"conversationalStream\": \"stream = client.chat.completions.create(\\n    model=\\\"{{ providerModelId }}\\\",\\n{{ inputs.asPythonString }}\\n    stream=True,\\n)\\n\\nfor chunk in stream:\\n    print(chunk.choices[0].delta.content, end=\\\"\\\") \",\n            \"documentQuestionAnswering\": \"output = client.document_question_answering(\\n    \\\"{{ inputs.asObj.image }}\\\",\\n    question=\\\"{{ inputs.asObj.question }}\\\",\\n    model=\\\"{{ model.id }}\\\",\\n) \",\n            \"imageToImage\": \"with open(\\\"{{ inputs.asObj.inputs }}\\\", \\\"rb\\\") as image_file:\\n   input_image = image_file.read()\\n\\n# output is a PIL.Image object\\nimage = client.image_to_image(\\n    input_image,\\n    prompt=\\\"{{ inputs.asObj.parameters.prompt }}\\\",\\n    model=\\\"{{ model.id }}\\\",\\n)\\n\",\n            \"imageToVideo\": \"with open(\\\"{{ inputs.asObj.inputs }}\\\", \\\"rb\\\") as image_file:\\n   input_image = image_file.read()\\n\\nvideo = client.image_to_video(\\n    input_image,\\n    prompt=\\\"{{ inputs.asObj.parameters.prompt }}\\\",\\n    model=\\\"{{ model.id }}\\\",\\n) \\n\",\n            \"importInferenceClient\": \"from huggingface_hub import InferenceClient\\n\\nclient = InferenceClient(\\n{% if endpointUrl %}\\n    base_url=\\\"{{ baseUrl }}\\\",\\n{% endif %}\\n{% if task != \\\"conversational\\\" or directRequest %}\\n    provider=\\\"{{ provider }}\\\",\\n{% endif %}\\n    api_key=\\\"{{ accessToken }}\\\",\\n{% if billTo %}\\n    bill_to=\\\"{{ billTo }}\\\",\\n{% endif %}\\n)\",\n            \"questionAnswering\": \"answer = client.question_answering(\\n    question=\\\"{{ inputs.asObj.question }}\\\",\\n    context=\\\"{{ inputs.asObj.context }}\\\",\\n    model=\\\"{{ model.id }}\\\",\\n) \",\n            \"tableQuestionAnswering\": \"answer = client.table_question_answering(\\n    query=\\\"{{ inputs.asObj.query }}\\\",\\n    table={{ inputs.asObj.table }},\\n    model=\\\"{{ model.id }}\\\",\\n) \",\n            \"textToImage\": \"# output is a PIL.Image object\\nimage = client.text_to_image(\\n    {{ inputs.asObj.inputs }},\\n    model=\\\"{{ model.id }}\\\",\\n) \",\n            \"textToSpeech\": \"# audio is returned as bytes\\naudio = client.text_to_speech(\\n    {{ inputs.asObj.inputs }},\\n    model=\\\"{{ model.id }}\\\",\\n) \\n\",\n            \"textToVideo\": \"video = client.text_to_video(\\n    {{ inputs.asObj.inputs }},\\n    model=\\\"{{ model.id }}\\\",\\n) \"\n        },\n        \"openai\": {\n            \"conversational\": \"from openai import OpenAI\\n\\nclient = OpenAI(\\n    base_url=\\\"{{ baseUrl }}\\\",\\n    api_key=\\\"{{ accessToken }}\\\",\\n{% if billTo %}\\n    default_headers={\\n        \\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\"\\n    }\\n{% endif %}\\n)\\n\\ncompletion = client.chat.completions.create(\\n    model=\\\"{{ providerModelId }}\\\",\\n{{ inputs.asPythonString }}\\n)\\n\\nprint(completion.choices[0].message) \",\n            \"conversationalStream\": \"from openai import OpenAI\\n\\nclient = OpenAI(\\n    base_url=\\\"{{ baseUrl }}\\\",\\n    api_key=\\\"{{ accessToken }}\\\",\\n{% if billTo %}\\n    default_headers={\\n        \\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\"\\n    }\\n{% endif %}\\n)\\n\\nstream = client.chat.completions.create(\\n    model=\\\"{{ providerModelId }}\\\",\\n{{ inputs.asPythonString }}\\n    stream=True,\\n)\\n\\nfor chunk in stream:\\n    print(chunk.choices[0].delta.content, end=\\\"\\\")\"\n        },\n        \"requests\": {\n            \"basic\": \"def query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.json()\\n\\noutput = query({\\n    \\\"inputs\\\": {{ providerInputs.asObj.inputs }},\\n}) \",\n            \"basicAudio\": \"def query(filename):\\n    with open(filename, \\\"rb\\\") as f:\\n        data = f.read()\\n    response = requests.post(API_URL, headers={\\\"Content-Type\\\": \\\"audio/flac\\\", **headers}, data=data)\\n    return response.json()\\n\\noutput = query({{ providerInputs.asObj.inputs }})\",\n            \"basicImage\": \"def query(filename):\\n    with open(filename, \\\"rb\\\") as f:\\n        data = f.read()\\n    response = requests.post(API_URL, headers={\\\"Content-Type\\\": \\\"image/jpeg\\\", **headers}, data=data)\\n    return response.json()\\n\\noutput = query({{ providerInputs.asObj.inputs }})\",\n            \"conversational\": \"def query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.json()\\n\\nresponse = query({\\n{{ autoInputs.asJsonString }}\\n})\\n\\nprint(response[\\\"choices\\\"][0][\\\"message\\\"])\",\n            \"conversationalStream\": \"def query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload, stream=True)\\n    for line in response.iter_lines():\\n        if not line.startswith(b\\\"data:\\\"):\\n            continue\\n        if line.strip() == b\\\"data: [DONE]\\\":\\n            return\\n        yield json.loads(line.decode(\\\"utf-8\\\").lstrip(\\\"data:\\\").rstrip(\\\"/n\\\"))\\n\\nchunks = query({\\n{{ autoInputs.asJsonString }},\\n    \\\"stream\\\": True,\\n})\\n\\nfor chunk in chunks:\\n    print(chunk[\\\"choices\\\"][0][\\\"delta\\\"][\\\"content\\\"], end=\\\"\\\")\",\n            \"documentQuestionAnswering\": \"def query(payload):\\n    with open(payload[\\\"image\\\"], \\\"rb\\\") as f:\\n        img = f.read()\\n        payload[\\\"image\\\"] = base64.b64encode(img).decode(\\\"utf-8\\\")\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.json()\\n\\noutput = query({\\n    \\\"inputs\\\": {\\n        \\\"image\\\": \\\"{{ inputs.asObj.image }}\\\",\\n        \\\"question\\\": \\\"{{ inputs.asObj.question }}\\\",\\n    },\\n}) \",\n            \"imageToImage\": \"\\ndef query(payload):\\n    with open(payload[\\\"inputs\\\"], \\\"rb\\\") as f:\\n        img = f.read()\\n        payload[\\\"inputs\\\"] = base64.b64encode(img).decode(\\\"utf-8\\\")\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.content\\n\\nimage_bytes = query({\\n{{ providerInputs.asJsonString }}\\n})\\n\\n# You can access the image with PIL.Image for example\\nimport io\\nfrom PIL import Image\\nimage = Image.open(io.BytesIO(image_bytes)) \",\n            \"imageToVideo\": \"\\ndef query(payload):\\n    with open(payload[\\\"inputs\\\"], \\\"rb\\\") as f:\\n        img = f.read()\\n        payload[\\\"inputs\\\"] = base64.b64encode(img).decode(\\\"utf-8\\\")\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.content\\n\\nvideo_bytes = query({\\n{{ inputs.asJsonString }}\\n})\\n\",\n            \"importRequests\": \"{% if importBase64 %}\\nimport base64\\n{% endif %}\\n{% if importJson %}\\nimport json\\n{% endif %}\\nimport requests\\n\\nAPI_URL = \\\"{{ fullUrl }}\\\"\\nheaders = {\\n    \\\"Authorization\\\": \\\"{{ authorizationHeader }}\\\",\\n{% if billTo %}\\n    \\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\"\\n{% endif %}\\n}\",\n            \"tabular\": \"def query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.content\\n\\nresponse = query({\\n    \\\"inputs\\\": {\\n        \\\"data\\\": {{ providerInputs.asObj.inputs }}\\n    },\\n}) \",\n            \"textToAudio\": \"{% if model.library_name == \\\"transformers\\\" %}\\ndef query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.content\\n\\naudio_bytes = query({\\n    \\\"inputs\\\": {{ inputs.asObj.inputs }},\\n})\\n# You can access the audio with IPython.display for example\\nfrom IPython.display import Audio\\nAudio(audio_bytes)\\n{% else %}\\ndef query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.json()\\n\\naudio, sampling_rate = query({\\n    \\\"inputs\\\": {{ inputs.asObj.inputs }},\\n})\\n# You can access the audio with IPython.display for example\\nfrom IPython.display import Audio\\nAudio(audio, rate=sampling_rate)\\n{% endif %} \",\n            \"textToImage\": \"{% if provider == \\\"hf-inference\\\" %}\\ndef query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.content\\n\\nimage_bytes = query({\\n    \\\"inputs\\\": {{ providerInputs.asObj.inputs }},\\n})\\n\\n# You can access the image with PIL.Image for example\\nimport io\\nfrom PIL import Image\\nimage = Image.open(io.BytesIO(image_bytes))\\n{% endif %}\",\n            \"textToSpeech\": \"{% if model.library_name == \\\"transformers\\\" %}\\ndef query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.content\\n\\naudio_bytes = query({\\n    \\\"text\\\": {{ inputs.asObj.inputs }},\\n})\\n# You can access the audio with IPython.display for example\\nfrom IPython.display import Audio\\nAudio(audio_bytes)\\n{% else %}\\ndef query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.json()\\n\\naudio, sampling_rate = query({\\n    \\\"text\\\": {{ inputs.asObj.inputs }},\\n})\\n# You can access the audio with IPython.display for example\\nfrom IPython.display import Audio\\nAudio(audio, rate=sampling_rate)\\n{% endif %} \",\n            \"zeroShotClassification\": \"def query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.json()\\n\\noutput = query({\\n    \\\"inputs\\\": {{ providerInputs.asObj.inputs }},\\n    \\\"parameters\\\": {\\\"candidate_labels\\\": [\\\"refund\\\", \\\"legal\\\", \\\"faq\\\"]},\\n}) \",\n            \"zeroShotImageClassification\": \"def query(data):\\n    with open(data[\\\"image_path\\\"], \\\"rb\\\") as f:\\n        img = f.read()\\n    payload={\\n        \\\"parameters\\\": data[\\\"parameters\\\"],\\n        \\\"inputs\\\": base64.b64encode(img).decode(\\\"utf-8\\\")\\n    }\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.json()\\n\\noutput = query({\\n    \\\"image_path\\\": {{ providerInputs.asObj.inputs }},\\n    \\\"parameters\\\": {\\\"candidate_labels\\\": [\\\"cat\\\", \\\"dog\\\", \\\"llama\\\"]},\\n}) \"\n        }\n    },\n    \"sh\": {\n        \"curl\": {\n            \"basic\": \"curl {{ fullUrl }} \\\\\\n    -X POST \\\\\\n    -H 'Authorization: {{ authorizationHeader }}' \\\\\\n    -H 'Content-Type: application/json' \\\\\\n{% if billTo %}\\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\\\\n{% endif %}\\n    -d '{\\n{{ providerInputs.asCurlString }}\\n    }'\",\n            \"basicAudio\": \"curl {{ fullUrl }} \\\\\\n    -X POST \\\\\\n    -H 'Authorization: {{ authorizationHeader }}' \\\\\\n    -H 'Content-Type: audio/flac' \\\\\\n{% if billTo %}\\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\\\\n{% endif %}\\n    --data-binary @{{ providerInputs.asObj.inputs }}\",\n            \"basicImage\": \"curl {{ fullUrl }} \\\\\\n    -X POST \\\\\\n    -H 'Authorization: {{ authorizationHeader }}' \\\\\\n    -H 'Content-Type: image/jpeg' \\\\\\n{% if billTo %}\\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\\\\n{% endif %}\\n    --data-binary @{{ providerInputs.asObj.inputs }}\",\n            \"conversational\": \"curl {{ fullUrl }} \\\\\\n    -H 'Authorization: {{ authorizationHeader }}' \\\\\\n    -H 'Content-Type: application/json' \\\\\\n{% if billTo %}\\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\\\\n{% endif %}\\n    -d '{\\n{{ autoInputs.asCurlString }},\\n        \\\"stream\\\": false\\n    }'\",\n            \"conversationalStream\": \"curl {{ fullUrl }} \\\\\\n    -H 'Authorization: {{ authorizationHeader }}' \\\\\\n    -H 'Content-Type: application/json' \\\\\\n{% if billTo %}\\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\\\\n{% endif %}\\n    -d '{\\n{{ autoInputs.asCurlString }},\\n        \\\"stream\\\": true\\n    }'\",\n            \"zeroShotClassification\": \"curl {{ fullUrl }} \\\\\\n    -X POST \\\\\\n    -d '{\\\"inputs\\\": {{ providerInputs.asObj.inputs }}, \\\"parameters\\\": {\\\"candidate_labels\\\": [\\\"refund\\\", \\\"legal\\\", \\\"faq\\\"]}}' \\\\\\n    -H 'Content-Type: application/json' \\\\\\n    -H 'Authorization: {{ authorizationHeader }}'\\n{% if billTo %} \\\\\\n    -H 'X-HF-Bill-To: {{ billTo }}'\\n{% endif %}\"\n        }\n    }\n};\n","import { Template } from \"@huggingface/jinja\";\nimport { getModelInputSnippet, inferenceSnippetLanguages, } from \"@huggingface/tasks\";\nimport { getProviderHelper } from \"../lib/getProviderHelper.js\";\nimport { makeRequestOptionsFromResolvedModel } from \"../lib/makeRequestOptions.js\";\nimport { templates } from \"./templates.exported.js\";\nimport { getLogger } from \"../lib/logger.js\";\nimport { HF_ROUTER_AUTO_ENDPOINT } from \"../config.js\";\nconst PYTHON_CLIENTS = [\"openai\", \"huggingface_hub\", \"fal_client\", \"requests\"];\nconst JS_CLIENTS = [\"openai\", \"huggingface.js\", \"fetch\"];\nconst SH_CLIENTS = [\"curl\"];\nconst CLIENTS = {\n    js: [...JS_CLIENTS],\n    python: [...PYTHON_CLIENTS],\n    sh: [...SH_CLIENTS],\n};\n// The \"auto\"-provider policy is only available through the HF SDKs (huggingface.js / huggingface_hub)\n// except for conversational tasks for which we have https://router.huggingface.co/v1/chat/completions\nconst CLIENTS_NON_CONVERSATIONAL_AUTO_POLICY = {\n    js: [\"huggingface.js\"],\n    python: [\"huggingface_hub\"],\n};\n// Helpers to find + load templates\nconst hasTemplate = (language, client, templateName) => templates[language]?.[client]?.[templateName] !== undefined;\nconst loadTemplate = (language, client, templateName) => {\n    const template = templates[language]?.[client]?.[templateName];\n    if (!template) {\n        throw new Error(`Template not found: ${language}/${client}/${templateName}`);\n    }\n    return (data) => new Template(template).render({ ...data });\n};\nconst snippetImportPythonInferenceClient = loadTemplate(\"python\", \"huggingface_hub\", \"importInferenceClient\");\nconst snippetImportRequests = loadTemplate(\"python\", \"requests\", \"importRequests\");\n// Needed for huggingface_hub basic snippets\nconst HF_PYTHON_METHODS = {\n    \"audio-classification\": \"audio_classification\",\n    \"audio-to-audio\": \"audio_to_audio\",\n    \"automatic-speech-recognition\": \"automatic_speech_recognition\",\n    \"document-question-answering\": \"document_question_answering\",\n    \"feature-extraction\": \"feature_extraction\",\n    \"fill-mask\": \"fill_mask\",\n    \"image-classification\": \"image_classification\",\n    \"image-segmentation\": \"image_segmentation\",\n    \"image-to-image\": \"image_to_image\",\n    \"image-to-video\": \"image_to_video\",\n    \"image-to-text\": \"image_to_text\",\n    \"image-text-to-image\": \"image_text_to_image\",\n    \"image-text-to-video\": \"image_text_to_video\",\n    \"object-detection\": \"object_detection\",\n    \"question-answering\": \"question_answering\",\n    \"sentence-similarity\": \"sentence_similarity\",\n    summarization: \"summarization\",\n    \"table-question-answering\": \"table_question_answering\",\n    \"tabular-classification\": \"tabular_classification\",\n    \"tabular-regression\": \"tabular_regression\",\n    \"text-classification\": \"text_classification\",\n    \"text-generation\": \"text_generation\",\n    \"text-to-image\": \"text_to_image\",\n    \"text-to-speech\": \"text_to_speech\",\n    \"text-to-video\": \"text_to_video\",\n    \"token-classification\": \"token_classification\",\n    translation: \"translation\",\n    \"visual-question-answering\": \"visual_question_answering\",\n    \"zero-shot-classification\": \"zero_shot_classification\",\n    \"zero-shot-image-classification\": \"zero_shot_image_classification\",\n};\n// Needed for huggingface.js basic snippets\nconst HF_JS_METHODS = {\n    \"automatic-speech-recognition\": \"automaticSpeechRecognition\",\n    \"feature-extraction\": \"featureExtraction\",\n    \"fill-mask\": \"fillMask\",\n    \"image-classification\": \"imageClassification\",\n    \"question-answering\": \"questionAnswering\",\n    \"sentence-similarity\": \"sentenceSimilarity\",\n    summarization: \"summarization\",\n    \"table-question-answering\": \"tableQuestionAnswering\",\n    \"text-classification\": \"textClassification\",\n    \"text-generation\": \"textGeneration\",\n    \"token-classification\": \"tokenClassification\",\n    \"text-to-speech\": \"textToSpeech\",\n    translation: \"translation\",\n};\n// Placeholders to replace with env variable in snippets\n// little hack to support both direct requests and routing => routed requests should start with \"hf_\"\nconst ACCESS_TOKEN_ROUTING_PLACEHOLDER = \"hf_token_placeholder\";\nconst ACCESS_TOKEN_DIRECT_REQUEST_PLACEHOLDER = \"not_hf_token_placeholder\";\n// Snippet generators\nconst snippetGenerator = (templateName, inputPreparationFn) => {\n    return (model, provider, inferenceProviderMapping, opts) => {\n        const logger = getLogger();\n        const providerModelId = inferenceProviderMapping?.providerId ?? model.id;\n        /// Hacky: hard-code conversational templates here\n        let task = model.pipeline_tag;\n        if (model.pipeline_tag &&\n            [\"text-generation\", \"image-text-to-text\"].includes(model.pipeline_tag) &&\n            model.tags.includes(\"conversational\")) {\n            templateName = opts?.streaming ? \"conversationalStream\" : \"conversational\";\n            inputPreparationFn = prepareConversationalInput;\n            task = \"conversational\";\n        }\n        let providerHelper;\n        try {\n            providerHelper = getProviderHelper(provider, task);\n        }\n        catch (e) {\n            logger.error(`Failed to get provider helper for ${provider} (${task})`, e);\n            return [];\n        }\n        const placeholder = opts?.directRequest\n            ? ACCESS_TOKEN_DIRECT_REQUEST_PLACEHOLDER\n            : ACCESS_TOKEN_ROUTING_PLACEHOLDER;\n        const accessTokenOrPlaceholder = opts?.accessToken ?? placeholder;\n        /// Prepare inputs + make request\n        const inputs = opts?.inputs\n            ? { inputs: opts.inputs }\n            : inputPreparationFn\n                ? inputPreparationFn(model, opts)\n                : { inputs: getModelInputSnippet(model) };\n        const request = makeRequestOptionsFromResolvedModel(providerModelId, providerHelper, {\n            accessToken: accessTokenOrPlaceholder,\n            provider,\n            endpointUrl: opts?.endpointUrl ?? (provider === \"auto\" ? HF_ROUTER_AUTO_ENDPOINT : undefined),\n            ...inputs,\n        }, inferenceProviderMapping, {\n            task,\n            billTo: opts?.billTo,\n        });\n        /// Parse request.info.body if not a binary.\n        /// This is the body sent to the provider. Important for snippets with raw payload (e.g curl, requests, etc.)\n        let providerInputs = inputs;\n        const bodyAsObj = request.info.body;\n        if (typeof bodyAsObj === \"string\") {\n            try {\n                providerInputs = JSON.parse(bodyAsObj);\n            }\n            catch (e) {\n                logger.error(\"Failed to parse body as JSON\", e);\n            }\n        }\n        // Inputs for the \"auto\" route is strictly the same as \"inputs\", except the model includes the provider\n        // If not \"auto\" route, use the providerInputs\n        const autoInputs = !opts?.endpointUrl && !opts?.directRequest\n            ? provider !== \"auto\"\n                ? {\n                    ...inputs,\n                    model: `${model.id}:${provider}`,\n                }\n                : {\n                    ...inputs,\n                    model: `${model.id}`, // if no :provider => auto\n                }\n            : providerInputs;\n        /// Prepare template injection data\n        const params = {\n            accessToken: accessTokenOrPlaceholder,\n            authorizationHeader: request.info.headers?.Authorization,\n            baseUrl: task === \"conversational\" && !opts?.endpointUrl && !opts?.directRequest\n                ? HF_ROUTER_AUTO_ENDPOINT\n                : removeSuffix(request.url, \"/chat/completions\"),\n            fullUrl: task === \"conversational\" && !opts?.endpointUrl && !opts?.directRequest\n                ? HF_ROUTER_AUTO_ENDPOINT + \"/chat/completions\"\n                : request.url,\n            inputs: {\n                asObj: inputs,\n                asCurlString: formatBody(inputs, \"curl\"),\n                asJsonString: formatBody(inputs, \"json\"),\n                asPythonString: formatBody(inputs, \"python\"),\n                asTsString: formatBody(inputs, \"ts\"),\n            },\n            providerInputs: {\n                asObj: providerInputs,\n                asCurlString: formatBody(providerInputs, \"curl\"),\n                asJsonString: formatBody(providerInputs, \"json\"),\n                asPythonString: formatBody(providerInputs, \"python\"),\n                asTsString: formatBody(providerInputs, \"ts\"),\n            },\n            autoInputs: {\n                asObj: autoInputs,\n                asCurlString: formatBody(autoInputs, \"curl\"),\n                asJsonString: formatBody(autoInputs, \"json\"),\n                asPythonString: formatBody(autoInputs, \"python\"),\n                asTsString: formatBody(autoInputs, \"ts\"),\n            },\n            model,\n            provider,\n            providerModelId: task === \"conversational\" && !opts?.endpointUrl && !opts?.directRequest\n                ? provider !== \"auto\"\n                    ? `${model.id}:${provider}` // e.g. \"moonshotai/Kimi-K2-Instruct:groq\"\n                    : model.id\n                : providerModelId ?? model.id,\n            billTo: opts?.billTo,\n            endpointUrl: opts?.endpointUrl,\n            task,\n            directRequest: !!opts?.directRequest,\n        };\n        /// Iterate over clients => check if a snippet exists => generate\n        const clients = provider === \"auto\" && task !== \"conversational\" ? CLIENTS_NON_CONVERSATIONAL_AUTO_POLICY : CLIENTS;\n        return inferenceSnippetLanguages\n            .map((language) => {\n            const langClients = clients[language] ?? [];\n            return langClients\n                .map((client) => {\n                if (!hasTemplate(language, client, templateName)) {\n                    return;\n                }\n                const template = loadTemplate(language, client, templateName);\n                if (client === \"huggingface_hub\" && templateName.includes(\"basic\")) {\n                    if (!(model.pipeline_tag && model.pipeline_tag in HF_PYTHON_METHODS)) {\n                        return;\n                    }\n                    params[\"methodName\"] = HF_PYTHON_METHODS[model.pipeline_tag];\n                }\n                if (client === \"huggingface.js\" && templateName.includes(\"basic\")) {\n                    if (!(model.pipeline_tag && model.pipeline_tag in HF_JS_METHODS)) {\n                        return;\n                    }\n                    params[\"methodName\"] = HF_JS_METHODS[model.pipeline_tag];\n                }\n                /// Generate snippet\n                let snippet = template(params).trim();\n                if (!snippet) {\n                    return;\n                }\n                /// Add import section separately\n                if (client === \"huggingface_hub\") {\n                    const importSection = snippetImportPythonInferenceClient({ ...params });\n                    snippet = `${importSection}\\n\\n${snippet}`;\n                }\n                else if (client === \"requests\") {\n                    const importSection = snippetImportRequests({\n                        ...params,\n                        importBase64: snippet.includes(\"base64\"),\n                        importJson: snippet.includes(\"json.\"),\n                    });\n                    snippet = `${importSection}\\n\\n${snippet}`;\n                }\n                /// Replace access token placeholder\n                if (snippet.includes(placeholder)) {\n                    snippet = replaceAccessTokenPlaceholder(opts?.directRequest, placeholder, snippet, language, provider, opts?.endpointUrl);\n                }\n                /// Snippet is ready!\n                return { language, client: client, content: snippet };\n            })\n                .filter((snippet) => snippet !== undefined);\n        })\n            .flat();\n    };\n};\nconst prepareDocumentQuestionAnsweringInput = (model) => {\n    return JSON.parse(getModelInputSnippet(model));\n};\nconst prepareImageToImageInput = (model) => {\n    const data = JSON.parse(getModelInputSnippet(model));\n    return { inputs: data.image, parameters: { prompt: data.prompt } };\n};\nconst prepareConversationalInput = (model, opts) => {\n    return {\n        messages: opts?.messages ?? getModelInputSnippet(model),\n        ...(opts?.temperature ? { temperature: opts?.temperature } : undefined),\n        ...(opts?.max_tokens ? { max_tokens: opts?.max_tokens } : undefined),\n        ...(opts?.top_p ? { top_p: opts?.top_p } : undefined),\n    };\n};\nconst prepareQuestionAnsweringInput = (model) => {\n    const data = JSON.parse(getModelInputSnippet(model));\n    return { question: data.question, context: data.context };\n};\nconst prepareTableQuestionAnsweringInput = (model) => {\n    const data = JSON.parse(getModelInputSnippet(model));\n    return { query: data.query, table: JSON.stringify(data.table) };\n};\nconst snippets = {\n    \"audio-classification\": snippetGenerator(\"basicAudio\"),\n    \"audio-to-audio\": snippetGenerator(\"basicAudio\"),\n    \"automatic-speech-recognition\": snippetGenerator(\"basicAudio\"),\n    \"document-question-answering\": snippetGenerator(\"documentQuestionAnswering\", prepareDocumentQuestionAnsweringInput),\n    \"feature-extraction\": snippetGenerator(\"basic\"),\n    \"fill-mask\": snippetGenerator(\"basic\"),\n    \"image-classification\": snippetGenerator(\"basicImage\"),\n    \"image-segmentation\": snippetGenerator(\"basicImage\"),\n    \"image-text-to-image\": snippetGenerator(\"imageToImage\", prepareImageToImageInput),\n    \"image-text-to-text\": snippetGenerator(\"conversational\"),\n    \"image-text-to-video\": snippetGenerator(\"imageToVideo\", prepareImageToImageInput),\n    \"image-to-image\": snippetGenerator(\"imageToImage\", prepareImageToImageInput),\n    \"image-to-text\": snippetGenerator(\"basicImage\"),\n    \"image-to-video\": snippetGenerator(\"imageToVideo\", prepareImageToImageInput),\n    \"object-detection\": snippetGenerator(\"basicImage\"),\n    \"question-answering\": snippetGenerator(\"questionAnswering\", prepareQuestionAnsweringInput),\n    \"sentence-similarity\": snippetGenerator(\"basic\"),\n    summarization: snippetGenerator(\"basic\"),\n    \"tabular-classification\": snippetGenerator(\"tabular\"),\n    \"tabular-regression\": snippetGenerator(\"tabular\"),\n    \"table-question-answering\": snippetGenerator(\"tableQuestionAnswering\", prepareTableQuestionAnsweringInput),\n    \"text-classification\": snippetGenerator(\"basic\"),\n    \"text-generation\": snippetGenerator(\"basic\"),\n    \"text-to-audio\": snippetGenerator(\"textToAudio\"),\n    \"text-to-image\": snippetGenerator(\"textToImage\"),\n    \"text-to-speech\": snippetGenerator(\"textToSpeech\"),\n    \"text-to-video\": snippetGenerator(\"textToVideo\"),\n    \"token-classification\": snippetGenerator(\"basic\"),\n    translation: snippetGenerator(\"basic\"),\n    \"zero-shot-classification\": snippetGenerator(\"zeroShotClassification\"),\n    \"zero-shot-image-classification\": snippetGenerator(\"zeroShotImageClassification\"),\n};\nexport function getInferenceSnippets(model, provider, inferenceProviderMapping, opts) {\n    return model.pipeline_tag && model.pipeline_tag in snippets\n        ? snippets[model.pipeline_tag]?.(model, provider, inferenceProviderMapping, opts) ?? []\n        : [];\n}\n// String manipulation helpers\nfunction formatBody(obj, format) {\n    switch (format) {\n        case \"curl\":\n            return indentString(formatBody(obj, \"json\"));\n        case \"json\":\n            /// Hacky: remove outer brackets to make is extendable in templates\n            return JSON.stringify(obj, null, 4).split(\"\\n\").slice(1, -1).join(\"\\n\");\n        case \"python\":\n            return indentString(Object.entries(obj)\n                .map(([key, value]) => {\n                const formattedValue = JSON.stringify(value, null, 4).replace(/\"/g, '\"');\n                return `${key}=${formattedValue},`;\n            })\n                .join(\"\\n\"));\n        case \"ts\":\n            /// Hacky: remove outer brackets to make is extendable in templates\n            return formatTsObject(obj).split(\"\\n\").slice(1, -1).join(\"\\n\");\n        default:\n            throw new Error(`Unsupported format: ${format}`);\n    }\n}\nfunction formatTsObject(obj, depth) {\n    depth = depth ?? 0;\n    /// Case int, boolean, string, etc.\n    if (typeof obj !== \"object\" || obj === null) {\n        return JSON.stringify(obj);\n    }\n    /// Case array\n    if (Array.isArray(obj)) {\n        const items = obj\n            .map((item) => {\n            const formatted = formatTsObject(item, depth + 1);\n            return `${\" \".repeat(4 * (depth + 1))}${formatted},`;\n        })\n            .join(\"\\n\");\n        return `[\\n${items}\\n${\" \".repeat(4 * depth)}]`;\n    }\n    /// Case mapping\n    const entries = Object.entries(obj);\n    const lines = entries\n        .map(([key, value]) => {\n        const formattedValue = formatTsObject(value, depth + 1);\n        const keyStr = /^[a-zA-Z_$][a-zA-Z0-9_$]*$/.test(key) ? key : `\"${key}\"`;\n        return `${\" \".repeat(4 * (depth + 1))}${keyStr}: ${formattedValue},`;\n    })\n        .join(\"\\n\");\n    return `{\\n${lines}\\n${\" \".repeat(4 * depth)}}`;\n}\nfunction indentString(str) {\n    return str\n        .split(\"\\n\")\n        .map((line) => \" \".repeat(4) + line)\n        .join(\"\\n\");\n}\nfunction removeSuffix(str, suffix) {\n    return str.endsWith(suffix) ? str.slice(0, -suffix.length) : str;\n}\nfunction replaceAccessTokenPlaceholder(directRequest, placeholder, snippet, language, provider, endpointUrl) {\n    // If \"opts.accessToken\" is not set, the snippets are generated with a placeholder.\n    // Once snippets are rendered, we replace the placeholder with code to fetch the access token from an environment variable.\n    // Determine if HF_TOKEN or specific provider token should be used\n    const useHfToken = !endpointUrl && // custom endpointUrl => use a generic API_TOKEN\n        (provider == \"hf-inference\" || // hf-inference provider => use $HF_TOKEN\n            (!directRequest && // if explicit directRequest => use provider-specific token\n                (snippet.includes(\"InferenceClient\") || // using a client => use $HF_TOKEN\n                    snippet.includes(\"https://router.huggingface.co\")))); // explicit routed request => use $HF_TOKEN\n    const accessTokenEnvVar = useHfToken\n        ? \"HF_TOKEN\" // e.g. routed request or hf-inference\n        : endpointUrl\n            ? \"API_TOKEN\"\n            : provider.toUpperCase().replace(\"-\", \"_\") + \"_API_KEY\"; // e.g. \"REPLICATE_API_KEY\"\n    // Replace the placeholder with the env variable\n    if (language === \"sh\") {\n        snippet = snippet.replace(`'Authorization: Bearer ${placeholder}'`, `\"Authorization: Bearer $${accessTokenEnvVar}\"` // e.g. \"Authorization: Bearer $HF_TOKEN\"\n        );\n    }\n    else if (language === \"python\") {\n        snippet = \"import os\\n\" + snippet;\n        snippet = snippet.replace(`\"${placeholder}\"`, `os.environ[\"${accessTokenEnvVar}\"]` // e.g. os.environ[\"HF_TOKEN\")\n        );\n        snippet = snippet.replace(`\"Bearer ${placeholder}\"`, `f\"Bearer {os.environ['${accessTokenEnvVar}']}\"` // e.g. f\"Bearer {os.environ['HF_TOKEN']}\"\n        );\n        snippet = snippet.replace(`\"Key ${placeholder}\"`, `f\"Key {os.environ['${accessTokenEnvVar}']}\"` // e.g. f\"Key {os.environ['FAL_AI_API_KEY']}\"\n        );\n        snippet = snippet.replace(`\"X-Key ${placeholder}\"`, `f\"X-Key {os.environ['${accessTokenEnvVar}']}\"` // e.g. f\"X-Key {os.environ['BLACK_FOREST_LABS_API_KEY']}\"\n        );\n    }\n    else if (language === \"js\") {\n        snippet = snippet.replace(`\"${placeholder}\"`, `process.env.${accessTokenEnvVar}` // e.g. process.env.HF_TOKEN\n        );\n        snippet = snippet.replace(`Authorization: \"Bearer ${placeholder}\",`, `Authorization: \\`Bearer $\\{process.env.${accessTokenEnvVar}}\\`,` // e.g. Authorization: `Bearer ${process.env.HF_TOKEN}`,\n        );\n        snippet = snippet.replace(`Authorization: \"Key ${placeholder}\",`, `Authorization: \\`Key $\\{process.env.${accessTokenEnvVar}}\\`,` // e.g. Authorization: `Key ${process.env.FAL_AI_API_KEY}`,\n        );\n        snippet = snippet.replace(`Authorization: \"X-Key ${placeholder}\",`, `Authorization: \\`X-Key $\\{process.env.${accessTokenEnvVar}}\\`,` // e.g. Authorization: `X-Key ${process.env.BLACK_FOREST_LABS_AI_API_KEY}`,\n        );\n    }\n    return snippet;\n}\n","import createLucideIcon from '../createLucideIcon';\n\n/**\n * @component @name Type\n * @description Lucide SVG icon component, renders SVG Element with children.\n *\n * @preview ![img](data:image/svg+xml;base64,PHN2ZyAgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIgogIHdpZHRoPSIyNCIKICBoZWlnaHQ9IjI0IgogIHZpZXdCb3g9IjAgMCAyNCAyNCIKICBmaWxsPSJub25lIgogIHN0cm9rZT0iIzAwMCIgc3R5bGU9ImJhY2tncm91bmQtY29sb3I6ICNmZmY7IGJvcmRlci1yYWRpdXM6IDJweCIKICBzdHJva2Utd2lkdGg9IjIiCiAgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIgogIHN0cm9rZS1saW5lam9pbj0icm91bmQiCj4KICA8cG9seWxpbmUgcG9pbnRzPSI0IDcgNCA0IDIwIDQgMjAgNyIgLz4KICA8bGluZSB4MT0iOSIgeDI9IjE1IiB5MT0iMjAiIHkyPSIyMCIgLz4KICA8bGluZSB4MT0iMTIiIHgyPSIxMiIgeTE9IjQiIHkyPSIyMCIgLz4KPC9zdmc+Cg==) - https://lucide.dev/icons/type\n * @see https://lucide.dev/guide/packages/lucide-react - Documentation\n *\n * @param {Object} props - Lucide icons props and any valid SVG attribute\n * @returns {JSX.Element} JSX Element\n *\n */\nconst Type = createLucideIcon('Type', [\n  ['polyline', { points: '4 7 4 4 20 4 20 7', key: '1nosan' }],\n  ['line', { x1: '9', x2: '15', y1: '20', y2: '20', key: 'swin9y' }],\n  ['line', { x1: '12', x2: '12', y1: '4', y2: '20', key: '1tx1rr' }],\n]);\n\nexport default Type;\n","import createLucideIcon from '../createLucideIcon';\n\n/**\n * @component @name Layers\n * @description Lucide SVG icon component, renders SVG Element with children.\n *\n * @preview ![img](data:image/svg+xml;base64,PHN2ZyAgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIgogIHdpZHRoPSIyNCIKICBoZWlnaHQ9IjI0IgogIHZpZXdCb3g9IjAgMCAyNCAyNCIKICBmaWxsPSJub25lIgogIHN0cm9rZT0iIzAwMCIgc3R5bGU9ImJhY2tncm91bmQtY29sb3I6ICNmZmY7IGJvcmRlci1yYWRpdXM6IDJweCIKICBzdHJva2Utd2lkdGg9IjIiCiAgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIgogIHN0cm9rZS1saW5lam9pbj0icm91bmQiCj4KICA8cG9seWdvbiBwb2ludHM9IjEyIDIgMiA3IDEyIDEyIDIyIDcgMTIgMiIgLz4KICA8cG9seWxpbmUgcG9pbnRzPSIyIDE3IDEyIDIyIDIyIDE3IiAvPgogIDxwb2x5bGluZSBwb2ludHM9IjIgMTIgMTIgMTcgMjIgMTIiIC8+Cjwvc3ZnPgo=) - https://lucide.dev/icons/layers\n * @see https://lucide.dev/guide/packages/lucide-react - Documentation\n *\n * @param {Object} props - Lucide icons props and any valid SVG attribute\n * @returns {JSX.Element} JSX Element\n *\n */\nconst Layers = createLucideIcon('Layers', [\n  ['polygon', { points: '12 2 2 7 12 12 22 7 12 2', key: '1b0ttc' }],\n  ['polyline', { points: '2 17 12 22 22 17', key: 'imjtdl' }],\n  ['polyline', { points: '2 12 12 17 22 12', key: '5dexcv' }],\n]);\n\nexport default Layers;\n","import createLucideIcon from '../createLucideIcon';\n\n/**\n * @component @name Image\n * @description Lucide SVG icon component, renders SVG Element with children.\n *\n * @preview ![img](data:image/svg+xml;base64,PHN2ZyAgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIgogIHdpZHRoPSIyNCIKICBoZWlnaHQ9IjI0IgogIHZpZXdCb3g9IjAgMCAyNCAyNCIKICBmaWxsPSJub25lIgogIHN0cm9rZT0iIzAwMCIgc3R5bGU9ImJhY2tncm91bmQtY29sb3I6ICNmZmY7IGJvcmRlci1yYWRpdXM6IDJweCIKICBzdHJva2Utd2lkdGg9IjIiCiAgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIgogIHN0cm9rZS1saW5lam9pbj0icm91bmQiCj4KICA8cmVjdCB3aWR0aD0iMTgiIGhlaWdodD0iMTgiIHg9IjMiIHk9IjMiIHJ4PSIyIiByeT0iMiIgLz4KICA8Y2lyY2xlIGN4PSI5IiBjeT0iOSIgcj0iMiIgLz4KICA8cGF0aCBkPSJtMjEgMTUtMy4wODYtMy4wODZhMiAyIDAgMCAwLTIuODI4IDBMNiAyMSIgLz4KPC9zdmc+Cg==) - https://lucide.dev/icons/image\n * @see https://lucide.dev/guide/packages/lucide-react - Documentation\n *\n * @param {Object} props - Lucide icons props and any valid SVG attribute\n * @returns {JSX.Element} JSX Element\n *\n */\nconst Image = createLucideIcon('Image', [\n  [\n    'rect',\n    {\n      width: '18',\n      height: '18',\n      x: '3',\n      y: '3',\n      rx: '2',\n      ry: '2',\n      key: '1m3agn',\n    },\n  ],\n  ['circle', { cx: '9', cy: '9', r: '2', key: 'af1f0g' }],\n  ['path', { d: 'm21 15-3.086-3.086a2 2 0 0 0-2.828 0L6 21', key: '1xmnt7' }],\n]);\n\nexport default Image;\n","import createLucideIcon from '../createLucideIcon';\n\n/**\n * @component @name Trash2\n * @description Lucide SVG icon component, renders SVG Element with children.\n *\n * @preview ![img](data:image/svg+xml;base64,PHN2ZyAgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIgogIHdpZHRoPSIyNCIKICBoZWlnaHQ9IjI0IgogIHZpZXdCb3g9IjAgMCAyNCAyNCIKICBmaWxsPSJub25lIgogIHN0cm9rZT0iIzAwMCIgc3R5bGU9ImJhY2tncm91bmQtY29sb3I6ICNmZmY7IGJvcmRlci1yYWRpdXM6IDJweCIKICBzdHJva2Utd2lkdGg9IjIiCiAgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIgogIHN0cm9rZS1saW5lam9pbj0icm91bmQiCj4KICA8cGF0aCBkPSJNMyA2aDE4IiAvPgogIDxwYXRoIGQ9Ik0xOSA2djE0YzAgMS0xIDItMiAySDdjLTEgMC0yLTEtMi0yVjYiIC8+CiAgPHBhdGggZD0iTTggNlY0YzAtMSAxLTIgMi0yaDRjMSAwIDIgMSAyIDJ2MiIgLz4KICA8bGluZSB4MT0iMTAiIHgyPSIxMCIgeTE9IjExIiB5Mj0iMTciIC8+CiAgPGxpbmUgeDE9IjE0IiB4Mj0iMTQiIHkxPSIxMSIgeTI9IjE3IiAvPgo8L3N2Zz4K) - https://lucide.dev/icons/trash-2\n * @see https://lucide.dev/guide/packages/lucide-react - Documentation\n *\n * @param {Object} props - Lucide icons props and any valid SVG attribute\n * @returns {JSX.Element} JSX Element\n *\n */\nconst Trash2 = createLucideIcon('Trash2', [\n  ['path', { d: 'M3 6h18', key: 'd0wm0j' }],\n  ['path', { d: 'M19 6v14c0 1-1 2-2 2H7c-1 0-2-1-2-2V6', key: '4alrt4' }],\n  ['path', { d: 'M8 6V4c0-1 1-2 2-2h4c1 0 2 1 2 2v2', key: 'v07s0e' }],\n  ['line', { x1: '10', x2: '10', y1: '11', y2: '17', key: '1uufr5' }],\n  ['line', { x1: '14', x2: '14', y1: '11', y2: '17', key: 'xtxkd' }],\n]);\n\nexport default Trash2;\n","import createLucideIcon from '../createLucideIcon';\n\n/**\n * @component @name Wand2\n * @description Lucide SVG icon component, renders SVG Element with children.\n *\n * @preview ![img](data:image/svg+xml;base64,PHN2ZyAgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIgogIHdpZHRoPSIyNCIKICBoZWlnaHQ9IjI0IgogIHZpZXdCb3g9IjAgMCAyNCAyNCIKICBmaWxsPSJub25lIgogIHN0cm9rZT0iIzAwMCIgc3R5bGU9ImJhY2tncm91bmQtY29sb3I6ICNmZmY7IGJvcmRlci1yYWRpdXM6IDJweCIKICBzdHJva2Utd2lkdGg9IjIiCiAgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIgogIHN0cm9rZS1saW5lam9pbj0icm91bmQiCj4KICA8cGF0aCBkPSJtMjEuNjQgMy42NC0xLjI4LTEuMjhhMS4yMSAxLjIxIDAgMCAwLTEuNzIgMEwyLjM2IDE4LjY0YTEuMjEgMS4yMSAwIDAgMCAwIDEuNzJsMS4yOCAxLjI4YTEuMiAxLjIgMCAwIDAgMS43MiAwTDIxLjY0IDUuMzZhMS4yIDEuMiAwIDAgMCAwLTEuNzJaIiAvPgogIDxwYXRoIGQ9Im0xNCA3IDMgMyIgLz4KICA8cGF0aCBkPSJNNSA2djQiIC8+CiAgPHBhdGggZD0iTTE5IDE0djQiIC8+CiAgPHBhdGggZD0iTTEwIDJ2MiIgLz4KICA8cGF0aCBkPSJNNyA4SDMiIC8+CiAgPHBhdGggZD0iTTIxIDE2aC00IiAvPgogIDxwYXRoIGQ9Ik0xMSAzSDkiIC8+Cjwvc3ZnPgo=) - https://lucide.dev/icons/wand-2\n * @see https://lucide.dev/guide/packages/lucide-react - Documentation\n *\n * @param {Object} props - Lucide icons props and any valid SVG attribute\n * @returns {JSX.Element} JSX Element\n *\n */\nconst Wand2 = createLucideIcon('Wand2', [\n  [\n    'path',\n    {\n      d: 'm21.64 3.64-1.28-1.28a1.21 1.21 0 0 0-1.72 0L2.36 18.64a1.21 1.21 0 0 0 0 1.72l1.28 1.28a1.2 1.2 0 0 0 1.72 0L21.64 5.36a1.2 1.2 0 0 0 0-1.72Z',\n      key: '1bcowg',\n    },\n  ],\n  ['path', { d: 'm14 7 3 3', key: '1r5n42' }],\n  ['path', { d: 'M5 6v4', key: 'ilb8ba' }],\n  ['path', { d: 'M19 14v4', key: 'blhpug' }],\n  ['path', { d: 'M10 2v2', key: '7u0qdc' }],\n  ['path', { d: 'M7 8H3', key: 'zfb6yr' }],\n  ['path', { d: 'M21 16h-4', key: '1cnmox' }],\n  ['path', { d: 'M11 3H9', key: '1obp7u' }],\n]);\n\nexport default Wand2;\n","import createLucideIcon from '../createLucideIcon';\n\n/**\n * @component @name Grid\n * @description Lucide SVG icon component, renders SVG Element with children.\n *\n * @preview ![img](data:image/svg+xml;base64,PHN2ZyAgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIgogIHdpZHRoPSIyNCIKICBoZWlnaHQ9IjI0IgogIHZpZXdCb3g9IjAgMCAyNCAyNCIKICBmaWxsPSJub25lIgogIHN0cm9rZT0iIzAwMCIgc3R5bGU9ImJhY2tncm91bmQtY29sb3I6ICNmZmY7IGJvcmRlci1yYWRpdXM6IDJweCIKICBzdHJva2Utd2lkdGg9IjIiCiAgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIgogIHN0cm9rZS1saW5lam9pbj0icm91bmQiCj4KICA8cmVjdCB3aWR0aD0iMTgiIGhlaWdodD0iMTgiIHg9IjMiIHk9IjMiIHJ4PSIyIiByeT0iMiIgLz4KICA8bGluZSB4MT0iMyIgeDI9IjIxIiB5MT0iOSIgeTI9IjkiIC8+CiAgPGxpbmUgeDE9IjMiIHgyPSIyMSIgeTE9IjE1IiB5Mj0iMTUiIC8+CiAgPGxpbmUgeDE9IjkiIHgyPSI5IiB5MT0iMyIgeTI9IjIxIiAvPgogIDxsaW5lIHgxPSIxNSIgeDI9IjE1IiB5MT0iMyIgeTI9IjIxIiAvPgo8L3N2Zz4K) - https://lucide.dev/icons/grid\n * @see https://lucide.dev/guide/packages/lucide-react - Documentation\n *\n * @param {Object} props - Lucide icons props and any valid SVG attribute\n * @returns {JSX.Element} JSX Element\n *\n */\nconst Grid = createLucideIcon('Grid', [\n  [\n    'rect',\n    {\n      width: '18',\n      height: '18',\n      x: '3',\n      y: '3',\n      rx: '2',\n      ry: '2',\n      key: '1m3agn',\n    },\n  ],\n  ['line', { x1: '3', x2: '21', y1: '9', y2: '9', key: '1vqk6q' }],\n  ['line', { x1: '3', x2: '21', y1: '15', y2: '15', key: 'o2sbyz' }],\n  ['line', { x1: '9', x2: '9', y1: '3', y2: '21', key: '13tij5' }],\n  ['line', { x1: '15', x2: '15', y1: '3', y2: '21', key: '1hpv9i' }],\n]);\n\nexport default Grid;\n","import createLucideIcon from '../createLucideIcon';\n\n/**\n * @component @name ArrowLeft\n * @description Lucide SVG icon component, renders SVG Element with children.\n *\n * @preview ![img](data:image/svg+xml;base64,PHN2ZyAgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIgogIHdpZHRoPSIyNCIKICBoZWlnaHQ9IjI0IgogIHZpZXdCb3g9IjAgMCAyNCAyNCIKICBmaWxsPSJub25lIgogIHN0cm9rZT0iIzAwMCIgc3R5bGU9ImJhY2tncm91bmQtY29sb3I6ICNmZmY7IGJvcmRlci1yYWRpdXM6IDJweCIKICBzdHJva2Utd2lkdGg9IjIiCiAgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIgogIHN0cm9rZS1saW5lam9pbj0icm91bmQiCj4KICA8cGF0aCBkPSJtMTIgMTktNy03IDctNyIgLz4KICA8cGF0aCBkPSJNMTkgMTJINSIgLz4KPC9zdmc+Cg==) - https://lucide.dev/icons/arrow-left\n * @see https://lucide.dev/guide/packages/lucide-react - Documentation\n *\n * @param {Object} props - Lucide icons props and any valid SVG attribute\n * @returns {JSX.Element} JSX Element\n *\n */\nconst ArrowLeft = createLucideIcon('ArrowLeft', [\n  ['path', { d: 'm12 19-7-7 7-7', key: '1l729n' }],\n  ['path', { d: 'M19 12H5', key: 'x3x0zl' }],\n]);\n\nexport default ArrowLeft;\n","import createLucideIcon from '../createLucideIcon';\n\n/**\n * @component @name Save\n * @description Lucide SVG icon component, renders SVG Element with children.\n *\n * @preview ![img](data:image/svg+xml;base64,PHN2ZyAgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIgogIHdpZHRoPSIyNCIKICBoZWlnaHQ9IjI0IgogIHZpZXdCb3g9IjAgMCAyNCAyNCIKICBmaWxsPSJub25lIgogIHN0cm9rZT0iIzAwMCIgc3R5bGU9ImJhY2tncm91bmQtY29sb3I6ICNmZmY7IGJvcmRlci1yYWRpdXM6IDJweCIKICBzdHJva2Utd2lkdGg9IjIiCiAgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIgogIHN0cm9rZS1saW5lam9pbj0icm91bmQiCj4KICA8cGF0aCBkPSJNMTkgMjFINWEyIDIgMCAwIDEtMi0yVjVhMiAyIDAgMCAxIDItMmgxMWw1IDV2MTFhMiAyIDAgMCAxLTIgMnoiIC8+CiAgPHBvbHlsaW5lIHBvaW50cz0iMTcgMjEgMTcgMTMgNyAxMyA3IDIxIiAvPgogIDxwb2x5bGluZSBwb2ludHM9IjcgMyA3IDggMTUgOCIgLz4KPC9zdmc+Cg==) - https://lucide.dev/icons/save\n * @see https://lucide.dev/guide/packages/lucide-react - Documentation\n *\n * @param {Object} props - Lucide icons props and any valid SVG attribute\n * @returns {JSX.Element} JSX Element\n *\n */\nconst Save = createLucideIcon('Save', [\n  [\n    'path',\n    {\n      d: 'M19 21H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h11l5 5v11a2 2 0 0 1-2 2z',\n      key: '1owoqh',\n    },\n  ],\n  ['polyline', { points: '17 21 17 13 7 13 7 21', key: '1md35c' }],\n  ['polyline', { points: '7 3 7 8 15 8', key: '8nz8an' }],\n]);\n\nexport default Save;\n","import createLucideIcon from '../createLucideIcon';\n\n/**\n * @component @name ZoomOut\n * @description Lucide SVG icon component, renders SVG Element with children.\n *\n * @preview ![img](data:image/svg+xml;base64,PHN2ZyAgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIgogIHdpZHRoPSIyNCIKICBoZWlnaHQ9IjI0IgogIHZpZXdCb3g9IjAgMCAyNCAyNCIKICBmaWxsPSJub25lIgogIHN0cm9rZT0iIzAwMCIgc3R5bGU9ImJhY2tncm91bmQtY29sb3I6ICNmZmY7IGJvcmRlci1yYWRpdXM6IDJweCIKICBzdHJva2Utd2lkdGg9IjIiCiAgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIgogIHN0cm9rZS1saW5lam9pbj0icm91bmQiCj4KICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjExIiByPSI4IiAvPgogIDxsaW5lIHgxPSIyMSIgeDI9IjE2LjY1IiB5MT0iMjEiIHkyPSIxNi42NSIgLz4KICA8bGluZSB4MT0iOCIgeDI9IjE0IiB5MT0iMTEiIHkyPSIxMSIgLz4KPC9zdmc+Cg==) - https://lucide.dev/icons/zoom-out\n * @see https://lucide.dev/guide/packages/lucide-react - Documentation\n *\n * @param {Object} props - Lucide icons props and any valid SVG attribute\n * @returns {JSX.Element} JSX Element\n *\n */\nconst ZoomOut = createLucideIcon('ZoomOut', [\n  ['circle', { cx: '11', cy: '11', r: '8', key: '4ej97u' }],\n  ['line', { x1: '21', x2: '16.65', y1: '21', y2: '16.65', key: '13gj7c' }],\n  ['line', { x1: '8', x2: '14', y1: '11', y2: '11', key: 'durymu' }],\n]);\n\nexport default ZoomOut;\n","import createLucideIcon from '../createLucideIcon';\n\n/**\n * @component @name ZoomIn\n * @description Lucide SVG icon component, renders SVG Element with children.\n *\n * @preview ![img](data:image/svg+xml;base64,PHN2ZyAgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIgogIHdpZHRoPSIyNCIKICBoZWlnaHQ9IjI0IgogIHZpZXdCb3g9IjAgMCAyNCAyNCIKICBmaWxsPSJub25lIgogIHN0cm9rZT0iIzAwMCIgc3R5bGU9ImJhY2tncm91bmQtY29sb3I6ICNmZmY7IGJvcmRlci1yYWRpdXM6IDJweCIKICBzdHJva2Utd2lkdGg9IjIiCiAgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIgogIHN0cm9rZS1saW5lam9pbj0icm91bmQiCj4KICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjExIiByPSI4IiAvPgogIDxsaW5lIHgxPSIyMSIgeDI9IjE2LjY1IiB5MT0iMjEiIHkyPSIxNi42NSIgLz4KICA8bGluZSB4MT0iMTEiIHgyPSIxMSIgeTE9IjgiIHkyPSIxNCIgLz4KICA8bGluZSB4MT0iOCIgeDI9IjE0IiB5MT0iMTEiIHkyPSIxMSIgLz4KPC9zdmc+Cg==) - https://lucide.dev/icons/zoom-in\n * @see https://lucide.dev/guide/packages/lucide-react - Documentation\n *\n * @param {Object} props - Lucide icons props and any valid SVG attribute\n * @returns {JSX.Element} JSX Element\n *\n */\nconst ZoomIn = createLucideIcon('ZoomIn', [\n  ['circle', { cx: '11', cy: '11', r: '8', key: '4ej97u' }],\n  ['line', { x1: '21', x2: '16.65', y1: '21', y2: '16.65', key: '13gj7c' }],\n  ['line', { x1: '11', x2: '11', y1: '8', y2: '14', key: '1vmskp' }],\n  ['line', { x1: '8', x2: '14', y1: '11', y2: '11', key: 'durymu' }],\n]);\n\nexport default ZoomIn;\n","import createLucideIcon from '../createLucideIcon';\n\n/**\n * @component @name Sparkles\n * @description Lucide SVG icon component, renders SVG Element with children.\n *\n * @preview ![img](data:image/svg+xml;base64,PHN2ZyAgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIgogIHdpZHRoPSIyNCIKICBoZWlnaHQ9IjI0IgogIHZpZXdCb3g9IjAgMCAyNCAyNCIKICBmaWxsPSJub25lIgogIHN0cm9rZT0iIzAwMCIgc3R5bGU9ImJhY2tncm91bmQtY29sb3I6ICNmZmY7IGJvcmRlci1yYWRpdXM6IDJweCIKICBzdHJva2Utd2lkdGg9IjIiCiAgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIgogIHN0cm9rZS1saW5lam9pbj0icm91bmQiCj4KICA8cGF0aCBkPSJtMTIgMy0xLjkxMiA1LjgxM2EyIDIgMCAwIDEtMS4yNzUgMS4yNzVMMyAxMmw1LjgxMyAxLjkxMmEyIDIgMCAwIDEgMS4yNzUgMS4yNzVMMTIgMjFsMS45MTItNS44MTNhMiAyIDAgMCAxIDEuMjc1LTEuMjc1TDIxIDEybC01LjgxMy0xLjkxMmEyIDIgMCAwIDEtMS4yNzUtMS4yNzVMMTIgM1oiIC8+CiAgPHBhdGggZD0iTTUgM3Y0IiAvPgogIDxwYXRoIGQ9Ik0xOSAxN3Y0IiAvPgogIDxwYXRoIGQ9Ik0zIDVoNCIgLz4KICA8cGF0aCBkPSJNMTcgMTloNCIgLz4KPC9zdmc+Cg==) - https://lucide.dev/icons/sparkles\n * @see https://lucide.dev/guide/packages/lucide-react - Documentation\n *\n * @param {Object} props - Lucide icons props and any valid SVG attribute\n * @returns {JSX.Element} JSX Element\n *\n */\nconst Sparkles = createLucideIcon('Sparkles', [\n  [\n    'path',\n    {\n      d: 'm12 3-1.912 5.813a2 2 0 0 1-1.275 1.275L3 12l5.813 1.912a2 2 0 0 1 1.275 1.275L12 21l1.912-5.813a2 2 0 0 1 1.275-1.275L21 12l-5.813-1.912a2 2 0 0 1-1.275-1.275L12 3Z',\n      key: '17u4zn',\n    },\n  ],\n  ['path', { d: 'M5 3v4', key: 'bklmnn' }],\n  ['path', { d: 'M19 17v4', key: 'iiml17' }],\n  ['path', { d: 'M3 5h4', key: 'nem4j1' }],\n  ['path', { d: 'M17 19h4', key: 'lbex7p' }],\n]);\n\nexport default Sparkles;\n","import createLucideIcon from '../createLucideIcon';\n\n/**\n * @component @name Copy\n * @description Lucide SVG icon component, renders SVG Element with children.\n *\n * @preview ![img](data:image/svg+xml;base64,PHN2ZyAgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIgogIHdpZHRoPSIyNCIKICBoZWlnaHQ9IjI0IgogIHZpZXdCb3g9IjAgMCAyNCAyNCIKICBmaWxsPSJub25lIgogIHN0cm9rZT0iIzAwMCIgc3R5bGU9ImJhY2tncm91bmQtY29sb3I6ICNmZmY7IGJvcmRlci1yYWRpdXM6IDJweCIKICBzdHJva2Utd2lkdGg9IjIiCiAgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIgogIHN0cm9rZS1saW5lam9pbj0icm91bmQiCj4KICA8cmVjdCB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHg9IjgiIHk9IjgiIHJ4PSIyIiByeT0iMiIgLz4KICA8cGF0aCBkPSJNNCAxNmMtMS4xIDAtMi0uOS0yLTJWNGMwLTEuMS45LTIgMi0yaDEwYzEuMSAwIDIgLjkgMiAyIiAvPgo8L3N2Zz4K) - https://lucide.dev/icons/copy\n * @see https://lucide.dev/guide/packages/lucide-react - Documentation\n *\n * @param {Object} props - Lucide icons props and any valid SVG attribute\n * @returns {JSX.Element} JSX Element\n *\n */\nconst Copy = createLucideIcon('Copy', [\n  [\n    'rect',\n    {\n      width: '14',\n      height: '14',\n      x: '8',\n      y: '8',\n      rx: '2',\n      ry: '2',\n      key: '17jyea',\n    },\n  ],\n  [\n    'path',\n    {\n      d: 'M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2',\n      key: 'zix9uf',\n    },\n  ],\n]);\n\nexport default Copy;\n","import createLucideIcon from '../createLucideIcon';\n\n/**\n * @component @name AlertCircle\n * @description Lucide SVG icon component, renders SVG Element with children.\n *\n * @preview ![img](data:image/svg+xml;base64,PHN2ZyAgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIgogIHdpZHRoPSIyNCIKICBoZWlnaHQ9IjI0IgogIHZpZXdCb3g9IjAgMCAyNCAyNCIKICBmaWxsPSJub25lIgogIHN0cm9rZT0iIzAwMCIgc3R5bGU9ImJhY2tncm91bmQtY29sb3I6ICNmZmY7IGJvcmRlci1yYWRpdXM6IDJweCIKICBzdHJva2Utd2lkdGg9IjIiCiAgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIgogIHN0cm9rZS1saW5lam9pbj0icm91bmQiCj4KICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgLz4KICA8bGluZSB4MT0iMTIiIHgyPSIxMiIgeTE9IjgiIHkyPSIxMiIgLz4KICA8bGluZSB4MT0iMTIiIHgyPSIxMi4wMSIgeTE9IjE2IiB5Mj0iMTYiIC8+Cjwvc3ZnPgo=) - https://lucide.dev/icons/alert-circle\n * @see https://lucide.dev/guide/packages/lucide-react - Documentation\n *\n * @param {Object} props - Lucide icons props and any valid SVG attribute\n * @returns {JSX.Element} JSX Element\n *\n */\nconst AlertCircle = createLucideIcon('AlertCircle', [\n  ['circle', { cx: '12', cy: '12', r: '10', key: '1mglay' }],\n  ['line', { x1: '12', x2: '12', y1: '8', y2: '12', key: '1pkeuh' }],\n  ['line', { x1: '12', x2: '12.01', y1: '16', y2: '16', key: '4dfq90' }],\n]);\n\nexport default AlertCircle;\n"],"names":["HF_HUB_URL","HF_ROUTER_URL","HF_ROUTER_AUTO_ENDPOINT","concat","HARDCODED_MODEL_INFERENCE_MAPPING","baseten","cerebras","clarifai","cohere","groq","hyperbolic","nebius","novita","nscale","openai","publicai","ovhcloud","replicate","sambanova","scaleway","together","wavespeed","InferenceClientError","Error","constructor","message","super","this","name","InferenceClientInputError","InferenceClientRoutingError","InferenceClientHttpRequestError","httpRequest","httpResponse","_defineProperty","_objectSpread","headers","Authorization","undefined","InferenceClientProviderApiError","InferenceClientHubApiError","InferenceClientProviderOutputError","toArray","obj","Array","isArray","TaskProviderHelper","provider","baseUrl","clientSideRoutingOnly","arguments","length","makeBaseUrl","params","authMethod","makeBody","args","data","JSON","stringify","preparePayload","makeUrl","route","makeRoute","replace","prepareHeaders","isBinary","accessToken","BaseConversationalTask","model","getResponse","response","choices","created","id","system_fingerprint","usage","BaseTextGenerationTask","res","every","x","generated_text","AutoRouterConversationalTask","base64FromBytes","arr","globalThis","Buffer","from","toString","bin","forEach","byte","push","String","fromCharCode","btoa","join","typedInclude","v","includes","omit","o","props","propsArr","Object","assign","map","prop","pick","keys","filter","EQUIVALENT_SENTENCE_TRANSFORMERS_TASKS","HFInferenceTask","startsWith","task","HFInferenceZeroShotClassificationTask","labels","scores","label","score","index","validateOutputElement","elem","HFInferenceTableQuestionAnsweringTask","validate","aggregator","answer","cells","coordinates","coord","globalLogger","console","getLogger","inferenceProviderMappingCache","Map","async","fetchInferenceProviderMappingForModel","modelId","options","inferenceProviderMapping","has","get","_options$fetch","_payload","url","resp","fetch","ok","_resp$headers$get","_resp$headers$get3","method","requestId","status","body","text","error","json","_resp$headers$get2","payload","_unused","_resp$headers$get4","_resp$headers$get5","entries","_ref","mapping","hfModelId","providerId","adapter","adapterWeightsPath","normalizeInferenceProviderMapping","set","resolveProvider","endpointUrl","logger","log","_mappings$","delay","ms","Promise","resolve","setTimeout","isUrl","modelOrUrl","test","FAL_AI_SUPPORTED_BLOB_TYPES","FalAITask","binary","FalAiQueueTask","getResponseFromQueueApi","request_id","parsedUrl","URL","protocol","host","response_url","pathname","queryParams","search","statusUrl","resultUrl","statusResponse","_statusResponse$heade","resultResponse","result","buildLoraPath","FEATHERLESS_API_BASE_URL","GROQ_API_BASE_URL","HYPERBOLIC_API_BASE_URL","NEBIUS_API_BASE_URL","NOVITA_API_BASE_URL","NSCALE_API_BASE_URL","OVHCLOUD_API_BASE_URL","ReplicateTask","input","parameters","prompt","inputs","version","split","Prefer","SCALEWAY_API_BASE_URL","TOGETHER_API_BASE_URL","WAVESPEEDAI_API_BASE_URL","buildImagesField","hasImages","base","Uint8Array","ArrayBuffer","arrayBuffer","images","value","WavespeedAITask","_params$mapping","loras","path","scale","resultPath","urls","_resultResponse$heade","taskResult","_taskResult$outputs","outputs","mediaResponse","_mediaResponse$header","blob","PROVIDERS","conversational","outputType","urlObj","polling_url","step","debug","searchParams","sample","image","sync_mode","model_name","urlResponse","_res$audio","audio","_urlResponse$headers$","statusText","_urlResponse$headers$2","video","_params$mapping2","preparePayloadAsync","mimeType","Blob","type","imageDataUrl","image_url","image_urls","contentType","base64audio","audio_url","base64Image","maskResponse","_maskResponse$headers","maskBlob","maskArrayBuffer","mask","max_tokens","max_new_tokens","b64_json","base64Data","base64Response","output","b64","then","buf","trim","endsWith","end","start","sequence","token","token_str","isNumArrayRec","maxDepth","curDepth","box","xmin","ymin","xmax","ymax","HFInference","entity_group","word","translation","translation_text","summarization","summary_text","messages","content","role","response_format","_responseFormat$json_","responseFormat","json_schema","schema","_response$choices$","item","embedding","_params$args$paramete","num_inference_steps","restParameters","_objectWithoutProperties","_excluded","steps","taskId","task_id","videos","video_url","lora_weights","inputObj","input_image","restArgs","base64","imageInput","audioInput","out","transcription","txt_file","r","strict","completion","_response_format$json","_args$images","_args$parameters","_args$parameters2","_args$images2","_args$parameters3","_args$parameters4","getProviderHelper","providerTasks","_OverloadYield","e","d","k","_wrapAsyncGenerator","AsyncGenerator","apply","t","resume","n","u","i","done","settle","reject","next","key","arg","_invoke","_awaitAsyncGenerator","_asyncGeneratorDelegate","pump","Symbol","iterator","_asyncIterator","asyncIterator","call","AsyncFromSyncIterator","TypeError","AsyncFromSyncIteratorContinuation","s","prototype","tasks","makeRequestOptions","providerHelper","maybeModel","makeRequestOptionsFromResolvedModel","hfModel","_taskInfo$models$leng","_res$headers$get","loadTaskInfo","taskInfo","models","loadDefaultModel","removeProviderPrefix","providerMapping","find","equivalentTasks","warn","getInferenceProviderMapping","resolvedModel","maybeProvider","remainingArgs","includeCredentials","signal","billTo","userAgent","navigator","credentials","info","slice","getLines","onLine","buffer","position","fieldLength","discardTrailingNewline","a","b","bufLength","lineStart","lineEnd","subarray","bodyToJson","parse","innerRequest","_response$headers$get5","requestContext","retry_on_error","_info$method4","_response$headers$get4","some","ct","_info$method","_response$headers$get","_output$error","_info$method2","_response$headers$get2","_info$method3","_response$headers$get3","chatCompletion","detail","innerStreamingRequest","_x","_x2","_x3","_innerStreamingRequest","_options$fetch2","_response$headers$get10","stream","_response$headers$get6","_info$method9","_response$headers$get1","_info$method5","_response$headers$get7","_info$method6","_response$headers$get8","_info$method7","_response$headers$get9","_info$method8","_response$headers$get0","_info$method0","_response$headers$get11","reader","getReader","events","onChunk","onId","onRetry","onMessage","event","retry","decoder","TextDecoder","line","field","decode","valueOffset","parseInt","isNaN","getMessages","read","_info$method1","_response$headers$get12","errorStr","releaseLock","request","streamingRequest","_streamingRequest","audioClassification","audioToAudio","automaticSpeechRecognition","textToSpeech","imageClassification","imageSegmentation","imageToImage","imageToText","imageToVideo","imageTextToImage","imageTextToVideo","objectDetection","textToImage","textToVideo","zeroShotImageClassification","chatCompletionStream","_chatCompletionStream","featureExtraction","fillMask","questionAnswering","sentenceSimilarity","tableQuestionAnswering","textClassification","textGeneration","textGenerationStream","_textGenerationStream","tokenClassification","zeroShotClassification","documentQuestionAnswering","reqArgs","question","visualQuestionAnswering","tabularClassification","tabularRegression","InferenceClient","defaultOptions","fn","defineProperty","enumerable","endpoint","HfInference","TOKEN_TYPES","freeze","Text","NumericLiteral","StringLiteral","Identifier","Equals","OpenParen","CloseParen","OpenStatement","CloseStatement","OpenExpression","CloseExpression","OpenSquareBracket","CloseSquareBracket","OpenCurlyBracket","CloseCurlyBracket","Comma","Dot","Colon","Pipe","CallOperator","AdditiveBinaryOperator","MultiplicativeBinaryOperator","ComparisonBinaryOperator","UnaryOperator","Comment","Token","isWord","char","isInteger","isWhitespace","ORDERED_MAPPING_TABLE","ESCAPE_CHARACTERS","Statement","Program","If","alternate","For","loopvar","iterable","defaultBlock","Break","Continue","SetStatement","assignee","Macro","Expression","MemberExpression","object","property","computed","CallExpression","callee","Literal","IntegerLiteral","FloatLiteral","ArrayLiteral","TupleLiteral","ObjectLiteral","BinaryExpression","operator","left","right","FilterExpression","operand","FilterStatement","SelectExpression","lhs","TestExpression","negate","UnaryExpression","argument","SliceExpression","stop","KeywordArgumentExpression","SpreadExpression","CallStatement","callerArgs","Ternary","condition","trueExpr","falseExpr","tokens","program","current","expect","prev","expectIdentifier","isIdentifier","SyntaxError","parseAny","parseExpressionSequence","is","isStatement","parseSetStatement","parseIfStatement","parsePrimaryExpression","parseArgs","parseMacroStatement","loopVariable","parseExpression","alternative","parseForStatement","callArgs","callExpr","filterNode","parseCallExpression","filterBody","parseJinjaStatement","parseJinjaExpression","_len","types","_key","_tokens$current","_tokens","_tokens2","_len2","names","_key2","_len3","_key3","expressions","isTuple","parseIfExpression","parseLogicalOrExpression","parseLogicalAndExpression","parseLogicalNegationExpression","parseAdditiveExpression","parseComparisonExpression","parseMultiplicativeExpression","expression","parseMemberExpression","expr","parseArgumentsList","parseMemberExpressionArgumentsList","slices","isSlice","parseTestExpression","member","parseCallMemberExpression","parseFilterExpression","num","Number","values","range","array","direction","Math","sign","max","min","strftime_now","format2","date","monthFormatterLong","Intl","DateTimeFormat","month","monthFormatterShort","pad2","getFullYear","getMonth","getDate","format","getHours","getMinutes","strftime","Date","BreakControl","ContinueControl","RuntimeValue","__bool__","BooleanValue","IntegerValue","FloatValue","toFixed","StringValue","FunctionValue","toUpperCase","toLowerCase","c","charAt","trimEnd","trimStart","pattern","ArrayValue","_args$","_args$2","sep","NullValue","maxsplit","match","matchAll","splice","part","oldValue","newValue","count","_args$2$value$get","str","oldvalue","newvalue","remaining","Infinity","RegExp","replaceAll","toJSON","indent","depth","convertUndefinedToNull","currentDepth","indentValue","repeat","basePadding","childrenPadding","core","ObjectValue","_ref2","_ref3","_this$value$get","defaultValue","items","_ref4","_positionalArgs$at","_ref5","_positionalArgs$at2","_ref6","_positionalArgs$at3","kwargs","positionalArgs","KeywordArgumentsValue","caseSensitive","at","by","reverse","_ref7","sort","compareRuntimeValues","size","_ref8","TupleValue","UndefinedValue","Environment","parent","declareVariable","convertToRuntimeValues","variables","setVariable","lookupVariable","_this$resolve$variabl","getAttributeValue","attributePath","parts","_value$value$get","isNumericLike","getNumericValue","aNum","bNum","aStr","bStr","Interpreter","env","global","run","evaluate","evaluateBinaryExpression","node","environment","rem","evaluateArguments","positionalArguments","keywordArguments","spreadNode","val","kwarg","applyFilter","seen","Set","add","builtin","builtins","parseFloat","abs","floor","_ref9","filterName","_kwargs$get","_ref0","_args$at","separator","_ref1","_args$at2","_args$3","_ref10","_args$4","booleanValue","_ref11","_args$at3","_ref12","_args$at4","_ref13","_args$at5","attribute","getSortValue","select","attr","testName","testFunction","tests","_len4","_key4","filtered","mapped","_ref14","_args$at6","_ref15","_args$at7","_ref16","_args$at8","width","first","blank","lines","indented","replaceFn","evaluateFilterExpression","evaluateTestExpression","evaluateSelectExpression","evaluateUnaryExpression","evaluateTernaryExpression","evalProgram","evaluateBlock","statements","statement","lastEvaluated","evaluateIdentifier","evaluateCallExpression","evaluateSliceExpression","evaluateMemberExpression","_object$value$get","evaluateSet","rhs","variableName","tuple","evaluateIf","evaluateFor","scope","scopeUpdateFunctions","loopScope","scopeUpdateFunction","scope2","j","noIteration","loop","err","evaluateMacro","_args$at9","macroScope","pop","nodeArg","passedArg","identifier","_ref17","_kwargs","evaluateCallStatement","callerFn","callerEnv","callBlockEnv","_callerArgs$i","param","macroArgs","macroKwargs","newEnv","evaluateFilterStatement","rendered","evaluatedKey","_ref18","_scope","_input","NEWLINE","createStatement","_len5","_key5","formatStatements","stmts","indentStr","stmt","pad","clauses","formatExpression","formatIf","formattedIterable","formatFor","formatSet","formatMacro","formatCallStatement","spec","formatFilterStatement","formatStatement","parentPrec","thisPrecedence","getBinaryOperatorPrecedence","elems","brackets","_ref19","st","Template","template","source","src","lstrip_blocks","trim_blocks","preprocess","cursorPosition","curlyBracketDepth","consumeWhile","predicate","escaped","unescaped","stripTrailingWhitespace","lastToken","skipLeadingWhitespace","main","_tokens$at","lastTokenType","stripBefore","comment","stripAfter","_tokens$at2","lastTokenType2","seq","frac","tokenize","parsed","render","setupGlobals","LIBRARY_TASK_MAPPING","MAPPING_EN","table","Repository","Stars","Contributors","context","candidate_labels","multi_class","source_sentence","sentences","MAPPING_ZH","MAPPING_FR","MAPPING_ES","MAPPING_RU","MAPPING_UK","MAPPING_IT","MAPPING_FA","MAPPING_AR","MAPPING_BN","MAPPING_MN","MAPPING_SI","MAPPING_DE","MAPPING_DV","PIPELINE_DATA","subtasks","modality","hideInDatasets","robotics","hideInModels","other","PIPELINE_TYPES","flatMap","datasets","description","demo","filename","metrics","spaces","summary","widgetModels","youtubeId","isPlaceholder","canonicalId","TASKS_MODEL_LIBRARIES","getData","partialTaskData","placeholder","libraries","audioTextToText","depthEstimation","visualDocumentRetrieval","imageFeatureExtraction","imageTextToText","keypointDetection","maskGeneration","videoClassification","reinforcementLearning","textRanking","unconditionalImageGeneration","videoTextToText","videoToVideo","zeroShotObjectDetection","textTo3D","imageTo3D","inputsTextGeneration","tags","pipeline_tag","inputsTabularPrediction","modelInputSnippets","inputsAudioToAudio","inputsAudioClassification","inputsAutomaticSpeechRecognition","inputsVisualQuestionAnswering","inputsFeatureExtraction","mask_token","inputsImageClassification","inputsImageToText","inputsImageToImage","inputsImageToVideo","inputsImageTextToImage","inputsImageTextToVideo","inputsImageSegmentation","inputsObjectDetection","inputsQuestionAnswering","inputsSentenceSimilarity","inputsSummarization","inputsTableQuestionAnswering","inputsTextClassification","inputsTextToImage","inputsTextToVideo","inputsTextToSpeech","inputsTextToAudio","inputsTokenClassification","inputsTranslation","inputsZeroShotClassification","inputsZeroShotImageClassification","getModelInputSnippet","noWrap","noQuotes","REGEX_QUOTES","stringifyMessages","opts","messagesStr","attributeKeyQuotes","customContentEscaper","TAG_CUSTOM_CODE","nameWithoutNamespace","splitted","get_base_diffusers_model","_model$cardData$base_","_model$cardData","cardData","base_model","get_prompt_from_diffusers_model","_model$widgetData$0$t","_model$widgetData","_model$cardData2","widgetData","instance_prompt","diffusersDefaultPrompt","diffusersImg2ImgDefaultPrompt","diffusersVideoDefaultPrompt","diffusers","codeSnippets","diffusers_inpainting","diffusers_controlnet","_get_prompt_from_diff5","diffusers_lora_image_to_image","_get_prompt_from_diff7","diffusers_lora_image_to_video","_get_prompt_from_diff6","diffusers_lora_text_to_video","_get_prompt_from_diff4","diffusers_lora","diffusers_textual_inversion","diffusers_flux_fill","_get_prompt_from_diff3","diffusers_image_to_video","_get_prompt_from_diff2","diffusers_image_to_image","_get_prompt_from_diff","diffusers_default","_keras_hub_tasks_with_example","CausalLM","TextToImage","TextClassifier","ImageClassifier","_keras_hub_task_without_example","transformers","_LIBRARY_TASK_MAPPING","transformersInfo","remote_code_snippet","autoSnippet","processor","processorVarName","auto_model","_model$config7","_model$config8","_model$config9","config","tokenizer_config","chat_template","processor_config","chat_template_jinja","hasChatTemplate","pipelineSnippet","ultralytics","versionTag","tag","className","pruna_diffusers","snippet","pruna_transformers","processedSnippets","pruna_default","MODEL_LIBRARIES_UI_ELEMENTS","acestep","prettyLabel","repoName","repoUrl","countDownloads","docsUrl","snippets","_model$config","adapter_transformers","allennlp","allennlpQuestionAnswering","allennlpUnknown","anemoi","araclip","asteroid","audiocraft","musicgen","audiogen","magnet","audioseal","bboxmaskpose","ben2","bertopic","big_vision","birder","birefnet","bm25s","boltzgen","cancertathomev2","cartesia_pytorch","cartesia_mlx","champ","chatterbox","chaossim","chat_tts","chattts","clara","clipscope","cosyvoice","cotracker","colpali","comet","cosmos","cxr_foundation","deepforest","encoder","features","out_channels","derm_foundation","dia2","diffree","diffusionkit","sd3Snippet","fluxSnippet","generateSnippet","doctr","edsnlp","packageName","elm","espnet","espnetTTS","espnetASR","fairseq","fastai","fastprint","fasttext","fixer","flair","fme","gliner","gliner2","grok","hallo","hermes","hezar","htrflow","imstoucan","infinitetalk","keras","_model$config$keras_h","_model$config2","keras_hub","_keras_hub_generic_backbone","kernels","kittentts","kronos","k2","litert","lerobot","smolvlaSnippets","lightglue","liveportrait","mindspore","matanyone","mesh_anything","merlin","medvae","mitie","mlx","mlxvlm","mlxchat","mlxlm","mlx_unknown","model2vec","moshi","mtvcraft","nemo","command","nemoDomainResolver","domain","open_clip","openpeerllm","outetts","_model$tags","paddlenlp","_model$config3","architectures","architecture","PaddleOCR","textline_detection","textline_recognition","seal_text_detection","doc_img_unwarping","doc_img_orientation_classification","textline_orientation_classification","chart_parsing","formula_recognition","layout_detection","table_cells_detection","wired_table_classification","table_structure_recognition","peft","_model$config$peft","_model$config0","base_model_name_or_path","peftBaseModel","task_type","peftTaskType","pefttask","peftTask","clip_model","vision_encoder","pxia","pyannote_audio_pipeline","pyannote_audio_model","pythae","quantumpeer","recurrentgemma","relik","refiners","renderformer","reverb","rkllm","saelens","sam2","same","sap_rpt_one_oss","sapiens","seedvr","_get_widget_examples_","exampleSentences","_model$widgetData2","_widgetExample$senten","widgetExample","get_widget_examples_from_st_model","setfit","sklearn","_model$config4","_model$config5","skopsmodelFile","file","skopssaveFormat","model_format","skopsPickle","modelFile","skopsFormat","skopsJobLib","spacy","speechbrain","_model$config6","speechbrainInterface","speechbrain_interface","speechbrainMethod","speechBrainMethod","monkeyocr","seed_story","soloaudio","songbloom","stanza","supertonic","swarmformer","genmo","tensorflowtts","tensorflowttsTextToMel","tensorflowttsMelToWav","tensorflowttsUnknown","tensorrt","tabpfn","terratorch","timesfm","timm","tirex","torchgeo","libName","trellis","univa","sentis","sana","videoprism","lvface","voicecraft","voxcpm","vui","vibevoice","videox_fun","wham","whisperkit","yolov10","zonos","_","GGMLFileQuantizationType","ggufQuants","GGUF_QUANT_RE","F32","BF16","F16","Q8_K_XL","Q8_0","Q6_K_XL","Q6_K","Q5_K_XL","Q5_K_M","Q5_K_S","Q5_0","Q5_1","Q4_K_XL","Q4_K_M","Q4_K_S","IQ4_NL","IQ4_XS","Q4_0_4_4","Q4_0_4_8","Q4_0_8_8","Q4_1_SOME_F16","Q4_0","Q4_1","Q4_2","Q4_3","MXFP4_MOE","Q3_K_XL","Q3_K_L","Q3_K_M","Q3_K_S","IQ3_M","IQ3_S","IQ3_XS","IQ3_XXS","Q2_K_XL","Q2_K","Q2_K_S","IQ2_M","IQ2_S","IQ2_XS","IQ2_XXS","IQ1_S","IQ1_M","TQ1_0","TQ2_0","GGMLQuantizationType","inferenceSnippetLanguages","templates","CLIENTS","js","python","sh","CLIENTS_NON_CONVERSATIONAL_AUTO_POLICY","loadTemplate","language","client","templateName","_templates$language2","snippetImportPythonInferenceClient","snippetImportRequests","HF_PYTHON_METHODS","HF_JS_METHODS","snippetGenerator","inputPreparationFn","_inferenceProviderMap","_opts$accessToken","_opts$endpointUrl","_request$info$headers","providerModelId","streaming","prepareConversationalInput","directRequest","accessTokenOrPlaceholder","providerInputs","bodyAsObj","autoInputs","authorizationHeader","suffix","fullUrl","asObj","asCurlString","formatBody","asJsonString","asPythonString","asTsString","clients","_clients$language","hasTemplate","_templates$language","importSection","importBase64","importJson","useHfToken","accessTokenEnvVar","replaceAccessTokenPlaceholder","flat","prepareImageToImageInput","_opts$messages","temperature","top_p","query","indentString","formattedValue","formatTsObject","formatted","keyStr","Type","createLucideIcon","points","x1","x2","y1","y2","Layers","Image","height","y","rx","ry","cx","cy","Trash2","Wand2","Grid","ArrowLeft","Save","ZoomOut","ZoomIn","Sparkles","Copy","AlertCircle"],"ignoreList":[],"sourceRoot":""}